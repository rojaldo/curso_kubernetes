<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.26">
<title>Curso Completo de Kubernetes</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock pre>code{display:block}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/atom-one-light.min.css">
</head>
<body class="book">
<div id="header">
<h1>Curso Completo de Kubernetes</h1>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_módulo_1_introducción_a_kubernetes">1. Módulo 1: Introducción a Kubernetes</a>
<ul class="sectlevel2">
<li><a href="#_qué_es_kubernetes">1.1. ¿Qué es Kubernetes?</a>
<ul class="sectlevel3">
<li><a href="#_historia_y_origen_del_proyecto">1.1.1. Historia y origen del proyecto</a></li>
<li><a href="#_problemas_que_resuelve_kubernetes">1.1.2. Problemas que resuelve Kubernetes</a></li>
<li><a href="#_comparación_con_otras_soluciones_de_orquestación">1.1.3. Comparación con otras soluciones de orquestación</a></li>
<li><a href="#_el_ecosistema_cloud_native_computing_foundation_cncf">1.1.4. El ecosistema Cloud Native Computing Foundation (CNCF)</a></li>
</ul>
</li>
<li><a href="#_arquitectura_de_kubernetes">1.2. Arquitectura de Kubernetes</a>
<ul class="sectlevel3">
<li><a href="#_componentes_del_control_plane">1.2.1. Componentes del Control Plane</a>
<ul class="sectlevel4">
<li><a href="#_api_server">API Server</a></li>
<li><a href="#_etcd">etcd</a></li>
<li><a href="#_scheduler">Scheduler</a></li>
<li><a href="#_controller_manager">Controller Manager</a></li>
<li><a href="#_cloud_controller_manager">Cloud Controller Manager</a></li>
</ul>
</li>
<li><a href="#_componentes_de_los_nodos">1.2.2. Componentes de los Nodos</a>
<ul class="sectlevel4">
<li><a href="#_kubelet">Kubelet</a></li>
<li><a href="#_kube_proxy">Kube-proxy</a></li>
<li><a href="#_container_runtime">Container Runtime</a></li>
</ul>
</li>
<li><a href="#_addons">1.2.3. Addons</a></li>
<li><a href="#_flujo_completo_de_kubectl_a_pod_en_ejecución">1.2.4. Flujo completo: De kubectl a Pod en ejecución</a></li>
</ul>
</li>
<li><a href="#_conceptos_fundamentales">1.3. Conceptos Fundamentales</a>
<ul class="sectlevel3">
<li><a href="#_clusters_nodos_y_pods">1.3.1. Clusters, Nodos y Pods</a></li>
<li><a href="#_contenedores_vs_pods">1.3.2. Contenedores vs Pods</a></li>
<li><a href="#_namespaces">1.3.3. Namespaces</a></li>
<li><a href="#_labels_y_selectors">1.3.4. Labels y Selectors</a></li>
<li><a href="#_annotations">1.3.5. Annotations</a></li>
</ul>
</li>
<li><a href="#_instalación_y_configuración_del_entorno">1.4. Instalación y Configuración del Entorno</a>
<ul class="sectlevel3">
<li><a href="#_opciones_de_instalación_local">1.4.1. Opciones de instalación local</a>
<ul class="sectlevel4">
<li><a href="#_minikube">Minikube</a></li>
<li><a href="#_kind_kubernetes_in_docker">Kind (Kubernetes in Docker)</a></li>
<li><a href="#_docker_desktop">Docker Desktop</a></li>
<li><a href="#_microk8s">MicroK8s</a></li>
</ul>
</li>
<li><a href="#_instalación_de_kubectl">1.4.2. Instalación de kubectl</a></li>
<li><a href="#_configuración_del_archivo_kubeconfig">1.4.3. Configuración del archivo kubeconfig</a></li>
<li><a href="#_verificación_de_la_instalación">1.4.4. Verificación de la instalación</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_2_trabajando_con_pods">2. Módulo 2: Trabajando con Pods</a>
<ul class="sectlevel2">
<li><a href="#_creación_y_gestión_de_pods">2.1. Creación y Gestión de Pods</a>
<ul class="sectlevel3">
<li><a href="#_anatomía_de_un_pod">2.1.1. Anatomía de un Pod</a></li>
<li><a href="#_manifiestos_yaml_para_pods">2.1.2. Manifiestos YAML para Pods</a></li>
<li><a href="#_comandos_básicos_con_kubectl">2.1.3. Comandos básicos con kubectl</a></li>
<li><a href="#_ciclo_de_vida_de_un_pod">2.1.4. Ciclo de vida de un Pod</a></li>
<li><a href="#_estados_de_los_pods">2.1.5. Estados de los Pods</a></li>
</ul>
</li>
<li><a href="#_pods_multi_contenedor">2.2. Pods Multi-contenedor</a>
<ul class="sectlevel3">
<li><a href="#_patrones_de_diseño">2.2.1. Patrones de diseño</a>
<ul class="sectlevel4">
<li><a href="#_patrón_sidecar">Patrón Sidecar</a></li>
<li><a href="#_patrón_ambassador">Patrón Ambassador</a></li>
<li><a href="#_patrón_adapter">Patrón Adapter</a></li>
</ul>
</li>
<li><a href="#_comunicación_entre_contenedores">2.2.2. Comunicación entre contenedores</a></li>
<li><a href="#_volúmenes_compartidos">2.2.3. Volúmenes compartidos</a></li>
</ul>
</li>
<li><a href="#_init_containers">2.3. Init Containers</a>
<ul class="sectlevel3">
<li><a href="#_propósito_y_casos_de_uso">2.3.1. Propósito y casos de uso</a></li>
<li><a href="#_configuración_de_init_containers">2.3.2. Configuración de init containers</a></li>
<li><a href="#_orden_de_ejecución">2.3.3. Orden de ejecución</a></li>
</ul>
</li>
<li><a href="#_debugging_y_troubleshooting">2.4. Debugging y Troubleshooting</a>
<ul class="sectlevel3">
<li><a href="#_logs_de_contenedores">2.4.1. Logs de contenedores</a></li>
<li><a href="#_ejecución_de_comandos_en_pods">2.4.2. Ejecución de comandos en Pods</a></li>
<li><a href="#_port_forwarding">2.4.3. Port-forwarding</a></li>
<li><a href="#_diagnóstico_de_problemas_comunes">2.4.4. Diagnóstico de problemas comunes</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_3_controllers_y_workloads">3. Módulo 3: Controllers y Workloads</a>
<ul class="sectlevel2">
<li><a href="#_replicasets">3.1. ReplicaSets</a>
<ul class="sectlevel3">
<li><a href="#_función_y_propósito">3.1.1. Función y propósito</a></li>
<li><a href="#_definición_de_replicasets">3.1.2. Definición de ReplicaSets</a></li>
<li><a href="#_escalado_manual">3.1.3. Escalado manual</a></li>
<li><a href="#_self_healing">3.1.4. Self-healing</a></li>
</ul>
</li>
<li><a href="#_deployments">3.2. Deployments</a>
<ul class="sectlevel3">
<li><a href="#_estrategias_de_despliegue">3.2.1. Estrategias de despliegue</a></li>
<li><a href="#_rollback_de_versiones">3.2.2. Rollback de versiones</a></li>
<li><a href="#_gestión_del_historial">3.2.3. Gestión del historial</a></li>
<li><a href="#_pause_y_resume_de_deployments">3.2.4. Pause y resume de deployments</a></li>
</ul>
</li>
<li><a href="#_statefulsets">3.3. StatefulSets</a>
<ul class="sectlevel3">
<li><a href="#_identidad_estable_de_pods">3.3.1. Identidad Estable de Pods</a></li>
<li><a href="#_almacenamiento_persistente_con_volumeclaimtemplates">3.3.2. Almacenamiento Persistente con VolumeClaimTemplates</a></li>
<li><a href="#_actualización_ordenada">3.3.3. Actualización Ordenada</a></li>
<li><a href="#_headless_services">3.3.4. Headless Services</a></li>
<li><a href="#_ejemplo_completo_mysql_con_replicación">3.3.5. Ejemplo Completo: MySQL con Replicación</a></li>
<li><a href="#_escalado_de_statefulsets">3.3.6. Escalado de StatefulSets</a></li>
<li><a href="#_manejo_de_ordenamiento">3.3.7. Manejo de Ordenamiento</a></li>
<li><a href="#_casos_de_uso_comunes">3.3.8. Casos de Uso Comunes</a></li>
<li><a href="#_best_practices_para_statefulsets">3.3.9. Best Practices para StatefulSets</a></li>
<li><a href="#_troubleshooting_común">3.3.10. Troubleshooting Común</a></li>
</ul>
</li>
<li><a href="#_daemonsets">3.4. DaemonSets</a>
<ul class="sectlevel3">
<li><a href="#_definición_básica_de_daemonsets">3.4.1. Definición Básica de DaemonSets</a></li>
<li><a href="#_selección_de_nodos_en_daemonsets">3.4.2. Selección de Nodos en DaemonSets</a></li>
<li><a href="#_actualización_de_daemonsets">3.4.3. Actualización de DaemonSets</a></li>
<li><a href="#_ejemplo_node_exporter_para_monitoreo">3.4.4. Ejemplo: Node Exporter para Monitoreo</a></li>
<li><a href="#_ejemplo_recolección_de_logs_con_fluent">3.4.5. Ejemplo: Recolección de Logs con Fluent</a></li>
<li><a href="#_ciclo_de_vida_y_comportamiento">3.4.6. Ciclo de Vida y Comportamiento</a></li>
<li><a href="#_acceso_a_host_desde_daemonsets">3.4.7. Acceso a Host desde DaemonSets</a></li>
<li><a href="#_best_practices_para_daemonsets">3.4.8. Best Practices para DaemonSets</a></li>
<li><a href="#_troubleshooting_comunes">3.4.9. Troubleshooting Comunes</a></li>
</ul>
</li>
<li><a href="#_jobs_y_cronjobs">3.5. Jobs y CronJobs</a>
<ul class="sectlevel3">
<li><a href="#_diferencia_deployment_vs_job">3.5.1. Diferencia: Deployment vs Job</a></li>
<li><a href="#_definición_básica_de_jobs">3.5.2. Definición Básica de Jobs</a></li>
<li><a href="#_paralelismo_y_completions">3.5.3. Paralelismo y Completions</a></li>
<li><a href="#_configuración_de_reintentos">3.5.4. Configuración de Reintentos</a></li>
<li><a href="#_casos_de_uso_jobs_complejos">3.5.5. Casos de Uso: Jobs Complejos</a></li>
<li><a href="#_limpieza_y_gestión_de_jobs">3.5.6. Limpieza y Gestión de Jobs</a></li>
<li><a href="#_cronjobs_tareas_programadas">3.5.7. CronJobs: Tareas Programadas</a></li>
<li><a href="#_ejemplos_prácticos_de_cronjobs">3.5.8. Ejemplos Prácticos de CronJobs</a></li>
<li><a href="#_concurrencypolicy_control_de_ejecuciones_simultáneas">3.5.9. concurrencyPolicy: Control de Ejecuciones Simultáneas</a></li>
<li><a href="#_planificación_de_cronjobs">3.5.10. Planificación de CronJobs</a></li>
<li><a href="#_best_practices_para_jobs_y_cronjobs">3.5.11. Best Practices para Jobs y CronJobs</a></li>
<li><a href="#_troubleshooting_común_2">3.5.12. Troubleshooting Común</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_4_servicios_y_redes">4. Módulo 4: Servicios y Redes</a>
<ul class="sectlevel2">
<li><a href="#_networking_en_kubernetes">4.1. Networking en Kubernetes</a>
<ul class="sectlevel3">
<li><a href="#_cni_container_network_interface">4.1.1. CNI: Container Network Interface</a></li>
<li><a href="#_comunicación_pod_to_pod">4.1.2. Comunicación Pod-to-Pod</a></li>
<li><a href="#_dns_en_kubernetes">4.1.3. DNS en Kubernetes</a></li>
<li><a href="#_flujo_de_paquetes_en_kubernetes">4.1.4. Flujo de paquetes en Kubernetes</a></li>
<li><a href="#_troubleshooting_de_conectividad">4.1.5. Troubleshooting de Conectividad</a></li>
<li><a href="#_best_practices_de_networking">4.1.6. Best Practices de Networking</a></li>
</ul>
</li>
<li><a href="#_services">4.2. Services</a>
<ul class="sectlevel3">
<li><a href="#_tipos_de_services">4.2.1. Tipos de Services</a></li>
<li><a href="#_tabla_comparativa_de_tipos_de_services">4.2.2. Tabla comparativa de tipos de Services</a></li>
<li><a href="#_selección_de_pods_mediante_labels">4.2.3. Selección de Pods mediante Labels</a></li>
<li><a href="#_endpoints">4.2.4. Endpoints</a></li>
<li><a href="#_ejemplo_service_con_múltiples_pods">4.2.5. Ejemplo: Service con múltiples Pods</a></li>
<li><a href="#_session_affinity">4.2.6. Session Affinity</a></li>
<li><a href="#_multi_port_services">4.2.7. Multi-port Services</a></li>
<li><a href="#_headless_services_2">4.2.8. Headless Services</a></li>
<li><a href="#_external_ips">4.2.9. External IPs</a></li>
<li><a href="#_best_practices_para_services">4.2.10. Best Practices para Services</a></li>
<li><a href="#_troubleshooting_de_services">4.2.11. Troubleshooting de Services</a></li>
</ul>
</li>
<li><a href="#_ingress">4.3. Ingress</a>
<ul class="sectlevel3">
<li><a href="#_yaml_básico_de_ingress">4.3.1. YAML básico de Ingress</a></li>
<li><a href="#_ingress_controllers">4.3.2. Ingress Controllers</a></li>
<li><a href="#_nginx_ingress_controller">4.3.3. NGINX Ingress Controller</a></li>
<li><a href="#_path_based_routing">4.3.4. Path-based Routing</a></li>
<li><a href="#_host_based_routing">4.3.5. Host-based Routing</a></li>
<li><a href="#_tlsssl_termination">4.3.6. TLS/SSL Termination</a></li>
<li><a href="#_cert_manager_certificados_automáticos">4.3.7. Cert-Manager: Certificados automáticos</a></li>
<li><a href="#_ejemplo_completo_multi_tenant_ingress">4.3.8. Ejemplo completo: Multi-tenant Ingress</a></li>
<li><a href="#_ingress_annotations">4.3.9. Ingress Annotations</a></li>
<li><a href="#_traefik_ingress_controller_moderno">4.3.10. Traefik: Ingress Controller moderno</a></li>
<li><a href="#_best_practices_para_ingress">4.3.11. Best Practices para Ingress</a></li>
<li><a href="#_troubleshooting_de_ingress">4.3.12. Troubleshooting de Ingress</a></li>
</ul>
</li>
<li><a href="#_network_policies">4.4. Network Policies</a>
<ul class="sectlevel3">
<li><a href="#_requisitos">4.4.1. Requisitos</a></li>
<li><a href="#_yaml_básico_de_network_policy">4.4.2. YAML básico de Network Policy</a></li>
<li><a href="#_selección_de_pods">4.4.3. Selección de Pods</a></li>
<li><a href="#_reglas_de_ingress">4.4.4. Reglas de Ingress</a></li>
<li><a href="#_reglas_de_egress">4.4.5. Reglas de Egress</a></li>
<li><a href="#_politicas_de_aislamiento_por_defecto">4.4.6. Politicas de aislamiento por defecto</a></li>
<li><a href="#_casos_de_uso_comunes_2">4.4.7. Casos de uso comunes</a></li>
<li><a href="#_segmentación_por_namespace">4.4.8. Segmentación por Namespace</a></li>
<li><a href="#_manejo_de_dns">4.4.9. Manejo de DNS</a></li>
<li><a href="#_herramientas_para_network_policies">4.4.10. Herramientas para Network Policies</a></li>
<li><a href="#_best_practices_para_network_policies">4.4.11. Best Practices para Network Policies</a></li>
<li><a href="#_troubleshooting_de_network_policies">4.4.12. Troubleshooting de Network Policies</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_5_almacenamiento">5. Módulo 5: Almacenamiento</a>
<ul class="sectlevel2">
<li><a href="#_volúmenes">5.1. Volúmenes</a>
<ul class="sectlevel3">
<li><a href="#_tipos_de_volúmenes_efímeros">5.1.1. Tipos de Volúmenes Efímeros</a></li>
<li><a href="#_hostpath_acceder_al_nodo_host">5.1.2. hostPath: Acceder al nodo host</a></li>
<li><a href="#_configmap_y_secret_como_volúmenes">5.1.3. configMap y secret como volúmenes</a></li>
<li><a href="#_montaje_de_volúmenes">5.1.4. Montaje de volúmenes</a></li>
<li><a href="#_ejemplo_completo_multi_container_con_volúmenes">5.1.5. Ejemplo completo: Multi-container con volúmenes</a></li>
<li><a href="#_best_practices_para_volúmenes">5.1.6. Best Practices para Volúmenes</a></li>
<li><a href="#_troubleshooting_de_volúmenes">5.1.7. Troubleshooting de Volúmenes</a></li>
</ul>
</li>
<li><a href="#_persistent_volumes_pv">5.2. Persistent Volumes (PV)</a>
<ul class="sectlevel3">
<li><a href="#_ciclo_de_vida_de_persistentvolumes">5.2.1. Ciclo de vida de PersistentVolumes</a></li>
<li><a href="#_modos_de_acceso_access_modes">5.2.2. Modos de Acceso (Access Modes)</a></li>
<li><a href="#_políticas_de_reclaim_reclaimpolicy">5.2.3. Políticas de Reclaim (ReclaimPolicy)</a></li>
<li><a href="#_storage_classes">5.2.4. Storage Classes</a></li>
<li><a href="#_pv_backend_diferentes_tipos_de_almacenamiento">5.2.5. PV Backend: Diferentes tipos de almacenamiento</a></li>
<li><a href="#_verificación_de_persistentvolumes">5.2.6. Verificación de PersistentVolumes</a></li>
<li><a href="#_best_practices_para_persistentvolumes">5.2.7. Best Practices para PersistentVolumes</a></li>
<li><a href="#_expansión_de_volúmenes">5.2.8. Expansión de Volúmenes</a></li>
<li><a href="#_snapshots_de_volúmenes">5.2.9. Snapshots de Volúmenes</a></li>
<li><a href="#_best_practices_para_pvc">5.2.10. Best Practices para PVC</a></li>
</ul>
</li>
<li><a href="#_dynamic_provisioning">5.3. Dynamic Provisioning</a>
<ul class="sectlevel3">
<li><a href="#_configurando_dynamic_provisioning">5.3.1. Configurando Dynamic Provisioning</a></li>
<li><a href="#_provisioners_comunes">5.3.2. Provisioners comunes</a></li>
<li><a href="#_best_practices_para_dynamic_provisioning">5.3.3. Best Practices para Dynamic Provisioning</a></li>
</ul>
</li>
<li><a href="#_statefulsets_con_almacenamiento">5.4. StatefulSets con Almacenamiento</a>
<ul class="sectlevel3">
<li><a href="#_best_practices_para_statefulsets_almacenamiento">5.4.1. Best Practices para StatefulSets + Almacenamiento</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_6_configuración_y_secrets">6. Módulo 6: Configuración y Secrets</a>
<ul class="sectlevel2">
<li><a href="#_configmaps">6.1. ConfigMaps</a>
<ul class="sectlevel3">
<li><a href="#_creación_de_configmaps">6.1.1. Creación de ConfigMaps</a></li>
<li><a href="#_consumo_en_pods">6.1.2. Consumo en Pods</a></li>
<li><a href="#_actualización_de_configmaps">6.1.3. Actualización de ConfigMaps</a></li>
<li><a href="#_ejemplo_completo_multi_file_configmap">6.1.4. Ejemplo completo: Multi-file ConfigMap</a></li>
<li><a href="#_best_practices_para_configmaps">6.1.5. Best Practices para ConfigMaps</a></li>
<li><a href="#_secrets">6.1.6. Secrets</a></li>
<li><a href="#_creación_de_secrets">6.1.7. Creación de Secrets</a></li>
<li><a href="#_codificación_base64">6.1.8. Codificación base64</a></li>
<li><a href="#_consumo_de_secrets">6.1.9. Consumo de Secrets</a></li>
<li><a href="#_buenas_prácticas_de_seguridad">6.1.10. Buenas prácticas de seguridad</a></li>
<li><a href="#_encriptación_en_reposo">6.1.11. Encriptación en reposo</a></li>
</ul>
</li>
<li><a href="#_gestión_de_variables_de_entorno">6.2. Gestión de Variables de Entorno</a>
<ul class="sectlevel3">
<li><a href="#_envfrom_inyección_bulk">6.2.1. EnvFrom: Inyección bulk</a></li>
<li><a href="#_downward_api_información_del_pod">6.2.2. Downward API: Información del Pod</a></li>
<li><a href="#_downward_api_con_volumen">6.2.3. Downward API con volumen</a></li>
<li><a href="#_best_practices_para_configuración">6.2.4. Best Practices para Configuración</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_7_seguridad">7. Módulo 7: Seguridad</a>
<ul class="sectlevel2">
<li><a href="#_authentication_y_authorization">7.1. Authentication y Authorization</a>
<ul class="sectlevel3">
<li><a href="#_conceptos_fundamentales_2">7.1.1. Conceptos fundamentales</a></li>
<li><a href="#_métodos_de_autenticación">7.1.2. Métodos de autenticación</a></li>
<li><a href="#_rbac_role_based_access_control">7.1.3. RBAC (Role-Based Access Control)</a></li>
<li><a href="#_mejores_prácticas_de_autenticación_y_autorización">7.1.4. Mejores prácticas de autenticación y autorización</a></li>
</ul>
</li>
<li><a href="#_service_accounts">7.2. Service Accounts</a>
<ul class="sectlevel3">
<li><a href="#_qué_es_un_service_account">7.2.1. ¿Qué es un Service Account?</a></li>
<li><a href="#_creación_y_gestión_de_service_accounts">7.2.2. Creación y gestión de Service Accounts</a></li>
<li><a href="#_token_de_autenticación">7.2.3. Token de autenticación</a></li>
<li><a href="#_montaje_automático_automountserviceaccounttoken">7.2.4. Montaje automático (automountServiceAccountToken)</a></li>
<li><a href="#_rbac_para_service_accounts">7.2.5. RBAC para Service Accounts</a></li>
<li><a href="#_caso_de_uso_aplicación_que_accede_a_api">7.2.6. Caso de uso: Aplicación que accede a API</a></li>
<li><a href="#_best_practices_para_service_accounts">7.2.7. Best Practices para Service Accounts</a></li>
</ul>
</li>
<li><a href="#_security_context">7.3. Security Context</a>
<ul class="sectlevel3">
<li><a href="#_qué_es_un_security_context">7.3.1. ¿Qué es un Security Context?</a></li>
<li><a href="#_configuración_a_nivel_de_pod">7.3.2. Configuración a nivel de Pod</a></li>
<li><a href="#_configuración_a_nivel_de_contenedor">7.3.3. Configuración a nivel de Contenedor</a></li>
<li><a href="#_capacidades_linux_linux_capabilities">7.3.4. Capacidades Linux (Linux Capabilities)</a></li>
<li><a href="#_runasuser_y_runasgroup">7.3.5. RunAsUser y RunAsGroup</a></li>
<li><a href="#_selinux_y_apparmor">7.3.6. SELinux y AppArmor</a></li>
<li><a href="#_caso_de_uso_aplicación_segura">7.3.7. Caso de uso: Aplicación segura</a></li>
<li><a href="#_best_practices_para_security_context">7.3.8. Best Practices para Security Context</a></li>
</ul>
</li>
<li><a href="#_pod_security_standards">7.4. Pod Security Standards</a>
<ul class="sectlevel3">
<li><a href="#_qué_son_pod_security_standards">7.4.1. ¿Qué son Pod Security Standards?</a></li>
<li><a href="#_nivel_privileged">7.4.2. Nivel Privileged</a></li>
<li><a href="#_nivel_baseline">7.4.3. Nivel Baseline</a></li>
<li><a href="#_nivel_restricted">7.4.4. Nivel Restricted</a></li>
<li><a href="#_pod_security_admission">7.4.5. Pod Security Admission</a></li>
<li><a href="#_configuración_en_kube_apiserver">7.4.6. Configuración en kube-apiserver</a></li>
<li><a href="#_mejor_estrategia_de_implementación">7.4.7. Mejor estrategia de implementación</a></li>
<li><a href="#_best_practices_para_pod_security_standards">7.4.8. Best Practices para Pod Security Standards</a></li>
</ul>
</li>
<li><a href="#_network_security">7.5. Network Security</a>
<ul class="sectlevel3">
<li><a href="#_network_policies_avanzadas">7.5.1. Network Policies Avanzadas</a></li>
<li><a href="#_seguridad_de_servicios">7.5.2. Seguridad de Servicios</a></li>
<li><a href="#_tlsmtls_en_comunicación_pod_to_pod">7.5.3. TLS/mTLS en comunicación Pod-to-Pod</a></li>
<li><a href="#_service_mesh_introducción">7.5.4. Service Mesh (Introducción)</a></li>
<li><a href="#_encriptación_de_tráfico">7.5.5. Encriptación de tráfico</a></li>
<li><a href="#_best_practices_para_network_security">7.5.6. Best Practices para Network Security</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_8_observabilidad">8. Módulo 8: Observabilidad</a>
<ul class="sectlevel2">
<li><a href="#_logging">8.1. Logging</a>
<ul class="sectlevel3">
<li><a href="#_por_qué_logging_es_crítico">8.1.1. ¿Por qué logging es crítico?</a></li>
<li><a href="#_logs_de_contenedores_2">8.1.2. Logs de Contenedores</a></li>
<li><a href="#_estrategias_de_logging">8.1.3. Estrategias de Logging</a></li>
<li><a href="#_logs_a_nivel_de_cluster">8.1.4. Logs a nivel de Cluster</a></li>
<li><a href="#_agregación_de_logs">8.1.5. Agregación de Logs</a></li>
<li><a href="#_búsqueda_de_logs_en_kibana">8.1.6. Búsqueda de logs en Kibana</a></li>
<li><a href="#_rotación_y_retención_de_logs">8.1.7. Rotación y retención de logs</a></li>
<li><a href="#_best_practices_para_logging">8.1.8. Best Practices para Logging</a></li>
</ul>
</li>
<li><a href="#_monitoring">8.2. Monitoring</a>
<ul class="sectlevel3">
<li><a href="#_métricas_en_kubernetes">8.2.1. Métricas en Kubernetes</a></li>
<li><a href="#_metrics_server">8.2.2. Metrics Server</a></li>
<li><a href="#_prometheus_y_grafana">8.2.3. Prometheus y Grafana</a></li>
<li><a href="#_alerting">8.2.4. Alerting</a></li>
<li><a href="#_custom_metrics">8.2.5. Custom Metrics</a></li>
<li><a href="#_best_practices_para_monitoring">8.2.6. Best Practices para Monitoring</a></li>
</ul>
</li>
<li><a href="#_health_checks">8.3. Health Checks</a>
<ul class="sectlevel3">
<li><a href="#_qué_son_health_checks">8.3.1. ¿Qué son Health Checks?</a></li>
<li><a href="#_liveness_probes">8.3.2. Liveness Probes</a></li>
<li><a href="#_readiness_probes">8.3.3. Readiness Probes</a></li>
<li><a href="#_startup_probes">8.3.4. Startup Probes</a></li>
<li><a href="#_tipos_de_probes">8.3.5. Tipos de Probes</a></li>
<li><a href="#_parámetros_comunes">8.3.6. Parámetros comunes</a></li>
<li><a href="#_best_practices_para_health_checks">8.3.7. Best Practices para Health Checks</a></li>
</ul>
</li>
<li><a href="#_resource_monitoring">8.4. Resource Monitoring</a>
<ul class="sectlevel3">
<li><a href="#_resource_requests_y_limits">8.4.1. Resource Requests y Limits</a></li>
<li><a href="#_cpu_y_memoria">8.4.2. CPU y Memoria</a></li>
<li><a href="#_qos_classes">8.4.3. QoS Classes</a></li>
<li><a href="#_definir_requests_y_limits">8.4.4. Definir Requests y Limits</a></li>
<li><a href="#_vertical_pod_autoscaler_vpa">8.4.5. Vertical Pod Autoscaler (VPA)</a></li>
<li><a href="#_best_practices_para_resource_monitoring">8.4.6. Best Practices para Resource Monitoring</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_9_escalado_y_performance">9. Módulo 9: Escalado y Performance</a>
<ul class="sectlevel2">
<li><a href="#_horizontal_pod_autoscaler_hpa">9.1. Horizontal Pod Autoscaler (HPA)</a>
<ul class="sectlevel3">
<li><a href="#_qué_es_hpa">9.1.1. ¿Qué es HPA?</a></li>
<li><a href="#_métricas_de_escalado">9.1.2. Métricas de Escalado</a></li>
<li><a href="#_configuración_de_hpa">9.1.3. Configuración de HPA</a></li>
<li><a href="#_comportamiento_de_escalado">9.1.4. Comportamiento de Escalado</a></li>
<li><a href="#_custom_metrics_2">9.1.5. Custom Metrics</a></li>
<li><a href="#_best_practices_para_hpa">9.1.6. Best Practices para HPA</a></li>
</ul>
</li>
<li><a href="#_vertical_pod_autoscaler_vpa_2">9.2. Vertical Pod Autoscaler (VPA)</a>
<ul class="sectlevel3">
<li><a href="#_introducción_a_vpa">9.2.1. Introducción a VPA</a></li>
<li><a href="#_modos_de_operación">9.2.2. Modos de Operación</a></li>
<li><a href="#_recomendaciones_de_vpa">9.2.3. Recomendaciones de VPA</a></li>
<li><a href="#_políticas_de_actualización">9.2.4. Políticas de Actualización</a></li>
<li><a href="#_best_practices_para_vpa">9.2.5. Best Practices para VPA</a></li>
</ul>
</li>
<li><a href="#_cluster_autoscaler">9.3. Cluster Autoscaler</a>
<ul class="sectlevel3">
<li><a href="#_qué_es_cluster_autoscaler">9.3.1. ¿Qué es Cluster Autoscaler?</a></li>
<li><a href="#_instalación_y_configuración">9.3.2. Instalación y Configuración</a></li>
<li><a href="#_políticas_de_escalado">9.3.3. Políticas de Escalado</a></li>
<li><a href="#_monitoreo_de_cluster_autoscaler">9.3.4. Monitoreo de Cluster Autoscaler</a></li>
<li><a href="#_best_practices_para_cluster_autoscaler">9.3.5. Best Practices para Cluster Autoscaler</a></li>
</ul>
</li>
<li><a href="#_resource_management">9.4. Resource Management</a>
<ul class="sectlevel3">
<li><a href="#_resource_quotas">9.4.1. Resource Quotas</a></li>
<li><a href="#_limit_ranges">9.4.2. Limit Ranges</a></li>
<li><a href="#_priority_classes">9.4.3. Priority Classes</a></li>
<li><a href="#_best_practices_para_resource_management">9.4.4. Best Practices para Resource Management</a></li>
</ul>
</li>
<li><a href="#_performance_tuning">9.5. Performance Tuning</a>
<ul class="sectlevel3">
<li><a href="#_node_affinity">9.5.1. Node Affinity</a></li>
<li><a href="#_pod_affinity_y_anti_affinity">9.5.2. Pod Affinity y Anti-Affinity</a></li>
<li><a href="#_taints_y_tolerations">9.5.3. Taints y Tolerations</a></li>
<li><a href="#_best_practices_para_performance_tuning">9.5.4. Best Practices para Performance Tuning</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_10_helm">10. Módulo 10: Helm</a>
<ul class="sectlevel2">
<li><a href="#_introducción_a_helm">10.1. Introducción a Helm</a>
<ul class="sectlevel3">
<li><a href="#_qué_es_helm">10.1.1. ¿Qué es Helm?</a></li>
<li><a href="#_ventajas_del_package_management">10.1.2. Ventajas del Package Management</a></li>
<li><a href="#_arquitectura_de_helm_3">10.1.3. Arquitectura de Helm 3</a></li>
<li><a href="#_instalación_de_helm">10.1.4. Instalación de Helm</a></li>
<li><a href="#_primeros_pasos_con_helm">10.1.5. Primeros pasos con Helm</a></li>
<li><a href="#_best_practices_para_helm">10.1.6. Best Practices para Helm</a></li>
</ul>
</li>
<li><a href="#_charts">10.2. Charts</a>
<ul class="sectlevel3">
<li><a href="#_estructura_de_un_chart">10.2.1. Estructura de un Chart</a></li>
<li><a href="#_valores_values_y_values_yaml">10.2.2. Valores (Values) y values.yaml</a></li>
<li><a href="#_plantillas_templates">10.2.3. Plantillas (Templates)</a></li>
<li><a href="#_chart_yaml_metadatos_del_chart">10.2.4. Chart.yaml: Metadatos del Chart</a></li>
<li><a href="#_dependencias_de_charts_subcharts">10.2.5. Dependencias de Charts (Subcharts)</a></li>
<li><a href="#_best_practices_para_charts">10.2.6. Best Practices para Charts</a></li>
</ul>
</li>
<li><a href="#_trabajando_con_helm">10.3. Trabajando con Helm</a>
<ul class="sectlevel3">
<li><a href="#_gestión_de_repositorios_de_helm">10.3.1. Gestión de Repositorios de Helm</a></li>
<li><a href="#_búsqueda_de_charts">10.3.2. Búsqueda de Charts</a></li>
<li><a href="#_instalación_de_charts">10.3.3. Instalación de Charts</a></li>
<li><a href="#_actualización_y_rollback_de_releases">10.3.4. Actualización y Rollback de Releases</a></li>
<li><a href="#_gestión_de_releases">10.3.5. Gestión de Releases</a></li>
<li><a href="#_estrategias_de_instalación_avanzadas">10.3.6. Estrategias de Instalación Avanzadas</a></li>
<li><a href="#_best_practices_para_trabajar_con_helm">10.3.7. Best Practices para Trabajar con Helm</a></li>
</ul>
</li>
<li><a href="#_creación_de_charts">10.4. Creación de Charts</a>
<ul class="sectlevel3">
<li><a href="#_creación_de_un_chart_desde_cero">10.4.1. Creación de un Chart desde Cero</a></li>
<li><a href="#_template_functions_y_pipelines">10.4.2. Template Functions y Pipelines</a></li>
<li><a href="#_control_de_flujo">10.4.3. Control de Flujo</a></li>
<li><a href="#_named_templates_y_helpers">10.4.4. Named Templates y Helpers</a></li>
<li><a href="#_testing_de_charts">10.4.5. Testing de Charts</a></li>
<li><a href="#_best_practices_para_crear_charts">10.4.6. Best Practices para Crear Charts</a></li>
</ul>
</li>
<li><a href="#_helm_avanzado">10.5. Helm Avanzado</a>
<ul class="sectlevel3">
<li><a href="#_hooks_ganchos_de_ciclo_de_vida">10.5.1. Hooks (Ganchos de Ciclo de Vida)</a></li>
<li><a href="#_gestión_de_dependencias_de_charts">10.5.2. Gestión de Dependencias de Charts</a></li>
<li><a href="#_subcharts_chart_reutilizables">10.5.3. Subcharts (Chart Reutilizables)</a></li>
<li><a href="#_repositorios_de_helm_hosting_y_distribución">10.5.4. Repositorios de Helm: Hosting y Distribución</a></li>
<li><a href="#_best_practices_para_helm_avanzado">10.5.5. Best Practices para Helm Avanzado</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_11_cicd_con_kubernetes">11. Módulo 11: CI/CD con Kubernetes</a>
<ul class="sectlevel2">
<li><a href="#_estrategias_de_deployment">11.1. Estrategias de Deployment</a></li>
<li><a href="#_gitops">11.2. GitOps</a></li>
<li><a href="#_cicd_pipelines">11.3. CI/CD Pipelines</a></li>
<li><a href="#_image_management">11.4. Image Management</a></li>
</ul>
</li>
<li><a href="#_módulo_12_service_mesh">12. Módulo 12: Service Mesh</a>
<ul class="sectlevel2">
<li><a href="#_introducción_a_service_mesh">12.1. Introducción a Service Mesh</a></li>
<li><a href="#_istio">12.2. Istio</a></li>
<li><a href="#_observabilidad_con_service_mesh">12.3. Observabilidad con Service Mesh</a></li>
<li><a href="#_seguridad_en_service_mesh">12.4. Seguridad en Service Mesh</a></li>
</ul>
</li>
<li><a href="#_módulo_13_operaciones_avanzadas">13. Módulo 13: Operaciones Avanzadas</a>
<ul class="sectlevel2">
<li><a href="#_cluster_management">13.1. Cluster Management</a></li>
<li><a href="#_custom_resources_crd">13.2. Custom Resources (CRD)</a></li>
<li><a href="#_admission_controllers">13.3. Admission Controllers</a></li>
<li><a href="#_api_server_2">13.4. API Server</a></li>
</ul>
</li>
<li><a href="#_módulo_14_kubernetes_en_producción">14. Módulo 14: Kubernetes en Producción</a>
<ul class="sectlevel2">
<li><a href="#_arquitectura_de_producción">14.1. Arquitectura de Producción</a></li>
<li><a href="#_hardening">14.2. Hardening</a></li>
<li><a href="#_disaster_recovery">14.3. Disaster Recovery</a></li>
<li><a href="#_cost_optimization">14.4. Cost Optimization</a></li>
<li><a href="#_troubleshooting_avanzado">14.5. Troubleshooting Avanzado</a></li>
</ul>
</li>
<li><a href="#_módulo_15_casos_de_uso_y_patrones">15. Módulo 15: Casos de Uso y Patrones</a>
<ul class="sectlevel2">
<li><a href="#_microservicios">15.1. Microservicios</a>
<ul class="sectlevel3">
<li><a href="#_arquitectura_de_microservicios_en_kubernetes">15.1.1. Arquitectura de Microservicios en Kubernetes</a></li>
<li><a href="#_service_discovery">15.1.2. Service Discovery</a></li>
<li><a href="#_patrones_api_gateway">15.1.3. Patrones API Gateway</a></li>
<li><a href="#_comunicación_entre_servicios">15.1.4. Comunicación Entre Servicios</a></li>
</ul>
</li>
<li><a href="#_bases_de_datos">15.2. Bases de Datos</a>
<ul class="sectlevel3">
<li><a href="#_despliegue_de_bases_de_datos">15.2.1. Despliegue de Bases de Datos</a></li>
<li><a href="#_statefulsets_para_bases_de_datos">15.2.2. StatefulSets para Bases de Datos</a></li>
<li><a href="#_operators_de_bases_de_datos">15.2.3. Operators de Bases de Datos</a></li>
<li><a href="#_backup_y_replicación">15.2.4. Backup y Replicación</a></li>
</ul>
</li>
<li><a href="#_machine_learning">15.3. Machine Learning</a>
<ul class="sectlevel3">
<li><a href="#_kubeflow">15.3.1. Kubeflow</a></li>
<li><a href="#_gpu_scheduling">15.3.2. GPU Scheduling</a></li>
<li><a href="#_model_serving">15.3.3. Model Serving</a></li>
<li><a href="#_mlops_pipelines">15.3.4. MLOps Pipelines</a></li>
</ul>
</li>
<li><a href="#_serverless">15.4. Serverless</a>
<ul class="sectlevel3">
<li><a href="#_knative">15.4.1. Knative</a></li>
<li><a href="#_knative_eventing">15.4.2. Knative Eventing</a></li>
<li><a href="#_openfaas">15.4.3. OpenFaaS</a></li>
<li><a href="#_kubeless">15.4.4. Kubeless</a></li>
<li><a href="#_arquitecturas_event_driven">15.4.5. Arquitecturas Event-Driven</a></li>
</ul>
</li>
<li><a href="#_iot_y_edge_computing">15.5. IoT y Edge Computing</a>
<ul class="sectlevel3">
<li><a href="#_k3s_kubernetes_ligero_para_edge">15.5.1. K3s: Kubernetes Ligero para Edge</a></li>
<li><a href="#_kubeedge">15.5.2. KubeEdge</a></li>
<li><a href="#_edge_deployments_patrones">15.5.3. Edge Deployments: Patrones</a></li>
<li><a href="#_restricciones_de_recursos_en_edge">15.5.4. Restricciones de Recursos en Edge</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_anexos">16. Anexos</a>
<ul class="sectlevel2">
<li><a href="#_a_comandos_kubectl_esenciales">16.1. A. Comandos kubectl Esenciales</a>
<ul class="sectlevel3">
<li><a href="#_gestión_de_recursos">16.1.1. Gestión de Recursos</a></li>
<li><a href="#_debugging_y_troubleshooting_2">16.1.2. Debugging y Troubleshooting</a></li>
<li><a href="#_consultas_y_filtros">16.1.3. Consultas y Filtros</a></li>
<li><a href="#_shortcuts_y_aliases_útiles">16.1.4. Shortcuts y Aliases Útiles</a></li>
</ul>
</li>
<li><a href="#_b_yaml_reference">16.2. B. YAML Reference</a>
<ul class="sectlevel3">
<li><a href="#_sintaxis_básica_de_yaml">16.2.1. Sintaxis Básica de YAML</a></li>
<li><a href="#_estructura_de_manifiestos_kubernetes">16.2.2. Estructura de Manifiestos Kubernetes</a></li>
<li><a href="#_versiones_de_api">16.2.3. Versiones de API</a></li>
<li><a href="#_campos_comunes_en_recursos">16.2.4. Campos Comunes en Recursos</a></li>
<li><a href="#_ejemplos_de_manifiestos_completos">16.2.5. Ejemplos de Manifiestos Completos</a></li>
</ul>
</li>
<li><a href="#_c_glosario">16.3. C. Glosario</a>
<ul class="sectlevel3">
<li><a href="#_términos_clave">16.3.1. Términos Clave</a></li>
<li><a href="#_acrónimos_comunes">16.3.2. Acrónimos Comunes</a></li>
<li><a href="#_conceptos_fundamentales_3">16.3.3. Conceptos Fundamentales</a></li>
</ul>
</li>
<li><a href="#_d_recursos_adicionales">16.4. D. Recursos Adicionales</a>
<ul class="sectlevel3">
<li><a href="#_documentación_oficial">16.4.1. Documentación Oficial</a></li>
<li><a href="#_libros_recomendados">16.4.2. Libros Recomendados</a></li>
<li><a href="#_plataformas_de_aprendizaje_online">16.4.3. Plataformas de Aprendizaje Online</a></li>
<li><a href="#_comunidades_y_foros">16.4.4. Comunidades y Foros</a></li>
<li><a href="#_blogs_y_sitios_de_referencia">16.4.5. Blogs y Sitios de Referencia</a></li>
<li><a href="#_herramientas_útiles">16.4.6. Herramientas Útiles</a></li>
<li><a href="#_guías_rápidas_cheat_sheets">16.4.7. Guías Rápidas (Cheat Sheets)</a></li>
<li><a href="#_certificaciones_kubernetes">16.4.8. Certificaciones Kubernetes</a></li>
<li><a href="#_canales_de_noticias">16.4.9. Canales de Noticias</a></li>
</ul>
</li>
<li><a href="#_e_certificaciones_kubernetes">16.5. E. Certificaciones Kubernetes</a>
<ul class="sectlevel3">
<li><a href="#_cka_certified_kubernetes_administrator">16.5.1. CKA (Certified Kubernetes Administrator)</a></li>
<li><a href="#_ckad_certified_kubernetes_application_developer">16.5.2. CKAD (Certified Kubernetes Application Developer)</a></li>
<li><a href="#_cks_certified_kubernetes_security_specialist">16.5.3. CKS (Certified Kubernetes Security Specialist)</a></li>
<li><a href="#_estrategia_de_preparación">16.5.4. Estrategia de Preparación</a></li>
<li><a href="#_después_de_la_certificación">16.5.5. Después de la Certificación</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_módulo_1_introducción_a_kubernetes">1. Módulo 1: Introducción a Kubernetes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_qué_es_kubernetes">1.1. ¿Qué es Kubernetes?</h3>
<div class="paragraph">
<p>Kubernetes, también conocido como K8s (por las 8 letras entre la 'K' y la 's'), es un sistema de orquestación de contenedores de código abierto que automatiza el despliegue, escalado y gestión de aplicaciones en contenedores.</p>
</div>
<div class="sect3">
<h4 id="_historia_y_origen_del_proyecto">1.1.1. Historia y origen del proyecto</h4>
<div class="paragraph">
<p>Kubernetes fue originalmente diseñado por Google y es el resultado de más de una década de experiencia ejecutando cargas de trabajo de producción a escala usando sistemas internos como Borg y Omega.</p>
</div>
<div class="paragraph">
<p><strong>Cronología:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>2003-2004</strong>: Google desarrolla internamente Borg, su primer sistema de gestión de contenedores</p>
</li>
<li>
<p><strong>2013</strong>: Google comienza a desarrollar Kubernetes basándose en las lecciones aprendidas de Borg</p>
</li>
<li>
<p><strong>Junio 2014</strong>: Google libera Kubernetes como proyecto de código abierto</p>
</li>
<li>
<p><strong>Julio 2015</strong>: Se lanza Kubernetes v1.0 y Google dona el proyecto a la Cloud Native Computing Foundation (CNCF)</p>
</li>
<li>
<p><strong>2016-presente</strong>: Kubernetes se convierte en el estándar de facto para orquestación de contenedores</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_problemas_que_resuelve_kubernetes">1.1.2. Problemas que resuelve Kubernetes</h4>
<div class="paragraph">
<p>Kubernetes aborda varios desafíos críticos en la gestión de aplicaciones modernas:</p>
</div>
<div class="paragraph">
<p><strong>1. Gestión de contenedores a escala</strong></p>
</div>
<div class="paragraph">
<p>Sin Kubernetes, gestionar cientos o miles de contenedores manualmente es prácticamente imposible. K8s automatiza:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Programación y distribución de contenedores en un cluster</p>
</li>
<li>
<p>Reinicio automático de contenedores fallidos</p>
</li>
<li>
<p>Reemplazo y reprogramación de contenedores cuando los nodos fallan</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>2. Alta disponibilidad</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes garantiza que las aplicaciones estén siempre disponibles mediante:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Réplicas automáticas de aplicaciones</p>
</li>
<li>
<p>Distribución de carga entre múltiples instancias</p>
</li>
<li>
<p>Health checks y auto-recuperación</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>3. Escalabilidad</strong></p>
</div>
<div class="paragraph">
<p>Permite escalar aplicaciones de forma:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Horizontal</strong>: Agregar o quitar instancias automáticamente según la demanda</p>
</li>
<li>
<p><strong>Vertical</strong>: Ajustar recursos (CPU, memoria) asignados a contenedores</p>
</li>
<li>
<p><strong>De cluster</strong>: Agregar o quitar nodos del cluster según sea necesario</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>4. Portabilidad</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes funciona en cualquier infraestructura:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>On-premise (en centros de datos propios)</p>
</li>
<li>
<p>Cloud público (AWS, GCP, Azure)</p>
</li>
<li>
<p>Cloud híbrido</p>
</li>
<li>
<p>Multi-cloud</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>5. Despliegues y actualizaciones sin tiempo de inactividad</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Rolling updates: actualizaciones graduales</p>
</li>
<li>
<p>Rollbacks automáticos si algo falla</p>
</li>
<li>
<p>Canary deployments para probar nuevas versiones</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>6. Gestión de configuración y secretos</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Separación de código y configuración</p>
</li>
<li>
<p>Gestión segura de credenciales y secretos</p>
</li>
<li>
<p>ConfigMaps para configuraciones dinámicas</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_comparación_con_otras_soluciones_de_orquestación">1.1.3. Comparación con otras soluciones de orquestación</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 30%;">
<col style="width: 30%;">
<col style="width: 30%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Característica</th>
<th class="tableblock halign-left valign-top">Kubernetes</th>
<th class="tableblock halign-left valign-top">Docker Swarm</th>
<th class="tableblock halign-left valign-top">Apache Mesos</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complejidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta, pero muy flexible</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Baja, fácil de comenzar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escalabilidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Excelente (miles de nodos)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buena (cientos de nodos)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Excelente (decenas de miles)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comunidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy grande y activa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Moderada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pequeña</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ecosistema</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy rico (CNCF)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Moderado</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Soporte empresarial</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Amplio (todos los principales clouds)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitado</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Curva de aprendizaje</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Empinada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Suave</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy empinada</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Auto-recuperación</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Excelente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buena</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buena</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Load balancing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integrado y avanzado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Básico</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Requiere configuración</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Casos de uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">General, microservicios</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aplicaciones simples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Big data, analytics</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ventajas de Kubernetes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Estándar de la industria con amplio soporte</p>
</li>
<li>
<p>Ecosistema maduro con miles de herramientas</p>
</li>
<li>
<p>Soporte nativo de todos los principales proveedores cloud</p>
</li>
<li>
<p>Arquitectura extensible mediante CRDs y Operators</p>
</li>
<li>
<p>Comunidad activa y documentación exhaustiva</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Desventajas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Curva de aprendizaje pronunciada</p>
</li>
<li>
<p>Mayor complejidad operacional</p>
</li>
<li>
<p>Requiere más recursos para clusters pequeños</p>
</li>
<li>
<p>Puede ser excesivo para aplicaciones simples</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_el_ecosistema_cloud_native_computing_foundation_cncf">1.1.4. El ecosistema Cloud Native Computing Foundation (CNCF)</h4>
<div class="paragraph">
<p>La Cloud Native Computing Foundation es una organización sin fines de lucro fundada en 2015 como parte de la Linux Foundation. Su misión es hacer que la computación nativa de la nube sea ubicua.</p>
</div>
<div class="paragraph">
<p><strong>Kubernetes en el contexto de CNCF:</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes es el proyecto "graduado" más importante de CNCF, pero el ecosistema incluye muchos otros proyectos complementarios:</p>
</div>
<div class="paragraph">
<p><strong>Proyectos CNCF relacionados con Kubernetes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 33.3333%;">
<col style="width: 50.0001%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Categoría</th>
<th class="tableblock halign-left valign-top">Proyectos</th>
<th class="tableblock halign-left valign-top">Propósito</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Runtime</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">containerd, CRI-O</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecutar contenedores</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Calico, Cilium, Flannel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Redes de contenedores</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service Mesh</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Istio, Linkerd, Envoy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestión de tráfico entre servicios</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Monitoring</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prometheus, Grafana</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Métricas y visualización</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Logging</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fluentd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Agregación de logs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tracing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Jaeger, OpenTelemetry</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Trazado distribuido</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rook, Longhorn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Almacenamiento persistente</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CI/CD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Argo, Flux, Tekton</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Despliegue continuo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falco, OPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Seguridad y políticas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Package Management</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Helm</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestión de aplicaciones K8s</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Niveles de madurez en CNCF:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Sandbox</strong>: Proyectos experimentales</p>
</li>
<li>
<p><strong>Incubating</strong>: Proyectos en crecimiento con adopción moderada</p>
</li>
<li>
<p><strong>Graduated</strong>: Proyectos maduros con adopción amplia (como Kubernetes, Prometheus, Envoy)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Cloud Native principles:</strong></p>
</div>
<div class="paragraph">
<p>La CNCF promueve aplicaciones que son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Containerized</strong>: Empaquetadas en contenedores</p>
</li>
<li>
<p><strong>Dynamically orchestrated</strong>: Gestionadas activamente por plataformas de orquestación</p>
</li>
<li>
<p><strong>Microservices-oriented</strong>: Construidas como servicios pequeños e independientes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Beneficios del ecosistema:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Interoperabilidad entre herramientas</p>
</li>
<li>
<p>Estándares abiertos</p>
</li>
<li>
<p>Neutralidad de proveedores</p>
</li>
<li>
<p>Innovación rápida</p>
</li>
<li>
<p>Soporte comunitario</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_arquitectura_de_kubernetes">1.2. Arquitectura de Kubernetes</h3>
<div class="paragraph">
<p>Kubernetes sigue una arquitectura cliente-servidor distribuida que separa claramente el plano de control (control plane) de los nodos de trabajo (worker nodes). Esta separación permite una alta disponibilidad y escalabilidad.</p>
</div>
<div class="paragraph">
<p><strong>Arquitectura general:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────────────────────┐
│                    CONTROL PLANE                        │
│  ┌──────────┐  ┌──────┐  ┌───────────┐  ┌────────────┐  │
│  │   API    │  │      │  │ Scheduler │  │ Controller │  │
│  │  Server  │  │ etcd │  │           │  │  Manager   │  │
│  └──────────┘  └──────┘  └───────────┘  └────────────┘  │
└─────────────────────────────────────────────────────────┘
                          │
        ┌─────────────────┼─────────────────┐
        │                 │                 │
┌───────▼──────┐  ┌───────▼──────┐  ┌──────▼───────┐
│   WORKER     │  │   WORKER     │  │   WORKER     │
│    NODE 1    │  │    NODE 2    │  │    NODE 3    │
│              │  │              │  │              │
│  ┌────────┐  │  │  ┌────────┐  │  │  ┌────────┐  │
│  │Kubelet │  │  │  │Kubelet │  │  │  │Kubelet │  │
│  ├────────┤  │  │  ├────────┤  │  │  ├────────┤  │
│  │Kube-   │  │  │  │Kube-   │  │  │  │Kube-   │  │
│  │proxy   │  │  │  │proxy   │  │  │  │proxy   │  │
│  ├────────┤  │  │  ├────────┤  │  │  ├────────┤  │
│  │Runtime │  │  │  │Runtime │  │  │  │Runtime │  │
│  └────────┘  │  │  └────────┘  │  │  └────────┘  │
│              │  │              │  │              │
│  [Pods...]   │  │  [Pods...]   │  │  [Pods...]   │
└──────────────┘  └──────────────┘  └──────────────┘</pre>
</div>
</div>
<div class="sect3">
<h4 id="_componentes_del_control_plane">1.2.1. Componentes del Control Plane</h4>
<div class="paragraph">
<p>El Control Plane (plano de control) es el cerebro del cluster de Kubernetes. Toma decisiones globales sobre el cluster y detecta y responde a eventos del cluster.</p>
</div>
<div class="sect4">
<h5 id="_api_server">API Server</h5>
<div class="paragraph">
<p><strong>kube-apiserver</strong> es el componente central del Control Plane y actúa como frontend para Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Expone la API de Kubernetes (RESTful)</p>
</li>
<li>
<p>Punto de entrada para todos los comandos administrativos</p>
</li>
<li>
<p>Valida y configura datos para objetos de la API</p>
</li>
<li>
<p>Única interfaz que interactúa directamente con etcd</p>
</li>
<li>
<p>Gestiona autenticación, autorización y admission control</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Diseñado para escalar horizontalmente (múltiples instancias)</p>
</li>
<li>
<p>Maneja todas las operaciones CRUD sobre objetos del cluster</p>
</li>
<li>
<p>Sirve como puente entre todos los componentes del cluster</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo de interacción:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cuando ejecutas un comando kubectl, este se comunica con el API Server
kubectl get pods

# Internamente hace una petición HTTP como:
GET /api/v1/namespaces/default/pods
Host: api-server.example.com
Authorization: Bearer &lt;token&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Puerto por defecto:</strong> 6443 (HTTPS)</p>
</div>
</div>
<div class="sect4">
<h5 id="_etcd">etcd</h5>
<div class="paragraph">
<p><strong>etcd</strong> es un almacén de datos distribuido, consistente y de alta disponibilidad que Kubernetes usa como base de datos para toda la información del cluster.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Almacena toda la configuración y estado del cluster</p>
</li>
<li>
<p>Única fuente de verdad (single source of truth)</p>
</li>
<li>
<p>Almacén clave-valor distribuido</p>
</li>
<li>
<p>Proporciona consistencia mediante algoritmo Raft</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Datos almacenados:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Configuración del cluster</p>
</li>
<li>
<p>Estado actual y deseado de todos los objetos</p>
</li>
<li>
<p>Secretos y ConfigMaps</p>
</li>
<li>
<p>Información de nodos, pods, servicios, etc.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Características importantes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Altamente disponible y distribuido</p>
</li>
<li>
<p>Soporta replicación (normalmente 3, 5 o 7 instancias)</p>
</li>
<li>
<p>Comunicación cifrada (TLS)</p>
</li>
<li>
<p>Backups críticos para disaster recovery</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo de estructura de datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>/registry/pods/default/nginx-pod
/registry/services/default/nginx-service
/registry/secrets/default/db-password
/registry/configmaps/default/app-config</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Puerto por defecto:</strong> 2379 (cliente), 2380 (peer)</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>etcd es crítico para el funcionamiento del cluster. La pérdida de datos de etcd significa la pérdida de todo el estado del cluster. Siempre mantén backups regulares.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_scheduler">Scheduler</h5>
<div class="paragraph">
<p><strong>kube-scheduler</strong> es responsable de asignar pods recién creados a nodos específicos del cluster.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Monitorea pods sin nodo asignado</p>
</li>
<li>
<p>Selecciona el mejor nodo para cada pod</p>
</li>
<li>
<p>Considera múltiples factores en la decisión</p>
</li>
<li>
<p>No ejecuta los pods (eso lo hace kubelet)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Factores de decisión:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Requisitos de recursos:</strong></p>
<div class="ulist">
<ul>
<li>
<p>CPU y memoria solicitadas</p>
</li>
<li>
<p>Recursos disponibles en cada nodo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Restricciones:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Node selectors</p>
</li>
<li>
<p>Affinity/Anti-affinity</p>
</li>
<li>
<p>Taints y tolerations</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Optimización:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Distribución de carga</p>
</li>
<li>
<p>Localidad de datos</p>
</li>
<li>
<p>Hardware específico (GPU, SSD)</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Proceso de scheduling:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. Filtrado (Filtering)
   └─&gt; Elimina nodos que no cumplen requisitos

2. Scoring (Puntuación)
   └─&gt; Asigna puntuación a nodos viables

3. Binding (Vinculación)
   └─&gt; Asigna el pod al nodo con mayor puntuación</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de decisión:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Pod solicitando 500m CPU y 1Gi memoria
apiVersion: v1
kind: Pod
metadata:
  name: resource-pod
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"

# Scheduler evaluará:
# - Nodo A: 2 CPU disponibles, 4Gi RAM → Viable ✓
# - Nodo B: 0.3 CPU disponibles, 2Gi RAM → Descartado ✗
# - Nodo C: 1 CPU disponible, 512Mi RAM → Descartado ✗</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_controller_manager">Controller Manager</h5>
<div class="paragraph">
<p><strong>kube-controller-manager</strong> ejecuta múltiples controladores que regulan el estado del cluster.</p>
</div>
<div class="paragraph">
<p><strong>Concepto de controlador:</strong></p>
</div>
<div class="paragraph">
<p>Un controlador es un bucle de control que observa el estado del cluster y hace cambios para mover el estado actual hacia el estado deseado.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>while true:
  estado_actual = observar_cluster()
  estado_deseado = leer_especificacion()

  if estado_actual != estado_deseado:
    realizar_cambios()

  sleep(intervalo)</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Controladores principales:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Node Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Monitorea el estado de los nodos</p>
</li>
<li>
<p>Detecta nodos caídos</p>
</li>
<li>
<p>Responde cuando los nodos fallan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Replication Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantiene el número correcto de pods para cada ReplicaSet</p>
</li>
<li>
<p>Crea o destruye pods según sea necesario</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Endpoints Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Popula objetos Endpoints (une Services y Pods)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Service Account &amp; Token Controllers</strong></p>
<div class="ulist">
<ul>
<li>
<p>Crea cuentas y tokens por defecto para namespaces</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Deployment Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Gestiona actualizaciones y rollbacks de Deployments</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Job Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Supervisa Jobs y crea Pods para ejecutarlos</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo de reconciliación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Usuario especifica: "Quiero 3 réplicas de nginx"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3  # Estado deseado
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21

# Replication Controller observa:
# - Estado actual: 2 pods corriendo
# - Estado deseado: 3 pods
# - Acción: Crear 1 pod adicional</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_cloud_controller_manager">Cloud Controller Manager</h5>
<div class="paragraph">
<p><strong>cloud-controller-manager</strong> permite que el código de Kubernetes y el del proveedor cloud evolucionen independientemente.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Integración con APIs de proveedores cloud</p>
</li>
<li>
<p>Gestión de recursos específicos del cloud</p>
</li>
<li>
<p>Abstracción de la infraestructura subyacente</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Controladores cloud-specific:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Node Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Verifica si los nodos eliminados han sido borrados en el cloud</p>
</li>
<li>
<p>Actualiza nodos con información del cloud (zona, región, tipo de instancia)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Route Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Configura rutas en la infraestructura cloud</p>
</li>
<li>
<p>Necesario para comunicación entre pods en diferentes nodos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Service Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Crea/actualiza/elimina load balancers del cloud</p>
</li>
<li>
<p>Asigna IPs públicas a Services tipo LoadBalancer</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo - Service LoadBalancer en AWS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web-app
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  type: LoadBalancer  # Cloud Controller Manager crea un ELB/NLB
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080

# Cloud Controller Manager:
# 1. Detecta Service tipo LoadBalancer
# 2. Llama a AWS API para crear Network Load Balancer
# 3. Configura health checks
# 4. Actualiza Service con IP pública del NLB</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_componentes_de_los_nodos">1.2.2. Componentes de los Nodos</h4>
<div class="paragraph">
<p>Los nodos worker son las máquinas (físicas o virtuales) donde se ejecutan las aplicaciones containerizadas.</p>
</div>
<div class="sect4">
<h5 id="_kubelet">Kubelet</h5>
<div class="paragraph">
<p><strong>kubelet</strong> es el agente principal que se ejecuta en cada nodo worker.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Registra el nodo en el API Server</p>
</li>
<li>
<p>Monitorea Pods asignados a su nodo</p>
</li>
<li>
<p>Ejecuta contenedores a través del container runtime</p>
</li>
<li>
<p>Reporta el estado de pods y nodos al API Server</p>
</li>
<li>
<p>Ejecuta health checks (liveness, readiness probes)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Responsabilidades:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pod Lifecycle Management</strong></p>
<div class="ulist">
<ul>
<li>
<p>Descarga imágenes de contenedores</p>
</li>
<li>
<p>Inicia y detiene contenedores</p>
</li>
<li>
<p>Reinicia contenedores fallidos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Volume Management</strong></p>
<div class="ulist">
<ul>
<li>
<p>Monta volúmenes según especificación</p>
</li>
<li>
<p>Gestiona plugins de volumen</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Resource Monitoring</strong></p>
<div class="ulist">
<ul>
<li>
<p>Monitorea uso de CPU, memoria, disco</p>
</li>
<li>
<p>Reporta métricas al API Server</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Flujo de trabajo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. kubelet consulta API Server cada X segundos
   └─&gt; "¿Hay pods asignados a mí?"

2. API Server responde con PodSpecs

3. kubelet compara estado actual vs deseado

4. Si hay diferencias:
   └─&gt; Llama al Container Runtime para crear/actualizar/eliminar contenedores

5. kubelet reporta estado de vuelta al API Server</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración importante:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># /var/lib/kubelet/config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
address: 0.0.0.0
port: 10250
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
authorization:
  mode: Webhook
clusterDomain: cluster.local
clusterDNS:
  - 10.96.0.10</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Puerto por defecto:</strong> 10250</p>
</div>
</div>
<div class="sect4">
<h5 id="_kube_proxy">Kube-proxy</h5>
<div class="paragraph">
<p><strong>kube-proxy</strong> es un proxy de red que mantiene reglas de red en cada nodo, permitiendo la comunicación con Pods.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Implementa el concepto de Services</p>
</li>
<li>
<p>Gestiona reglas de red/iptables en el nodo</p>
</li>
<li>
<p>Balancea carga de tráfico hacia Pods</p>
</li>
<li>
<p>Mantiene conectividad de red</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Modos de operación:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>iptables mode</strong> (por defecto)</p>
<div class="ulist">
<ul>
<li>
<p>Usa reglas iptables para redirección</p>
</li>
<li>
<p>Selección aleatoria de pods backend</p>
</li>
<li>
<p>Mejor rendimiento que userspace</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>IPVS mode</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa Linux IPVS (IP Virtual Server)</p>
</li>
<li>
<p>Mejor rendimiento a gran escala</p>
</li>
<li>
<p>Más algoritmos de balanceo (round-robin, least-connection, etc.)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>userspace mode</strong> (legacy)</p>
<div class="ulist">
<ul>
<li>
<p>kube-proxy actúa como proxy real</p>
</li>
<li>
<p>Menos eficiente</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo de funcionamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Service definition
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
  clusterIP: 10.96.100.50

# kube-proxy crea reglas iptables en cada nodo:
# "Todo tráfico a 10.96.100.50:80 → distribuir a pods backend:8080"

# Reglas iptables generadas (simplificado):
-A KUBE-SERVICES -d 10.96.100.50/32 -p tcp --dport 80 -j KUBE-SVC-BACKEND
-A KUBE-SVC-BACKEND -m statistic --mode random --probability 0.33 -j KUBE-SEP-POD1
-A KUBE-SVC-BACKEND -m statistic --mode random --probability 0.50 -j KUBE-SEP-POD2
-A KUBE-SVC-BACKEND -j KUBE-SEP-POD3</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diagrama de tráfico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Cliente (en Pod A)
     │
     │ Solicita: backend:80
     ▼
[kube-proxy iptables]
     │
     ├─&gt; 33% → Pod Backend 1 (10.244.1.5:8080)
     ├─&gt; 33% → Pod Backend 2 (10.244.2.3:8080)
     └─&gt; 34% → Pod Backend 3 (10.244.3.7:8080)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_container_runtime">Container Runtime</h5>
<div class="paragraph">
<p>El <strong>Container Runtime</strong> es el software responsable de ejecutar contenedores.</p>
</div>
<div class="paragraph">
<p><strong>Interfaz CRI (Container Runtime Interface):</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes usa CRI para comunicarse con diferentes runtimes sin acoplamientos estrictos.</p>
</div>
<div class="paragraph">
<p><strong>Runtimes soportados:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>containerd</strong></p>
<div class="ulist">
<ul>
<li>
<p>Runtime más popular actualmente</p>
</li>
<li>
<p>Graduado de CNCF</p>
</li>
<li>
<p>Usado por Docker Desktop, GKE, EKS</p>
</li>
<li>
<p>Ligero y eficiente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>CRI-O</strong></p>
<div class="ulist">
<ul>
<li>
<p>Diseñado específicamente para Kubernetes</p>
</li>
<li>
<p>Implementación ligera de OCI</p>
</li>
<li>
<p>Usado por OpenShift</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Docker Engine</strong> (via cri-dockerd)</p>
<div class="ulist">
<ul>
<li>
<p>Soporte legacy mediante adaptador</p>
</li>
<li>
<p>Deprecated desde Kubernetes 1.24</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Responsabilidades del runtime:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Descargar imágenes de registros</p>
</li>
<li>
<p>Desempaquetar imágenes</p>
</li>
<li>
<p>Ejecutar contenedores</p>
</li>
<li>
<p>Gestionar el ciclo de vida de contenedores</p>
</li>
<li>
<p>Proporcionar interfaz CRI para kubelet</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Flujo de ejecución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet
  │
  │ (CRI API calls)
  ▼
Container Runtime (containerd/CRI-O)
  │
  │ (OCI runtime spec)
  ▼
runc / crun / kata-containers
  │
  ▼
Linux Kernel (cgroups, namespaces)
  │
  ▼
[Container running]</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de configuración containerd:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml"># /etc/containerd/config.toml
[plugins."io.containerd.grpc.v1.cri"]
  sandbox_image = "registry.k8s.io/pause:3.9"

[plugins."io.containerd.grpc.v1.cri".containerd]
  snapshotter = "overlayfs"

  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
    runtime_type = "io.containerd.runc.v2"

    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = true</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_addons">1.2.3. Addons</h4>
<div class="paragraph">
<p>Además de los componentes core, Kubernetes usa Addons para extender funcionalidad:</p>
</div>
<div class="paragraph">
<p><strong>DNS (CoreDNS)</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Servicio DNS para el cluster</p>
</li>
<li>
<p>Permite resolución de nombres de Services</p>
</li>
<li>
<p>Crítico para service discovery</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Dashboard</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Interfaz web para gestionar el cluster</p>
</li>
<li>
<p>Visualización de recursos</p>
</li>
<li>
<p>No recomendado para producción (usar CLI/GitOps)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Container Resource Monitoring</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Recopila métricas de contenedores</p>
</li>
<li>
<p>Metrics Server para HPA</p>
</li>
<li>
<p>Prometheus para monitoring avanzado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Cluster-level Logging</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregación de logs</p>
</li>
<li>
<p>EFK Stack (Elasticsearch, Fluentd, Kibana)</p>
</li>
<li>
<p>Loki, Splunk, etc.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_flujo_completo_de_kubectl_a_pod_en_ejecución">1.2.4. Flujo completo: De kubectl a Pod en ejecución</h4>
<div class="paragraph">
<p>Veamos cómo interactúan todos los componentes cuando creas un Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. Usuario ejecuta:
   $ kubectl run nginx --image=nginx

2. kubectl → API Server
   └─&gt; POST /api/v1/namespaces/default/pods

3. API Server:
   └─&gt; Valida la petición
   └─&gt; Autentica y autoriza
   └─&gt; Ejecuta admission controllers
   └─&gt; Escribe el Pod en etcd (estado: Pending, sin nodo asignado)

4. Scheduler (observando API Server):
   └─&gt; Detecta Pod sin nodo
   └─&gt; Evalúa nodos disponibles
   └─&gt; Selecciona mejor nodo (ej: node-2)
   └─&gt; Actualiza Pod en API Server: nodeName=node-2

5. API Server actualiza etcd con la asignación

6. kubelet en node-2 (polling API Server):
   └─&gt; Detecta nuevo Pod asignado a su nodo
   └─&gt; Llama a Container Runtime (containerd)
   └─&gt; Container Runtime:
       └─&gt; Descarga imagen nginx desde Docker Hub
       └─&gt; Crea contenedor
       └─&gt; Inicia contenedor

7. kubelet reporta estado a API Server:
   └─&gt; Pod status: Running

8. API Server actualiza etcd

9. kube-proxy en todos los nodos:
   └─&gt; Si el Pod es parte de un Service
   └─&gt; Actualiza reglas iptables/IPVS</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diagrama temporal:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Tiempo  kubectl  API Server  etcd  Scheduler  kubelet  Runtime
  │       │         │         │        │         │        │
  0       ├────────&gt;│ Crear   │        │         │        │
  │       │         │ Pod     │        │         │        │
  1       │         ├────────&gt;│ Save   │         │        │
  │       │         │         │ Pending│         │        │
  2       │         │&lt;────────┤        │         │        │
  │       │         │                  │         │        │
  3       │         │         │    Watch         │        │
  │       │         │         │&lt;───────┘         │        │
  4       │         │         │        │ Assign  │        │
  │       │         │         │        │ node-2  │        │
  5       │         │ Update  │&lt;───────┤         │        │
  │       │         ├────────&gt;│ nodeName         │        │
  6       │         │         │        │       Watch      │
  │       │         │         │        │&lt;────────┘        │
  7       │         │         │        │         │ Start  │
  │       │         │         │        │         ├───────&gt;│
  8       │         │         │        │         │  Pull  │
  │       │         │         │        │         │  Run   │
  9       │         │ Update  │        │   Report│        │
  │       │         │&lt;────────┼────────┼─────────┤        │
 10       │         ├────────&gt;│ Running│         │        │
  │       │         │         │        │         │        │
  ▼       ▼         ▼         ▼        ▼         ▼        ▼</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_conceptos_fundamentales">1.3. Conceptos Fundamentales</h3>
<div class="paragraph">
<p>Kubernetes introduce varios conceptos fundamentales que son esenciales para entender cómo funciona el sistema. Estos conceptos son la base sobre la que se construyen todas las funcionalidades avanzadas.</p>
</div>
<div class="sect3">
<h4 id="_clusters_nodos_y_pods">1.3.1. Clusters, Nodos y Pods</h4>
<div class="paragraph">
<p><strong>Cluster</strong></p>
</div>
<div class="paragraph">
<p>Un cluster de Kubernetes es un conjunto de máquinas (nodos) que ejecutan aplicaciones containerizadas gestionadas por Kubernetes.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────┐
│         KUBERNETES CLUSTER              │
│                                         │
│  ┌────────────────┐   ┌──────────────┐  │
│  │ Control Plane  │   │ Worker Nodes │  │
│  │    Nodes       │   │              │  │
│  │  (1 o más)     │   │  (1 o más)   │  │
│  └────────────────┘   └──────────────┘  │
└─────────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Componentes de un cluster:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Control Plane Nodes</strong>: Gestionan el cluster</p>
</li>
<li>
<p><strong>Worker Nodes</strong>: Ejecutan las aplicaciones</p>
</li>
<li>
<p><strong>Networking</strong>: Comunicación entre componentes</p>
</li>
<li>
<p><strong>Storage</strong>: Sistemas de almacenamiento</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Nodos (Nodes)</strong></p>
</div>
<div class="paragraph">
<p>Un nodo es una máquina de trabajo (física o virtual) en Kubernetes donde se ejecutan los Pods.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de nodos:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Master/Control Plane Nodes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ejecutan componentes del control plane</p>
</li>
<li>
<p>Generalmente no ejecutan aplicaciones de usuario</p>
</li>
<li>
<p>Pueden ser múltiples para alta disponibilidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Worker Nodes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ejecutan los Pods con las aplicaciones</p>
</li>
<li>
<p>Contienen kubelet, kube-proxy y container runtime</p>
</li>
<li>
<p>Pueden ser escalados según demanda</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Información de un nodo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get nodes

# Salida:
NAME           STATUS   ROLES           AGE   VERSION
control-plane  Ready    control-plane   30d   v1.28.0
worker-1       Ready    &lt;none&gt;          30d   v1.28.0
worker-2       Ready    &lt;none&gt;          30d   v1.28.0
worker-3       Ready    &lt;none&gt;          30d   v1.28.0

# Ver detalles de un nodo:
kubectl describe node worker-1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Información que muestra:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Capacidad (CPU, memoria, pods máximos)</p>
</li>
<li>
<p>Condiciones (Ready, DiskPressure, MemoryPressure)</p>
</li>
<li>
<p>Pods en ejecución</p>
</li>
<li>
<p>Recursos asignados vs disponibles</p>
</li>
<li>
<p>Sistema operativo e información de kernel</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Pods</strong></p>
</div>
<div class="paragraph">
<p>Un Pod es la unidad más pequeña desplegable en Kubernetes. Representa una o más contenedores que deben ejecutarse juntos en el mismo nodo.</p>
</div>
<div class="paragraph">
<p><strong>Características de los Pods:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparten dirección IP</p>
</li>
<li>
<p>Comparten namespace de red</p>
</li>
<li>
<p>Pueden compartir volúmenes</p>
</li>
<li>
<p>Se programan juntos en el mismo nodo</p>
</li>
<li>
<p>Escalan como unidad</p>
</li>
<li>
<p>Efímeros por naturaleza (no persistentes)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ciclo de vida:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Pending → Running → Succeeded/Failed
                  ↓
              CrashLoopBackOff (si falla repetidamente)</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de Pod simple:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
    env: production
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear y gestionar el Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear el Pod
kubectl apply -f nginx-pod.yaml

# Ver Pods
kubectl get pods

# Ver detalles
kubectl describe pod nginx-pod

# Ver logs
kubectl logs nginx-pod

# Eliminar el Pod
kubectl delete pod nginx-pod</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_contenedores_vs_pods">1.3.2. Contenedores vs Pods</h4>
<div class="paragraph">
<p>Es crucial entender la diferencia entre contenedores y Pods:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 40%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Contenedor</th>
<th class="tableblock halign-left valign-top">Pod</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Definición</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unidad de empaquetado (Docker, containerd)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unidad de despliegue en Kubernetes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Necesita configuración de red</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">IP compartida entre todos los contenedores</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Almacenamiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Volúmenes propios</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Volúmenes compartidos entre contenedores</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lifecycle</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestionado por runtime</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestionado por Kubernetes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A en contexto K8s</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pods se replican</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso típico</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una aplicación</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una o más aplicaciones relacionadas</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>¿Cuándo usar múltiples contenedores en un Pod?</strong></p>
</div>
<div class="paragraph">
<p><strong>Casos de uso válidos:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Sidecar pattern</strong>: Contenedor helper que extiende funcionalidad</p>
<div class="ulist">
<ul>
<li>
<p>Ejemplo: Contenedor de logs que envía logs a sistema centralizado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Ambassador pattern</strong>: Proxy para comunicación externa</p>
<div class="ulist">
<ul>
<li>
<p>Ejemplo: Proxy local para base de datos remota</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Adapter pattern</strong>: Normaliza output/interfaces</p>
<div class="ulist">
<ul>
<li>
<p>Ejemplo: Adaptador que convierte métricas a formato estándar</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo de Pod multi-contenedor (Sidecar):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  containers:
  # Contenedor principal
  - name: main-app
    image: myapp:1.0
    volumeMounts:
    - name: logs
      mountPath: /var/log/app

  # Sidecar para procesar logs
  - name: log-processor
    image: fluentd:latest
    volumeMounts:
    - name: logs
      mountPath: /var/log/app

  volumes:
  - name: logs
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Regla general:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Un contenedor por Pod</strong>: Si los contenedores pueden ejecutarse independientemente</p>
</li>
<li>
<p><strong>Múltiples contenedores por Pod</strong>: Solo si están estrechamente acoplados y deben compartir recursos</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_namespaces">1.3.3. Namespaces</h4>
<div class="paragraph">
<p>Los Namespaces proporcionan un mecanismo para aislar grupos de recursos dentro de un mismo cluster.</p>
</div>
<div class="paragraph">
<p><strong>Propósito:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Dividir recursos del cluster entre múltiples usuarios/equipos</p>
</li>
<li>
<p>Proporcionar scope para nombres (los nombres deben ser únicos por namespace)</p>
</li>
<li>
<p>Aplicar políticas de recursos (quotas, network policies)</p>
</li>
<li>
<p>Organización lógica de recursos</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Namespaces por defecto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get namespaces

# Salida:
NAME              STATUS   AGE
default           Active   30d   # Namespace por defecto
kube-system       Active   30d   # Componentes del sistema
kube-public       Active   30d   # Recursos públicos
kube-node-lease   Active   30d   # Heartbeats de nodos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Descripción de namespaces del sistema:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>default</strong>: Namespace por defecto para recursos sin namespace especificado</p>
</li>
<li>
<p><strong>kube-system</strong>: Objetos creados por el sistema Kubernetes (DNS, Dashboard, etc.)</p>
</li>
<li>
<p><strong>kube-public</strong>: Recursos públicos accesibles para todos (incluso no autenticados)</p>
</li>
<li>
<p><strong>kube-node-lease</strong>: Objetos de lease para heartbeats de nodos</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Crear namespace:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: desarrollo
  labels:
    env: dev
    team: backend</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear namespace
kubectl create namespace desarrollo

# O con archivo YAML
kubectl apply -f namespace.yaml

# Crear recursos en un namespace
kubectl apply -f app.yaml -n desarrollo

# Listar recursos en namespace específico
kubectl get pods -n desarrollo

# Listar recursos en todos los namespaces
kubectl get pods --all-namespaces
# O abreviado:
kubectl get pods -A</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cambiar namespace por defecto en contexto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver contexto actual
kubectl config current-context

# Cambiar namespace por defecto
kubectl config set-context --current --namespace=desarrollo

# Verificar
kubectl config view --minify | grep namespace:</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de uso - Entornos separados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Namespace para desarrollo
apiVersion: v1
kind: Namespace
metadata:
  name: dev
---
# Namespace para producción
apiVersion: v1
kind: Namespace
metadata:
  name: prod
---
# La misma app puede existir en ambos
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp  # Mismo nombre, diferentes namespaces
  namespace: dev
spec:
  replicas: 1
  # ... especificación
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp  # Mismo nombre, diferentes namespaces
  namespace: prod
spec:
  replicas: 3  # Más réplicas en producción
  # ... especificación</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>No todos los objetos están en un namespace. Nodos, PersistentVolumes, y Namespaces mismos son cluster-wide y no pertenecen a ningún namespace.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong>Ver qué recursos están en namespace:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Recursos en namespace
kubectl api-resources --namespaced=true

# Recursos cluster-wide
kubectl api-resources --namespaced=false</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_labels_y_selectors">1.3.4. Labels y Selectors</h4>
<div class="paragraph">
<p>Labels son pares clave-valor que se adjuntan a objetos como Pods, Services, Deployments, etc. Son fundamentales para la organización y selección de recursos.</p>
</div>
<div class="paragraph">
<p><strong>Labels</strong></p>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pares clave-valor arbitrarios</p>
</li>
<li>
<p>Pueden añadirse en tiempo de creación o modificarse después</p>
</li>
<li>
<p>Múltiples labels por objeto</p>
</li>
<li>
<p>No proporcionan unicidad (múltiples objetos pueden tener los mismos labels)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Sintaxis:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Clave: <code>[prefix/]name</code></p>
</li>
<li>
<p>Prefijo (opcional): max 253 caracteres (DNS subdomain)</p>
</li>
<li>
<p>Nombre: max 63 caracteres (alfanumérico, <code>-</code>, <code>_</code>, <code>.</code>)</p>
</li>
<li>
<p>Valor: max 63 caracteres</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplos de buenos labels:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">metadata:
  labels:
    # Entorno
    environment: production
    env: prod

    # Aplicación
    app: nginx
    app.kubernetes.io/name: nginx
    app.kubernetes.io/version: "1.21"
    app.kubernetes.io/component: frontend

    # Equipo/Ownership
    team: platform
    owner: devops

    # Release tracking
    release: stable
    version: v2.1.0

    # Tier
    tier: frontend
    layer: presentation</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de Pod con labels:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx-prod-frontend
  labels:
    app: nginx
    environment: production
    tier: frontend
    version: "1.21"
spec:
  containers:
  - name: nginx
    image: nginx:1.21</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gestionar labels con kubectl:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver labels
kubectl get pods --show-labels

# Ver pods con labels específicos como columnas
kubectl get pods -L app,environment

# Añadir label
kubectl label pods nginx-prod-frontend region=us-west

# Modificar label existente
kubectl label pods nginx-prod-frontend version=1.22 --overwrite

# Eliminar label
kubectl label pods nginx-prod-frontend version-</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Selectors</strong></p>
</div>
<div class="paragraph">
<p>Los Selectors permiten filtrar/seleccionar objetos basándose en sus labels. Son usados extensivamente por Services, Deployments, etc.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de selectors:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Equality-based</strong> (basados en igualdad):</p>
<div class="ulist">
<ul>
<li>
<p><code>=</code> o <code>==</code>: igualdad</p>
</li>
<li>
<p><code>!=</code>: desigualdad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Set-based</strong> (basados en conjuntos):</p>
<div class="ulist">
<ul>
<li>
<p><code>in</code>: valor en conjunto</p>
</li>
<li>
<p><code>notin</code>: valor no en conjunto</p>
</li>
<li>
<p><code>exists</code>: label existe</p>
</li>
<li>
<p><code>!</code>: label no existe</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplos con kubectl:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Equality-based
kubectl get pods -l environment=production
kubectl get pods -l environment!=production
kubectl get pods -l tier=frontend,environment=production  # AND

# Set-based
kubectl get pods -l 'environment in (production,staging)'
kubectl get pods -l 'tier notin (frontend,backend)'
kubectl get pods -l 'version'  # Label exists
kubectl get pods -l '!version'  # Label doesn't exist

# Combinaciones
kubectl get pods -l 'environment=production,tier in (frontend,backend)'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Selectors en manifiestos:</strong></p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Service seleccionando Pods</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  selector:
    app: nginx      # Selecciona Pods con app=nginx
    tier: frontend  # Y tier=frontend
  ports:
  - port: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Deployment (matchLabels y matchExpressions)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    # Equality-based (más común)
    matchLabels:
      app: nginx
      tier: frontend

    # Set-based (más flexible)
    matchExpressions:
    - key: environment
      operator: In
      values:
      - production
      - staging
    - key: legacy
      operator: DoesNotExist
  template:
    metadata:
      labels:
        app: nginx
        tier: frontend
        environment: production
    spec:
      containers:
      - name: nginx
        image: nginx:1.21</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso de uso común: Blue-Green deployment</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Deployment BLUE
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: app
        image: myapp:1.0
---
# Deployment GREEN
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: app
        image: myapp:2.0
---
# Service - cambiar selector para switch
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
    version: blue  # Cambiar a 'green' para switch
  ports:
  - port: 80</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_annotations">1.3.5. Annotations</h4>
<div class="paragraph">
<p>Las Annotations son similares a los labels, pero están diseñadas para metadatos no identificatorios que no se usan para seleccionar objetos.</p>
</div>
<div class="paragraph">
<p><strong>Diferencias entre Labels y Annotations:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 40%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Labels</th>
<th class="tableblock halign-left valign-top">Annotations</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propósito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identificar y seleccionar objetos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Añadir metadata arbitrario</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Usados por</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes (selectors)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Herramientas externas, usuarios</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitaciones de valor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">63 caracteres</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sin límite práctico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Consultas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pueden filtrarse con selectors</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No filtrables</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejemplos de uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>app=nginx</code>, <code>env=prod</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URLs, configuración JSON, descripciones largas</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Casos de uso de Annotations:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Información de build/release</strong></p>
<div class="ulist">
<ul>
<li>
<p>Git commit SHA</p>
</li>
<li>
<p>Build timestamp</p>
</li>
<li>
<p>Release notes URL</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configuración de herramientas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ingress controllers (NGINX, Traefik)</p>
</li>
<li>
<p>Service meshes (Istio)</p>
</li>
<li>
<p>Monitoring (Prometheus)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Contacto y documentación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Responsable del recurso</p>
</li>
<li>
<p>Documentación</p>
</li>
<li>
<p>Enlaces a dashboards</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Metadata de integración</strong></p>
<div class="ulist">
<ul>
<li>
<p>IDs de sistemas externos</p>
</li>
<li>
<p>Configuración específica de cloud provider</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo con múltiples annotations:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
  labels:
    app: myapp
    version: "2.1.0"
  annotations:
    # Build information
    build.date: "2024-01-15T10:30:00Z"
    git.commit: "a3f5c8d"
    git.branch: "main"

    # Contact information
    owner: "platform-team@example.com"
    documentation: "https://wiki.example.com/myapp"
    oncall: "https://oncall.example.com/platform"

    # Integration metadata
    monitoring.prometheus.io/scrape: "true"
    monitoring.prometheus.io/port: "9090"
    monitoring.prometheus.io/path: "/metrics"

    # Description
    description: |
      Main application pod running customer-facing API.
      Handles authentication and request routing.
spec:
  containers:
  - name: app
    image: myapp:2.1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Ingress con annotations (NGINX)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  annotations:
    # NGINX Ingress Controller específico
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"

    # Cert-manager para TLS automático
    cert-manager.io/cluster-issuer: "letsencrypt-prod"

    # Configuración custom
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers "X-Frame-Options: DENY";
      more_set_headers "X-Content-Type-Options: nosniff";
spec:
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app-service
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gestionar annotations con kubectl:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver annotations
kubectl describe pod app-pod | grep -A 10 Annotations

# Añadir annotation
kubectl annotate pod app-pod contact="team@example.com"

# Modificar annotation
kubectl annotate pod app-pod contact="newteam@example.com" --overwrite

# Eliminar annotation
kubectl annotate pod app-pod contact-

# Añadir annotation con valor multilínea
kubectl annotate pod app-pod description="This is a long
description that spans
multiple lines"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico: Deployment completo con labels y annotations</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  namespace: production
  labels:
    # Labels para identificación
    app: webapp
    component: frontend
    environment: production
  annotations:
    # Annotations para metadata
    deployment.kubernetes.io/revision: "3"
    kubernetes.io/change-cause: "Update to version 2.1.0 with bug fixes"
    description: "Main web application serving customer traffic"
    owner: "frontend-team@example.com"
spec:
  replicas: 5
  selector:
    matchLabels:
      app: webapp
      component: frontend
  template:
    metadata:
      labels:
        # Labels en Pods (deben coincidir con selector)
        app: webapp
        component: frontend
        environment: production
        version: "2.1.0"
      annotations:
        # Annotations en Pods
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
        build.git.commit: "a3f5c8d9"
        build.timestamp: "2024-01-15T10:30:00Z"
    spec:
      containers:
      - name: webapp
        image: webapp:2.1.0
        ports:
        - containerPort: 8080
        env:
        - name: ENVIRONMENT
          value: "production"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices:</strong></p>
</div>
<div class="paragraph">
<p><strong>Para Labels:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Usa labels consistentes y bien definidos</p>
</li>
<li>
<p>Incluye información de identificación crítica (app, version, component)</p>
</li>
<li>
<p>Mantén un esquema de naming consistente</p>
</li>
<li>
<p>Usa prefijos para labels organizacionales (<code>myorg.com/team</code>)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Para Annotations:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Usa annotations para metadata que no afecta la programación</p>
</li>
<li>
<p>Documenta el significado de annotations personalizadas</p>
</li>
<li>
<p>No uses annotations para datos sensibles (usa Secrets)</p>
</li>
<li>
<p>Mantén el tamaño razonable (aunque no hay límite estricto)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_instalación_y_configuración_del_entorno">1.4. Instalación y Configuración del Entorno</h3>
<div class="paragraph">
<p>Para aprender y desarrollar con Kubernetes, existen varias opciones para configurar un entorno local. Cada opción tiene sus ventajas y casos de uso específicos.</p>
</div>
<div class="sect3">
<h4 id="_opciones_de_instalación_local">1.4.1. Opciones de instalación local</h4>
<div class="paragraph">
<p>Comparación rápida de las opciones disponibles:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 11.1111%;">
<col style="width: 22.2222%;">
<col style="width: 22.2222%;">
<col style="width: 22.2222%;">
<col style="width: 22.2223%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Herramienta</th>
<th class="tableblock halign-left valign-top">Ventajas</th>
<th class="tableblock halign-left valign-top">Desventajas</th>
<th class="tableblock halign-left valign-top">Casos de uso</th>
<th class="tableblock halign-left valign-top">Sistemas</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minikube</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fácil de usar, múltiples drivers, addons</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Overhead de VM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aprendizaje, desarrollo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linux, macOS, Windows</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kind</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy rápido, ligero, ideal para CI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo Docker, básico</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CI/CD, testing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linux, macOS, Windows</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Docker Desktop</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integrado, fácil setup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo 1 nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Desarrollo simple</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">macOS, Windows</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MicroK8s</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción-ready, snap packages</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo Linux nativamente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Edge, IoT, desarrollo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linux (nativo), macOS/Win (VM)</p></td>
</tr>
</tbody>
</table>
<div class="sect4">
<h5 id="_minikube">Minikube</h5>
<div class="paragraph">
<p>Minikube es la herramienta más popular para ejecutar Kubernetes localmente. Crea una VM o contenedor que ejecuta un cluster de un solo nodo.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="paragraph">
<p><strong>Linux:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando binario directo
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# O usando package manager
# Debian/Ubuntu
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb
sudo dpkg -i minikube_latest_amd64.deb

# Fedora/RHEL
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-latest.x86_64.rpm
sudo rpm -Uvh minikube-latest.x86_64.rpm</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>macOS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando Homebrew
brew install minikube

# O usando binario
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64
sudo install minikube-darwin-amd64 /usr/local/bin/minikube</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Windows:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-powershell hljs" data-lang="powershell"># Usando Chocolatey
choco install minikube

# O descargar el instalador desde:
# https://github.com/kubernetes/minikube/releases/latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Drivers disponibles:</strong></p>
</div>
<div class="paragraph">
<p>Minikube soporta varios drivers para ejecutar el cluster:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>docker</strong>: Usa Docker containers (recomendado)</p>
</li>
<li>
<p><strong>virtualbox</strong>: Usa VirtualBox VM</p>
</li>
<li>
<p><strong>hyperv</strong>: Hyper-V en Windows</p>
</li>
<li>
<p><strong>kvm2</strong>: KVM en Linux</p>
</li>
<li>
<p><strong>hyperkit</strong>: HyperKit en macOS</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Iniciar Minikube:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Iniciar con driver por defecto (docker)
minikube start

# Iniciar con driver específico
minikube start --driver=docker

# Iniciar con configuración personalizada
minikube start \
  --cpus=4 \
  --memory=8192 \
  --disk-size=50g \
  --kubernetes-version=v1.28.0

# Iniciar con múltiples nodos
minikube start --nodes=3</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos útiles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado
minikube status

# Detener el cluster
minikube stop

# Eliminar el cluster
minikube delete

# SSH al nodo
minikube ssh

# Ver dashboard
minikube dashboard

# Ver IP del cluster
minikube ip

# Listar addons disponibles
minikube addons list

# Habilitar addon
minikube addons enable ingress
minikube addons enable metrics-server

# Ver logs
minikube logs</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Addons populares:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ingress Controller
minikube addons enable ingress

# Metrics Server (para HPA)
minikube addons enable metrics-server

# Dashboard
minikube addons enable dashboard

# Registry
minikube addons enable registry

# Storage provisioner
minikube addons enable storage-provisioner</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Trabajar con imágenes Docker locales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Configurar shell para usar Docker de Minikube
eval $(minikube docker-env)

# Ahora docker build construirá dentro de Minikube
docker build -t myapp:local .

# Usar en Pod (importante: imagePullPolicy: Never)
kubectl run myapp --image=myapp:local --image-pull-policy=Never

# Volver a Docker local
eval $(minikube docker-env -u)</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_kind_kubernetes_in_docker">Kind (Kubernetes in Docker)</h5>
<div class="paragraph">
<p>Kind (Kubernetes IN Docker) ejecuta clusters de Kubernetes usando contenedores Docker como nodos. Es extremadamente rápido y ligero.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="paragraph">
<p><strong>Linux:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando binario
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>macOS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando Homebrew
brew install kind

# O usando binario
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-darwin-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Windows:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-powershell hljs" data-lang="powershell"># Usando Chocolatey
choco install kind

# O descargar desde GitHub releases</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear cluster simple (1 nodo)
kind create cluster

# Crear cluster con nombre específico
kind create cluster --name dev-cluster

# Crear cluster con versión específica
kind create cluster --image kindest/node:v1.28.0

# Ver clusters
kind get clusters

# Eliminar cluster
kind delete cluster --name dev-cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración avanzada con archivo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># kind-config.yaml - Cluster multi-nodo
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  # Control plane node
  - role: control-plane
    kubeadmConfigPatches:
    - |
      kind: InitConfiguration
      nodeRegistration:
        kubeletExtraArgs:
          node-labels: "ingress-ready=true"
    extraPortMappings:
    - containerPort: 80
      hostPort: 80
      protocol: TCP
    - containerPort: 443
      hostPort: 443
      protocol: TCP

  # Worker nodes
  - role: worker
  - role: worker
  - role: worker</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear cluster con configuración
kind create cluster --config kind-config.yaml --name multi-node</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cargar imágenes locales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Construir imagen
docker build -t myapp:1.0 .

# Cargar en Kind
kind load docker-image myapp:1.0 --name dev-cluster

# Ahora se puede usar en Pods
kubectl run myapp --image=myapp:1.0 --image-pull-policy=Never</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configurar Ingress en Kind:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear cluster con port mappings (ver config arriba)

# 2. Instalar NGINX Ingress Controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml

# 3. Esperar a que esté listo
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=90s

# 4. Ahora Ingress funcionará en localhost:80/443</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_docker_desktop">Docker Desktop</h5>
<div class="paragraph">
<p>Docker Desktop incluye una instalación de Kubernetes de un solo nodo que se integra perfectamente con Docker.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Descargar Docker Desktop:</p>
<div class="ulist">
<ul>
<li>
<p>macOS: <a href="https://www.docker.com/products/docker-desktop" class="bare">https://www.docker.com/products/docker-desktop</a></p>
</li>
<li>
<p>Windows: <a href="https://www.docker.com/products/docker-desktop" class="bare">https://www.docker.com/products/docker-desktop</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Instalar Docker Desktop</p>
</li>
<li>
<p>Habilitar Kubernetes:</p>
<div class="ulist">
<ul>
<li>
<p>Abrir Docker Desktop</p>
</li>
<li>
<p>Settings/Preferences → Kubernetes</p>
</li>
<li>
<p>Marcar "Enable Kubernetes"</p>
</li>
<li>
<p>Click "Apply &amp; Restart"</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Integración nativa con Docker</p>
</li>
<li>
<p>Cluster de un solo nodo</p>
</li>
<li>
<p>kubectl incluido</p>
</li>
<li>
<p>Automáticamente configura kubeconfig</p>
</li>
<li>
<p>Fácil reset del cluster</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Configuración de recursos:</strong></p>
</div>
<div class="paragraph">
<p>En Docker Desktop Settings:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">Resources:
  CPUs: 4
  Memory: 8 GB
  Swap: 2 GB
  Disk: 64 GB</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Reset de Kubernetes:</strong></p>
</div>
<div class="paragraph">
<p>Si necesitas empezar desde cero:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Settings → Kubernetes → Reset Kubernetes Cluster</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Limitaciones:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Solo un nodo (no multi-nodo)</p>
</li>
<li>
<p>Menos flexible que otras opciones</p>
</li>
<li>
<p>Solo disponible en macOS y Windows</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_microk8s">MicroK8s</h5>
<div class="paragraph">
<p>MicroK8s es una distribución ligera de Kubernetes diseñada para IoT, edge computing y desarrollo. Es especialmente popular en Ubuntu.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="paragraph">
<p><strong>Linux (Ubuntu/Debian):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar usando snap
sudo snap install microk8s --classic

# Añadir usuario al grupo
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube

# Recargar grupos (o logout/login)
newgrp microk8s

# Verificar
microk8s status --wait-ready</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>macOS/Windows:</strong></p>
</div>
<div class="paragraph">
<p>MicroK8s usa Multipass para crear una VM:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># macOS
brew install ubuntu/microk8s/microk8s
microk8s install

# Windows - descargar desde:
# https://microk8s.io/docs/install-windows</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos útiles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Iniciar/Detener
microk8s start
microk8s stop

# Estado
microk8s status

# kubectl (prefijo microk8s)
microk8s kubectl get nodes

# O crear alias
alias kubectl='microk8s kubectl'

# Configurar kubeconfig para kubectl normal
microk8s config &gt; ~/.kube/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Addons:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Listar addons
microk8s enable --help

# Habilitar addons comunes
microk8s enable dns
microk8s enable dashboard
microk8s enable storage
microk8s enable ingress
microk8s enable registry
microk8s enable metrics-server

# Istio
microk8s enable istio

# Prometheus
microk8s enable prometheus</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>High Availability:</strong></p>
</div>
<div class="paragraph">
<p>MicroK8s soporta clustering:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En el primer nodo
microk8s add-node
# Esto genera un comando join

# En los nodos adicionales
microk8s join &lt;ip&gt;:&lt;port&gt;/&lt;token&gt;

# Ver nodos
microk8s kubectl get nodes</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_instalación_de_kubectl">1.4.2. Instalación de kubectl</h4>
<div class="paragraph">
<p>kubectl es la herramienta de línea de comandos para interactuar con clusters Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="paragraph">
<p><strong>Linux:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar última versión
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

# Validar binario (opcional)
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check

# Instalar
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Verificar
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>macOS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando Homebrew
brew install kubectl

# O usando binario
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/amd64/kubectl"
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl

# Verificar
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Windows:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-powershell hljs" data-lang="powershell"># Usando Chocolatey
choco install kubernetes-cli

# O usando Scoop
scoop install kubectl

# Verificar
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Autocompletado:</strong></p>
</div>
<div class="paragraph">
<p><strong>Bash:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar bash-completion primero (si no está)
sudo apt-get install bash-completion  # Debian/Ubuntu
sudo yum install bash-completion       # RHEL/CentOS

# Configurar autocompletado
echo 'source &lt;(kubectl completion bash)' &gt;&gt;~/.bashrc
echo 'alias k=kubectl' &gt;&gt;~/.bashrc
echo 'complete -o default -F __start_kubectl k' &gt;&gt;~/.bashrc

# Aplicar cambios
source ~/.bashrc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Zsh:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">echo 'source &lt;(kubectl completion zsh)' &gt;&gt;~/.zshrc
echo 'alias k=kubectl' &gt;&gt;~/.zshrc
echo 'compdef __start_kubectl k' &gt;&gt;~/.zshrc

source ~/.zshrc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Plugins útiles:</strong></p>
</div>
<div class="paragraph">
<p><strong>krew (plugin manager):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar krew
(
  set -x; cd "$(mktemp -d)" &amp;&amp;
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &amp;&amp;
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &amp;&amp;
  KREW="krew-${OS}_${ARCH}" &amp;&amp;
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &amp;&amp;
  tar zxvf "${KREW}.tar.gz" &amp;&amp;
  ./"${KREW}" install krew
)

# Añadir al PATH
export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"

# Instalar plugins útiles
kubectl krew install ctx      # Cambiar contextos
kubectl krew install ns       # Cambiar namespaces
kubectl krew install tree     # Ver recursos en árbol
kubectl krew install tail     # Tail logs de múltiples pods</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_del_archivo_kubeconfig">1.4.3. Configuración del archivo kubeconfig</h4>
<div class="paragraph">
<p>El archivo kubeconfig contiene la información necesaria para conectarse a clusters de Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Ubicación por defecto:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Linux/macOS: <code>~/.kube/config</code></p>
</li>
<li>
<p>Windows: <code>%USERPROFILE%\.kube\config</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Estructura del kubeconfig:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Config
current-context: minikube  # Contexto activo

# Clusters - información de conexión
clusters:
- cluster:
    certificate-authority: /path/to/ca.crt
    server: https://192.168.49.2:8443
  name: minikube

- cluster:
    certificate-authority-data: LS0tLS1CRUdJTi...
    server: https://production-cluster.example.com:6443
  name: production

# Users - credenciales de autenticación
users:
- name: minikube
  user:
    client-certificate: /path/to/client.crt
    client-key: /path/to/client.key

- name: admin-prod
  user:
    token: eyJhbGciOiJSUzI1NiIsImtpZCI6...

# Contexts - combinación de cluster + user + namespace
contexts:
- context:
    cluster: minikube
    user: minikube
    namespace: default
  name: minikube

- context:
    cluster: production
    user: admin-prod
    namespace: production
  name: prod-context</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gestionar contextos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver configuración actual
kubectl config view

# Ver configuración sin datos sensibles ocultos
kubectl config view --raw

# Listar clusters
kubectl config get-clusters

# Listar contextos
kubectl config get-contexts

# Ver contexto actual
kubectl config current-context

# Cambiar contexto
kubectl config use-context prod-context

# Crear nuevo contexto
kubectl config set-context dev-context \
  --cluster=minikube \
  --user=developer \
  --namespace=development

# Cambiar namespace del contexto actual
kubectl config set-context --current --namespace=kube-system

# Eliminar contexto
kubectl config delete-context old-context</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Múltiples archivos kubeconfig:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usar archivo específico
kubectl --kubeconfig=/path/to/custom-config get pods

# O configurar variable de entorno
export KUBECONFIG=/path/to/config1:/path/to/config2
# kubectl fusionará ambos archivos

# Hacer permanente
echo 'export KUBECONFIG=$HOME/.kube/config:$HOME/.kube/config-prod' &gt;&gt; ~/.bashrc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Añadir cluster manualmente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Añadir cluster
kubectl config set-cluster my-cluster \
  --server=https://k8s.example.com:6443 \
  --certificate-authority=/path/to/ca.crt

# 2. Añadir usuario
kubectl config set-credentials my-user \
  --client-certificate=/path/to/client.crt \
  --client-key=/path/to/client.key

# 3. Crear contexto
kubectl config set-context my-context \
  --cluster=my-cluster \
  --user=my-user \
  --namespace=default

# 4. Usar contexto
kubectl config use-context my-context</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_verificación_de_la_instalación">1.4.4. Verificación de la instalación</h4>
<div class="paragraph">
<p>Una vez instalado todo, verifica que funciona correctamente:</p>
</div>
<div class="paragraph">
<p><strong>1. Verificar kubectl:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Versión de cliente
kubectl version --client

# Salida esperada:
# Client Version: v1.28.0
# Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Verificar cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Versión de cliente y servidor
kubectl version

# Información del cluster
kubectl cluster-info

# Salida esperada:
# Kubernetes control plane is running at https://127.0.0.1:xxxxx
# CoreDNS is running at https://127.0.0.1:xxxxx/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Verificar nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get nodes

# Salida esperada:
# NAME       STATUS   ROLES           AGE   VERSION
# minikube   Ready    control-plane   5m    v1.28.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Verificar componentes del sistema:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get pods -n kube-system

# Deberías ver:
# - coredns
# - etcd
# - kube-apiserver
# - kube-controller-manager
# - kube-proxy
# - kube-scheduler</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Verificar namespaces:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get namespaces

# Salida esperada:
# NAME              STATUS   AGE
# default           Active   5m
# kube-node-lease   Active   5m
# kube-public       Active   5m
# kube-system       Active   5m</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>6. Prueba de despliegue:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear un deployment de prueba
kubectl create deployment nginx --image=nginx

# Esperar a que esté listo
kubectl wait --for=condition=available --timeout=60s deployment/nginx

# Verificar
kubectl get deployments
kubectl get pods

# Exponer como servicio
kubectl expose deployment nginx --port=80 --type=NodePort

# Ver servicio
kubectl get services nginx

# Limpiar
kubectl delete deployment nginx
kubectl delete service nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>7. Verificar acceso al dashboard (si está habilitado):</strong></p>
</div>
<div class="paragraph">
<p><strong>Minikube:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">minikube dashboard
# Abrirá el dashboard en el navegador</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Otros clusters:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar dashboard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

# Crear usuario admin para acceder
kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard
kubectl create clusterrolebinding dashboard-admin \
  --clusterrole=cluster-admin \
  --serviceaccount=kubernetes-dashboard:dashboard-admin

# Obtener token
kubectl -n kubernetes-dashboard create token dashboard-admin

# Iniciar proxy
kubectl proxy

# Acceder en:
# http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/
# Usar el token para login</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Troubleshooting común:</strong></p>
</div>
<div class="paragraph">
<p><strong>Problema: kubectl no encuentra el cluster</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar kubeconfig
echo $KUBECONFIG
kubectl config view

# Si está vacío, configurar
export KUBECONFIG=~/.kube/config

# O generar desde tu herramienta
minikube update-context
# o
kind export kubeconfig --name &lt;cluster-name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Connection refused al API server</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar que el cluster está corriendo
minikube status
# o
kind get clusters
# o
docker ps  # Ver contenedores de Kind

# Reiniciar si es necesario
minikube start
# o
kind create cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Permisos insuficientes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar contexto y usuario
kubectl config current-context
kubectl auth can-i get pods

# Ver permisos del usuario actual
kubectl auth can-i --list</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Recursos para verificación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Estado general del cluster
kubectl get all --all-namespaces

# Eventos del cluster (útil para debugging)
kubectl get events --all-namespaces --sort-by='.lastTimestamp'

# Información de recursos
kubectl top nodes    # Requiere metrics-server
kubectl top pods -A

# Verificar API resources disponibles
kubectl api-resources

# Verificar versiones de API
kubectl api-versions</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con esto, tienes un entorno de Kubernetes completamente funcional y verificado, listo para comenzar a aprender y desarrollar aplicaciones.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_2_trabajando_con_pods">2. Módulo 2: Trabajando con Pods</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_creación_y_gestión_de_pods">2.1. Creación y Gestión de Pods</h3>
<div class="paragraph">
<p>Los Pods son la unidad fundamental de despliegue en Kubernetes. En esta sección, aprenderemos cómo crear, gestionar y entender el ciclo de vida de los Pods.</p>
</div>
<div class="sect3">
<h4 id="_anatomía_de_un_pod">2.1.1. Anatomía de un Pod</h4>
<div class="paragraph">
<p>Un Pod encapsula uno o más contenedores, almacenamiento compartido (volúmenes), una dirección IP única y opciones que controlan cómo deben ejecutarse los contenedores.</p>
</div>
<div class="paragraph">
<p><strong>Estructura de un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────┐
│              POD (IP: 10.244.1.5)       │
│                                         │
│  ┌─────────────────┐  ┌──────────────┐ │
│  │   Container 1   │  │ Container 2  │ │
│  │                 │  │              │ │
│  │  App Process    │  │ Sidecar      │ │
│  │  Port: 8080     │  │ Port: 9090   │ │
│  │                 │  │              │ │
│  └────────┬────────┘  └──────┬───────┘ │
│           │                  │         │
│           └──────┬───────────┘         │
│                  │                     │
│         ┌────────▼────────┐            │
│         │  Shared Volume  │            │
│         │   (emptyDir)    │            │
│         └─────────────────┘            │
│                                         │
│  Network Namespace (localhost)          │
│  IPC Namespace                          │
│  UTS Namespace                          │
└─────────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Componentes principales de un Pod:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Metadata</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nombre único en el namespace</p>
</li>
<li>
<p>Labels y annotations</p>
</li>
<li>
<p>Namespace</p>
</li>
<li>
<p>UID generado automáticamente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Spec (Especificación)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Lista de contenedores</p>
</li>
<li>
<p>Volúmenes</p>
</li>
<li>
<p>Restart policy</p>
</li>
<li>
<p>DNS policy</p>
</li>
<li>
<p>Service account</p>
</li>
<li>
<p>Security context</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Status (Estado actual)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Phase (Pending, Running, Succeeded, Failed, Unknown)</p>
</li>
<li>
<p>Conditions</p>
</li>
<li>
<p>Container statuses</p>
</li>
<li>
<p>IP del Pod</p>
</li>
<li>
<p>Start time</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_manifiestos_yaml_para_pods">2.1.2. Manifiestos YAML para Pods</h4>
<div class="paragraph">
<p>Un manifiesto YAML describe el estado deseado de un Pod. Veamos ejemplos desde simple a complejo.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Pod básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1           # Versión de la API
kind: Pod                # Tipo de recurso
metadata:
  name: nginx-simple     # Nombre del Pod
  labels:
    app: nginx
    environment: dev
spec:
  containers:
  - name: nginx          # Nombre del contenedor
    image: nginx:1.21    # Imagen de contenedor
    ports:
    - containerPort: 80  # Puerto expuesto</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Pod con configuración de recursos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx-with-resources
  namespace: production
  labels:
    app: nginx
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
      protocol: TCP

    # Recursos solicitados y límites
    resources:
      requests:
        memory: "128Mi"    # Mínimo garantizado
        cpu: "250m"        # 0.25 CPU cores
      limits:
        memory: "256Mi"    # Máximo permitido
        cpu: "500m"        # 0.5 CPU cores

    # Variables de entorno
    env:
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Pod completo con health checks</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: webapp-complete
  labels:
    app: webapp
    version: "2.0"
  annotations:
    description: "Complete web application pod with health checks"
spec:
  # Contenedores
  containers:
  - name: webapp
    image: myapp:2.0
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP

    # Recursos
    resources:
      requests:
        memory: "256Mi"
        cpu: "500m"
      limits:
        memory: "512Mi"
        cpu: "1000m"

    # Variables de entorno
    env:
    - name: DATABASE_HOST
      value: "postgres.default.svc.cluster.local"
    - name: DATABASE_PORT
      value: "5432"

    # Liveness Probe - determina si el contenedor está vivo
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 30  # Espera antes del primer check
      periodSeconds: 10         # Frecuencia de checks
      timeoutSeconds: 5         # Timeout de cada check
      failureThreshold: 3       # Fallos antes de reiniciar

    # Readiness Probe - determina si el contenedor está listo para tráfico
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 2

    # Startup Probe - para aplicaciones con startup lento
    startupProbe:
      httpGet:
        path: /startup
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      failureThreshold: 30      # Permite hasta 300s para startup

    # Volume mounts
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
    - name: data
      mountPath: /var/data

  # Política de reinicio
  restartPolicy: Always  # Always, OnFailure, Never

  # DNS Policy
  dnsPolicy: ClusterFirst

  # Service Account
  serviceAccountName: webapp-sa

  # Security Context a nivel de Pod
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000

  # Volúmenes
  volumes:
  - name: config
    configMap:
      name: webapp-config
  - name: data
    emptyDir: {}

  # Node selector - programa en nodos específicos
  nodeSelector:
    disktype: ssd

  # Tolerations - permite scheduling en nodos con taints
  tolerations:
  - key: "environment"
    operator: "Equal"
    value: "production"
    effect: "NoSchedule"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Campos importantes del spec:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 50%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Campo</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Valores comunes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">containers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lista de contenedores en el Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Array de container specs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">restartPolicy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuándo reiniciar contenedores</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Always, OnFailure, Never</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nodeSelector</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selecciona nodos por labels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Map de key-value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">volumes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Volúmenes disponibles para el Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Array de volume specs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imagePullPolicy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuándo descargar la imagen</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Always, IfNotPresent, Never</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hostname</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hostname del Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">subdomain</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Subdomain del Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">dnsPolicy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Política de DNS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ClusterFirst, Default, None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">serviceAccountName</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service account a usar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">priority</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prioridad del Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">schedulerName</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scheduler custom</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_comandos_básicos_con_kubectl">2.1.3. Comandos básicos con kubectl</h4>
<div class="paragraph">
<p><strong>Crear Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear desde archivo YAML
kubectl apply -f pod.yaml

# Crear desde archivo con verbose output
kubectl apply -f pod.yaml -v=8

# Crear desde URL
kubectl apply -f https://example.com/pod.yaml

# Crear Pod imperativo (rápido para testing)
kubectl run nginx --image=nginx

# Con puerto expuesto
kubectl run webapp --image=myapp:1.0 --port=8080

# Con variables de entorno
kubectl run myapp --image=busybox --env="KEY=value" --env="ENV=prod"

# Modo dry-run (ver YAML sin crear)
kubectl run nginx --image=nginx --dry-run=client -o yaml

# Guardar YAML generado
kubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Listar Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Listar pods en namespace actual
kubectl get pods

# Listar con más información
kubectl get pods -o wide

# Todos los namespaces
kubectl get pods --all-namespaces
kubectl get pods -A

# Formato de salida específico
kubectl get pods -o yaml        # YAML completo
kubectl get pods -o json        # JSON completo
kubectl get pods -o name        # Solo nombres

# Mostrar labels
kubectl get pods --show-labels

# Filtrar por labels
kubectl get pods -l app=nginx
kubectl get pods -l 'environment in (prod,staging)'

# Watch mode (actualización continua)
kubectl get pods -w

# Ordenar por edad
kubectl get pods --sort-by=.metadata.creationTimestamp

# Custom columns
kubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,IP:.status.podIP</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver detalles de un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descripción completa
kubectl describe pod nginx

# Ver YAML completo
kubectl get pod nginx -o yaml

# Ver solo el spec
kubectl get pod nginx -o jsonpath='{.spec}'

# Ver status
kubectl get pod nginx -o jsonpath='{.status.phase}'

# Ver IP
kubectl get pod nginx -o jsonpath='{.status.podIP}'

# Ver condiciones
kubectl get pod nginx -o jsonpath='{.status.conditions[*].type}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Modificar Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Editar en editor
kubectl edit pod nginx

# Aplicar cambios desde archivo
kubectl apply -f pod-updated.yaml

# Patch específico
kubectl patch pod nginx -p '{"spec":{"containers":[{"name":"nginx","image":"nginx:1.22"}]}}'

# Patch desde archivo
kubectl patch pod nginx --patch-file patch.yaml

# Replace (elimina y recrea)
kubectl replace -f pod.yaml --force</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Eliminar Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Eliminar por nombre
kubectl delete pod nginx

# Eliminar desde archivo
kubectl delete -f pod.yaml

# Eliminar por label
kubectl delete pods -l app=nginx

# Eliminar todos los pods en namespace
kubectl delete pods --all

# Eliminar con grace period
kubectl delete pod nginx --grace-period=30

# Eliminar inmediatamente (forzar)
kubectl delete pod nginx --grace-period=0 --force

# Eliminar y esperar a que termine
kubectl delete pod nginx --wait=true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos de debugging:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs
kubectl logs nginx

# Logs de contenedor específico (si hay múltiples)
kubectl logs nginx -c container-name

# Seguir logs (tail -f)
kubectl logs -f nginx

# Logs previos (si el contenedor crasheó)
kubectl logs nginx --previous

# Últimas N líneas
kubectl logs nginx --tail=50

# Desde hace X tiempo
kubectl logs nginx --since=1h

# Ejecutar comando en contenedor
kubectl exec nginx -- ls /
kubectl exec nginx -- env

# Shell interactivo
kubectl exec -it nginx -- /bin/bash
kubectl exec -it nginx -- sh

# En contenedor específico
kubectl exec -it nginx -c sidecar -- /bin/bash

# Port forwarding
kubectl port-forward nginx 8080:80

# Copiar archivos
kubectl cp nginx:/etc/nginx/nginx.conf ./nginx.conf
kubectl cp ./local-file nginx:/tmp/remote-file</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ciclo_de_vida_de_un_pod">2.1.4. Ciclo de vida de un Pod</h4>
<div class="paragraph">
<p>El ciclo de vida de un Pod pasa por varias fases desde su creación hasta su terminación.</p>
</div>
<div class="paragraph">
<p><strong>Fases del ciclo de vida:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>    ┌─────────────┐
    │   PENDING   │ ← Pod creado, esperando scheduling
    └──────┬──────┘
           │
           ▼
    ┌─────────────┐
    │  RUNNING    │ ← Pod asignado a nodo, contenedores iniciados
    └──────┬──────┘
           │
           ├─────────────────┐
           │                 │
           ▼                 ▼
    ┌─────────────┐   ┌─────────────┐
    │  SUCCEEDED  │   │   FAILED    │
    └─────────────┘   └─────────────┘

    ┌─────────────┐
    │   UNKNOWN   │ ← Estado no puede determinarse
    └─────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Detalle de cada fase:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pending</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pod aceptado por Kubernetes</p>
</li>
<li>
<p>Esperando ser programado en un nodo</p>
</li>
<li>
<p>Descargando imágenes</p>
</li>
<li>
<p>Creando contenedores</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Running</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pod asignado a un nodo</p>
</li>
<li>
<p>Al menos un contenedor está ejecutándose</p>
</li>
<li>
<p>O está en proceso de iniciar/reiniciar</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Succeeded</strong></p>
<div class="ulist">
<ul>
<li>
<p>Todos los contenedores terminaron exitosamente</p>
</li>
<li>
<p>No se reiniciarán</p>
</li>
<li>
<p>Típico de Jobs</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Failed</strong></p>
<div class="ulist">
<ul>
<li>
<p>Todos los contenedores han terminado</p>
</li>
<li>
<p>Al menos uno terminó con error (exit code != 0)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Unknown</strong></p>
<div class="ulist">
<ul>
<li>
<p>Estado del Pod no puede determinarse</p>
</li>
<li>
<p>Generalmente por pérdida de comunicación con el nodo</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Estados de los contenedores:</strong></p>
</div>
<div class="paragraph">
<p>Dentro de un Pod, cada contenedor tiene su propio estado:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Waiting</strong></p>
<div class="ulist">
<ul>
<li>
<p>Esperando para iniciar</p>
</li>
<li>
<p>Descargando imagen</p>
</li>
<li>
<p>Aplicando Secrets</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Running</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ejecutándose sin problemas</p>
</li>
<li>
<p>PostStart hook completado (si existe)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Terminated</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ha terminado de ejecutarse</p>
</li>
<li>
<p>Ya sea exitosamente o con error</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo de verificación de fase:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver fase del Pod
kubectl get pod nginx -o jsonpath='{.status.phase}'

# Ver estado de contenedores
kubectl get pod nginx -o jsonpath='{.status.containerStatuses[*].state}'

# Ver razón si está en espera
kubectl get pod nginx -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}'</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_estados_de_los_pods">2.1.5. Estados de los Pods</h4>
<div class="paragraph">
<p>Los Pods pueden tener varias condiciones que describen su estado actual.</p>
</div>
<div class="paragraph">
<p><strong>Pod Conditions:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 50%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Condition</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Valores</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PodScheduled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod ha sido programado a un nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True, False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Initialized</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Init containers han completado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True, False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ContainersReady</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Todos los contenedores están listos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True, False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ready</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod puede servir requests</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True, False</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Estados comunes y su significado:</strong></p>
</div>
<div class="paragraph">
<p><strong>Running y Ready</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          5m

# Interpretación:
# - STATUS: Running = Pod ejecutándose
# - READY: 1/1 = 1 de 1 contenedores listo
# - RESTARTS: 0 = No ha tenido reinicios</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pending - ImagePullBackOff</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS             RESTARTS   AGE
webapp  0/1     ImagePullBackOff   0          2m

# Causa: No puede descargar la imagen
# Soluciones:
# - Verificar nombre de imagen
# - Verificar acceso al registry
# - Verificar imagePullSecrets</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pending - Insufficient resources</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS    RESTARTS   AGE
webapp  0/1     Pending   0          30s

# Ver razón:
kubectl describe pod webapp
# Events:
#   Warning  FailedScheduling  pod has unbound immediate PersistentVolumeClaims
#   Warning  FailedScheduling  0/3 nodes are available: insufficient cpu

# Causa: No hay nodos con recursos suficientes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CrashLoopBackOff</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS             RESTARTS   AGE
webapp  0/1     CrashLoopBackOff   5          10m

# Interpretación:
# - Contenedor inicia pero crashea inmediatamente
# - Kubernetes lo reinicia automáticamente
# - Backoff exponencial entre reintentos

# Debugging:
kubectl logs webapp
kubectl logs webapp --previous  # Ver logs del crash anterior
kubectl describe pod webapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Error - Failed</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS   RESTARTS   AGE
job-1   0/1     Error    0          1m

# Causa: Contenedor terminó con exit code != 0
# Ver logs para detalles
kubectl logs job-1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CreateContainerConfigError</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS                       RESTARTS   AGE
webapp  0/1     CreateContainerConfigError   0          1m

# Causa común:
# - ConfigMap o Secret referenciado no existe
# - Permisos incorrectos
kubectl describe pod webapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ErrImagePull</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS         RESTARTS   AGE
webapp  0/1     ErrImagePull   0          30s

# Causa: Error al descargar imagen
# - Imagen no existe
# - Registry no accesible
# - Credenciales incorrectas</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Evicted</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">NAME    READY   STATUS    RESTARTS   AGE
webapp  0/1     Evicted   0          1h

# Causa: Nodo sin recursos (memoria, disco)
# Pod fue desalojado para liberar recursos
# Ver razón:
kubectl get pod webapp -o jsonpath='{.status.reason}'
kubectl get pod webapp -o jsonpath='{.status.message}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Container Restart Reasons:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Ver razón de último reinicio
kubectl get pod webapp -o jsonpath='{.status.containerStatuses[0].lastState.terminated.reason}'

# Razones comunes:
# - Error: Exit code != 0
# - OOMKilled: Out of Memory
# - Completed: Exit code 0 (para Jobs)
# - ContainerCannotRun: Error al ejecutar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo completo de análisis de estado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado general
kubectl get pods

# Pod específico con detalles
kubectl describe pod problematic-pod

# Salida importante a revisar:
# ========================
# Status: Pending/Running/Failed
# Conditions:
#   Type              Status
#   Initialized       True
#   Ready             False    ← Pod no está listo
#   ContainersReady   False    ← Contenedores no están listos
#   PodScheduled      True
#
# Container States:
#   State:          Waiting
#     Reason:       CrashLoopBackOff  ← Razón del problema
#
# Events:  ← Eventos ordenados cronológicamente
#   Type     Reason     Message
#   Warning  BackOff    Back-off restarting failed container
#   Warning  Failed     Error: container exited with code 1

# Ver logs para entender el error
kubectl logs problematic-pod

# Si hay múltiples contenedores
kubectl logs problematic-pod -c container-name

# Ver logs del crash anterior
kubectl logs problematic-pod --previous</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estados de health checks:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Liveness Probe Failed
# Resultado: Kubernetes reinicia el contenedor

# Readiness Probe Failed
# Resultado: Pod removido de endpoints de Service
#            (no recibe tráfico pero sigue corriendo)

# Startup Probe Failed
# Resultado: Si falla después de failureThreshold,
#            contenedor se reinicia

# Ver estado de probes
kubectl describe pod webapp | grep -A 5 "Liveness\|Readiness\|Startup"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitoreo continuo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Watch pods en tiempo real
kubectl get pods -w

# Ver eventos en tiempo real
kubectl get events -w

# Ver pods con custom columns útiles
kubectl get pods -o custom-columns=\
NAME:.metadata.name,\
STATUS:.status.phase,\
READY:.status.conditions[?(@.type==\"Ready\")].status,\
RESTARTS:.status.containerStatuses[0].restartCount,\
AGE:.metadata.creationTimestamp

# Filtrar pods no healthy
kubectl get pods --field-selector=status.phase!=Running

# Ver pods con errores
kubectl get pods --field-selector=status.phase=Failed</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para gestión de Pods:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Siempre define recursos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Requests y limits para CPU y memoria</p>
</li>
<li>
<p>Previene OutOfMemory kills</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa health checks apropiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Liveness: detecta contenedores zombies</p>
</li>
<li>
<p>Readiness: controla tráfico</p>
</li>
<li>
<p>Startup: para apps con inicialización lenta</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura restart policies correctamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Always: para servicios de larga duración</p>
</li>
<li>
<p>OnFailure: para jobs</p>
</li>
<li>
<p>Never: para debugging</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa labels consistentemente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Facilita selección y organización</p>
</li>
<li>
<p>Importante para Services y Deployments</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No uses Pods directamente en producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa Deployments, StatefulSets, etc.</p>
</li>
<li>
<p>Pods directos no tienen auto-recuperación completa</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_pods_multi_contenedor">2.2. Pods Multi-contenedor</h3>
<div class="paragraph">
<p>Aunque la mayoría de los Pods contienen un solo contenedor, hay casos en los que múltiples contenedores deben ejecutarse juntos. Los Pods multi-contenedor permiten agrupar contenedores estrechamente acoplados que comparten recursos.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo usar múltiples contenedores?</strong></p>
</div>
<div class="paragraph">
<p>Usa múltiples contenedores en un Pod cuando:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Los contenedores DEBEN ejecutarse en el mismo nodo</p>
</li>
<li>
<p>Necesitan compartir el mismo ciclo de vida</p>
</li>
<li>
<p>Comparten volúmenes/recursos</p>
</li>
<li>
<p>Se comunican vía localhost</p>
</li>
<li>
<p>Uno extiende la funcionalidad del otro</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Si los contenedores pueden ejecutarse independientemente, usa Pods separados. Los Pods multi-contenedor son para contenedores estrechamente acoplados que forman una unidad lógica.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_patrones_de_diseño">2.2.1. Patrones de diseño</h4>
<div class="paragraph">
<p>Hay tres patrones principales para Pods multi-contenedor:</p>
</div>
<div class="sect4">
<h5 id="_patrón_sidecar">Patrón Sidecar</h5>
<div class="paragraph">
<p>El contenedor sidecar extiende y mejora el contenedor principal sin que este lo sepa.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Contenedor helper que agrega funcionalidad</p>
</li>
<li>
<p>Corre en paralelo con el contenedor principal</p>
</li>
<li>
<p>Comparte el mismo ciclo de vida</p>
</li>
<li>
<p>Casos de uso: logging, monitoring, proxies, adaptadores</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌────────────────────────────────────┐
│          POD                       │
│  ┌──────────────┐  ┌────────────┐ │
│  │   Main App   │  │  Sidecar   │ │
│  │              │  │            │ │
│  │ Escribe logs │─&gt;│Lee y envía │ │
│  │ a archivo    │  │logs        │ │
│  └──────────────┘  └────────────┘ │
│         │              │          │
│         └──────┬───────┘          │
│                │                  │
│         ┌──────▼──────┐           │
│         │   Volume    │           │
│         │   Shared    │           │
│         └─────────────┘           │
└────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Logging Sidecar</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: webserver-with-logging
spec:
  # Volumen compartido para logs
  volumes:
  - name: shared-logs
    emptyDir: {}

  containers:
  # Contenedor principal - servidor web
  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
    ports:
    - containerPort: 80

  # Sidecar - procesador de logs
  - name: log-shipper
    image: fluent/fluentd:v1.14
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
      readOnly: true
    env:
    - name: FLUENTD_CONF
      value: "fluent.conf"
    - name: FLUENT_ELASTICSEARCH_HOST
      value: "elasticsearch.logging.svc.cluster.local"
    - name: FLUENT_ELASTICSEARCH_PORT
      value: "9200"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Git Sync Sidecar</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-with-git-sync
spec:
  volumes:
  - name: html
    emptyDir: {}

  containers:
  # Contenedor principal - servidor web
  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html
      readOnly: true
    ports:
    - containerPort: 80

  # Sidecar - sincroniza contenido desde Git
  - name: git-sync
    image: k8s.gcr.io/git-sync:v3.1.6
    volumeMounts:
    - name: html
      mountPath: /tmp/git
    env:
    - name: GIT_SYNC_REPO
      value: "https://github.com/example/website.git"
    - name: GIT_SYNC_BRANCH
      value: "main"
    - name: GIT_SYNC_ROOT
      value: "/tmp/git"
    - name: GIT_SYNC_DEST
      value: "html"
    - name: GIT_SYNC_PERIOD
      value: "60s"  # Sincroniza cada 60s</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Monitoring Sidecar</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-monitoring
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
spec:
  containers:
  # Contenedor principal
  - name: application
    image: myapp:1.0
    ports:
    - containerPort: 8080
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"

  # Sidecar - exportador de métricas
  - name: metrics-exporter
    image: prom/statsd-exporter:v0.22.0
    ports:
    - name: metrics
      containerPort: 9090
    args:
    - --web.listen-address=:9090
    - --statsd.listen-udp=:8125
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_patrón_ambassador">Patrón Ambassador</h5>
<div class="paragraph">
<p>El contenedor ambassador actúa como proxy para el contenedor principal, simplificando su conexión con servicios externos.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Proxy que maneja la complejidad de red</p>
</li>
<li>
<p>Traduce/encapsula protocolos</p>
</li>
<li>
<p>Maneja conexiones externas</p>
</li>
<li>
<p>Casos de uso: proxy de DB, API gateways, service mesh</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────┐
│              POD                        │
│  ┌──────────────┐      ┌─────────────┐ │
│  │   Main App   │      │ Ambassador  │ │
│  │              │      │   Proxy     │ │
│  │ Conecta a   ─┼──────&gt;             │ │
│  │ localhost    │      │             │ │
│  └──────────────┘      └──────┬──────┘ │
│                               │        │
└───────────────────────────────┼────────┘
                                │
                                ▼
                    ┌───────────────────┐
                    │ External Service  │
                    │  (Base de Datos,  │
                    │   API, etc.)      │
                    └───────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Database Proxy Ambassador</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-db-proxy
spec:
  containers:
  # Contenedor principal - aplicación
  - name: application
    image: myapp:1.0
    env:
    # App se conecta a localhost (el ambassador)
    - name: DATABASE_HOST
      value: "127.0.0.1"
    - name: DATABASE_PORT
      value: "5432"
    ports:
    - containerPort: 8080

  # Ambassador - proxy de base de datos
  - name: cloudsql-proxy
    image: gcr.io/cloudsql-docker/gce-proxy:1.33.2
    command:
    - "/cloud_sql_proxy"
    - "-instances=my-project:us-central1:my-database=tcp:5432"
    - "-credential_file=/secrets/credentials.json"
    volumeMounts:
    - name: cloudsql-credentials
      mountPath: /secrets
      readOnly: true
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"

  volumes:
  - name: cloudsql-credentials
    secret:
      secretName: cloudsql-credentials</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Ambassador para Service Mesh</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-envoy
spec:
  containers:
  # Contenedor principal
  - name: application
    image: myapp:1.0
    ports:
    - containerPort: 8080
    env:
    # Todas las llamadas externas pasan por el proxy
    - name: HTTP_PROXY
      value: "http://127.0.0.1:8001"

  # Ambassador - Envoy proxy
  - name: envoy
    image: envoyproxy/envoy:v1.24.0
    ports:
    - containerPort: 8001  # Proxy port
    - containerPort: 9901  # Admin port
    volumeMounts:
    - name: envoy-config
      mountPath: /etc/envoy
    command:
    - "envoy"
    - "-c"
    - "/etc/envoy/envoy.yaml"
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"

  volumes:
  - name: envoy-config
    configMap:
      name: envoy-config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: API Rate Limiting Ambassador</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-rate-limiter
spec:
  containers:
  # Contenedor principal
  - name: api-server
    image: my-api:1.0
    ports:
    - containerPort: 8080

  # Ambassador - rate limiter
  - name: rate-limiter
    image: nginx:1.21
    ports:
    - containerPort: 80  # Puerto público
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/nginx.conf
      subPath: nginx.conf
    # NGINX configurado con rate limiting
    # Proxy pass a 127.0.0.1:8080

  volumes:
  - name: nginx-config
    configMap:
      name: nginx-rate-limit-config</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_patrón_adapter">Patrón Adapter</h5>
<div class="paragraph">
<p>El contenedor adapter transforma la salida del contenedor principal a un formato estándar.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Normaliza/estandariza outputs</p>
</li>
<li>
<p>Traduce formatos de datos</p>
</li>
<li>
<p>Casos de uso: normalizar logs, métricas, monitoreo</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌──────────────────────────────────────────┐
│               POD                        │
│  ┌──────────────┐     ┌──────────────┐  │
│  │   Main App   │     │   Adapter    │  │
│  │              │     │              │  │
│  │ Logs en     ─┼────&gt;│ Convierte a  │  │
│  │ formato      │     │ formato      │  │
│  │ custom       │     │ estándar     │  │
│  └──────────────┘     └──────┬───────┘  │
│                              │          │
└──────────────────────────────┼──────────┘
                               │
                               ▼
                    ┌──────────────────┐
                    │ Monitoring System│
                    │ (espera formato  │
                    │  estándar)       │
                    └──────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Log Format Adapter</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-log-adapter
spec:
  volumes:
  - name: logs
    emptyDir: {}

  containers:
  # Contenedor principal - genera logs en formato custom
  - name: application
    image: legacy-app:1.0
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
    # App escribe logs en formato propietario

  # Adapter - convierte logs a JSON estándar
  - name: log-adapter
    image: busybox:1.35
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
      readOnly: true
    command:
    - sh
    - -c
    - |
      tail -f /var/log/app/application.log | while read line; do
        # Convierte formato custom a JSON
        timestamp=$(echo $line | cut -d'|' -f1)
        level=$(echo $line | cut -d'|' -f2)
        message=$(echo $line | cut -d'|' -f3)
        echo "{\"timestamp\":\"$timestamp\",\"level\":\"$level\",\"message\":\"$message\"}"
      done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Metrics Format Adapter</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-metrics-adapter
spec:
  containers:
  # Contenedor principal - expone métricas en formato custom
  - name: application
    image: myapp:1.0
    ports:
    - containerPort: 8080  # App port
    - containerPort: 9999  # Custom metrics port

  # Adapter - convierte a formato Prometheus
  - name: metrics-adapter
    image: custom-metrics-adapter:1.0
    ports:
    - containerPort: 9090  # Prometheus metrics port
    env:
    - name: SOURCE_METRICS_URL
      value: "http://127.0.0.1:9999/metrics"
    - name: TARGET_FORMAT
      value: "prometheus"
    resources:
      requests:
        cpu: "50m"
        memory: "64Mi"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Protocol Adapter</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-protocol-adapter
spec:
  containers:
  # Contenedor principal - protocolo binario custom
  - name: legacy-service
    image: legacy-service:1.0
    ports:
    - containerPort: 9000
      protocol: TCP

  # Adapter - traduce a HTTP/REST
  - name: protocol-adapter
    image: protocol-adapter:1.0
    ports:
    - containerPort: 8080  # HTTP endpoint
    env:
    - name: BACKEND_HOST
      value: "127.0.0.1"
    - name: BACKEND_PORT
      value: "9000"
    - name: PROTOCOL
      value: "binary"
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_comunicación_entre_contenedores">2.2.2. Comunicación entre contenedores</h4>
<div class="paragraph">
<p>Los contenedores en un Pod comparten el mismo namespace de red, lo que facilita su comunicación.</p>
</div>
<div class="paragraph">
<p><strong>Métodos de comunicación:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Network - localhost</strong></p>
<div class="ulist">
<ul>
<li>
<p>Todos los contenedores comparten IP</p>
</li>
<li>
<p>Pueden comunicarse vía <code>127.0.0.1</code> o <code>localhost</code></p>
</li>
<li>
<p>No hay aislamiento de red entre contenedores del mismo Pod</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>IPC (Inter-Process Communication)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Shared memory</p>
</li>
<li>
<p>Semáforos</p>
</li>
<li>
<p>Message queues</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Volúmenes compartidos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Archivos</p>
</li>
<li>
<p>Sockets Unix</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Comunicación vía localhost</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: multi-container-communication
spec:
  containers:
  # Backend - escucha en puerto 8080
  - name: backend
    image: backend-api:1.0
    ports:
    - containerPort: 8080

  # Frontend - se conecta a localhost:8080
  - name: frontend
    image: frontend-app:1.0
    env:
    - name: BACKEND_URL
      value: "http://localhost:8080"  # Mismo Pod!
    ports:
    - containerPort: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Comunicación vía volumen compartido</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: shared-volume-communication
spec:
  volumes:
  - name: shared-data
    emptyDir: {}

  containers:
  # Producer - escribe datos
  - name: data-producer
    image: busybox:1.35
    volumeMounts:
    - name: shared-data
      mountPath: /data
    command:
    - sh
    - -c
    - |
      while true; do
        echo "$(date): New data" &gt;&gt; /data/stream.log
        sleep 5
      done

  # Consumer - lee datos
  - name: data-consumer
    image: busybox:1.35
    volumeMounts:
    - name: shared-data
      mountPath: /data
      readOnly: true
    command:
    - sh
    - -c
    - "tail -f /data/stream.log"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Comunicación vía Unix Socket</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: unix-socket-communication
spec:
  volumes:
  - name: socket-dir
    emptyDir: {}

  containers:
  # Server - crea socket Unix
  - name: socket-server
    image: socket-server:1.0
    volumeMounts:
    - name: socket-dir
      mountPath: /var/run/sockets
    command:
    - /app/server
    - --socket=/var/run/sockets/app.sock

  # Client - se conecta al socket
  - name: socket-client
    image: socket-client:1.0
    volumeMounts:
    - name: socket-dir
      mountPath: /var/run/sockets
    command:
    - /app/client
    - --socket=/var/run/sockets/app.sock</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Consideraciones de comunicación:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 40%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Método</th>
<th class="tableblock halign-left valign-top">Ventajas</th>
<th class="tableblock halign-left valign-top">Desventajas</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">localhost</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, rápido, sin overhead</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No funciona entre Pods</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Volúmenes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Persistencia, logs, archivos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">I/O más lento que red</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unix Sockets</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy rápido, bajo overhead</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo mismo Pod, requiere volumen</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shared Memory</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Extremadamente rápido</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complejo, requiere sincronización</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_volúmenes_compartidos">2.2.3. Volúmenes compartidos</h4>
<div class="paragraph">
<p>Los volúmenes permiten compartir datos entre contenedores en un Pod.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de volúmenes comunes para compartir:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>emptyDir</strong></p>
<div class="ulist">
<ul>
<li>
<p>Directorio vacío creado al iniciar el Pod</p>
</li>
<li>
<p>Destruido cuando el Pod termina</p>
</li>
<li>
<p>Puede ser en disco o memoria (RAM)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>configMap</strong></p>
<div class="ulist">
<ul>
<li>
<p>Configuración como archivos</p>
</li>
<li>
<p>Solo lectura</p>
</li>
<li>
<p>Compartir configuración</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>secret</strong></p>
<div class="ulist">
<ul>
<li>
<p>Datos sensibles como archivos</p>
</li>
<li>
<p>Solo lectura</p>
</li>
<li>
<p>Compartir credenciales</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>persistentVolumeClaim</strong></p>
<div class="ulist">
<ul>
<li>
<p>Almacenamiento persistente</p>
</li>
<li>
<p>Sobrevive reinicios del Pod</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: emptyDir para datos temporales</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: shared-emptydir
spec:
  volumes:
  - name: cache
    emptyDir: {}

  containers:
  - name: writer
    image: busybox:1.35
    volumeMounts:
    - name: cache
      mountPath: /cache
    command:
    - sh
    - -c
    - |
      while true; do
        echo "Writing to cache at $(date)" &gt; /cache/data.txt
        sleep 10
      done

  - name: reader
    image: busybox:1.35
    volumeMounts:
    - name: cache
      mountPath: /cache
      readOnly: true
    command:
    - sh
    - -c
    - "while true; do cat /cache/data.txt; sleep 5; done"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: emptyDir en memoria (para alta velocidad)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: memory-cache
spec:
  volumes:
  - name: cache
    emptyDir:
      medium: Memory  # Usa RAM en lugar de disco
      sizeLimit: 1Gi  # Límite de 1GB

  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: cache
      mountPath: /tmp/cache
    resources:
      limits:
        memory: "2Gi"  # Debe ser &gt; sizeLimit del volumen</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: ConfigMap compartido</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: shared-config
data:
  app.conf: |
    server_name=example.com
    port=8080
    debug=false
  nginx.conf: |
    worker_processes 2;
    events { worker_connections 1024; }
---
apiVersion: v1
kind: Pod
metadata:
  name: shared-configmap
spec:
  volumes:
  - name: config
    configMap:
      name: shared-config

  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
    command:
    - /app/server
    - --config=/etc/config/app.conf

  - name: nginx
    image: nginx:1.21
    volumeMounts:
    - name: config
      mountPath: /etc/nginx
      readOnly: true
    # Usa nginx.conf del ConfigMap</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 4: Patrón completo - Web app con logging</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: webapp-with-sidecar-logging
  labels:
    app: webapp
spec:
  # Volúmenes compartidos
  volumes:
  # Logs compartidos
  - name: app-logs
    emptyDir: {}
  # Configuración
  - name: app-config
    configMap:
      name: webapp-config
  # Datos persistentes
  - name: data
    persistentVolumeClaim:
      claimName: webapp-pvc

  containers:
  # Contenedor principal - Web Application
  - name: webapp
    image: webapp:2.0
    ports:
    - containerPort: 8080

    # Monta todos los volúmenes
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
    - name: app-config
      mountPath: /etc/config
      readOnly: true
    - name: data
      mountPath: /var/data

    # Recursos
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"

    # Health checks
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10

    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5

  # Sidecar - Log Shipper
  - name: log-shipper
    image: fluentd:v1.14
    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true

    env:
    - name: FLUENT_ELASTICSEARCH_HOST
      value: "elasticsearch.logging.svc.cluster.local"
    - name: FLUENT_ELASTICSEARCH_PORT
      value: "9200"

    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "200m"
        memory: "256Mi"

  # Sidecar - Metrics Exporter
  - name: metrics-exporter
    image: prometheus-exporter:1.0
    ports:
    - name: metrics
      containerPort: 9090

    volumeMounts:
    - name: app-logs
      mountPath: /var/log/app
      readOnly: true

    resources:
      requests:
        cpu: "50m"
        memory: "64Mi"
      limits:
        cpu: "100m"
        memory: "128Mi"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para Pods Multi-contenedor:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Mantén sidecars ligeros</strong></p>
<div class="ulist">
<ul>
<li>
<p>Limita CPU y memoria</p>
</li>
<li>
<p>Evita sobrecarga innecesaria</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Define recursos para TODOS los contenedores</strong></p>
<div class="ulist">
<ul>
<li>
<p>Requests y limits individuales</p>
</li>
<li>
<p>El total cuenta para scheduling</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa volúmenes apropiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>emptyDir para datos temporales</p>
</li>
<li>
<p>ConfigMaps para configuración</p>
</li>
<li>
<p>Secrets para credenciales</p>
</li>
<li>
<p>PVC para datos persistentes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Considera el orden de inicio</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa init containers si necesitas orden estricto</p>
</li>
<li>
<p>Sidecars inician en paralelo con el main</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Health checks individuales</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada contenedor debe tener sus propios probes</p>
</li>
<li>
<p>Un contenedor fallido afecta todo el Pod</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Logging y debugging</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa nombres descriptivos para contenedores</p>
</li>
<li>
<p>Especifica <code>-c container-name</code> en comandos kubectl</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_init_containers">2.3. Init Containers</h3>
<div class="paragraph">
<p>Los Init Containers son contenedores especializados que se ejecutan ANTES de que los contenedores principales de la aplicación inicien. Son útiles para tareas de inicialización y setup.</p>
</div>
<div class="sect3">
<h4 id="_propósito_y_casos_de_uso">2.3.1. Propósito y casos de uso</h4>
<div class="paragraph">
<p><strong>Características de los Init Containers:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se ejecutan hasta completarse antes de que los contenedores principales inicien</p>
</li>
<li>
<p>Se ejecutan en orden secuencial (uno tras otro)</p>
</li>
<li>
<p>Si uno falla, Kubernetes reinicia el Pod</p>
</li>
<li>
<p>Tienen su propia imagen, recursos y configuración</p>
</li>
<li>
<p>Comparten volúmenes con los contenedores principales</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diferencias con contenedores regulares:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 40%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Init Containers</th>
<th class="tableblock halign-left valign-top">Contenedores Principales</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecución</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secuencial, antes de los principales</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Paralelo, después de init containers</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ciclo de vida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecuta hasta completarse y termina</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Corre continuamente (generalmente)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recursos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Puede usar más recursos temporalmente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recursos persistentes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Probes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No soporta liveness, readiness</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Soporta todos los probes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reinicio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reinicia en orden si falla</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reinicia según restartPolicy</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Casos de uso comunes:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Esperar dependencias</strong></p>
<div class="ulist">
<ul>
<li>
<p>Esperar a que una base de datos esté lista</p>
</li>
<li>
<p>Verificar que servicios externos estén disponibles</p>
</li>
<li>
<p>Comprobar precondiciones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Setup de configuración</strong></p>
<div class="ulist">
<ul>
<li>
<p>Generar archivos de configuración</p>
</li>
<li>
<p>Procesar templates</p>
</li>
<li>
<p>Descargar configuración desde servicios externos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Clonar repositorios</strong></p>
<div class="ulist">
<ul>
<li>
<p>Git clone de código/configuración</p>
</li>
<li>
<p>Descargar assets/recursos</p>
</li>
<li>
<p>Preparar contenido estático</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Registrar el Pod</strong></p>
<div class="ulist">
<ul>
<li>
<p>Registrar en service discovery</p>
</li>
<li>
<p>Actualizar load balancers</p>
</li>
<li>
<p>Notificar sistemas externos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad y permisos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cambiar permisos de archivos</p>
</li>
<li>
<p>Generar certificados</p>
</li>
<li>
<p>Configurar secrets</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Migraciones de base de datos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ejecutar scripts de migración</p>
</li>
<li>
<p>Verificar esquema</p>
</li>
<li>
<p>Seed de datos iniciales</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_de_init_containers">2.3.2. Configuración de init containers</h4>
<div class="paragraph">
<p><strong>Sintaxis básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
spec:
  # Init containers se definen aquí
  initContainers:
  - name: init-myservice
    image: busybox:1.35
    command: ['sh', '-c', 'echo Init container 1']

  - name: init-mydb
    image: busybox:1.35
    command: ['sh', '-c', 'echo Init container 2']

  # Contenedores principales
  containers:
  - name: myapp-container
    image: myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Esperar a que un servicio esté disponible</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: myapp-with-init
spec:
  initContainers:
  # Espera a que el servicio MySQL esté disponible
  - name: wait-for-mysql
    image: busybox:1.35
    command:
    - 'sh'
    - '-c'
    - |
      echo "Waiting for MySQL to be ready..."
      until nslookup mysql.default.svc.cluster.local; do
        echo "MySQL not ready yet, waiting..."
        sleep 2
      done
      echo "MySQL is ready!"

  # Espera a que el servicio Redis esté disponible
  - name: wait-for-redis
    image: busybox:1.35
    command:
    - 'sh'
    - '-c'
    - |
      echo "Waiting for Redis..."
      until nslookup redis.default.svc.cluster.local; do
        echo "Redis not ready, waiting..."
        sleep 2
      done
      echo "Redis is ready!"

  # Contenedor principal
  containers:
  - name: myapp
    image: myapp:1.0
    env:
    - name: MYSQL_HOST
      value: "mysql.default.svc.cluster.local"
    - name: REDIS_HOST
      value: "redis.default.svc.cluster.local"
    ports:
    - containerPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Clonar repositorio Git</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-with-git-init
spec:
  # Volumen compartido
  volumes:
  - name: workdir
    emptyDir: {}

  initContainers:
  # Clona el repositorio
  - name: git-clone
    image: alpine/git:latest
    args:
    - clone
    - --single-branch
    - --branch=main
    - https://github.com/example/website.git
    - /work-dir
    volumeMounts:
    - name: workdir
      mountPath: /work-dir

  # Instala dependencias
  - name: install-deps
    image: node:18-alpine
    workingDir: /work-dir
    command:
    - npm
    - install
    volumeMounts:
    - name: workdir
      mountPath: /work-dir

  # Construye la aplicación
  - name: build
    image: node:18-alpine
    workingDir: /work-dir
    command:
    - npm
    - run
    - build
    volumeMounts:
    - name: workdir
      mountPath: /work-dir

  # Contenedor principal
  containers:
  - name: web-server
    image: nginx:1.21
    volumeMounts:
    - name: workdir
      mountPath: /usr/share/nginx/html
      subPath: dist  # Usa solo el directorio dist
    ports:
    - containerPort: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Generar configuración</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-generated-config
spec:
  volumes:
  - name: config
    emptyDir: {}
  - name: config-template
    configMap:
      name: app-config-template

  initContainers:
  # Genera configuración desde template
  - name: generate-config
    image: busybox:1.35
    volumeMounts:
    - name: config-template
      mountPath: /templates
    - name: config
      mountPath: /config
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    command:
    - sh
    - -c
    - |
      # Reemplaza variables en template
      sed -e "s/\${POD_NAME}/$POD_NAME/g" \
          -e "s/\${POD_NAMESPACE}/$POD_NAMESPACE/g" \
          -e "s/\${POD_IP}/$POD_IP/g" \
          /templates/app.conf.template &gt; /config/app.conf
      echo "Configuration generated:"
      cat /config/app.conf

  containers:
  - name: application
    image: myapp:1.0
    volumeMounts:
    - name: config
      mountPath: /etc/config
    command:
    - /app/server
    - --config=/etc/config/app.conf</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 4: Migración de base de datos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-db-migration
spec:
  initContainers:
  # Ejecuta migraciones de base de datos
  - name: db-migration
    image: migrate/migrate:v4.15.2
    command:
    - migrate
    - -path=/migrations
    - -database=postgres://user:password@postgres:5432/mydb?sslmode=disable
    - up
    volumeMounts:
    - name: migrations
      mountPath: /migrations
    env:
    - name: DB_HOST
      value: "postgres.default.svc.cluster.local"
    - name: DB_PORT
      value: "5432"
    - name: DB_NAME
      value: "mydb"
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: username
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: password

  containers:
  - name: application
    image: myapp:1.0
    env:
    - name: DATABASE_URL
      value: "postgres://$(DB_USER):$(DB_PASSWORD)@$(DB_HOST):$(DB_PORT)/$(DB_NAME)"
    ports:
    - containerPort: 8080

  volumes:
  - name: migrations
    configMap:
      name: db-migrations</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 5: Cambiar permisos y ownership</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-volume-permissions
spec:
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: app-data

  initContainers:
  # Configura permisos correctos
  - name: fix-permissions
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "Fixing permissions on /data..."
      chown -R 1000:1000 /data
      chmod -R 755 /data
      echo "Permissions fixed!"
    volumeMounts:
    - name: data
      mountPath: /data
    securityContext:
      runAsUser: 0  # Necesita root para cambiar ownership

  containers:
  - name: application
    image: myapp:1.0
    volumeMounts:
    - name: data
      mountPath: /var/app/data
    securityContext:
      runAsUser: 1000  # App corre como usuario 1000
      runAsGroup: 1000</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 6: Verificar precondiciones</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-health-check
spec:
  initContainers:
  # Verifica que la API externa esté disponible
  - name: check-api
    image: curlimages/curl:latest
    command:
    - sh
    - -c
    - |
      echo "Checking external API health..."
      max_attempts=30
      attempt=0

      until [ $attempt -eq $max_attempts ]; do
        if curl -f https://api.example.com/health; then
          echo "API is healthy!"
          exit 0
        fi
        echo "API not ready, attempt $((attempt+1))/$max_attempts"
        sleep 10
        attempt=$((attempt+1))
      done

      echo "API failed health check after $max_attempts attempts"
      exit 1

  # Verifica conectividad de base de datos
  - name: check-database
    image: postgres:14-alpine
    command:
    - sh
    - -c
    - |
      echo "Checking database connectivity..."
      until pg_isready -h $DB_HOST -p $DB_PORT -U $DB_USER; do
        echo "Database not ready, waiting..."
        sleep 3
      done
      echo "Database is ready!"
    env:
    - name: DB_HOST
      value: "postgres.default.svc.cluster.local"
    - name: DB_PORT
      value: "5432"
    - name: DB_USER
      value: "myapp"
    - name: PGPASSWORD
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: password

  containers:
  - name: application
    image: myapp:1.0
    env:
    - name: DATABASE_URL
      value: "postgres://myapp@postgres.default.svc.cluster.local:5432/mydb"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 7: Descargar certificados</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-certs
spec:
  volumes:
  - name: certs
    emptyDir: {}

  initContainers:
  # Descarga certificados desde Vault
  - name: fetch-certificates
    image: vault:1.12.0
    command:
    - sh
    - -c
    - |
      # Autentica con Vault
      vault login -method=kubernetes role=myapp

      # Descarga certificados
      vault read -field=certificate secret/certs/myapp &gt; /certs/tls.crt
      vault read -field=key secret/certs/myapp &gt; /certs/tls.key
      vault read -field=ca secret/certs/ca &gt; /certs/ca.crt

      # Configura permisos
      chmod 600 /certs/tls.key
      chmod 644 /certs/tls.crt /certs/ca.crt

      echo "Certificates downloaded successfully"
    volumeMounts:
    - name: certs
      mountPath: /certs
    env:
    - name: VAULT_ADDR
      value: "https://vault.default.svc.cluster.local:8200"

  containers:
  - name: application
    image: myapp:1.0
    volumeMounts:
    - name: certs
      mountPath: /etc/ssl/certs
      readOnly: true
    env:
    - name: TLS_CERT_FILE
      value: "/etc/ssl/certs/tls.crt"
    - name: TLS_KEY_FILE
      value: "/etc/ssl/certs/tls.key"
    - name: CA_CERT_FILE
      value: "/etc/ssl/certs/ca.crt"
    ports:
    - containerPort: 8443</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_orden_de_ejecución">2.3.3. Orden de ejecución</h4>
<div class="paragraph">
<p>Los init containers se ejecutan en un orden muy específico, que es crucial para entender su comportamiento.</p>
</div>
<div class="paragraph">
<p><strong>Flujo de ejecución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Pod creado
    │
    ▼
Scheduler asigna Pod a nodo
    │
    ▼
Kubelet descarga imágenes
    │
    ▼
┌───────────────────────────────┐
│ INIT CONTAINERS (secuencial)  │
│                               │
│  ┌────────────────────┐       │
│  │ Init Container 1   │       │
│  │ (debe completarse) │       │
│  └─────────┬──────────┘       │
│            │ ✓ Success        │
│            ▼                  │
│  ┌────────────────────┐       │
│  │ Init Container 2   │       │
│  │ (debe completarse) │       │
│  └─────────┬──────────┘       │
│            │ ✓ Success        │
│            ▼                  │
│  ┌────────────────────┐       │
│  │ Init Container N   │       │
│  │ (debe completarse) │       │
│  └─────────┬──────────┘       │
│            │ ✓ Success        │
└────────────┼──────────────────┘
             │
             ▼
┌───────────────────────────────┐
│ MAIN CONTAINERS (paralelo)    │
│                               │
│  ┌────────┐  ┌────────┐       │
│  │ Main 1 │  │ Main 2 │       │
│  └────────┘  └────────┘       │
│  (corren simultáneamente)      │
└───────────────────────────────┘
             │
             ▼
          Pod Running</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Reglas de ejecución:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Orden secuencial estricto</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los init containers se ejecutan uno a la vez</p>
</li>
<li>
<p>El siguiente no inicia hasta que el anterior complete exitosamente</p>
</li>
<li>
<p>Si uno falla, los siguientes no se ejecutan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Debe completarse exitosamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada init container debe terminar con exit code 0</p>
</li>
<li>
<p>Si falla (exit code != 0), Kubernetes reinicia el Pod</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Reintentos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Si un init container falla, el Pod se reinicia</p>
</li>
<li>
<p>Todos los init containers se ejecutan de nuevo desde el principio</p>
</li>
<li>
<p>Sigue la <code>restartPolicy</code> del Pod</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Recursos compartidos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Todos los init containers y main containers comparten volúmenes</p>
</li>
<li>
<p>Los cambios hechos por init containers persisten</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ejemplo con logging de orden:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: init-order-demo
spec:
  initContainers:
  - name: init-1
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "$(date): Init container 1 starting"
      sleep 5
      echo "$(date): Init container 1 completed"

  - name: init-2
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "$(date): Init container 2 starting"
      sleep 5
      echo "$(date): Init container 2 completed"

  - name: init-3
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "$(date): Init container 3 starting"
      sleep 5
      echo "$(date): Init container 3 completed"

  containers:
  - name: main-app
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      echo "$(date): Main container starting"
      echo "All init containers have completed!"
      sleep 3600

# Ver el orden de ejecución:
# kubectl logs init-order-demo -c init-1
# kubectl logs init-order-demo -c init-2
# kubectl logs init-order-demo -c init-3
# kubectl logs init-order-demo -c main-app</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitorear init containers:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver status de init containers
kubectl describe pod myapp-pod

# Salida muestra:
# Init Containers:
#   init-myservice:
#     State:      Terminated
#       Reason:   Completed
#       Exit Code: 0
#   init-mydb:
#     State:      Running
#       Started:  ...

# Ver logs de init container específico
kubectl logs myapp-pod -c init-myservice

# Ver logs de todos los init containers
kubectl logs myapp-pod --all-containers=true --prefix=true

# Ver eventos para troubleshooting
kubectl get events --field-selector involvedObject.name=myapp-pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de manejo de fallos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: init-failure-handling
spec:
  restartPolicy: Always  # Reinicia automáticamente en caso de fallo

  initContainers:
  # Este init container podría fallar
  - name: check-dependency
    image: busybox:1.35
    command:
    - sh
    - -c
    - |
      max_retries=10
      retry_interval=5

      for i in $(seq 1 $max_retries); do
        echo "Attempt $i/$max_retries to connect to service..."

        if nslookup my-service.default.svc.cluster.local; then
          echo "Service found!"
          exit 0
        fi

        if [ $i -eq $max_retries ]; then
          echo "Failed after $max_retries attempts"
          exit 1
        fi

        echo "Service not found, waiting $retry_interval seconds..."
        sleep $retry_interval
      done

  containers:
  - name: app
    image: myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para Init Containers:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Mantén init containers ligeros</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa imágenes pequeñas (busybox, alpine)</p>
</li>
<li>
<p>Solo realiza tareas necesarias</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa timeouts</strong></p>
<div class="ulist">
<ul>
<li>
<p>No esperes indefinidamente</p>
</li>
<li>
<p>Falla rápido si algo está mal</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Logging detallado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Log cada paso importante</p>
</li>
<li>
<p>Facilita debugging</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Idempotencia</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los init containers deben poder ejecutarse múltiples veces</p>
</li>
<li>
<p>Deben producir el mismo resultado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Minimiza dependencias</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cuantos menos init containers, mejor</p>
</li>
<li>
<p>Agrupa tareas relacionadas si es posible</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Recursos apropiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Define requests/limits</p>
</li>
<li>
<p>Init containers pueden usar más recursos temporalmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Manejo de errores</strong></p>
<div class="ulist">
<ul>
<li>
<p>Exit codes apropiados (0 = éxito, != 0 = fallo)</p>
</li>
<li>
<p>Logs descriptivos de errores</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_debugging_y_troubleshooting">2.4. Debugging y Troubleshooting</h3>
<div class="paragraph">
<p>El debugging de Pods es una habilidad esencial para cualquier desarrollador o administrador de Kubernetes. Esta sección cubre las técnicas y herramientas más importantes.</p>
</div>
<div class="sect3">
<h4 id="_logs_de_contenedores">2.4.1. Logs de contenedores</h4>
<div class="paragraph">
<p>Los logs son la primera herramienta para diagnosticar problemas en Pods.</p>
</div>
<div class="paragraph">
<p><strong>Comandos básicos de logs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs de un Pod (si solo tiene un contenedor)
kubectl logs pod-name

# Ver logs de contenedor específico
kubectl logs pod-name -c container-name

# Seguir logs en tiempo real (similar a tail -f)
kubectl logs -f pod-name

# Ver logs de un contenedor anterior (si crasheó)
kubectl logs pod-name --previous

# Últimas N líneas
kubectl logs pod-name --tail=100

# Logs desde hace X tiempo
kubectl logs pod-name --since=10m
kubectl logs pod-name --since=1h
kubectl logs pod-name --since=2024-01-15T10:00:00Z

# Logs con timestamps
kubectl logs pod-name --timestamps

# Logs de todos los contenedores en el Pod
kubectl logs pod-name --all-containers=true

# Con prefijo del nombre del contenedor
kubectl logs pod-name --all-containers=true --prefix=true

# Combinar múltiples opciones
kubectl logs pod-name --tail=50 --timestamps --since=1h -f</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de logs con múltiples contenedores:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver qué contenedores tiene el Pod
kubectl get pod myapp -o jsonpath='{.spec.containers[*].name}'

# Ver logs de cada contenedor
kubectl logs myapp -c webapp
kubectl logs myapp -c sidecar
kubectl logs myapp -c init-container --previous

# Ver logs de todos con prefijos
kubectl logs myapp --all-containers=true --prefix=true --tail=20</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Troubleshooting con logs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Caso 1: CrashLoopBackOff - ver por qué crashea
kubectl logs crashing-pod --previous

# Caso 2: Pod no inicia - ver init containers
kubectl describe pod stuck-pod
kubectl logs stuck-pod -c init-container-name

# Caso 3: Errores intermitentes - seguir en tiempo real
kubectl logs problematic-pod -f | grep ERROR

# Caso 4: Filtrar logs para búsqueda específica
kubectl logs myapp | grep "database connection"
kubectl logs myapp --since=30m | grep -i error

# Caso 5: Guardar logs para análisis
kubectl logs myapp --all-containers=true &gt; pod-logs.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Limitaciones de kubectl logs:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Solo muestra logs de stdout/stderr</p>
</li>
<li>
<p>No persiste logs de Pods eliminados</p>
</li>
<li>
<p>Limitado a logs del contenedor actual y anterior</p>
</li>
<li>
<p>Para logs históricos, usa sistemas de agregación (ELK, Loki, etc.)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_ejecución_de_comandos_en_pods">2.4.2. Ejecución de comandos en Pods</h4>
<div class="paragraph">
<p>Ejecutar comandos dentro de contenedores es fundamental para debugging interactivo.</p>
</div>
<div class="paragraph">
<p><strong>kubectl exec:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ejecutar comando simple
kubectl exec pod-name -- ls -la /app

# Ver variables de entorno
kubectl exec pod-name -- env

# Ver procesos
kubectl exec pod-name -- ps aux

# Ver conectividad de red
kubectl exec pod-name -- ping google.com
kubectl exec pod-name -- nslookup mysql.default.svc.cluster.local
kubectl exec pod-name -- curl http://api-service:8080/health

# En contenedor específico
kubectl exec pod-name -c container-name -- command

# Shell interactivo (bash)
kubectl exec -it pod-name -- /bin/bash

# Shell interactivo (sh si no hay bash)
kubectl exec -it pod-name -- /bin/sh

# Shell en contenedor específico
kubectl exec -it pod-name -c sidecar -- /bin/bash

# Ejecutar script
kubectl exec pod-name -- /bin/bash -c "echo 'Script commands here'"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplos prácticos de debugging:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar archivos de configuración
kubectl exec myapp -- cat /etc/config/app.conf

# 2. Verificar permisos de archivos
kubectl exec myapp -- ls -la /var/data

# 3. Verificar espacio en disco
kubectl exec myapp -- df -h

# 4. Verificar memoria
kubectl exec myapp -- free -m

# 5. Ver logs de aplicación dentro del contenedor
kubectl exec myapp -- tail -f /var/log/app/application.log

# 6. Probar conectividad a base de datos
kubectl exec myapp -- nc -zv mysql.default.svc.cluster.local 3306

# 7. Verificar DNS
kubectl exec myapp -- nslookup kubernetes.default
kubectl exec myapp -- cat /etc/resolv.conf

# 8. Verificar procesos
kubectl exec myapp -- ps aux | grep java

# 9. Instalar herramientas de debugging (temporal)
kubectl exec -it myapp -- sh
  apk add curl  # En Alpine Linux
  apt-get update &amp;&amp; apt-get install -y curl  # En Debian/Ubuntu
  yum install -y curl  # En RHEL/CentOS

# 10. Verificar montaje de volúmenes
kubectl exec myapp -- mount | grep /var/data</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Debugging interactivo avanzado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Sesión interactiva completa
kubectl exec -it myapp -- /bin/bash

# Dentro del contenedor:
&gt; whoami
&gt; pwd
&gt; env | grep DATABASE
&gt; cat /proc/1/environ | tr '\0' '\n'  # Variables del proceso principal
&gt; netstat -tulpn  # Puertos en escucha
&gt; ss -tulpn  # Alternativa moderna a netstat
&gt; lsof -i :8080  # Ver qué usa el puerto 8080
&gt; curl localhost:8080/health
&gt; top  # Ver uso de recursos
&gt; strace -p 1  # Trace del proceso principal (requiere privilegios)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Limitaciones de kubectl exec:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Requiere que el contenedor esté corriendo</p>
</li>
<li>
<p>No funciona en contenedores terminados</p>
</li>
<li>
<p>Algunas imágenes mínimas no tienen shell (busybox, scratch)</p>
</li>
<li>
<p>Puede requerir permisos adicionales según el securityContext</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_port_forwarding">2.4.3. Port-forwarding</h4>
<div class="paragraph">
<p>Port-forwarding permite acceder a puertos de Pods sin exponer Services.</p>
</div>
<div class="paragraph">
<p><strong>Sintaxis básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Forward puerto del Pod a localhost
kubectl port-forward pod/pod-name 8080:80

# Especificar puerto local diferente
kubectl port-forward pod/nginx 8888:80

# Múltiples puertos
kubectl port-forward pod/myapp 8080:80 9090:9000

# Forward de Service
kubectl port-forward service/myapp 8080:80

# Forward de Deployment
kubectl port-forward deployment/myapp 8080:8080

# Escuchar en todas las interfaces (por defecto solo localhost)
kubectl port-forward --address 0.0.0.0 pod/myapp 8080:80

# Especificar namespace
kubectl port-forward -n production pod/myapp 8080:80

# Forward en background (requiere &amp; al final)
kubectl port-forward pod/myapp 8080:80 &gt; /dev/null 2&gt;&amp;1 &amp;</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Casos de uso:</strong></p>
</div>
<div class="paragraph">
<p><strong>1. Acceder a aplicación web:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Forward puerto de app web
kubectl port-forward pod/webapp 8080:80

# Abrir en navegador
open http://localhost:8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Acceder a base de datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Forward puerto de PostgreSQL
kubectl port-forward pod/postgres-0 5432:5432

# Conectar con cliente local
psql -h localhost -p 5432 -U myuser -d mydb

# O con otra herramienta
pgcli postgresql://user:pass@localhost:5432/mydb</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Debugging de API:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Forward API
kubectl port-forward pod/api-server 8080:8080

# Probar endpoints
curl http://localhost:8080/health
curl http://localhost:8080/api/v1/users

# Con Postman/Insomnia
# URL: http://localhost:8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Acceder a Prometheus/Grafana:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Prometheus
kubectl port-forward -n monitoring pod/prometheus-0 9090:9090

# Grafana
kubectl port-forward -n monitoring service/grafana 3000:3000

# Acceder en navegador
open http://localhost:9090  # Prometheus
open http://localhost:3000  # Grafana</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Debugging de Kafka:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Forward Kafka broker
kubectl port-forward pod/kafka-0 9092:9092

# Producir mensaje
echo "test message" | kafka-console-producer --broker-list localhost:9092 --topic test

# Consumir mensajes
kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>6. Forward múltiples Pods simultáneamente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Terminal 1
kubectl port-forward pod/pod-1 8080:80

# Terminal 2
kubectl port-forward pod/pod-2 8081:80

# Terminal 3
kubectl port-forward pod/pod-3 8082:80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Automatización de port-forward:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Script para mantener port-forward activo
#!/bin/bash

POD_NAME="myapp"
LOCAL_PORT=8080
REMOTE_PORT=80

while true; do
  echo "Starting port-forward..."
  kubectl port-forward pod/$POD_NAME $LOCAL_PORT:$REMOTE_PORT

  if [ $? -ne 0 ]; then
    echo "Port-forward failed, retrying in 5 seconds..."
    sleep 5
  fi
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Alternativa: kubectl proxy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Inicia proxy a API server
kubectl proxy --port=8001

# Acceder a Pods vía proxy API
# http://localhost:8001/api/v1/namespaces/default/pods/pod-name/proxy/

# Ejemplo: acceder a servicio en pod
curl http://localhost:8001/api/v1/namespaces/default/pods/myapp/proxy/health</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_diagnóstico_de_problemas_comunes">2.4.4. Diagnóstico de problemas comunes</h4>
<div class="paragraph">
<p><strong>Problema 1: Pod en estado Pending</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver detalles del Pod
kubectl describe pod pending-pod

# Buscar en eventos:
# - "Insufficient cpu" o "Insufficient memory"
# - "No nodes available"
# - "FailedScheduling"

# Soluciones:
# 1. Ver recursos disponibles en nodos
kubectl top nodes

# 2. Ver qué está consumiendo recursos
kubectl top pods --all-namespaces --sort-by=memory
kubectl top pods --all-namespaces --sort-by=cpu

# 3. Reducir requests del Pod o agregar nodos

# 4. Verificar taints y tolerations
kubectl describe nodes | grep -A 5 Taints

# 5. Ver por qué no se programa
kubectl get events --field-selector involvedObject.name=pending-pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 2: ImagePullBackOff / ErrImagePull</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver detalles
kubectl describe pod image-pull-pod

# Eventos comunes:
# - "Failed to pull image"
# - "repository does not exist"
# - "unauthorized: authentication required"

# Verificaciones:
# 1. Nombre de imagen correcto
kubectl get pod image-pull-pod -o jsonpath='{.spec.containers[*].image}'

# 2. Registry accesible
# Probar pull manual en un nodo
docker pull nginx:1.21

# 3. Verificar imagePullSecrets
kubectl get pod image-pull-pod -o jsonpath='{.spec.imagePullSecrets}'

# 4. Ver si el secret existe
kubectl get secrets

# Soluciones:
# - Corregir nombre de imagen
# - Crear imagePullSecret si es registry privado
kubectl create secret docker-registry regcred \
  --docker-server=https://index.docker.io/v1/ \
  --docker-username=user \
  --docker-password=pass \
  --docker-email=email@example.com

# - Referenciar en Pod
spec:
  imagePullSecrets:
  - name: regcred</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 3: CrashLoopBackOff</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs del crash
kubectl logs crash-pod --previous

# Ver razón de terminación
kubectl get pod crash-pod -o jsonpath='{.status.containerStatuses[0].lastState.terminated.reason}'

# Ver exit code
kubectl get pod crash-pod -o jsonpath='{.status.containerStatuses[0].lastState.terminated.exitCode}'

# Causas comunes:
# - Exit code 137: OOMKilled (Out of Memory)
# - Exit code 1: Error de aplicación
# - Exit code 0 con restartPolicy=Always: App termina cuando no debería

# Debugging:
# 1. Si es OOMKilled, aumentar memory limits
resources:
  limits:
    memory: "512Mi"  # Aumentar

# 2. Ver uso de memoria antes del kill
kubectl top pod crash-pod

# 3. Si es error de aplicación, revisar logs
kubectl logs crash-pod --previous | tail -50

# 4. Verificar health checks
kubectl describe pod crash-pod | grep -A 10 "Liveness\|Readiness"

# 5. Ejecutar localmente para debug
docker run -it image:tag sh</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 4: Pod no recibe tráfico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar que Pod está Ready
kubectl get pods

# Si no está Ready:
kubectl describe pod not-ready-pod

# 2. Verificar readiness probe
kubectl describe pod not-ready-pod | grep -A 10 Readiness

# 3. Probar readiness probe manualmente
kubectl exec not-ready-pod -- curl http://localhost:8080/ready

# 4. Verificar Service
kubectl get service myapp-service

# 5. Ver endpoints del Service
kubectl get endpoints myapp-service

# Si endpoints está vacío:
# - Verificar que labels del Pod coinciden con selector del Service
kubectl get pod not-ready-pod --show-labels
kubectl get service myapp-service -o jsonpath='{.spec.selector}'

# 6. Probar conectividad desde otro Pod
kubectl run test --image=busybox:1.35 --rm -it -- sh
  wget -O- http://myapp-service:80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 5: Problemas de red/DNS</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar DNS desde Pod
kubectl exec myapp -- nslookup kubernetes.default

# 2. Ver configuración DNS
kubectl exec myapp -- cat /etc/resolv.conf

# 3. Verificar CoreDNS está corriendo
kubectl get pods -n kube-system -l k8s-app=kube-dns

# 4. Ver logs de CoreDNS
kubectl logs -n kube-system -l k8s-app=kube-dns

# 5. Probar conectividad pod-to-pod
# Desde un Pod temporal
kubectl run test --image=busybox:1.35 --rm -it -- sh
  ping 10.244.1.5  # IP del Pod destino
  telnet myapp-service 80
  nc -zv myapp-service 80

# 6. Verificar Network Policies
kubectl get networkpolicies --all-namespaces

# 7. Verificar CNI plugin
kubectl get pods -n kube-system | grep calico
kubectl get pods -n kube-system | grep flannel</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 6: Problemas de volúmenes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar PVC está bound
kubectl get pvc

# 2. Ver detalles de PVC
kubectl describe pvc my-pvc

# 3. Ver PV asociado
kubectl get pv

# 4. Ver eventos de volumen
kubectl get events --field-selector reason=FailedMount

# 5. Verificar permisos de montaje
kubectl exec pod-with-volume -- ls -la /mount/path

# 6. Ver tipo de error
kubectl describe pod pod-with-volume | grep -A 20 "Events:"

# Errores comunes:
# - "Volume could not be attached"
# - "Multi-Attach error"
# - "Permission denied"

# 7. Verificar StorageClass
kubectl get storageclass
kubectl describe storageclass standard</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 7: ConfigMap/Secret no encontrado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver error
kubectl describe pod config-pod

# Error típico: "configmap 'my-config' not found"

# 1. Listar ConfigMaps
kubectl get configmaps

# 2. Verificar namespace
kubectl get configmaps --all-namespaces | grep my-config

# 3. Ver contenido
kubectl describe configmap my-config

# 4. Verificar nombre en Pod
kubectl get pod config-pod -o yaml | grep configMap

# 5. Crear si no existe
kubectl create configmap my-config --from-literal=key=value</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Herramientas de debugging avanzadas:</strong></p>
</div>
<div class="paragraph">
<p><strong>1. Ephemeral Containers (Kubernetes 1.23+):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar contenedor de debugging a Pod en ejecución
kubectl debug -it pod-name --image=busybox:1.35 --target=container-name

# Con imagen de debugging más completa
kubectl debug -it pod-name --image=nicolaka/netshoot

# Copiar Pod para debugging (no afecta original)
kubectl debug pod-name -it --copy-to=pod-name-debug --container=debug -- sh</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. kubectl-debug plugin:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar via krew
kubectl krew install debug

# Debugear Pod
kubectl debug pod-name --agentless --port-forward</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Stern (logs de múltiples pods):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar stern
brew install stern  # macOS
# O desde releases: github.com/stern/stern

# Ver logs de todos los pods que coincidan
stern myapp

# Con selector de labels
stern --selector app=myapp

# Múltiples contenedores
stern myapp --all-namespaces --container=sidecar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Kubetail:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs de múltiples pods en paralelo
kubetail myapp

# Con namespace
kubetail myapp -n production

# Con selector
kubetail -l app=myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Checklist de troubleshooting:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Estado del Pod
kubectl get pod problematic-pod -o wide

# 2. Eventos
kubectl get events --field-selector involvedObject.name=problematic-pod --sort-by='.lastTimestamp'

# 3. Descripción completa
kubectl describe pod problematic-pod

# 4. Logs
kubectl logs problematic-pod --all-containers=true --previous

# 5. YAML actual
kubectl get pod problematic-pod -o yaml

# 6. Recursos del nodo
kubectl describe node node-name

# 7. Estado del cluster
kubectl get nodes
kubectl get pods --all-namespaces

# 8. Logs de componentes del sistema
kubectl logs -n kube-system kube-apiserver-master
kubectl logs -n kube-system kube-controller-manager-master
kubectl logs -n kube-system kube-scheduler-master

# 9. Verificar RBAC si hay problemas de permisos
kubectl auth can-i --list --as=system:serviceaccount:default:myapp

# 10. Métricas (si metrics-server está instalado)
kubectl top pod problematic-pod
kubectl top node</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para Debugging:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Logging estructurado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa JSON en logs para facilitar parsing</p>
</li>
<li>
<p>Incluye IDs de request/transaction</p>
</li>
<li>
<p>Niveles de log apropiados (DEBUG, INFO, WARN, ERROR)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Health checks bien implementados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Readiness: verifica dependencias</p>
</li>
<li>
<p>Liveness: verifica estado de la app</p>
</li>
<li>
<p>No compartas la misma ruta para ambos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Recursos definidos correctamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Requests basadas en uso real</p>
</li>
<li>
<p>Limits con margen para picos</p>
</li>
<li>
<p>Monitorear uso real con <code>kubectl top</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Labels y annotations</strong></p>
<div class="ulist">
<ul>
<li>
<p>Labels consistentes para selección</p>
</li>
<li>
<p>Annotations con metadata útil (version, git commit, etc.)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitoreo proactivo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa Prometheus/Grafana</p>
</li>
<li>
<p>Alertas en métricas clave</p>
</li>
<li>
<p>Logs centralizados (ELK, Loki)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Debugging en desarrollo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa entornos locales (minikube, kind)</p>
</li>
<li>
<p>Prueba en ambiente similar a producción</p>
</li>
<li>
<p>Usa herramientas de debugging remoto cuando sea necesario</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_3_controllers_y_workloads">3. Módulo 3: Controllers y Workloads</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_replicasets">3.1. ReplicaSets</h3>
<div class="paragraph">
<p>ReplicaSets son controladores que aseguran que un número específico de réplicas de un Pod se ejecutan en todo momento. Son la base de los Deployments.</p>
</div>
<div class="paragraph">
<p><strong>Nota</strong>: En la mayoría de los casos, deberías usar Deployments en lugar de ReplicaSets directamente, ya que los Deployments proporcionan actualizaciones declarativas de Pods.</p>
</div>
<div class="sect3">
<h4 id="_función_y_propósito">3.1.1. Función y propósito</h4>
<div class="paragraph">
<p><strong>¿Qué es un ReplicaSet?</strong></p>
</div>
<div class="paragraph">
<p>Un ReplicaSet es un controlador que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Mantiene un conjunto estable de Pods en ejecución</p>
</li>
<li>
<p>Asegura que un número especificado de réplicas del Pod existe en todo momento</p>
</li>
<li>
<p>Crea/elimina Pods según sea necesario para mantener el número deseado</p>
</li>
<li>
<p>Reemplaza Pods que fallan, son eliminados o terminados</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama de funcionamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌──────────────────────────────────────┐
│       ReplicaSet Controller          │
│  (Observa y mantiene estado)         │
├──────────────────────────────────────┤
│                                      │
│  Deseado: 3 réplicas                 │
│  Actual:  2 Pods corriendo           │
│  Acción:  Crear 1 Pod más            │
│                                      │
└──────────────────────────────────────┘
             │
             ├──────────────────────┐
             │                      │
         ┌───▼────┐  ┌───┐  ┌──────▼──┐
         │ Pod 1  │  │Pod│  │ Pod 3   │
         │Running │  │ 2 │  │Creating │
         └────────┘  └───┘  └─────────┘</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_definición_de_replicasets">3.1.2. Definición de ReplicaSets</h4>
<div class="paragraph">
<p><strong>Sintaxis básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx
spec:
  replicas: 3  # Número de Pods deseados
  selector:
    matchLabels:
      app: nginx  # Debe coincidir con labels del template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Campos importantes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Campo</th>
<th class="tableblock halign-left valign-top">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número de Pods que deben estar ejecutándose</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">selector</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cómo identificar Pods que pertenecen a este ReplicaSet</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especificación del Pod a crear</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">minReadySeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Segundos que un Pod debe estar listo antes de contarse como disponible</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">progressDeadlineSeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tiempo máximo para que ReplicaSet haga progreso</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo completo con más opciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: web-rs
  namespace: production
  labels:
    app: web
    tier: frontend
spec:
  replicas: 5
  minReadySeconds: 10  # Espera 10s después de Ready
  progressDeadlineSeconds: 600  # Timeout de 10 minutos

  selector:
    matchLabels:
      app: web
      tier: frontend
    matchExpressions:
    - key: version
      operator: In
      values:
      - v1
      - v1.1

  template:
    metadata:
      labels:
        app: web
        tier: frontend
        version: v1.1
    spec:
      containers:
      - name: web
        image: web:1.1
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: "250m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos básicos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear ReplicaSet
kubectl apply -f replicaset.yaml

# Listar ReplicaSets
kubectl get replicaset
kubectl get rs

# Ver detalles
kubectl describe rs nginx-rs

# Ver Pods creados por ReplicaSet
kubectl get pods -l app=nginx

# Ver YAML completo
kubectl get rs nginx-rs -o yaml

# Eliminar ReplicaSet (también elimina Pods)
kubectl delete rs nginx-rs

# Eliminar ReplicaSet pero mantener Pods
kubectl delete rs nginx-rs --cascade=orphan</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_escalado_manual">3.1.3. Escalado manual</h4>
<div class="paragraph">
<p><strong>Cambiar el número de réplicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Escalar usando kubectl scale
kubectl scale rs nginx-rs --replicas=5

# Escalar a cero (detiene todos los Pods)
kubectl scale rs nginx-rs --replicas=0

# Escalar a 2
kubectl scale rs nginx-rs --replicas=2

# Escalar basado en archivo YAML
kubectl scale -f replicaset.yaml --replicas=10</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Editar ReplicaSet directamente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Editar en línea
kubectl edit rs nginx-rs

# Buscar el campo replicas y cambiar el número
# spec:
#   replicas: 5   # Cambiar a 3

# Guardar y salir del editor
# El ReplicaSet ajustará automáticamente el número de Pods</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patch para cambiar réplicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Patch específico
kubectl patch rs nginx-rs -p '{"spec":{"replicas":10}}'

# Patch desde JSON Patch
kubectl patch rs nginx-rs --type='json' -p='[{"op": "replace", "path": "/spec/replicas", "value": 7}]'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitorear escalado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Pods mientras se escalan
kubectl get pods -l app=nginx -w

# Ver eventos del ReplicaSet
kubectl describe rs nginx-rs

# Ver métricas si metrics-server está instalado
kubectl top pods -l app=nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico de escalado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear ReplicaSet con 2 réplicas
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: app-rs
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0
EOF

# Ver Pods creados
kubectl get pods -l app=myapp

# Escalar a 5
kubectl scale rs app-rs --replicas=5

# Ver cómo se crean los Pods
kubectl get pods -l app=myapp -w

# Escalar a 1
kubectl scale rs app-rs --replicas=1

# Ver cómo se eliminan los Pods
kubectl get pods -l app=myapp</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_self_healing">3.1.4. Self-healing</h4>
<div class="paragraph">
<p>El self-healing es la capacidad de ReplicaSet de recuperarse automáticamente cuando Pods fallan.</p>
</div>
<div class="paragraph">
<p><strong>Cómo funciona:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Monitoreo continuo
    │
    ▼
┌──────────────────────────────┐
│ ReplicaSet Controller        │
│ Cada 5-10 segundos:          │
│ 1. Cuenta Pods actuales      │
│ 2. Compara con replicas      │
│ 3. Toma acciones correctivas │
└──────────────────────────────┘
    │
    ├─ Pod falla → Crear nuevo Pod
    ├─ Pod eliminado → Crear nuevo Pod
    ├─ Pod extra → Eliminar Pod
    └─ Pod no listo → Mantener monitoreo</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Escenarios de self-healing:</strong></p>
</div>
<div class="paragraph">
<p><strong>1. Pod crashea:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear ReplicaSet
kubectl apply -f rs.yaml

# Ver Pods
kubectl get pods

# Eliminar manualmente un Pod
kubectl delete pod pod-name

# ReplicaSet crea automáticamente uno nuevo
kubectl get pods

# Ver eventos
kubectl describe rs my-rs</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Nodo falla:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cuando un nodo falla y sus Pods se marcan como terminados,
# el ReplicaSet crea los Pods en nodos disponibles

# Ver Pods en nodo que falló
kubectl get pods -o wide

# Después de eviction/timeout:
# - Pods se marcan como Terminating/Terminated
# - ReplicaSet crea nuevos Pods en otros nodos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Monitoreo de self-healing:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver eventos de ReplicaSet
kubectl describe rs my-rs

# Salida muestra:
# Events:
#   Type    Reason           Message
#   ----    ------           -------
#   Normal  SuccessfulCreate Created pod: pod-1
#   Normal  SuccessfulDelete Deleted pod: pod-2
#   Normal  SuccessfulCreate Created pod: pod-3

# Ver logs si es necesario
kubectl logs -n kube-system -l component=replicaset-controller</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear ReplicaSet con 3 réplicas
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: resilient-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: resilient
  template:
    metadata:
      labels:
        app: resilient
    spec:
      containers:
      - name: app
        image: myapp:1.0
        command: ["sleep", "3600"]
EOF

# 2. Ver Pods creados
kubectl get pods -l app=resilient

# 3. Eliminar un Pod (simular fallo)
kubectl delete pod resilient-app-xxxxx

# 4. Observar cómo ReplicaSet crea uno nuevo
# (Puede tomar 1-2 segundos)
kubectl get pods -l app=resilient

# 5. Ver que hay 3 Pods nuevamente
# Nota: El nuevo Pod tendrá un nombre diferente</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Limitaciones del self-healing:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Solo recupera el número de réplicas, no realiza backups</p>
</li>
<li>
<p>No puede recuperar de fallos de aplicación inherentes</p>
</li>
<li>
<p>Los Pods recién creados son instancias nuevas</p>
</li>
<li>
<p>Datos locales en el Pod se pierden</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Best Practices:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa Deployments en lugar de ReplicaSets directamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los Deployments proporcionan actualizaciones declarativas</p>
</li>
<li>
<p>Mayor flexibilidad para cambios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Define recursos adecuados</strong></p>
<div class="ulist">
<ul>
<li>
<p>CPU/Memory requests para scheduling</p>
</li>
<li>
<p>Limits para evitar agotamiento</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa health checks</strong></p>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
<li>
<p>Los Pods sin respuesta se reemplazan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa selectors específicos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evita capturar Pods no deseados</p>
</li>
<li>
<p>Mantén selectores simples</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea eventos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Revisa frecuentemente eventos del ReplicaSet</p>
</li>
<li>
<p>Alerta en patrones de fallo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combina con autoscaling</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa HPA (Horizontal Pod Autoscaler)</p>
</li>
<li>
<p>Escala automáticamente según métricas</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_deployments">3.2. Deployments</h3>
<div class="paragraph">
<p>Los Deployments son la forma recomendada de ejecutar Pods stateless en Kubernetes. Proporcionan actualizaciones declarativas de Pods y ReplicaSets, con manejo automático de versiones e historial.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo usar Deployments?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones web stateless</p>
</li>
<li>
<p>APIs REST</p>
</li>
<li>
<p>Microservicios</p>
</li>
<li>
<p>Cualquier aplicación que puede tener múltiples réplicas idénticas</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>¿Cuándo NO usar Deployments?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones con estado (usa StatefulSets)</p>
</li>
<li>
<p>Necesitas controlador personalizado</p>
</li>
<li>
<p>Un único Pod (usa Pod directamente)</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_estrategias_de_despliegue">3.2.1. Estrategias de despliegue</h4>
<div class="paragraph">
<p><strong>Rolling Update (por defecto)</strong></p>
</div>
<div class="paragraph">
<p>En una Rolling Update, los Pods se reemplazan gradualmente. Los Pods nuevos se crean mientras los antiguos se terminan.</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Sin tiempo de inactividad</p>
</li>
<li>
<p>Permite detectar problemas con la nueva versión</p>
</li>
<li>
<p>Fácil de revertir</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Versión 1: ▌▌▌▌▌ (5 Pods)
Actualizar a Versión 2...
Paso 1:    ▌▌▌▌ ▎
Paso 2:    ▌▌▌ ▎▎
Paso 3:    ▌▌ ▎▎▎
Paso 4:    ▌ ▎▎▎▎
Paso 5:     ▎▎▎▎▎ (5 Pods de versión 2)</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deployment
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1          # Máximo Pods extras durante actualización
      maxUnavailable: 0    # Máximo Pods que pueden estar no disponibles
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: web
        image: web:v2
        ports:
        - containerPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parámetros importantes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parámetro</th>
<th class="tableblock halign-left valign-top">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">maxSurge</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de Pods extras permitidos durante actualización. Puede ser número o porcentaje (ej: "25%")</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">maxUnavailable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de Pods que pueden estar no disponibles. Puede ser número o porcentaje</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">minReadySeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Segundos que un Pod debe estar listo antes de considerarlo disponible</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo de Rolling Update segura:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: production-app
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2          # 2 Pods extras
      maxUnavailable: 1    # 1 Pod puede estar no disponible

  minReadySeconds: 30      # Espera 30s antes de reemplazar

  selector:
    matchLabels:
      app: production

  template:
    metadata:
      labels:
        app: production
        version: v2
    spec:
      containers:
      - name: app
        image: app:v2
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Recreate</strong></p>
</div>
<div class="paragraph">
<p>En una estrategia Recreate, todos los Pods antiguos se terminan antes de crear los nuevos.</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Garantiza que no hay dos versiones corriendo simultáneamente</p>
</li>
<li>
<p>Simple de entender</p>
</li>
<li>
<p>Uso de recursos predecible</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Desventajas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Tiempo de inactividad durante la actualización</p>
</li>
<li>
<p>No ideal para aplicaciones críticas</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Versión 1: ▌▌▌▌▌
Terminar todos los Pods...
           (esperando)
Crear nuevos Pods...
Versión 2: ▎▎▎▎▎</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: batch-job
spec:
  replicas: 3
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: batch
  template:
    metadata:
      labels:
        app: batch
    spec:
      containers:
      - name: batch
        image: batch-processor:v2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cuándo usar Recreate:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones que no pueden correr múltiples versiones</p>
</li>
<li>
<p>Migraciones de base de datos</p>
</li>
<li>
<p>Cambios incompatibles en estado compartido</p>
</li>
<li>
<p>Entornos de desarrollo/testing</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_rollback_de_versiones">3.2.2. Rollback de versiones</h4>
<div class="paragraph">
<p>Kubernetes mantiene un historial de revisiones de Deployments, permitiendo rollback rápido.</p>
</div>
<div class="paragraph">
<p><strong>Ver historial de despliegues:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver revisiones
kubectl rollout history deployment/web-deployment

# Salida:
# REVISION  CHANGE-CAUSE
# 1         &lt;none&gt;
# 2         kubectl apply --filename=web.yaml
# 3         kubectl set image deployment/web web=web:v3

# Ver detalles de una revisión específica
kubectl rollout history deployment/web-deployment --revision=2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Realizar rollback:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Rollback a la revisión anterior
kubectl rollout undo deployment/web-deployment

# Rollback a una revisión específica
kubectl rollout undo deployment/web-deployment --to-revision=1

# Ver cambios durante rollback
kubectl rollout history deployment/web-deployment

# Ver estado del rollback
kubectl rollout status deployment/web-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pausar y reanudar despliegues:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Pausar un despliegue en progreso
kubectl rollout pause deployment/web-deployment

# Ver estado actual
kubectl get deployment web-deployment

# Hacer cambios mientras está pausado
kubectl set image deployment/web-deployment web=web:v4 --record

# Reanudar el despliegue
kubectl rollout resume deployment/web-deployment

# Ver estado
kubectl rollout status deployment/web-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico de actualización con rollback:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear Deployment original
kubectl apply -f deployment-v1.yaml

# 2. Ver revisión actual
kubectl rollout history deployment/web

# 3. Actualizar imagen
kubectl set image deployment/web web=web:v2 --record

# 4. Monitorear el despliegue
kubectl rollout status deployment/web -w

# 5. Si hay problemas, hacer rollback
kubectl rollout undo deployment/web

# 6. Verificar que se revirtió
kubectl rollout status deployment/web</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gestión_del_historial">3.2.3. Gestión del historial</h4>
<div class="paragraph">
<p><strong>Limitar el historial de revisiones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  revisionHistoryLimit: 10  # Mantener últimas 10 revisiones
  # Valor por defecto es 10
  # Establecer en 0 para deshabilitar rollbacks

  # ... resto de configuración</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver cambios entre revisiones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver qué cambió en una revisión
kubectl rollout history deployment/web --revision=2

# Comparar con YAML actual
kubectl get deployment web -o yaml &gt; current.yaml
kubectl get deployment web --revision=1 -o yaml &gt; revision1.yaml
diff revision1.yaml current.yaml

# Ver eventos de despliegue
kubectl describe deployment web | tail -20</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pause_y_resume_de_deployments">3.2.4. Pause y resume de deployments</h4>
<div class="paragraph">
<p><strong>Pausar actualizaciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Útil para aplicar múltiples cambios a la vez
kubectl rollout pause deployment/web

# Cambio 1
kubectl set image deployment/web web=web:v3

# Cambio 2
kubectl set env deployment/web ENV=production

# Cambio 3
kubectl patch deployment web -p '{"spec":{"minReadySeconds":30}}'

# Ahora reanudar (todos los cambios se aplican a la vez)
kubectl rollout resume deployment/web

# Monitorear
kubectl rollout status deployment/web</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de pausa estratégica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Pausar despliegue
kubectl rollout pause deployment/web

# 2. Actualizar la imagen
kubectl set image deployment/web \
  web=web:v4 \
  --record

# 3. Escalar Pods
kubectl scale deployment/web --replicas=10

# 4. Cambiar recurso limits
kubectl set resources deployment/web \
  --limits=cpu=500m,memory=512Mi \
  --requests=cpu=250m,memory=256Mi

# 5. Reanudar
kubectl rollout resume deployment/web

# Todos los cambios se aplicarán con la estrategia RollingUpdate</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cancelar una actualización pausada:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver que está pausado
kubectl rollout status deployment/web

# Para cancelar cambios sin aplicar
kubectl rollout undo deployment/web

# Ver que se revirtió a la versión anterior
kubectl rollout status deployment/web</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitoreo durante despliegues:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado en tiempo real
kubectl rollout status deployment/web -w

# Ver réplicas durante despliegue
kubectl get deployment web --watch

# Ver Pods siendo reemplazados
kubectl get pods -l app=web -w

# Ver eventos
kubectl get events --field-selector involvedObject.name=web

# Ver imagen actual
kubectl get deployment web -o jsonpath='{.spec.template.spec.containers[0].image}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo completo: Canary Deployment</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Deployment original con 10 réplicas
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: app:v1
EOF

# 2. Pausar despliegue
kubectl rollout pause deployment/app

# 3. Actualizar imagen (crea 1 Pod con v2)
kubectl set image deployment/app app=app:v2

# 4. Dejar corriendo v1 y v2 juntas por monitoreo
kubectl rollout status deployment/app

# 5. Si todo OK, reanudar
kubectl rollout resume deployment/app

# 6. Monitorear actualización completa
kubectl rollout status deployment/app -w</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para Deployments:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa RollingUpdate por defecto</strong></p>
<div class="ulist">
<ul>
<li>
<p>Minimiza tiempo de inactividad</p>
</li>
<li>
<p>Permite detección de problemas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura health checks apropiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Readiness probe: indica si puede recibir tráfico</p>
</li>
<li>
<p>Liveness probe: indica si está vivo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Define minReadySeconds</strong></p>
<div class="ulist">
<ul>
<li>
<p>Espera suficiente tiempo para estabilización</p>
</li>
<li>
<p>Típicamente 10-30 segundos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa record para cambios</strong></p>
<div class="ulist">
<ul>
<li>
<p><code>--record</code> guarda el comando que causó cambio</p>
</li>
<li>
<p>Facilita auditoría</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea despliegues</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa <code>rollout status</code> durante actualizaciones</p>
</li>
<li>
<p>Configura alertas en eventos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Planifica rollbacks</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantén revisiones útiles</p>
</li>
<li>
<p>Prueba rollbacks en staging</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa labels y annotations</strong></p>
<div class="ulist">
<ul>
<li>
<p>Versión de la aplicación</p>
</li>
<li>
<p>Git commit SHA</p>
</li>
<li>
<p>Change cause</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_statefulsets">3.3. StatefulSets</h3>
<div class="paragraph">
<p><strong>¿Qué son los StatefulSets?</strong></p>
</div>
<div class="paragraph">
<p>StatefulSets es un controlador de Kubernetes diseñado para gestionar aplicaciones con estado (stateful). A diferencia de los Deployments que son ideales para aplicaciones sin estado (stateless), los StatefulSets proporcionan:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Identidad estable de Pods</strong>: Cada Pod tiene un nombre y hostname persistente</p>
</li>
<li>
<p><strong>Almacenamiento persistente</strong>: Cada Pod puede tener su propio volumen dedicado</p>
</li>
<li>
<p><strong>Actualización ordenada</strong>: Los Pods se actualizan de forma ordenada</p>
</li>
<li>
<p><strong>Escalado ordenado</strong>: Los Pods se escalan y se reducen ordenadamente</p>
</li>
<li>
<p><strong>Garantías de orden de inicio</strong>: Los Pods se inician en orden y uno a uno</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Tabla comparativa: Deployments vs StatefulSets</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Característica</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">StatefulSet</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identidad Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera (web-abc123)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Estable (mysql-0, mysql-1, mysql-2)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre de host</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No persistente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Persistente (pod-name.service-name.ns)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Almacenamiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Compartido o efímero</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PVC por Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escalado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Paralelo, rápido</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secuencial</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Actualización</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rápida, paralela</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lenta, secuencial</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Red</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Balanceada por Service</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Headless Service con DNS de Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Orden de inicio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sin garantía</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Garantizado</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo: Diferencia en nomenclatura</strong></p>
</div>
<div class="paragraph">
<p>Deployment con 3 réplicas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>web-xyz789     web-abc123     web-def456
(efímero)      (efímero)      (efímero)</pre>
</div>
</div>
<div class="paragraph">
<p>StatefulSet con 3 réplicas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>mysql-0  →  mysql-0.mysql.default.svc.cluster.local
mysql-1  →  mysql-1.mysql.default.svc.cluster.local
mysql-2  →  mysql-2.mysql.default.svc.cluster.local
(estable)</pre>
</div>
</div>
<div class="sect3">
<h4 id="_identidad_estable_de_pods">3.3.1. Identidad Estable de Pods</h4>
<div class="paragraph">
<p>Los Pods en un StatefulSet tienen identidades estables y predecibles:</p>
</div>
<div class="paragraph">
<p><strong>Nombre y Ordinal</strong></p>
</div>
<div class="paragraph">
<p>Cada Pod en un StatefulSet tiene un nombre formado por: <code>&lt;StatefulSet-name&gt;-&lt;ordinal&gt;</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># StatefulSet: mysql
# Replicas: 3
# Resultado:
mysql-0   (ordinal 0)
mysql-1   (ordinal 1)
mysql-2   (ordinal 2)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Hostname Estable</strong></p>
</div>
<div class="paragraph">
<p>El hostname dentro del Pod es el mismo que su nombre:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En el Pod mysql-0:
hostname
# Salida: mysql-0

# En el Pod mysql-1:
hostname
# Salida: mysql-1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>DNS Estable</strong></p>
</div>
<div class="paragraph">
<p>Cada Pod tiene un DNS predecible. Con un Headless Service:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Format: &lt;pod-name&gt;.&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local
mysql-0.mysql.default.svc.cluster.local
mysql-1.mysql.default.svc.cluster.local
mysql-2.mysql.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Casos de uso para identidad estable:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Bases de datos con replicación</strong>: MySQL Replication identifica nodos por hostname</p>
</li>
<li>
<p><strong>Sistemas distribuidos</strong>: Etcd, Zookeeper usan identidades estables</p>
</li>
<li>
<p><strong>Clustering</strong>: Cassandra, Elasticsearch necesitan direcciones predecibles</p>
</li>
<li>
<p><strong>Configuración Master-Slave</strong>: La replicación requiere conocer los miembros</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_almacenamiento_persistente_con_volumeclaimtemplates">3.3.2. Almacenamiento Persistente con VolumeClaimTemplates</h4>
<div class="paragraph">
<p>StatefulSets usan <code>volumeClaimTemplates</code> para crear un PVC por cada Pod:</p>
</div>
<div class="paragraph">
<p><strong>Definición básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql              # Headless Service (requerido)
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:5.7
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 10Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cómo funciona volumeClaimTemplates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">StatefulSet con 3 réplicas
        ↓
Crea 3 PVCs:
- mysql-data-0 (10Gi)
- mysql-data-1 (10Gi)
- mysql-data-2 (10Gi)
        ↓
Cada Pod obtiene su PVC dedicado:
- mysql-0 → mysql-data-0
- mysql-1 → mysql-data-1
- mysql-2 → mysql-data-2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Durabilidad y persistencia:</strong></p>
</div>
<div class="paragraph">
<p>Si un Pod se elimina, el PVC persiste. Cuando se recrea el Pod, se remontan los datos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Eliminar Pod mysql-0
kubectl delete pod mysql-0

# 2. StatefulSet recrea mysql-0
# 3. El nuevo mysql-0 se monta a mysql-data-0 (datos intactos)
# 4. mysql-0 recupera su estado anterior</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_actualización_ordenada">3.3.3. Actualización Ordenada</h4>
<div class="paragraph">
<p>Los StatefulSets actualizan Pods uno a uno, en orden inverso (del más alto ordinal al más bajo):</p>
</div>
<div class="paragraph">
<p><strong>Estrategia RollingUpdate:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: app
spec:
  serviceName: app
  replicas: 3
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0  # Actualizar todos los Pods (0 = comenzar desde 0)
  selector:
    matchLabels:
      app: app
  template:
    metadata:
      labels:
        app: app
    spec:
      containers:
      - name: app
        image: app:v1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de actualización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Inicial: app-0, app-1, app-2 (todos en v1)

# Actualizar imagen a v2
kubectl set image statefulset/app app=app:v2

# Orden de actualización (inverso):
# 1. app-2 → actualizar y esperar a Ready
# 2. app-1 → actualizar y esperar a Ready
# 3. app-0 → actualizar y esperar a Ready</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualización Canary con partition:</strong></p>
</div>
<div class="paragraph">
<p><code>partition</code> controla cuál ordinal comienza la actualización:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># updateStrategy con partition: 2
# Solo actualizar app-2, mantener app-0 y app-1 en v1
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 2</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cambiar imagen a v2
kubectl set image statefulset/app app=app:v2 --record

# Con partition: 2, solo app-2 se actualiza
# Estado:
# app-0: v1 (sin cambios)
# app-1: v1 (sin cambios)
# app-2: v2 (actualizado)

# Monitorear app-2 en producción...

# Cuando esté listo, reducir partition:
kubectl patch statefulset app -p '{"spec":{"updateStrategy":{"rollingUpdate":{"partition":0}}}}'

# Ahora se actualizan app-1 y app-0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estrategia OnDelete:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">updateStrategy:
  type: OnDelete</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con OnDelete, no se actualiza automáticamente. Se actualiza solo cuando se elimina el Pod manualmente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># El cambio de imagen no actualiza Pods automáticamente
kubectl set image statefulset/mysql mysql=mysql:8.0

# Debe eliminar manualmente para disparar actualización:
kubectl delete pod mysql-0
# Se recrea con imagen nueva mysql:8.0</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_headless_services">3.3.4. Headless Services</h4>
<div class="paragraph">
<p>StatefulSets requieren un Headless Service para funcionar correctamente:</p>
</div>
<div class="paragraph">
<p><strong>¿Qué es un Headless Service?</strong></p>
</div>
<div class="paragraph">
<p>Un Headless Service es un Service sin ClusterIP (ClusterIP: None). En lugar de balancear carga, proporciona DNS para cada Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None              # Headless - sin balanceo
  selector:
    app: mysql
  ports:
  - port: 3306
    targetPort: 3306</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Resolución DNS en Headless Service:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Query: mysql.default.svc.cluster.local
# Respuesta: Todos los Pods
# 10.0.0.1 (mysql-0)
# 10.0.0.2 (mysql-1)
# 10.0.0.3 (mysql-2)

# Query: mysql-0.mysql.default.svc.cluster.local
# Respuesta: Solo mysql-0
# 10.0.0.1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>StatefulSet con Headless Service:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
# Headless Service
apiVersion: v1
kind: Service
metadata:
  name: postgresql
spec:
  clusterIP: None
  selector:
    app: postgresql
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
---
# StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: postgresql
  replicas: 3
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      containers:
      - name: postgresql
        image: postgresql:13
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_completo_mysql_con_replicación">3.3.5. Ejemplo Completo: MySQL con Replicación</h4>
<div class="paragraph">
<p><strong>Diagrama de arquitectura:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────────────────────┐
│     MySQL Replication Cluster               │
├─────────────────────────────────────────────┤
│  mysql-0       mysql-1       mysql-2       │
│  (Master)      (Slave)       (Slave)       │
│    [10G]         [10G]         [10G]       │
│     PVC-0        PVC-1         PVC-2       │
└─────────────────────────────────────────────┘
          ↑           ↑           ↑
   mysql.default.svc.cluster.local (Headless)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración completa:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  master.cnf: |
    # Master configuration
    [mysqld]
    binlog_format = ROW
    log-bin = mysql-bin
  slave.cnf: |
    # Slave configuration
    [mysqld]
    relay-log = mysql-relay-bin
    relay-log-index = mysql-relay-bin.index
---
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None
  selector:
    app: mysql
  ports:
  - name: mysql
    port: 3306
    targetPort: 3306
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      initContainers:
      - name: init-mysql
        image: mysql:5.7
        command:
        - bash
        - -c
        - |
          set -ex
          # Generar MySQL server ID basado en ordinal
          ordinal=\${HOSTNAME##*-}
          echo "Server ID: \$((100 + ordinal))" &gt; /mnt/conf.d/server_id.cnf

          # Copiar configuración master o slave
          if [[ \$ordinal -eq 0 ]]; then
            cp /mnt/config-map/master.cnf /mnt/conf.d/
          else
            cp /mnt/config-map/slave.cnf /mnt/conf.d/
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt/conf.d
        - name: config-map
          mountPath: /mnt/config-map
      - name: clone-mysql
        image: xtrabackup:2.4
        command:
        - bash
        - -c
        - |
          set -ex

          # No clonar en el primer Pod
          [[ \$(hostname) == "mysql-0" ]] &amp;&amp; exit 0

          # Clonaje del Pod anterior
          while true; do
            mysql-xtrabackup --backup \\
              --host=mysql-\$((ordinal-1)).mysql \\
              --user=root \\
              --password=\${MYSQL_ROOT_PASSWORD} \\
              --stream=xbstream \\
              --dir=/tmp
            if [[ -f "/tmp/xtrabackup_info" ]]; then
              break
            fi
            echo "Esperando Pod anterior..."
            sleep 5
          done
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
      containers:
      - name: mysql
        image: mysql:5.7
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
      volumes:
      - name: config-map
        configMap:
          name: mysql-config
      - name: conf
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: default
      resources:
        requests:
          storage: 10Gi
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar replicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado del master (mysql-0)
kubectl exec mysql-0 -- mysql -uroot -p\${MYSQL_ROOT_PASSWORD} -e \
  "SHOW MASTER STATUS\G"

# Ver estado de slaves
kubectl exec mysql-1 -- mysql -uroot -p\${MYSQL_ROOT_PASSWORD} -e \
  "SHOW SLAVE STATUS\G"

# Probar replicación: insertar en master
kubectl exec mysql-0 -- mysql -uroot -p\${MYSQL_ROOT_PASSWORD} -e \
  "CREATE DATABASE test; CREATE TABLE test.data (id INT PRIMARY KEY AUTO_INCREMENT, val VARCHAR(100));"

# Verificar en slave
kubectl exec mysql-1 -- mysql -uroot -p\${MYSQL_ROOT_PASSWORD} -e \
  "SELECT * FROM test.data;"</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_escalado_de_statefulsets">3.3.6. Escalado de StatefulSets</h4>
<div class="paragraph">
<p>El escalado es ordenado y determinístico:</p>
</div>
<div class="paragraph">
<p><strong>Escalado hacia arriba:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Aumentar de 3 a 5 réplicas
# Nuevos Pods se crean en orden:
kubectl scale statefulset mysql --replicas=5

# Orden de creación:
# 1. mysql-3 (creado y esperado a Ready)
# 2. mysql-4 (creado y esperado a Ready)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Reducción de escala:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Reducir de 5 a 2 réplicas
kubectl scale statefulset mysql --replicas=2

# Orden de eliminación (inverso):
# 1. mysql-4 (eliminado primero)
# 2. mysql-3 (eliminado segundo)
# mysql-0, mysql-1 permanecen

# IMPORTANTE: Los PVCs NO se eliminan automáticamente
# Debe eliminar manualmente si no los necesita:
kubectl delete pvc data-mysql-4 data-mysql-3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_manejo_de_ordenamiento">3.3.7. Manejo de Ordenamiento</h4>
<div class="paragraph">
<p>StatefulSets tiene control fino sobre el ordenamiento mediante <code>podManagementPolicy</code>:</p>
</div>
<div class="paragraph">
<p><strong>RollingUpdate (defecto):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  podManagementPolicy: Parallel  # Se crean/actualizan en paralelo
  # Sin esperar a que esté Ready</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ordered (secuencial):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  podManagementPolicy: Ordered  # Espera a que esté Ready antes de crear siguiente</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Parallel: mysql-0, mysql-1, mysql-2 se crean juntos
# Rápido pero sin garantías de orden

# Ordered: mysql-0 espera a Ready → mysql-1 espera a Ready → mysql-2
# Lento pero garantizado</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_casos_de_uso_comunes">3.3.8. Casos de Uso Comunes</h4>
<div class="paragraph">
<p><strong>1. Bases de datos con persistencia:</strong>
- MySQL con replicación
- PostgreSQL con clustering
- MongoDB con sharding</p>
</div>
<div class="paragraph">
<p><strong>2. Sistemas de mensajería:</strong>
- Kafka con temas y particiones
- RabbitMQ con clustering
- Redis Sentinel</p>
</div>
<div class="paragraph">
<p><strong>3. Almacenamiento distribuido:</strong>
- Cassandra
- Elasticsearch
- Ceph</p>
</div>
<div class="paragraph">
<p><strong>4. Aplicaciones que requieren identidad estable:</strong>
- Git servers con identidad
- Aplicaciones que cachean por hostname
- Sistemas que necesitan persistencia de estado</p>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_statefulsets">3.3.9. Best Practices para StatefulSets</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa Headless Services siempre</strong></p>
<div class="ulist">
<ul>
<li>
<p>Requerido para DNS de Pod individual</p>
</li>
<li>
<p>Evita balanceo incorrecto</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Planifica almacenamiento</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa StorageClasses apropiadas</p>
</li>
<li>
<p>Dimensiona PVCs correctamente</p>
</li>
<li>
<p>Monitorea uso de disco</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Ordena según aplicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa Ordered para replicación master-slave</p>
</li>
<li>
<p>Usa Parallel para clústeres distribuidos</p>
</li>
<li>
<p>Ajusta según requisitos de inicialización</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Maneja eliminación de Pods</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ten cuidado al escalar hacia abajo</p>
</li>
<li>
<p>Verifica que no haya datos en Pods siendo eliminados</p>
</li>
<li>
<p>Usa <code>StatefulSet.Spec.VolumeClaimPolicy</code> para control automático</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea replicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>En bases de datos, verifica lag de replicación</p>
</li>
<li>
<p>Configura alertas para Pods no listos</p>
</li>
<li>
<p>Prueba failover regularmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Backup y recovery</strong></p>
<div class="ulist">
<ul>
<li>
<p>Implementa backups automáticos</p>
</li>
<li>
<p>Prueba restauración periódicamente</p>
</li>
<li>
<p>Mantén snapshots de volúmenes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configuración de readiness/liveness</strong></p>
<div class="ulist">
<ul>
<li>
<p>Define probes que reflejen estado real</p>
</li>
<li>
<p>Readiness: ¿listo para tráfico? (replicación sincronizada)</p>
</li>
<li>
<p>Liveness: ¿proceso corriendo? (no mata por lentitud)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Versionado de imagen</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usa etiquetas específicas (mysql:5.7.30, no mysql:5.7)</p>
</li>
<li>
<p>Facilita rollbacks</p>
</li>
<li>
<p>Compatible con partition updates</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_común">3.3.10. Troubleshooting Común</h4>
<div class="paragraph">
<p><strong>Problema: Pod no avanza de Pending</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar eventos
kubectl describe statefulset mysql
kubectl describe pod mysql-0

# Causas comunes:
# - PVC no se puede crear (storage class no existe)
# - No hay nodos con suficiente espacio
# - Init container falla</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Pod queda en CrashLoopBackOff</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs
kubectl logs mysql-0
kubectl logs mysql-0 -c clone-mysql

# Verificar comandos en init containers
kubectl describe pod mysql-0

# Causas:
# - Falla en init container (clonaje no completo)
# - Configuración incorrecta de MySQL
# - Permisos de volumen</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Escalado lento</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Aumentar paralelismo:
kubectl patch statefulset mysql -p \
  '{"spec":{"podManagementPolicy":"Parallel"}}'

# CUIDADO: Puede romper garantías de orden
# Solo para aplicaciones que lo permiten</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: PVCs quedan huérfanos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver PVCs huérfanos
kubectl get pvc | grep -v "Bound"

# Opción 1: Vincular manualmente a nuevo Pod
kubectl patch pvc data-mysql-0 -p '{...}'

# Opción 2: Eliminar si están rotos
kubectl delete pvc data-mysql-3</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_daemonsets">3.4. DaemonSets</h3>
<div class="paragraph">
<p><strong>¿Qué son los DaemonSets?</strong></p>
</div>
<div class="paragraph">
<p>Un DaemonSet es un controlador de Kubernetes que asegura que una copia de un Pod se ejecute en cada nodo del cluster. Diferente a los Deployments y StatefulSets, los DaemonSets no tiene réplicas configurables - siempre hay exactamente un Pod por nodo (salvo excepciones).</p>
</div>
<div class="paragraph">
<p><strong>Casos de uso principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Recolección de logs</strong>: Fluent, Filebeat, Logstash en cada nodo</p>
</li>
<li>
<p><strong>Monitoreo</strong>: Prometheus Node Exporter, Telegraf en todos los nodos</p>
</li>
<li>
<p><strong>Almacenamiento distribuido</strong>: Ceph, Gluster con agentes en cada nodo</p>
</li>
<li>
<p><strong>Networking</strong>: CNI plugins, kube-proxy ejecutándose en cada nodo</p>
</li>
<li>
<p><strong>Seguridad</strong>: Falco, SELinux agents para auditoría</p>
</li>
<li>
<p><strong>Mantenimiento</strong>: Actualización de paquetes, limpieza de registros</p>
</li>
<li>
<p><strong>Sincronización</strong>: NTP clients, sincronización de estado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Diferencia entre Deployment y DaemonSet</strong></p>
</div>
<div class="paragraph">
<p>Con Deployment (3 réplicas en cluster de 10 nodos):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Nodo1: [Pod]
Nodo2: [Pod]
Nodo3: [Pod]
Nodo4: -
Nodo5: -
...
Nodo10: -</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con DaemonSet (mismo cluster):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Nodo1: [Pod]
Nodo2: [Pod]
Nodo3: [Pod]
Nodo4: [Pod]
Nodo5: [Pod]
...
Nodo10: [Pod]</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_definición_básica_de_daemonsets">3.4.1. Definición Básica de DaemonSets</h4>
<div class="paragraph">
<p><strong>YAML básico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        ports:
        - containerPort: 9100</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comparación: Deployment vs DaemonSet vs StatefulSet</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">DaemonSet</th>
<th class="tableblock halign-left valign-top">StatefulSet</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Réplicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configurable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 por nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configurable</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pods por nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Varía (0 o más)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Exactamente 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Varía según réplicas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Estable</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Caso de uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apps stateless</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Agentes en nodos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apps stateful</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ordenamiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sin garantía</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Por nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secuencial</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_selección_de_nodos_en_daemonsets">3.4.2. Selección de Nodos en DaemonSets</h4>
<div class="paragraph">
<p>Los DaemonSets pueden ejecutarse en subconjuntos de nodos mediante selección:</p>
</div>
<div class="paragraph">
<p><strong>nodeSelector:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-monitor
spec:
  selector:
    matchLabels:
      app: gpu-monitor
  template:
    metadata:
      labels:
        app: gpu-monitor
    spec:
      nodeSelector:
        nvidia.com/gpu: "true"  # Solo en nodos con GPUs
      containers:
      - name: monitor
        image: gpu-monitor:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar labels en nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver todos los labels de nodos
kubectl get nodes --show-labels

# Etiquetar un nodo
kubectl label nodes node-1 nvidia.com/gpu=true

# Verificar que DaemonSet se crea en nodo específico
kubectl get pods -o wide</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Affinidad de nodos (más avanzado):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: storage-agent
spec:
  selector:
    matchLabels:
      app: storage-agent
  template:
    metadata:
      labels:
        app: storage-agent
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: storage-type
                operator: In
                values:
                - fast-ssd
                - fast-nvme
      containers:
      - name: agent
        image: storage-agent:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Tolerations (tolerar taints de nodos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: system-monitor
spec:
  selector:
    matchLabels:
      app: system-monitor
  template:
    metadata:
      labels:
        app: system-monitor
    spec:
      tolerations:
      # Tolerar nodos master (normalmente tienen taint NoSchedule)
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      containers:
      - name: monitor
        image: system-monitor:latest</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_actualización_de_daemonsets">3.4.3. Actualización de DaemonSets</h4>
<div class="paragraph">
<p>Los DaemonSets soportan dos estrategias de actualización:</p>
</div>
<div class="paragraph">
<p><strong>RollingUpdate (por defecto):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # Máximo 1 Pod no disponible durante actualización
  selector:
    matchLabels:
      app: filebeat
  template:
    metadata:
      labels:
        app: filebeat
    spec:
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:7.10.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>OnDelete:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: critical-agent
spec:
  updateStrategy:
    type: OnDelete  # Solo actualiza cuando Pod se elimina manualmente
  selector:
    matchLabels:
      app: critical-agent
  template:
    metadata:
      labels:
        app: critical-agent
    spec:
      containers:
      - name: agent
        image: critical-agent:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de actualización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cambiar imagen (con RollingUpdate)
kubectl set image daemonset/filebeat filebeat=docker.elastic.co/beats/filebeat:7.11.0

# Ver progreso de actualización
kubectl rollout status daemonset/filebeat

# Historial de rollout
kubectl rollout history daemonset/filebeat

# Rollback a versión anterior
kubectl rollout undo daemonset/filebeat

# Ver pods siendo actualizados
kubectl get pods -l app=filebeat --sort-by=.metadata.creationTimestamp</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_node_exporter_para_monitoreo">3.4.4. Ejemplo: Node Exporter para Monitoreo</h4>
<div class="paragraph">
<p><strong>Setup completo de Prometheus Node Exporter:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: v1
kind: Service
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  type: ClusterIP
  ports:
  - port: 9100
    targetPort: 9100
    name: http
  selector:
    app: node-exporter
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
      hostNetwork: true           # Usa red del host
      hostPID: true               # Acceso a procesos del host
      hostIPC: true               # Acceso a IPC del host
      containers:
      - name: node-exporter
        image: prom/node-exporter:v1.2.2
        args:
          - "--path.procfs=/host/proc"
          - "--path.sysfs=/host/sys"
          - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($|/)"
        ports:
        - containerPort: 9100
          name: http
        resources:
          limits:
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        - name: rootfs
          mountPath: /rootfs
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: rootfs
        hostPath:
          path: /</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar node exporter en todos los nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver DaemonSet status
kubectl describe daemonset -n monitoring node-exporter

# Ver pods en todos los nodos
kubectl get pods -n monitoring -o wide -l app=node-exporter

# Conectar a metrics de un nodo específico
kubectl port-forward -n monitoring daemonset/node-exporter 9100:9100

# En otra terminal:
curl http://localhost:9100/metrics | grep node_cpu_seconds_total</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_recolección_de_logs_con_fluent">3.4.5. Ejemplo: Recolección de Logs con Fluent</h4>
<div class="paragraph">
<p><strong>Fluent bit como DaemonSet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Daemon Off
        Flush 5
        Log_Level info

    [INPUT]
        Name tail
        Tag docker.*
        Path /var/log/containers/*.log
        Parser docker
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On

    [FILTER]
        Name kubernetes
        Match docker.*
        Kube_URL https://kubernetes.default.svc:443
        Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token
        Keep_Log On

    [OUTPUT]
        Name stackdriver
        Match *
        google_service_credentials /var/secrets/google/key.json
        resource k8s_container
        k8s_cluster_name my-cluster
        k8s_cluster_location us-central1
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluent-bit
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: fluent-bit
    spec:
      tolerations:
      - effect: NoExecute
        key: node.kubernetes.io/not-ready
        tolerationSeconds: 5
      - effect: NoExecute
        key: node.kubernetes.io/unreachable
        tolerationSeconds: 5
      serviceAccountName: fluent-bit
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:1.8.0
        volumeMounts:
        - name: config
          mountPath: /fluent-bit/etc/
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        resources:
          limits:
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
      volumes:
      - name: config
        configMap:
          name: fluent-bit-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluent-bit
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  - pods/logs
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit
subjects:
- kind: ServiceAccount
  name: fluent-bit
  namespace: logging</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ciclo_de_vida_y_comportamiento">3.4.6. Ciclo de Vida y Comportamiento</h4>
<div class="paragraph">
<p><strong>Creación de DaemonSet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Se crea DaemonSet en API
2. Controlador itera sobre todos los nodos
3. Para cada nodo (sin exclusiones):
   - Crea un Pod con el template
4. Pod se asigna directamente al nodo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cuando se agrega un nodo nuevo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Nuevo nodo se une al cluster
kubectl get nodes
# NAME      STATUS   ROLES   ...
# node-1    Ready    &lt;none&gt;
# node-2    Ready    &lt;none&gt;
# node-3    Ready    &lt;none&gt;  (nuevo)

# 2. DaemonSet detecta automáticamente
# 3. Crea un Pod en node-3 en segundos

kubectl get pods -o wide
# NAME                    READY   STATUS    NODE
# node-exporter-abc12     1/1     Running   node-1
# node-exporter-def45     1/1     Running   node-2
# node-exporter-ghi78     1/1     Running   node-3 (nuevo)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cuando se remueve un nodo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Drenar nodo (graceful)
kubectl drain node-3 --ignore-daemonsets

# 2. DaemonSet elimina Pod del nodo
# 3. Nodo se marca como unschedulable

# 4. Cuando se vuelve a agregar
kubectl uncordon node-3

# 5. DaemonSet detecta y recrea Pod automáticamente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_acceso_a_host_desde_daemonsets">3.4.7. Acceso a Host desde DaemonSets</h4>
<div class="paragraph">
<p>DaemonSets puede acceder a recursos del nodo host:</p>
</div>
<div class="paragraph">
<p><strong>hostNetwork:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  template:
    spec:
      hostNetwork: true  # Usa el namespace de red del host
      containers:
      - name: app
        image: app:latest</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con hostNetwork: true
# Pod accede a puertos en 0.0.0.0 del host
# Puede ver todos los procesos de red del nodo
netstat -tlnp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>hostPID:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  template:
    spec:
      hostPID: true  # Acceso a PID del host
      containers:
      - name: monitor
        image: monitor:latest</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con hostPID: true
# Puede ver todos los procesos del nodo
ps aux | grep -v container</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>hostIPC:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  template:
    spec:
      hostIPC: true  # Acceso a IPC del host
      containers:
      - name: agent
        image: agent:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Volúmenes hostPath:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  template:
    spec:
      containers:
      - name: app
        volumeMounts:
        - name: sys
          mountPath: /host/sys
      volumes:
      - name: sys
        hostPath:
          path: /sys
          type: Directory</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_daemonsets">3.4.8. Best Practices para DaemonSets</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa tolerations para nodos especiales</strong></p>
<div class="ulist">
<ul>
<li>
<p>Master/control-plane siempre tienen taints</p>
</li>
<li>
<p>Configura tolerations explícitamente</p>
</li>
<li>
<p>Documenta por qué necesitas ejecutar en cada nodo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Define recursos adecuadamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>DaemonSets ejecutan en cada nodo</p>
</li>
<li>
<p>El overhead se multiplica por número de nodos</p>
</li>
<li>
<p>Establece requests y limits apropiados</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa health checks</strong></p>
<div class="ulist">
<ul>
<li>
<p>Readiness: ¿listo para recibir tráfico?</p>
</li>
<li>
<p>Liveness: ¿el proceso está vivo?</p>
</li>
<li>
<p>Importante para agentes críticos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Actualiza cuidadosamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>maxUnavailable controla velocidad</p>
</li>
<li>
<p>Comienza con maxUnavailable: 1</p>
</li>
<li>
<p>Monitorea impacto antes de aumentar</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta el caso de uso</strong></p>
<div class="ulist">
<ul>
<li>
<p>¿Por qué se necesita en cada nodo?</p>
</li>
<li>
<p>¿Qué datos accede del host?</p>
</li>
<li>
<p>¿Qué permisos necesita?</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Considera performance</strong></p>
<div class="ulist">
<ul>
<li>
<p>No crees DaemonSets innecesarios</p>
</li>
<li>
<p>Usa nodeSelector para limitar si es posible</p>
</li>
<li>
<p>Monitorea uso de recursos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad en hostPath</strong></p>
<div class="ulist">
<ul>
<li>
<p>Limita acceso de volúmenes</p>
</li>
<li>
<p>Usa readOnly cuando sea posible</p>
</li>
<li>
<p>Ten cuidado con volúmenes de root</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Planifica tamaño de cluster</strong></p>
<div class="ulist">
<ul>
<li>
<p>Recurso: N pods × (requests de cada pod)</p>
</li>
<li>
<p>Ejemplo: 100 nodos × 256Mi = 25Gi de memoria</p>
</li>
<li>
<p>Escala según necesidad de nodos</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_comunes">3.4.9. Troubleshooting Comunes</h4>
<div class="paragraph">
<p><strong>Problema: Pod no se crea en algunos nodos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar taints en nodos
kubectl describe node node-1 | grep Taints

# Si hay taints, agregar tolerations en DaemonSet
kubectl patch daemonset my-daemon --type merge -p \
  '{"spec":{"template":{"spec":{"tolerations":[{"key":"mykey","operator":"Equal","value":"myvalue","effect":"NoSchedule"}]}}}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: DaemonSet actualiza muy lentamente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar maxUnavailable
kubectl get daemonset my-daemon -o jsonpath='{.spec.updateStrategy}'

# Aumentar maxUnavailable para actualizar más rápido
# (CUIDADO: puede afectar servicio)
kubectl patch daemonset my-daemon -p \
  '{"spec":{"updateStrategy":{"rollingUpdate":{"maxUnavailable":2}}}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Pod crashea en todos los nodos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs del DaemonSet
kubectl logs -l app=my-daemon --tail=50 -f

# Ver eventos de los pods
kubectl describe pod -l app=my-daemon

# Rollback a versión anterior
kubectl rollout undo daemonset/my-daemon</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: DaemonSet usa demasiados recursos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Limitar a nodos específicos
kubectl patch daemonset my-daemon -p \
  '{"spec":{"template":{"spec":{"nodeSelector":{"role":"compute"}}}}}'

# Etiquetar nodos apropiados primero
kubectl label node node-1 role=compute</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_jobs_y_cronjobs">3.5. Jobs y CronJobs</h3>
<div class="paragraph">
<p><strong>¿Qué son los Jobs?</strong></p>
</div>
<div class="paragraph">
<p>Un Job en Kubernetes es un controlador que crea Pods para ejecutar tareas batch (no continuas). A diferencia de otros controladores:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Objetivo de finalización</strong>: El Job se completa cuando sus Pods terminan exitosamente</p>
</li>
<li>
<p><strong>No reinicia indefinidamente</strong>: Los Pods se ejecutan una vez y terminan</p>
</li>
<li>
<p><strong>Garantiza completitud</strong>: Reinicia Pods si fallan (hasta completarse)</p>
</li>
<li>
<p><strong>Paralelismo configurable</strong>: Puede ejecutar múltiples Pods en paralelo</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Casos de uso principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Procesamiento batch</strong>: Procesar archivos CSV, logs, datos</p>
</li>
<li>
<p><strong>Cálculos complejos</strong>: Rendering, análisis científicos</p>
</li>
<li>
<p><strong>Exportación/Import de datos</strong>: Backup, restore de bases de datos</p>
</li>
<li>
<p><strong>Trabajos programados</strong>: Jobs disparados por eventos externos</p>
</li>
<li>
<p><strong>Limpiezas periódicas</strong>: Compresión, archivado de datos</p>
</li>
<li>
<p><strong>Notificaciones</strong>: Envío de emails, alerts</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_diferencia_deployment_vs_job">3.5.1. Diferencia: Deployment vs Job</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Característica</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">Job</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propósito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Servir tráfico continuo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecutar tarea hasta completarse</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reinician indefinidamente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Terminan cuando la tarea finaliza</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Réplicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mantiene # configurable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crea # según paralelismo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Éxito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod corriendo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Completions alcanzadas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Típica duración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Horas/días</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minutos/horas</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_definición_básica_de_jobs">3.5.2. Definición Básica de Jobs</h4>
<div class="paragraph">
<p><strong>YAML básico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: process-files
spec:
  completions: 1        # Número de Pods que deben completarse
  parallelism: 1        # Número de Pods en paralelo
  backoffLimit: 3       # Reintentos antes de fallar
  template:
    spec:
      containers:
      - name: process
        image: python:3.9
        command: ["python", "process.py"]
      restartPolicy: Never  # Never o OnFailure (no Always en Jobs)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estados de un Job:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Estados posibles:
# 1. Active: Ejecutándose
# 2. Succeeded: Completado exitosamente
# 3. Failed: Falló definitivamente

# Ver estado
kubectl describe job process-files

# Ver pods del job
kubectl get pods -l job-name=process-files</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_paralelismo_y_completions">3.5.3. Paralelismo y Completions</h4>
<div class="paragraph">
<p><strong>Diferentes patrones de ejecución:</strong></p>
</div>
<div class="paragraph">
<p><strong>Patrón 1: Tarea simple (1 Pod que completa)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  completions: 1
  parallelism: 1
  # Se crea 1 Pod
  # Cuando termina exitosamente: Job completado</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 2: Completar múltiples veces (1 Pod a la vez)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  completions: 5       # Necesita 5 terminaciones exitosas
  parallelism: 1       # Pero solo 1 a la vez
  # Crea Pod 1 → espera a completarse → crea Pod 2 → ...
  # Orden secuencial, toma 5× el tiempo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 3: Trabajo paralelo (múltiples Pods juntos)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  completions: 10
  parallelism: 5       # 5 Pods en paralelo
  # Crea 5 Pods → esperan a completar → crea siguiente batch
  # Reducción: 2 batches en lugar de 10 secuenciales</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 4: Trabajo con work queue (sin completions)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  completions: null    # Puede omitirse
  parallelism: 3
  # Crea 3 Pods
  # Cuando 1 termina exitosamente: Job completado
  # Otros Pods se eliminan
  # Patrón: trabajo disponible en queue, toma 1 Pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico: Procesar 100 archivos en paralelo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: process-images
spec:
  completions: 100       # Necesita procesar 100 imágenes
  parallelism: 10        # 10 workers en paralelo
  backoffLimit: 2        # Reintentar 2 veces si falla
  template:
    spec:
      containers:
      - name: worker
        image: image-processor:latest
        env:
        - name: TOTAL_JOBS
          value: "100"
        - name: PARALLELISM
          value: "10"
      restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Lógica en el contenedor:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">#!/bin/bash
# El contenedor de worker debe:
# 1. Determinar qué porción procesar
# 2. Procesar la porción asignada
# 3. Reportar éxito/fallo

# Opción: cada Pod procesa 1 archivo
# Opción: usar Job index (BATCH_JOB_SEQUENCE_NUM)

# Job índices (feature alpha/beta):
export JOB_INDEX=$((RANDOM % PARALLELISM))
echo "Processing file $JOB_INDEX of $TOTAL_JOBS"
process_file.py --index=$JOB_INDEX</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_de_reintentos">3.5.4. Configuración de Reintentos</h4>
<div class="paragraph">
<p><strong>backoffLimit: Número máximo de reintentos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  backoffLimit: 3
  # Primera ejecución
  # Fallo → reintento 1
  # Fallo → reintento 2
  # Fallo → reintento 3
  # Fallo → Job fallido</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>activeDeadlineSeconds: Timeout total del Job</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  activeDeadlineSeconds: 3600  # 1 hora máximo
  # Si el Job no completa en 1 hora: fallo
  # Incluso si hay reintentos disponibles</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Reintentos con backoff</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: unreliable-task
spec:
  backoffLimit: 4
  activeDeadlineSeconds: 600  # 10 minutos máximo
  template:
    spec:
      containers:
      - name: task
        image: unreliable-service:latest
        # El contenedor falla aleatoriamente
      restartPolicy: OnFailure
      # OnFailure: reintenta en el mismo Pod
      # Never: crea nuevo Pod para cada intento</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_casos_de_uso_jobs_complejos">3.5.5. Casos de Uso: Jobs Complejos</h4>
<div class="paragraph">
<p><strong>Job: Procesamiento ETL (Extract, Transform, Load)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: etl-pipeline
spec:
  completions: 5      # 5 tablas a procesar
  parallelism: 2      # 2 tablas en paralelo
  backoffLimit: 3
  template:
    metadata:
      labels:
        job: etl
    spec:
      containers:
      - name: etl-worker
        image: etl-worker:1.0
        env:
        - name: DATABASE_HOST
          valueFrom:
            configMapKeyRef:
              name: db-config
              key: host
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        emptyDir: {}
      restartPolicy: OnFailure
      # Asegurar suficiente tiempo
      terminationGracePeriodSeconds: 30
EOF

# Monitorear progreso
kubectl describe job etl-pipeline

# Ver pods en paralelo
kubectl get pods -l job-name=etl-pipeline --watch</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Job: Análisis de Datos Distribuido</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: data-analysis
spec:
  parallelism: 4
  completions: 4
  template:
    spec:
      containers:
      - name: analyzer
        image: data-analyzer:latest
        args:
          - "--input=/data"
          - "--output=/results"
        resources:
          requests:
            cpu: 2
            memory: 4Gi
          limits:
            cpu: 4
            memory: 8Gi
        volumeMounts:
        - name: input-data
          mountPath: /data
          readOnly: true
        - name: results
          mountPath: /results
      volumes:
      - name: input-data
        persistentVolumeClaim:
          claimName: analysis-data
      - name: results
        persistentVolumeClaim:
          claimName: analysis-results
      restartPolicy: Never</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_limpieza_y_gestión_de_jobs">3.5.6. Limpieza y Gestión de Jobs</h4>
<div class="paragraph">
<p><strong>Política de limpieza automática:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  ttlSecondsAfterFinished: 3600
  # Job completado hace más de 1 hora se elimina automáticamente
  # Útil para ahorrar espacio en etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos de gestión:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Jobs completados
kubectl get jobs

# Ver Job en detalle
kubectl describe job process-files

# Ver logs de todos los Pods del Job
kubectl logs -l job-name=process-files --all-containers=true

# Eliminar Job (mantiene Pods)
kubectl delete job process-files

# Eliminar Job y sus Pods
kubectl delete job process-files --cascade=foreground

# Ver Jobs en namespace específico
kubectl get jobs -n production</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_cronjobs_tareas_programadas">3.5.7. CronJobs: Tareas Programadas</h4>
<div class="paragraph">
<p><strong>¿Qué es un CronJob?</strong></p>
</div>
<div class="paragraph">
<p>Un CronJob es un controlador que crea Jobs automáticamente en horarios específicos. Funciona como <code>cron</code> en sistemas Unix.</p>
</div>
<div class="paragraph">
<p><strong>Sintaxis de CronJob (cron expression):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Formato: minuto hora día_mes mes día_semana
# *    *    *    *    *
# |    |    |    |    |
# |    |    |    |    +--- Día de la semana (0-6, 0=domingo)
# |    |    |    +------- Mes (1-12)
# |    |    +----------- Día del mes (1-31)
# |    +--------------- Hora (0-23)
# +------------------- Minuto (0-59)

Ejemplos:
0 2 * * *       # Cada día a las 2:00 AM
0 */4 * * *     # Cada 4 horas
0 9 * * 1-5     # Lunes a viernes a las 9:00 AM
0 0 1 * *       # Primer día del mes a medianoche
*/15 * * * *    # Cada 15 minutos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>YAML básico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-daily
spec:
  schedule: "0 2 * * *"      # 2:00 AM cada día
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: backup-tool:latest
            command: ["backup.sh"]
          restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CronJob con timezone (beta feature):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-daily
spec:
  timezone: "America/New_York"
  schedule: "0 2 * * *"
  # 2:00 AM en New York, no UTC
  jobTemplate:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplos_prácticos_de_cronjobs">3.5.8. Ejemplos Prácticos de CronJobs</h4>
<div class="paragraph">
<p><strong>CronJob 1: Backup diario de base de datos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mysql-backup
spec:
  schedule: "0 2 * * *"        # 2:00 AM cada día
  successfulJobsHistoryLimit: 3  # Mantener últimos 3 backups
  failedJobsHistoryLimit: 1      # Mantener último fallo
  jobTemplate:
    spec:
      backoffLimit: 2
      template:
        spec:
          serviceAccountName: backup-service
          containers:
          - name: backup
            image: mysql:8.0
            env:
            - name: MYSQL_HOST
              value: mysql-primary.database.svc.cluster.local
            - name: MYSQL_USER
              value: backup
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-backup-credentials
                  key: password
            - name: BACKUP_PATH
              value: /backups
            command:
            - /bin/bash
            - -c
            - |
              set -e
              TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
              BACKUP_FILE=\$BACKUP_PATH/mysql_\$TIMESTAMP.sql

              echo "Starting backup at \$(date)"
              mysqldump -h \$MYSQL_HOST -u \$MYSQL_USER -p\$MYSQL_PASSWORD \\
                --all-databases --single-transaction &gt; \$BACKUP_FILE

              echo "Backup completed: \$BACKUP_FILE"
              echo "Size: \$(du -h \$BACKUP_FILE)"

              # Mantener últimos 7 días
              find \$BACKUP_PATH -name "mysql_*.sql" -mtime +7 -delete
            volumeMounts:
            - name: backups
              mountPath: /backups
            resources:
              requests:
                cpu: 500m
                memory: 512Mi
              limits:
                cpu: 1
                memory: 1Gi
          volumes:
          - name: backups
            persistentVolumeClaim:
              claimName: backup-storage
          restartPolicy: OnFailure
EOF

# Ver CronJobs
kubectl get cronjobs

# Ver próxima ejecución
kubectl describe cronjob mysql-backup

# Ver histórico de Jobs creados
kubectl get jobs -l cronjob=mysql-backup</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CronJob 2: Limpieza de logs y caché</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-job
spec:
  schedule: "0 3 * * 0"        # 3:00 AM todos los domingos
  concurrencyPolicy: Forbid    # No ejecutar si hay una corriendo
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: cleanup
            image: busybox:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting cleanup at $(date)"

              # Limpiar logs viejos
              find /var/log -name "*.log" -mtime +30 -delete

              # Comprimir logs de la semana pasada
              find /var/log -name "*.log" -mtime +7 -mtime -30 -exec gzip {} \;

              # Estadísticas
              du -sh /var/log

              echo "Cleanup completed"
            volumeMounts:
            - name: logs
              mountPath: /var/log
          volumes:
          - name: logs
            hostPath:
              path: /var/log
          restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CronJob 3: Sincronización de datos cada hora</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: data-sync
spec:
  schedule: "0 * * * *"         # Cada hora
  concurrencyPolicy: Replace    # Si no terminó, crear nueva ejecución
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      activeDeadlineSeconds: 1800  # 30 minutos máximo
      backoffLimit: 2
      template:
        spec:
          containers:
          - name: sync
            image: data-sync-service:latest
            env:
            - name: SOURCE_DB
              valueFrom:
                configMapKeyRef:
                  name: sync-config
                  key: source_db
            - name: TARGET_DB
              valueFrom:
                configMapKeyRef:
                  name: sync-config
                  key: target_db
            - name: API_KEY
              valueFrom:
                secretKeyRef:
                  name: sync-credentials
                  key: api_key
          restartPolicy: OnFailure</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_concurrencypolicy_control_de_ejecuciones_simultáneas">3.5.9. concurrencyPolicy: Control de Ejecuciones Simultáneas</h4>
<div class="paragraph">
<p>CronJob tiene 3 políticas de concurrencia:</p>
</div>
<div class="paragraph">
<p><strong>Allow (por defecto):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  concurrencyPolicy: Allow
  # Permite múltiples Jobs ejecutando simultáneamente
  # Si el cron ejecuta antes de que termine el anterior: 2 Jobs</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Forbid:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  concurrencyPolicy: Forbid
  schedule: "0 * * * *"
  # Si hay Job ejecutando: NO crea uno nuevo
  # Espera a siguiente ventana de tiempo
  # Útil para backup: no múltiples backups juntos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Replace:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  concurrencyPolicy: Replace
  # Si hay Job ejecutando: cancela y crea uno nuevo
  # Útil para sincronización: que sea frecuente y reciente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_planificación_de_cronjobs">3.5.10. Planificación de CronJobs</h4>
<div class="paragraph">
<p><strong>Consideraciones al agendar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Ventana de tiempo:
   ¿Cuánto tarda la tarea normalmente?
   ¿Cuánto es el máximo esperado?
   Agendarla con suficiente margen

2. Distribución de carga:
   No agendar todas a la misma hora
   Ejemplo: 0 2 * * * (backup), 0 3 * * * (sync)
   Evita picos de carga

3. Timezone:
   UTC por defecto
   Usar timezone en v1.25+ para horarios locales

4. Retry:
   backoffLimit: reintentos si falla
   activeDeadlineSeconds: timeout total

5. Historico:
   successfulJobsHistoryLimit: cuantos successful mantener
   failedJobsHistoryLimit: cuantos failed mantener
   Importante para auditoría y debugging</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_jobs_y_cronjobs">3.5.11. Best Practices para Jobs y CronJobs</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Define restartPolicy apropiada</strong></p>
<div class="ulist">
<ul>
<li>
<p>Never: Nuevo Pod para cada intento</p>
</li>
<li>
<p>OnFailure: Reintenta en el mismo Pod</p>
</li>
<li>
<p>Never es más seguro para tareas stateful</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura resourceRequest adecuadamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Jobs son predecibles, dimensiona bien</p>
</li>
<li>
<p>Evita Out-of-Memory kills</p>
</li>
<li>
<p>Monitorea uso real vs estimado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa mecanismo de bloqueo</strong></p>
<div class="ulist">
<ul>
<li>
<p>CronJob puede dispararse múltiples veces</p>
</li>
<li>
<p>Usa locks en aplicación (base de datos, archivos)</p>
</li>
<li>
<p>O usa concurrencyPolicy: Forbid</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa ttlSecondsAfterFinished</strong></p>
<div class="ulist">
<ul>
<li>
<p>Limpia Jobs completados automáticamente</p>
</li>
<li>
<p>Ahorra espacio en etcd</p>
</li>
<li>
<p>Típicamente: 7 días = 604800 segundos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea ejecución</strong></p>
<div class="ulist">
<ul>
<li>
<p>Configura alertas para Jobs fallidos</p>
</li>
<li>
<p>Verifica que CronJobs se ejecuten en horarios esperados</p>
</li>
<li>
<p>Revisa logs regularmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta la propósito del Job</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué tarea realiza</p>
</li>
<li>
<p>Cuánto tiempo toma</p>
</li>
<li>
<p>Qué hacer si falla</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa ConfigMaps y Secrets</strong></p>
<div class="ulist">
<ul>
<li>
<p>Configuración en ConfigMaps</p>
</li>
<li>
<p>Credenciales en Secrets</p>
</li>
<li>
<p>Facilita actualización sin cambiar imagen</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Prueba jobs manualmente primero</strong></p>
<div class="ulist">
<ul>
<li>
<p>Crea Job (no CronJob) para probar</p>
</li>
<li>
<p>Valida en staging</p>
</li>
<li>
<p>Luego automatiza con CronJob</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_común_2">3.5.12. Troubleshooting Común</h4>
<div class="paragraph">
<p><strong>Problema: CronJob no se ejecuta</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar programación
kubectl get cronjob cleanup
kubectl describe cronjob cleanup

# Ver eventos
kubectl get events | grep cleanup

# Causas comunes:
# - Sintaxis de schedule incorrecta
# - ServiceAccount sin permisos
# - Cluster sin suficientes recursos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Job se ejecuta múltiples veces</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Jobs del CronJob
kubectl get jobs -l cronjob=my-cronjob

# Si hay múltiples simultáneos:
# Cambiar concurrencyPolicy a Forbid o Replace

kubectl patch cronjob my-cronjob -p '{"spec":{"concurrencyPolicy":"Forbid"}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Job tarda mucho o timeout</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs del Pod
kubectl logs -l job-name=my-job

# Verificar resourceRequest vs uso real
kubectl top pod -l job-name=my-job

# Aumentar activeDeadlineSeconds
kubectl patch job my-job -p '{"spec":{"activeDeadlineSeconds":7200}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Job entra en backoff loop</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver razón de fallo
kubectl describe pod -l job-name=my-job | grep "Last State"

# Ver logs completos
kubectl logs -l job-name=my-job --previous

# Aumentar backoffLimit si es transitorio
# O reducir si hay error permanente</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_4_servicios_y_redes">4. Módulo 4: Servicios y Redes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_networking_en_kubernetes">4.1. Networking en Kubernetes</h3>
<div class="paragraph">
<p><strong>Modelo de red de Kubernetes</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes implementa un modelo de red plano y agnóstico. Las características fundamentales son:</p>
</div>
<div class="paragraph">
<p><strong>Principios del modelo de red:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Todos los Pods pueden comunicarse entre sí</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sin NAT (Network Address Translation)</p>
</li>
<li>
<p>Dentro del mismo cluster</p>
</li>
<li>
<p>Independientemente del nodo donde corran</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Todos los nodos pueden comunicarse con todos los Pods</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sin NAT requerido</p>
</li>
<li>
<p>Comunicación directa</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>La dirección IP de un Pod es su propia dirección</strong></p>
<div class="ulist">
<ul>
<li>
<p>No hay aliasing</p>
</li>
<li>
<p>Transparencia en la comunicación</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Diagrama del modelo de red:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────────────────────────┐
│         Cluster Kubernetes                       │
├─────────────────────────────────────────────────┤
│  ┌──────────────────┐      ┌──────────────────┐ │
│  │  Nodo 1          │      │  Nodo 2          │ │
│  ├──────────────────┤      ├──────────────────┤ │
│  │ Pod A (10.0.0.1) │      │ Pod C (10.0.0.3) │ │
│  │ Pod B (10.0.0.2) │      │ Pod D (10.0.0.4) │ │
│  │                  │      │                  │ │
│  │ eth0: 192.168.1.1│      │ eth0: 192.168.1.2│ │
│  └──────────────────┘      └──────────────────┘ │
│         │                          │             │
│         └──────────────────────────┘             │
│     (Red overlay o L3: 10.0.0.0/24)             │
│     (Red nodos: 192.168.1.0/24)                 │
└─────────────────────────────────────────────────┘

Pod A → Pod C (sin NAT):
10.0.0.1 → 10.0.0.3 ✓
(no se reescribe IP de origen)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Espacios de direcciones:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Pod CIDR</strong>: Red de Pods (típicamente 10.0.0.0/8 o 10.0.0.0/16)</p>
</li>
<li>
<p><strong>Service CIDR</strong>: Red de Services (típicamente 10.96.0.0/12)</p>
</li>
<li>
<p><strong>Node CIDR</strong>: Red de nodos (depende de cloud provider)</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_cni_container_network_interface">4.1.1. CNI: Container Network Interface</h4>
<div class="paragraph">
<p><strong>¿Qué es CNI?</strong></p>
</div>
<div class="paragraph">
<p>CNI es un estándar que define cómo deben conectarse los contenedores en Kubernetes. Kubernetes delega el networking a plugins CNI.</p>
</div>
<div class="paragraph">
<p><strong>Responsabilidades del plugin CNI:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Crear interfaz de red en el contenedor</strong></p>
<div class="ulist">
<ul>
<li>
<p>Asignar dirección IP del Pod</p>
</li>
<li>
<p>Configurar rutas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Conectar contenedor a la red del cluster</strong></p>
<div class="ulist">
<ul>
<li>
<p>Red overlay o L3 routing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Mantener conectividad entre Pods</strong></p>
</li>
<li>
<p><strong>Implementar Network Policies (algunos plugins)</strong></p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Plugins CNI populares:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Plugin</th>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Características</th>
<th class="tableblock halign-left valign-top">Casos de uso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flannel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Overlay</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, ligero</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Desarrollo, clusters pequeños</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Calico</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">L3 Routing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alto rendimiento, network policies</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción, clusters grandes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weave</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Overlay</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Balanceo automático</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking flexible</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cilium</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">eBPF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alto rendimiento, seguridad avanzada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción crítica</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AWS VPC CNI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nativo AWS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integración AWS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Clusters EKS</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubenet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(legacy)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, limitado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo GCP GKE</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OVN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Open vSwitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">L2/L3, avanzado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Red empresarial</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Instalación de CNI:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar CNI instalado
kubectl get nodes
# STATUS debe ser "Ready" (indica CNI funciona)

# Buscar pods de CNI
kubectl get pods -n kube-system -o wide

# Ejemplo: Flannel
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# Ejemplo: Calico
kubectl apply -f https://docs.projectcalico.org/manifests/tigera-operator.yaml

# Verificar
kubectl get daemonset -n kube-system
kubectl get pods -n calico-system</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_comunicación_pod_to_pod">4.1.2. Comunicación Pod-to-Pod</h4>
<div class="paragraph">
<p><strong>Dentro del mismo nodo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────┐
│  Nodo 1                     │
├─────────────────────────────┤
│  ┌──────────┐  ┌──────────┐ │
│  │ Pod A    │  │ Pod B    │ │
│  │10.0.0.1  │  │10.0.0.2  │ │
│  └──────────┘  └──────────┘ │
│       │              │       │
│       └──────┬───────┘       │
│              │               │
│        virtual bridge       │
│        (docker0, cni0)      │
│              │               │
│         eth0 │               │
│       192.168.1.1            │
└─────────────────────────────┘

Comunicación directa a través del bridge virtual</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Entre diferentes nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌──────────────────────┐       ┌──────────────────────┐
│  Nodo 1              │       │  Nodo 2              │
├──────────────────────┤       ├──────────────────────┤
│  Pod A (10.0.0.1)    │       │  Pod C (10.0.0.3)    │
└──────────────────────┘       └──────────────────────┘
         │                              ▲
      10.0.0.1                       10.0.0.3
         │                              │
         └──────────────────────────────┘
              (overlay network)
         o
      (encapsulation si es necesario)

Dependiendo del plugin CNI:
- Flannel: VXLAN encapsulation
- Calico: BGP routing (sin encapsulation)
- Weave: Encryption optional</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico: Comunicación entre Pods</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Terminal 1: crear Pod servidor
kubectl run server --image=nginx:latest --port=80

# Esperar a que esté listo
kubectl wait --for=condition=ready pod/server --timeout=300s

# Terminal 2: crear Pod cliente
kubectl run -it client --image=busybox --rm --restart=Never -- sh

# En el cliente:
# Obtener IP del servidor
SERVER_IP=$(kubectl get pod server -o jsonpath='{.status.podIP}')
echo $SERVER_IP

# Probar conectividad
wget http://$SERVER_IP
# Debería funcionar sin ninguna configuración especial</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dns_en_kubernetes">4.1.3. DNS en Kubernetes</h4>
<div class="paragraph">
<p><strong>Servicio DNS en el cluster:</strong></p>
</div>
<div class="paragraph">
<p>El DNS en Kubernetes es proporcionado por CoreDNS (o kube-dns en versiones antiguas).</p>
</div>
<div class="paragraph">
<p><strong>Pods DNS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver DNS en el cluster
kubectl get pods -n kube-system | grep dns

# CoreDNS típicamente corre en kube-system
# kubectl get svc -n kube-system
# kube-dns (10.96.0.10) es el DNS del cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Resolución de nombres:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Formato: &lt;pod-name&gt;.&lt;namespace&gt;.pod.cluster.local

Ejemplos:
- mypod.default.pod.cluster.local → 10.0.0.5
- mysql-0.default.pod.cluster.local → 10.0.0.10

Service DNS:
- &lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local
- web.production.svc.cluster.local → 10.96.1.5

Corto (mismo namespace):
- web → web.default.svc.cluster.local
- mysql → mysql.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración DNS de un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En cualquier Pod, /etc/resolv.conf tiene:
cat /etc/resolv.conf
# nameserver 10.96.0.10  (DNS del cluster)
# search default.svc.cluster.local svc.cluster.local cluster.local
# options ndots:5</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Politica de resolución DNS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  dnsPolicy: ClusterFirst        # Por defecto: cluster primero
  dnsConfig:
    nameservers:
      - 8.8.8.8
    searches:
      - my-domain.com
  containers:
  - name: app
    image: app:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>Opciones de <code>dnsPolicy</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>ClusterFirst</strong> (por defecto): DNS del cluster, fallback a DNS del nodo</p>
</li>
<li>
<p><strong>ClusterFirstWithHostNet</strong>: DNS del cluster incluso con hostNetwork: true</p>
</li>
<li>
<p><strong>Default</strong>: DNS del nodo</p>
</li>
<li>
<p><strong>None</strong>: usa dnsConfig</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Resolver nombres desde un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear un Pod con herramientas
kubectl run debug --image=nicolaka/netshoot -it --rm --restart=Never -- bash

# Resolver un Service
nslookup kubernetes.default.svc.cluster.local

# Resolver otro Pod
nslookup mysql-0.mysql.default.pod.cluster.local

# Ver configuración DNS
cat /etc/resolv.conf

# Diagnosticar DNS
dig @10.96.0.10 web.default.svc.cluster.local

# Probar conectividad de red
ping 10.96.1.5
curl http://web.default.svc.cluster.local</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_flujo_de_paquetes_en_kubernetes">4.1.4. Flujo de paquetes en Kubernetes</h4>
<div class="paragraph">
<p><strong>Ejemplo: Pod A (nodo 1) → Pod B (nodo 2)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Pod A genera paquete:
   Origen: 10.0.0.1 (Pod A)
   Destino: 10.0.0.2 (Pod B)

2. Sale de Pod A a través de virtual interface

3. Llega al plugin CNI que:
   - Si está en el mismo nodo: entrega directamente
   - Si está en otro nodo:
     a) Flannel: encapsula en VXLAN, envía a nodo 2
     b) Calico: usa BGP routing hacia nodo 2

4. En nodo 2, CNI:
   - Desencapsula (si fue encapsulado)
   - Entrega a Pod B

5. Pod B recibe paquete con IP original intacta
   Origen: 10.0.0.1
   Destino: 10.0.0.2</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_de_conectividad">4.1.5. Troubleshooting de Conectividad</h4>
<div class="paragraph">
<p><strong>Problema: Pod no puede resolver nombres</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar CoreDNS está running
kubectl get pods -n kube-system -l k8s-app=kube-dns

# Ver logs de CoreDNS
kubectl logs -n kube-system -l k8s-app=kube-dns

# Verificar configuración DNS de Pod
kubectl exec my-pod -- cat /etc/resolv.conf

# Probar resolución
kubectl exec my-pod -- nslookup kubernetes.default</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Pod no puede alcanzar otro Pod</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar IP del Pod destino
kubectl get pod target-pod -o wide

# Desde Pod origen:
kubectl exec source-pod -- ping &lt;target-ip&gt;

# Si falla, verificar CNI:
# 1. ¿Está instalado el plugin CNI?
kubectl get daemonset -n kube-system

# 2. ¿El CNI pod está running?
kubectl get pods -n kube-system -l app=flannel

# 3. Ver logs del CNI
kubectl logs -n kube-system &lt;cni-pod-name&gt;

# 4. Verificar rutas en el nodo
kubectl debug node/node-name -it --image=ubuntu
# En el nodo:
ip route  # Debe haber ruta a Pod CIDR</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Service no es accesible desde Pod</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar Service existe
kubectl get svc my-service

# Verificar Service tiene Endpoints
kubectl get endpoints my-service

# Desde Pod, probar conectividad
kubectl exec my-pod -- nslookup my-service

# Ver logs de CoreDNS
kubectl logs -n kube-system -l k8s-app=kube-dns | grep my-service</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_de_networking">4.1.6. Best Practices de Networking</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Entiende el modelo de red de tu CNI</strong></p>
<div class="ulist">
<ul>
<li>
<p>Overlay vs routing directo</p>
</li>
<li>
<p>Implicaciones de performance</p>
</li>
<li>
<p>Encapsulation overhead</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa DNS en lugar de IPs</strong></p>
<div class="ulist">
<ul>
<li>
<p>IPs de Pods son efímeras</p>
</li>
<li>
<p>DNS proporciona descubrimiento automático</p>
</li>
<li>
<p>Usa Service DNS (FQDN corto)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura dnsPolicy apropiadamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>ClusterFirst es el defecto usual</p>
</li>
<li>
<p>ClusterFirstWithHostNet para hostNetwork pods</p>
</li>
<li>
<p>None solo si necesitas control total</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea conectividad de red</strong></p>
<div class="ulist">
<ul>
<li>
<p>Prueba resolución DNS regularmente</p>
</li>
<li>
<p>Verifica latencia entre nodos</p>
</li>
<li>
<p>Monitorea pérdida de paquetes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Planifica capacidad de red</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pods CIDR: suficientemente grande para crecer</p>
</li>
<li>
<p>Service CIDR: separada de Pod CIDR</p>
</li>
<li>
<p>Node CIDR: no debe superponerse</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa herramientas de debug</strong></p>
<div class="ulist">
<ul>
<li>
<p>kubectl exec para diagnosticar</p>
</li>
<li>
<p>Imágenes con netshoot (nicolaka/netshoot)</p>
</li>
<li>
<p>tcpdump para análisis de paquetes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Mantén seguridad en mente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Implementa Network Policies desde el inicio</p>
</li>
<li>
<p>No confíes en aislamiento solo por namespace</p>
</li>
<li>
<p>Criptografía entre nodos si es sensible</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Optimiza para latencia</strong></p>
<div class="ulist">
<ul>
<li>
<p>Preferentemente coloca Pods relacionados en mismo nodo</p>
</li>
<li>
<p>Considera node affinity para aplicaciones latency-sensitive</p>
</li>
<li>
<p>Monitorea jitter de red</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_services">4.2. Services</h3>
<div class="paragraph">
<p><strong>¿Qué es un Service?</strong></p>
</div>
<div class="paragraph">
<p>Un Service en Kubernetes es una abstracción que expone un conjunto de Pods como un servicio de red. Proporciona:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Dirección IP estable</strong>: incluso cuando Pods cambian</p>
</li>
<li>
<p><strong>Nombre DNS estable</strong>: para descubrimiento de servicios</p>
</li>
<li>
<p><strong>Load balancing</strong>: distribuye tráfico entre Pods</p>
</li>
<li>
<p><strong>Acceso consistente</strong>: sin necesidad de conocer IPs de Pods</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>¿Por qué necesitamos Services?</strong></p>
</div>
<div class="paragraph">
<p>Los Pods son efímeros. Sus IPs cambian cuando se recrean. Un Service proporciona una dirección estable para acceder a Pods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Sin Service:
Pod A (10.0.0.1) muere
↓
Nuevo Pod A (10.0.0.5)
↑
Cliente debe conocer nueva IP

Con Service:
Pod A (10.0.0.1) → web.default.svc.cluster.local (10.96.1.5)
Pod B (10.0.0.2) →
Pod C (10.0.0.3) →
↓
Pod A muere
↓
Nuevo Pod A (10.0.0.5) → web.default.svc.cluster.local (10.96.1.5)
↑
Cliente sigue usando mismo nombre</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_tipos_de_services">4.2.1. Tipos de Services</h4>
<div class="paragraph">
<p><strong>ClusterIP (por defecto)</strong></p>
</div>
<div class="paragraph">
<p>Service que solo es accesible dentro del cluster.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: ClusterIP
  selector:
    app: web
  ports:
  - protocol: TCP
    port: 80          # Puerto del Service
    targetPort: 8080  # Puerto del Pod</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear Service
kubectl apply -f service.yaml

# Ver Service
kubectl get svc web
# NAME   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)
# web    ClusterIP   10.96.1.5    &lt;none&gt;        80/TCP

# Acceder desde dentro del cluster
kubectl exec -it client-pod -- wget http://web

# Acceder por IP
kubectl exec -it client-pod -- wget http://10.96.1.5:80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>NodePort</strong></p>
</div>
<div class="paragraph">
<p>Service expuesto en cada nodo en un puerto estático.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: NodePort
  selector:
    app: web
  ports:
  - protocol: TCP
    port: 80          # Puerto en el Service
    targetPort: 8080  # Puerto en el Pod
    nodePort: 30080   # Puerto en cada nodo (30000-32767)</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Kubernetes asigna puerto automáticamente si no especificas
# Rango: 30000-32767

# Ver servicio
kubectl get svc web
# NAME   TYPE       CLUSTER-IP   EXTERNAL-IP   PORT(S)
# web    NodePort   10.96.1.5    &lt;none&gt;        80:30080/TCP

# Acceder desde fuera del cluster
curl http://node-ip:30080
curl http://192.168.1.1:30080

# O usar cualquier nodo
curl http://192.168.1.2:30080
curl http://192.168.1.3:30080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso de uso NodePort:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Desarrollo/testing</p>
</li>
<li>
<p>Exposición temporal</p>
</li>
<li>
<p>Aplicaciones que no requieren load balancer</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>LoadBalancer</strong></p>
</div>
<div class="paragraph">
<p>Service expuesto externamente usando un cloud load balancer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver servicio
kubectl get svc web
# NAME   TYPE           CLUSTER-IP   EXTERNAL-IP     PORT(S)
# web    LoadBalancer   10.96.1.5    203.0.113.100   80:30080/TCP

# La dirección EXTERNAL-IP es asignada por el cloud provider

# Acceder desde fuera
curl http://203.0.113.100</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración avanzada de LoadBalancer:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
  loadBalancerSourceRanges:
  - 203.0.113.0/24  # Solo desde este CIDR
  loadBalancerIP: 203.0.113.100  # IP específica (si soporta el provider)
  externalTrafficPolicy: Local  # No SNAT local traffic</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ExternalName</strong></p>
</div>
<div class="paragraph">
<p>Service que redirige a un nombre externo (CNAME).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: external-db
spec:
  type: ExternalName
  externalName: db.example.com
  ports:
  - port: 5432</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Desde un Pod del cluster:
kubectl exec -it client-pod -- psql -h external-db -U user

# Se resuelve como:
# external-db.default.svc.cluster.local → db.example.com</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tabla_comparativa_de_tipos_de_services">4.2.2. Tabla comparativa de tipos de Services</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Acceso</th>
<th class="tableblock halign-left valign-top">Rango de puertos</th>
<th class="tableblock halign-left valign-top">Casos de uso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ClusterIP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo intra-cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cualquiera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comunicación interna, databases, caches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NodePort</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Extra-cluster (nodo:puerto)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">30000-32767</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Desarrollo, testing, sin load balancer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LoadBalancer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Extra-cluster (IP pública)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cualquiera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción, acceso público</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ExternalName</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DNS externo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integración con servicios externos</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_selección_de_pods_mediante_labels">4.2.3. Selección de Pods mediante Labels</h4>
<div class="paragraph">
<p>Los Services usan selectors (basados en labels) para identificar qué Pods están detrás.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web           # Selecciona Pods con label app=web
    version: v1        # Y label version=v1
  ports:
  - port: 80
    targetPort: 8080
---
# Pods que coinciden:
apiVersion: v1
kind: Pod
metadata:
  name: web-pod-1
  labels:
    app: web          # ✓ Seleccionado
    version: v1       # ✓ Seleccionado
spec:
  containers:
  - name: app
    image: web:v1
---
# Este Pod NO es seleccionado:
apiVersion: v1
kind: Pod
metadata:
  name: web-pod-2
  labels:
    app: web          # ✓
    version: v2       # ✗ (necesita v1)
spec:
  containers:
  - name: app
    image: web:v2</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver qué Pods están detrás del Service
kubectl get endpoints web

# Ver detallado
kubectl describe svc web

# Ver Pods seleccionados
kubectl get pods -l app=web,version=v1</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_endpoints">4.2.4. Endpoints</h4>
<div class="paragraph">
<p>Los Endpoints son los Pods reales detrás de un Service.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Endpoints
kubectl get endpoints web

# ENDPOINTS           AGE
# 10.0.0.10:8080,10.0.0.11:8080   3m

# Ver detallado
kubectl describe endpoints web

# Formato YAML
kubectl get endpoints web -o yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Cuando Kubernetes detecta cambios en Pods que coinciden con los selectores, actualiza automáticamente los Endpoints.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Pod A creado con label app=web
   ↓
2. Service selector busca label app=web
   ↓
3. Pod A IP añadida a Endpoints
   ↓
4. Pod A muere
   ↓
5. IP removida de Endpoints automáticamente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_service_con_múltiples_pods">4.2.5. Ejemplo: Service con múltiples Pods</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
---
apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: app
        image: nginx:latest
        ports:
        - containerPort: 8080
EOF

# Ver Service
kubectl get svc web

# Ver Endpoints (3 Pods)
kubectl get endpoints web
# ENDPOINTS                                                 AGE
# 10.0.0.10:8080,10.0.0.11:8080,10.0.0.12:8080          2m

# Verificar balanceo de carga
kubectl run -it client --image=busybox --rm --restart=Never -- \
  wget -O- http://web

# Cada petición va a un Pod diferente (round-robin)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_session_affinity">4.2.6. Session Affinity</h4>
<div class="paragraph">
<p>Por defecto, el tráfico se distribuye sin estado entre Pods. Session Affinity permite "pegar" un cliente a un Pod.</p>
</div>
<div class="paragraph">
<p><strong>ClientIP affinity:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web
  sessionAffinity: ClientIP    # "pega" cliente a Pod
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800    # 3 horas
  ports:
  - port: 80
    targetPort: 8080</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Mismo cliente siempre va al mismo Pod
# Útil para aplicaciones que almacenan estado en memoria

kubectl run -it client --image=busybox --rm --restart=Never -- sh

# Dentro del cliente:
# Primera petición → Pod A
wget -O- http://web

# Segunda petición → Pod A (mismo, no Pod B)
wget -O- http://web

# Tercera petición → Pod A (mismo)
wget -O- http://web</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Casos de uso para Session Affinity:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones con sesiones en memoria</p>
</li>
<li>
<p>Caches locales</p>
</li>
<li>
<p>Conexiones con estado prolongado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>NOTA:</strong> Mejor que usar session affinity es:
- Almacenar sesiones en cache distribuido (Redis)
- Usar cookies para tracking
- Hacer la aplicación stateless</p>
</div>
</div>
<div class="sect3">
<h4 id="_multi_port_services">4.2.7. Multi-port Services</h4>
<div class="paragraph">
<p>Un Service puede exponer múltiples puertos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  - name: https
    port: 443
    targetPort: 8443
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: 9090
    protocol: TCP</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Acceder a diferentes puertos
kubectl exec client -- wget http://web:80    # HTTP
kubectl exec client -- wget https://web:443  # HTTPS
kubectl exec client -- wget http://web:9090  # Metrics</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_headless_services_2">4.2.8. Headless Services</h4>
<div class="paragraph">
<p>Un Service sin ClusterIP que proporciona DNS directo a Pods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None              # Headless
  selector:
    app: mysql
  ports:
  - port: 3306
    targetPort: 3306</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con Headless Service (como StatefulSet):
nslookup mysql.default.svc.cluster.local
# ANSWER SECTION:
# mysql.default.svc.cluster.local. 30 IN A 10.0.0.10
# mysql.default.svc.cluster.local. 30 IN A 10.0.0.11
# mysql.default.svc.cluster.local. 30 IN A 10.0.0.12

# Resolución de Pod individual:
nslookup mysql-0.mysql.default.svc.cluster.local
# ANSWER SECTION:
# mysql-0.mysql.default.svc.cluster.local. 30 IN A 10.0.0.10</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_external_ips">4.2.9. External IPs</h4>
<div class="paragraph">
<p>Exponer un Service en IPs específicas de los nodos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web
  externalIPs:
  - 192.168.1.10
  - 192.168.1.11
  ports:
  - port: 80
    targetPort: 8080</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Accesible en las IPs especificadas
curl http://192.168.1.10:80
curl http://192.168.1.11:80</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_services">4.2.10. Best Practices para Services</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa nombres descriptivos</strong></p>
<div class="ulist">
<ul>
<li>
<p>web, api, database, cache</p>
</li>
<li>
<p>Facilita discovery</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Elige el tipo correcto</strong></p>
<div class="ulist">
<ul>
<li>
<p>ClusterIP para comunicación interna</p>
</li>
<li>
<p>LoadBalancer para acceso externo</p>
</li>
<li>
<p>NodePort solo para testing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Especifica puertos con nombres</strong></p>
<div class="ulist">
<ul>
<li>
<p>Facilita debugging y monitoreo</p>
</li>
<li>
<p>Mejor para multi-port services</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa selectores consistentes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Labels deben coincidir con Pods</p>
</li>
<li>
<p>Mantén convención de naming</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea Endpoints</strong></p>
<div class="ulist">
<ul>
<li>
<p>Verifica que Pods estén "seleccionados"</p>
</li>
<li>
<p>Alertas si Endpoints vacío</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Cuidado con Session Affinity</strong></p>
<div class="ulist">
<ul>
<li>
<p>Puede causar desbalanceo</p>
</li>
<li>
<p>Mejor ser stateless</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta propósito del Service</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué aplicaciones sirve</p>
</li>
<li>
<p>Qué puerto usan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa Network Policies con Services</strong></p>
<div class="ulist">
<ul>
<li>
<p>Controla qué puede acceder</p>
</li>
<li>
<p>Defense in depth</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_de_services">4.2.11. Troubleshooting de Services</h4>
<div class="paragraph">
<p><strong>Problema: Endpoints vacío</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Service
kubectl describe svc web

# Ver Endpoints
kubectl get endpoints web
# Debería mostrar IPs de Pods, si está vacío:

# 1. Ver Pods disponibles
kubectl get pods -o wide

# 2. Ver qué labels tienen los Pods
kubectl get pods --show-labels

# 3. Verificar selector del Service
kubectl get svc web -o yaml
# Mirar spec.selector

# 4. Verificar Pods con ese selector
kubectl get pods -l app=web

# Causa común: labels no coinciden</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Service no responde</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar Service existe y tiene ClusterIP
kubectl get svc web

# 2. Verificar endpoints no vacíos
kubectl get endpoints web

# 3. Probar conectividad a Pod directamente
kubectl exec client -- ping &lt;pod-ip&gt;

# 4. Verificar kube-proxy
kubectl get daemonset -n kube-system kube-proxy
kubectl logs -n kube-system -l component=kube-proxy

# 5. Ver iptables/ipvs en nodo
kubectl debug node/node-name -it --image=ubuntu
# En el nodo:
sudo iptables -L -n | grep &lt;service-ip&gt;
sudo ipvsadm -L  # si usa IPVS</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: LoadBalancer sin EXTERNAL-IP</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar Service
kubectl get svc web

# Ver eventos
kubectl describe svc web

# Causas:
# - Cloud provider no soporta LoadBalancer
# - Cuota de IPs agotada
# - Provider no configurado

# En metal desnudo, usar metallb
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/main/config/manifests/metallb-native.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ingress">4.3. Ingress</h3>
<div class="paragraph">
<p><strong>¿Qué es Ingress?</strong></p>
</div>
<div class="paragraph">
<p>Ingress es una API de Kubernetes que expone rutas HTTP/HTTPS desde fuera del cluster a Services dentro del cluster. Proporciona:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Routing de tráfico</strong>: dirigir tráfico a diferentes Services basado en hostname/ruta</p>
</li>
<li>
<p><strong>TLS/SSL termination</strong>: manejo de certificados</p>
</li>
<li>
<p><strong>Load balancing</strong>: distribución de carga HTTP(S)</p>
</li>
<li>
<p><strong>Virtual hosting</strong>: múltiples dominios en un solo Ingress</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama: Ingress vs LoadBalancer Service</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌────────────────────────────────────────────────┐
│         LoadBalancer Service                    │
├────────────────────────────────────────────────┤
│  Cliente HTTP → LB IP:80 → Pods                │
│  127.0.0.1:80 (ej)                             │
│  (nivel 4, transporte)                         │
└────────────────────────────────────────────────┘

┌────────────────────────────────────────────────┐
│              Ingress                            │
├────────────────────────────────────────────────┤
│  Cliente HTTP → LB IP:80 → Ingress Controller   │
│  ↓                                              │
│  Parsea Host/Path HTTP                         │
│  ↓                                              │
│  web.example.com/api → service-api             │
│  web.example.com/v2 → service-v2               │
│  api.example.com → service-api-internal        │
│  (nivel 7, aplicación)                         │
└────────────────────────────────────────────────┘

LoadBalancer: L4 (transporte)
Ingress: L7 (aplicación)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>¿Cuándo usar Ingress?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Múltiples dominios/subdomios</p>
</li>
<li>
<p>Basado en paths de URLs</p>
</li>
<li>
<p>Compartir un LoadBalancer entre múltiples Services</p>
</li>
<li>
<p>TLS/SSL termination centralizado</p>
</li>
<li>
<p>Rate limiting, autenticación</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_yaml_básico_de_ingress">4.3.1. YAML básico de Ingress</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
spec:
  rules:
  - host: web.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web
            port:
              number: 80</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear Ingress
kubectl apply -f ingress.yaml

# Ver Ingress
kubectl get ingress

# Ver detallado
kubectl describe ingress web-ingress

# Actualizar /etc/hosts para testing local
echo "127.0.0.1 web.example.com" &gt;&gt; /etc/hosts

# Acceder
curl http://web.example.com</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ingress_controllers">4.3.2. Ingress Controllers</h4>
<div class="paragraph">
<p>Un Ingress Controller es un controlador que implementa Ingress.Kubernetes NO incluye uno por defecto. Debes instalar uno.</p>
</div>
<div class="paragraph">
<p><strong>Controladores populares:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Controlador</th>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Características</th>
<th class="tableblock halign-left valign-top">Casos de uso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NGINX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reverse proxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, rápido, estable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La mayoría de casos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Traefik</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reverse proxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Moderno, auto-discovery</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Microservicios, dinámico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HAProxy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Load balancer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alto rendimiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción crítica</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Istio Ingress Gateway</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service mesh</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Routing avanzado, observabilidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Architecturas service mesh</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AWS ALB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nativo AWS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integración AWS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Clusters EKS</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GCP Cloud Load Balancer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nativo GCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integración GCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Clusters GKE</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_nginx_ingress_controller">4.3.3. NGINX Ingress Controller</h4>
<div class="paragraph">
<p><strong>Instalación de NGINX Ingress Controller:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Opción 1: usando Helm (recomendado)
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace

# Opción 2: usando manifiestos
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/cloud/deploy.yaml

# Verificar instalación
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx

# Obtener IP del LoadBalancer
kubectl get svc -n ingress-nginx ingress-nginx-controller
# NAME                              TYPE           CLUSTER-IP     EXTERNAL-IP
# ingress-nginx-controller          LoadBalancer   10.96.1.5      203.0.113.100</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Ingress NGINX con host y path</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp
spec:
  ingressClassName: nginx
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 80
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api
            port:
              number: 8080
      - path: /v2
        pathType: Prefix
        backend:
          service:
            name: api-v2
            port:
              number: 8080</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_path_based_routing">4.3.4. Path-based Routing</h4>
<div class="paragraph">
<p>Enrutar basado en la ruta de la URL:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web
spec:
  ingressClassName: nginx
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: website
            port:
              number: 80
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 8080
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: admin-panel
            port:
              number: 3000
      - path: /api/v2
        pathType: Prefix
        backend:
          service:
            name: api-v2
            port:
              number: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Tipos de pathType:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Prefix</strong>: <code>/api</code> coincide <code>/api</code>, <code>/api/v1</code>, <code>/api/users</code></p>
</li>
<li>
<p><strong>Exact</strong>: <code>/api</code> coincide solo <code>/api</code> (no <code>/api/v1</code>)</p>
</li>
<li>
<p><strong>ImplementationSpecific</strong>: depende del controlador</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Requests a example.com:
GET /                   → website service
GET /api                → api-service
GET /api/v1            → api-service (coincide /api)
GET /admin             → admin-panel
GET /admin/users       → admin-panel
GET /api/v2            → api-v2 (coincide /api/v2 exacto)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_host_based_routing">4.3.5. Host-based Routing</h4>
<div class="paragraph">
<p>Enrutar basado en el hostname:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-tenant
spec:
  ingressClassName: nginx
  rules:
  - host: customer-a.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: customer-a-app
            port:
              number: 80
  - host: customer-b.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: customer-b-app
            port:
              number: 80
  - host: "*.example.com"  # Wildcard
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: default-app
            port:
              number: 80</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Requests:
customer-a.example.com → customer-a-app service
customer-b.example.com → customer-b-app service
customer-c.example.com → default-app service
subdomain.example.com → default-app service</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tlsssl_termination">4.3.6. TLS/SSL Termination</h4>
<div class="paragraph">
<p>Exponer HTTPS a través de Ingress:</p>
</div>
<div class="paragraph">
<p><strong>Crear certificado TLS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Opción 1: Crear con OpenSSL
openssl req -x509 -newkey rsa:4096 -keyout tls.key -out tls.crt -days 365 -nodes

# Opción 2: Usar certificado existente
# Tienes tls.crt y tls.key

# Crear Secret
kubectl create secret tls web-tls --cert=tls.crt --key=tls.key</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ingress con TLS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: secure-app
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - app.example.com
    secretName: web-tls         # Secret con cert/key
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 80</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Acceder con HTTPS
curl https://app.example.com

# Verificar certificado
openssl s_client -connect app.example.com:443</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Múltiples certificados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-tls
spec:
  tls:
  - hosts:
    - app.example.com
    secretName: app-tls
  - hosts:
    - api.example.com
    secretName: api-tls
  - hosts:
    - "*.internal.example.com"
    secretName: wildcard-tls
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 80
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api
            port:
              number: 8080</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_cert_manager_certificados_automáticos">4.3.7. Cert-Manager: Certificados automáticos</h4>
<div class="paragraph">
<p>Cert-Manager genera y renueva certificados automáticamente usando Let&#8217;s Encrypt.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar cert-manager
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.10.0/cert-manager.yaml

# Verificar
kubectl get pods -n cert-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ClusterIssuer para Let&#8217;s Encrypt:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ingress con auto-certificado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"  # Ref al issuer
spec:
  tls:
  - hosts:
    - app.example.com
    secretName: app-tls-auto     # Se crea automáticamente
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 80</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cert-manager crea automáticamente:
# 1. Certificate resource
# 2. Valida con Let's Encrypt
# 3. Crea Secret con certificado
# 4. Renueva automáticamente (60 días antes de expirar)

# Ver Certificates
kubectl get certificate

# Ver Secret creado
kubectl get secret app-tls-auto -o yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_completo_multi_tenant_ingress">4.3.8. Ejemplo completo: Multi-tenant Ingress</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
---
# Namespace para tenants
apiVersion: v1
kind: Namespace
metadata:
  name: tenants
---
# Services para cada tenant
apiVersion: v1
kind: Service
metadata:
  name: tenant-a-app
  namespace: tenants
spec:
  selector:
    tenant: a
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: tenant-b-app
  namespace: tenants
spec:
  selector:
    tenant: b
  ports:
  - port: 80
    targetPort: 8080
---
# Deployments para cada tenant
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tenant-a
  namespace: tenants
spec:
  replicas: 2
  selector:
    matchLabels:
      tenant: a
  template:
    metadata:
      labels:
        tenant: a
    spec:
      containers:
      - name: app
        image: nginx:latest
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tenant-b
  namespace: tenants
spec:
  replicas: 2
  selector:
    matchLabels:
      tenant: b
  template:
    metadata:
      labels:
        tenant: b
    spec:
      containers:
      - name: app
        image: nginx:latest
---
# Ingress multi-tenant
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-tenant
  namespace: tenants
spec:
  ingressClassName: nginx
  rules:
  - host: a.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: tenant-a-app
            port:
              number: 80
  - host: b.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: tenant-b-app
            port:
              number: 80
EOF

# Verificar
kubectl get ingress -n tenants
kubectl get svc -n tenants
kubectl get pods -n tenants</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ingress_annotations">4.3.9. Ingress Annotations</h4>
<div class="paragraph">
<p>Las anotaciones permiten configuración avanzada del controlador:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: advanced
  annotations:
    # NGINX-específicas
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/limit-rps: "10"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"

    # Cert-manager
    cert-manager.io/cluster-issuer: "letsencrypt-prod"

    # Auth
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: basic-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api
            port:
              number: 8080</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_traefik_ingress_controller_moderno">4.3.10. Traefik: Ingress Controller moderno</h4>
<div class="paragraph">
<p><strong>Instalación de Traefik:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con Helm
helm repo add traefik https://traefik.github.io/charts
helm install traefik traefik/traefik \
  --namespace traefik \
  --create-namespace

# Verificar
kubectl get pods -n traefik
kubectl get svc -n traefik</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ingress con Traefik:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app
  annotations:
    traefik.ingress.kubernetes.io/router.tls: "true"
spec:
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>Traefik también soporta CRDs nativos (IngressRoute) para configuración más avanzada.</p>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_ingress">4.3.11. Best Practices para Ingress</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Elige el controlador adecuado</strong></p>
<div class="ulist">
<ul>
<li>
<p>NGINX para la mayoría de casos</p>
</li>
<li>
<p>Traefik si necesitas auto-discovery</p>
</li>
<li>
<p>Cloud-native si usas EKS/GKE/AKS</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa tls automático</strong></p>
<div class="ulist">
<ul>
<li>
<p>Implementa cert-manager</p>
</li>
<li>
<p>Let&#8217;s Encrypt para dominios públicos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Organiza Ingress resources</strong></p>
<div class="ulist">
<ul>
<li>
<p>Uno por aplicación</p>
</li>
<li>
<p>Agrupa por namespace</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa rate limiting</strong></p>
<div class="ulist">
<ul>
<li>
<p>Previene abuso</p>
</li>
<li>
<p>Protege backends</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa reescritura de URLs</strong></p>
<div class="ulist">
<ul>
<li>
<p>rewrite-target para servicios internos</p>
</li>
<li>
<p>Mantiene URLs limpias para usuarios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea Ingress Controller</strong></p>
<div class="ulist">
<ul>
<li>
<p>Logs de HTTP</p>
</li>
<li>
<p>Métricas (Prometheus)</p>
</li>
<li>
<p>Alertas para 5xx errors</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta reglas de routing</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué lleva a dónde</p>
</li>
<li>
<p>Quién puede acceder</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Valida configuración</strong></p>
<div class="ulist">
<ul>
<li>
<p>Verifica Ingress antes de desplegar</p>
</li>
<li>
<p>Prueba routing antes en staging</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_de_ingress">4.3.12. Troubleshooting de Ingress</h4>
<div class="paragraph">
<p><strong>Problema: Ingress sin IP externa</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado
kubectl get ingress

# Ver detallado
kubectl describe ingress myapp

# Verificar que el controlador está corriendo
kubectl get pods -n ingress-nginx

# Si hay error, ver eventos
kubectl get events -n ingress-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: 404 Not Found</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar que Service existe
kubectl get svc

# Verificar que Service tiene endpoints
kubectl get endpoints

# Probar acceso directo a Pod
kubectl exec client -- wget http://service-ip

# Ver logs del Ingress Controller
kubectl logs -n ingress-nginx &lt;controller-pod&gt;

# Verificar path correcto en Ingress
kubectl get ingress -o yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: HTTPS certificado inválido</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar Secret existe
kubectl get secret

# Ver contenido del Secret
kubectl get secret tls-secret -o yaml

# Verificar certificado
kubectl get secret tls-secret -o jsonpath='{.data.tls\.crt}' | base64 -d | openssl x509 -noout -text

# Si usa cert-manager, ver Certificate
kubectl get certificate

# Ver eventos del Certificate
kubectl describe certificate myapp</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_network_policies">4.4. Network Policies</h3>
<div class="paragraph">
<p><strong>¿Qué es una Network Policy?</strong></p>
</div>
<div class="paragraph">
<p>Una Network Policy es una especificación de cómo grupos de Pods pueden comunicarse entre sí y otros endpoints en la red. Proporciona:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Aislamiento de red</strong>: restricción de tráfico entre Pods</p>
</li>
<li>
<p><strong>Seguridad</strong>: principio de menor privilegio en red</p>
</li>
<li>
<p><strong>Segmentación</strong>: separación lógica de aplicaciones</p>
</li>
<li>
<p><strong>Control granular</strong>: reglas por Pod, namespace, puerto</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>¿Por qué Network Policies?</strong></p>
</div>
<div class="paragraph">
<p>Por defecto, en Kubernetes todos los Pods pueden comunicarse con todos los demás Pods. Network Policies restringen esta comunicación.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Sin Network Policy:
┌─────────────────────────────────────┐
│  Namespace: production              │
├─────────────────────────────────────┤
│  web ↔ api ↔ database ↔ monitoring │
│     Cualquier Pod habla con cualquier otro
└─────────────────────────────────────┘

Con Network Policy:
┌─────────────────────────────────────┐
│  Namespace: production              │
├─────────────────────────────────────┤
│  web → api → database               │
│              ↑                       │
│        (monitoring no puede acceder) │
└─────────────────────────────────────┘</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_requisitos">4.4.1. Requisitos</h4>
<div class="paragraph">
<p>Network Policies se requiere que el CNI lo soporte:
- Calico: ✓ soporta
- Cilium: ✓ soporta
- Flannel: ✗ NO soporta
- Weave: ✓ soporta</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar si tu CNI soporta Network Policies
kubectl get daemonset -n kube-system
# Si ves calico-node, cilium-agent, weave: OK
# Si ves flannel-ds: Network Policies no funcionarán</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_yaml_básico_de_network_policy">4.4.2. YAML básico de Network Policy</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
spec:
  podSelector: {}  # Aplica a todos los Pods
  policyTypes:
  - Ingress
  - Egress
  ingress: []      # Ningún ingress permitido
  egress: []       # Ningún egress permitido</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Aplicar Network Policy
kubectl apply -f netpol.yaml

# Ver Network Policies
kubectl get networkpolicy

# Ver detallado
kubectl describe networkpolicy deny-all</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_selección_de_pods">4.4.3. Selección de Pods</h4>
<div class="paragraph">
<p>Network Policies usan pod selectors basados en labels:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web
spec:
  podSelector:
    matchLabels:
      app: web      # Aplica a Pods con label app=web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: client  # Permite tráfico desde Pods con label app=client
    ports:
    - protocol: TCP
      port: 80</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reglas_de_ingress">4.4.4. Reglas de Ingress</h4>
<div class="paragraph">
<p>Ingress controla tráfico entrante a un Pod.</p>
</div>
<div class="paragraph">
<p><strong>Estructura básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: client
    - namespaceSelector:
        matchLabels:
          name: frontend
    - ipBlock:
        cidr: 203.0.113.0/24
    ports:
    - protocol: TCP
      port: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>Esto significa: "Permite ingress si proviene de (Pod con label app=client) O (namespace frontend) O (CIDR 203.0.113.0/24) EN puertos TCP 80".</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Permitir desde Pods específicos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-api
spec:
  podSelector:
    matchLabels:
      app: database
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api     # Solo Pods con label app=api
    ports:
    - protocol: TCP
      port: 5432      # Solo puerto 5432 (PostgreSQL)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Permitir desde Namespace específico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-namespace
spec:
  podSelector:
    matchLabels:
      app: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: frontend  # Solo desde namespace "frontend"
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Permitir desde CIDR específico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-cidr
spec:
  podSelector:
    matchLabels:
      app: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - ipBlock:
        cidr: 10.0.0.0/8  # Permitir desde esta red
        except:
        - 10.0.0.5/32     # Excepto esta IP
    ports:
    - protocol: TCP
      port: 443</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reglas_de_egress">4.4.5. Reglas de Egress</h4>
<div class="paragraph">
<p>Egress controla tráfico saliente de un Pod.</p>
</div>
<div class="paragraph">
<p><strong>Estructura:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: api
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Restricción de egress</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: restrict-egress
spec:
  podSelector:
    matchLabels:
      app: web
  policyTypes:
  - Egress
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: api     # Solo puede enviar a api
    ports:
    - protocol: TCP
      port: 8080
  - to:
    - podSelector:
        matchLabels:
          app: database  # Y a database
    ports:
    - protocol: TCP
      port: 5432
  # DNS es especial (necesario excepto si desactivas)
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_politicas_de_aislamiento_por_defecto">4.4.6. Politicas de aislamiento por defecto</h4>
<div class="paragraph">
<p><strong>Deny All Ingress:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  # ingress: [] (vacío = rechaza todo)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Después de aplicar esta policy, NADA puede entrar a ningún Pod a menos que haya otra policy que permita.</p>
</div>
<div class="paragraph">
<p><strong>Deny All Egress:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-egress
spec:
  podSelector: {}
  policyTypes:
  - Egress
  # egress: [] (vacío = rechaza todo)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Después de aplicar, ningún Pod puede salir a menos que haya otra policy.</p>
</div>
<div class="paragraph">
<p><strong>Deny All (Ingress y Egress):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_casos_de_uso_comunes_2">4.4.7. Casos de uso comunes</h4>
<div class="paragraph">
<p><strong>Caso 1: Arquitectura de 3 capas (web, api, database)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
# 1. Permitir tráfico a web (desde internet)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-to-web
spec:
  podSelector:
    matchLabels:
      tier: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector: {}  # Desde cualquier namespace
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
---
# 2. Web puede hablar con api
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-to-api
spec:
  podSelector:
    matchLabels:
      tier: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: web
    ports:
    - protocol: TCP
      port: 8080
---
# 3. API puede hablar con database
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-api-to-db
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: api
    ports:
    - protocol: TCP
      port: 5432
---
# 4. Denegar todo lo demás (default deny)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  # (ingress y egress vacías = rechaza todo excepto lo permitido arriba)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso 2: Aislamiento por tenant (multi-tenant)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">---
# Tenant A puede hablar internamente
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: tenant-a-internal
spec:
  podSelector:
    matchLabels:
      tenant: a
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tenant: a
  egress:
  - to:
    - podSelector:
        matchLabels:
          tenant: a
  - to:
    - namespaceSelector: {}  # DNS
    ports:
    - protocol: UDP
      port: 53
---
# Tenant B aislado
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: tenant-b-internal
spec:
  podSelector:
    matchLabels:
      tenant: b
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tenant: b
  egress:
  - to:
    - podSelector:
        matchLabels:
          tenant: b
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_segmentación_por_namespace">4.4.8. Segmentación por Namespace</h4>
<div class="paragraph">
<p>Network Policies pueden aislar namespaces completos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Etiquetar namespace
kubectl label namespace frontend name=frontend
kubectl label namespace backend name=backend
kubectl label namespace database name=database</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Backend solo puede acceder a database
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-to-db
  namespace: backend
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: database
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - namespaceSelector: {}  # DNS
    ports:
    - protocol: UDP
      port: 53
---
# Frontend solo puede acceder a backend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-to-backend
  namespace: frontend
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: backend
    ports:
    - protocol: TCP
      port: 8080
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_manejo_de_dns">4.4.9. Manejo de DNS</h4>
<div class="paragraph">
<p>DNS es especial. Si bloqueas egress, necesitas permitir DNS (puerto 53 UDP):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  egress:
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53  # DNS query
    - protocol: TCP
      port: 53  # DNS query (TCP)
  - to:
    - podSelector:
        matchLabels:
          app: api
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sin esto, los Pods no pueden resolver nombres de otros Services.</p>
</div>
</div>
<div class="sect3">
<h4 id="_herramientas_para_network_policies">4.4.10. Herramientas para Network Policies</h4>
<div class="paragraph">
<p><strong>Tester de NetworkPolicy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver si tráfico está permitido
kubectl run -it --image=nicolaka/netshoot debug --rm --restart=Never -- bash

# Dentro del Pod:
# Probar conectividad
wget http://api:8080
curl http://database:5432

# Ver IPs de otros Pods
nslookup api.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Visualización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Network Policies
kubectl get networkpolicy
kubectl get networkpolicy -A

# Ver detalles
kubectl describe networkpolicy &lt;name&gt;

# Ver en YAML
kubectl get networkpolicy -o yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_network_policies">4.4.11. Best Practices para Network Policies</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Empieza permisivo, termina restrictivo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Primero permite lo necesario</p>
</li>
<li>
<p>Luego añade deny-all</p>
</li>
<li>
<p>No es al revés</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa labels consistentemente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Etiquetar todos los Pods apropiadamente</p>
</li>
<li>
<p>Labels para tier, app, tenant, env</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Agrupa reglas por lógica</strong></p>
<div class="ulist">
<ul>
<li>
<p>Una policy por relación (web→api, api→db)</p>
</li>
<li>
<p>Facilita mantenimiento</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Permite DNS explícitamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Si usas egress policy, permite port 53</p>
</li>
<li>
<p>Sino, los Pods no pueden resolver nombres</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea tráfico bloqueado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Activar logging en el CNI</p>
</li>
<li>
<p>Alertas para tráfico rechazado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta políticas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué permite cada policy</p>
</li>
<li>
<p>Por qué es necesaria</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Prueba antes de producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>Aplica en staging primero</p>
</li>
<li>
<p>Verifica que no rompe aplicaciones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa namespaces para separación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada tenant en namespace distinto</p>
</li>
<li>
<p>Facilita aislamiento</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_de_network_policies">4.4.12. Troubleshooting de Network Policies</h4>
<div class="paragraph">
<p><strong>Problema: Tráfico bloqueado inesperadamente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Network Policies aplicadas
kubectl get networkpolicy

# Ver detalles de una policy
kubectl describe networkpolicy &lt;name&gt;

# Verificar labels de Pods
kubectl get pods --show-labels

# Revisar si labels coinciden con selectors
# Causa común: labels no coinciden

# Probar tráfico directo
kubectl exec &lt;pod&gt; -- curl http://&lt;destino&gt;

# Ver logs del CNI
kubectl logs -n kube-system -l k8s-app=calico-node</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: DNS no funciona</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar egress allow DNS
kubectl describe networkpolicy &lt;name&gt;

# Debe haber:
# to: namespaceSelector: {}
# port: 53 UDP

# Agregar si falta:
# spec:
#   egress:
#   - to:
#     - namespaceSelector: {}
#     ports:
#     - protocol: UDP
#       port: 53</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Ingress/Egress rechaza legítimamente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver tráfico actual
kubectl exec &lt;pod&gt; -- netstat -tlnp

# Identificar qué necesita comunicarse con qué
# Luego crear policies permitiendo eso

# Mejor: aplicar deny-all luego allow específico
# Que al revés (deny específico)</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_5_almacenamiento">5. Módulo 5: Almacenamiento</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_volúmenes">5.1. Volúmenes</h3>
<div class="paragraph">
<p><strong>¿Qué es un volumen?</strong></p>
</div>
<div class="paragraph">
<p>Un volumen en Kubernetes es una forma de almacenamiento que persiste durante la vida de un Pod. Los volúmenes permiten:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Compartir datos entre contenedores</strong> en el mismo Pod</p>
</li>
<li>
<p><strong>Acceder a datos del nodo host</strong></p>
</li>
<li>
<p><strong>Almacenar datos de forma temporal</strong></p>
</li>
<li>
<p><strong>Inyectar configuración en Pods</strong> (ConfigMaps, Secrets)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ciclo de vida:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando se crea un Pod se crean sus volúmenes</p>
</li>
<li>
<p>Cuando se elimina el Pod se eliminan los volúmenes (excepto PVs)</p>
</li>
<li>
<p>Los datos dentro persisten mientras el Pod exista</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diferencia: Volúmenes vs PersistentVolumes</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Volumen</th>
<th class="tableblock halign-left valign-top">PersistentVolume</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ciclo de vida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod (efímero)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cluster (persistente)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alcance</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Todo el cluster</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Provisioning</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual o automático</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual o dinámico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Casos de uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporal, cache, config</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bases de datos, backups</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Persistencia</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se elimina con Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Persiste después del Pod</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_tipos_de_volúmenes_efímeros">5.1.1. Tipos de Volúmenes Efímeros</h4>
<div class="paragraph">
<p><strong>emptyDir: Almacenamiento temporal</strong></p>
</div>
<div class="paragraph">
<p>Un volumen vacío que se crea cuando se crea el Pod y se elimina cuando se elimina.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: multi-container
spec:
  containers:
  - name: writer
    image: busybox
    command: ["sh", "-c"]
    args:
    - |
      while true; do
        echo "$(date): hello from writer" &gt;&gt; /data/log.txt
        sleep 5
      done
    volumeMounts:
    - name: data
      mountPath: /data
  - name: reader
    image: busybox
    command: ["sh", "-c"]
    args:
    - |
      while true; do
        cat /data/log.txt
        sleep 10
      done
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Casos de uso emptyDir:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Cache entre contenedores</strong>: un contenedor escribe, otro lee</p>
</li>
<li>
<p><strong>Almacenamiento temporal</strong>: archivos que se descartan con Pod</p>
</li>
<li>
<p><strong>Git-sync sidecar</strong>: descargar código en volumen compartido</p>
</li>
<li>
<p><strong>Log processor</strong>: un contenedor escribe logs, otro los procesa</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>emptyDir con límite de tamaño:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">volumes:
- name: cache
  emptyDir:
    sizeLimit: 1Gi  # Máximo 1GB, luego el Pod se evicta</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>emptyDir con tipo de almacenamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">volumes:
- name: cache
  emptyDir:
    medium: Memory  # Usar RAM en lugar de disco
    sizeLimit: 512Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>Usar <code>medium: Memory</code> es útil para caches rápidos pero consume memoria del nodo.</p>
</div>
</div>
<div class="sect3">
<h4 id="_hostpath_acceder_al_nodo_host">5.1.2. hostPath: Acceder al nodo host</h4>
<div class="paragraph">
<p>Un volumen que monta un archivo o directorio del nodo host.</p>
</div>
<div class="paragraph">
<p><strong>ADVERTENCIA:</strong> <code>hostPath</code> es potencialmente inseguro. Evitarlo en clusters multi-tenant.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: host-access
spec:
  containers:
  - name: app
    image: busybox
    volumeMounts:
    - name: host-logs
      mountPath: /host-logs
  volumes:
  - name: host-logs
    hostPath:
      path: /var/log      # Ruta en el nodo
      type: Directory     # Debe ser directorio</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Tipos de hostPath:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Verificación</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">(vacío)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No verificar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sin validación</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DirectoryOrCreate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Directorio, crear si no existe</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crea si falta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Directory</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Debe existir directorio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falla si no existe</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FileOrCreate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo, crear si no existe</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crea si falta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">File</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Debe existir archivo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falla si no existe</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Socket</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Socket UNIX existente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falla si no es socket</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CharDevice</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dispositivo char existente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falla si no es char device</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BlockDevice</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dispositivo block existente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Falla si no es block device</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo: Monitoreo con acceso a host</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: system-monitor
spec:
  containers:
  - name: monitor
    image: busybox
    command: ["sh", "-c"]
    args:
    - |
      while true; do
        echo "=== CPU Info ==="
        cat /host-proc/cpuinfo | head -5
        echo "=== Memory Info ==="
        cat /host-proc/meminfo | head -3
        sleep 10
      done
    volumeMounts:
    - name: proc
      mountPath: /host-proc
    - name: sys
      mountPath: /host-sys
  volumes:
  - name: proc
    hostPath:
      path: /proc
      type: Directory
  - name: sys
    hostPath:
      path: /sys
      type: Directory</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configmap_y_secret_como_volúmenes">5.1.3. configMap y secret como volúmenes</h4>
<div class="paragraph">
<p>ConfigMaps y Secrets pueden montarse como volúmenes en Pods.</p>
</div>
<div class="paragraph">
<p><strong>ConfigMap como volumen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear ConfigMap con archivos
kubectl create configmap app-config \
  --from-literal=database.host=localhost \
  --from-literal=database.port=5432</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: app:latest
    volumeMounts:
    - name: config
      mountPath: /etc/config
  volumes:
  - name: config
    configMap:
      name: app-config
      items:
      - key: database.host
        path: db-host.txt      # Renombar clave a archivo
      - key: database.port
        path: db-port.txt
      defaultMode: 0644       # Permisos (octal)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Secret como volumen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear Secret
kubectl create secret generic db-credentials \
  --from-literal=username=admin \
  --from-literal=password=secret123</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: app:latest
    volumeMounts:
    - name: secrets
      mountPath: /etc/secrets
      readOnly: true        # Recomendado para secrets
  volumes:
  - name: secrets
    secret:
      secretName: db-credentials
      defaultMode: 0400     # Solo lectura (permisos)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Acceder desde el contenedor:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con volumen montado, los archivos están disponibles:
ls /etc/config
# database.host
# database.port

cat /etc/config/database.host
# localhost

cat /etc/config/database.port
# 5432</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_montaje_de_volúmenes">5.1.4. Montaje de volúmenes</h4>
<div class="paragraph">
<p><strong>Estructura completa de volumeMounts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  containers:
  - name: app
    volumeMounts:
    - name: data           # Nombre del volumen (debe coincidir)
      mountPath: /app/data # Ruta en el contenedor
      subPath: subfolder   # Opcional: subcarpeta del volumen
      readOnly: false      # Lectura/escritura (defecto)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo con subPath:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: multi-mount
spec:
  containers:
  - name: app
    image: app:latest
    volumeMounts:
    - name: shared
      mountPath: /app/logs
      subPath: logs        # Monta solo la subcarpeta logs/
    - name: shared
      mountPath: /app/data
      subPath: data        # Monta solo la subcarpeta data/
  volumes:
  - name: shared
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sin <code>subPath</code>, ambas volumeMounts sobreescribirían. Con <code>subPath</code>, montan diferentes carpetas.</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_completo_multi_container_con_volúmenes">5.1.5. Ejemplo completo: Multi-container con volúmenes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
apiVersion: v1
kind: Pod
metadata:
  name: log-processor
spec:
  containers:
  # Contenedor que escribe logs
  - name: producer
    image: busybox
    command: ["sh", "-c"]
    args:
    - |
      counter=0
      while true; do
        counter=$((counter+1))
        echo "[\$(date '+%Y-%m-%d %H:%M:%S')] Event \$counter" &gt;&gt; /logs/events.log
        sleep 2
      done
    volumeMounts:
    - name: logs
      mountPath: /logs

  # Contenedor que procesa los logs
  - name: processor
    image: busybox
    command: ["sh", "-c"]
    args:
    - |
      sleep 3  # Esperar a que exista el archivo
      while true; do
        wc -l /logs/events.log
        sleep 5
      done
    volumeMounts:
    - name: logs
      mountPath: /logs
      readOnly: true

  volumes:
  - name: logs
    emptyDir:
      sizeLimit: 100Mi
EOF

# Ver logs
kubectl logs log-processor -c producer
kubectl logs log-processor -c processor</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_volúmenes">5.1.6. Best Practices para Volúmenes</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa emptyDir para datos temporales</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cache, buffers, workspace</p>
</li>
<li>
<p>Se elimina con Pod (OK)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Evita hostPath en producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>Seguridad: acceso sin restricciones</p>
</li>
<li>
<p>Portabilidad: vinculado a nodo específico</p>
</li>
<li>
<p>Usa PersistentVolumes si necesitas persistencia</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monta Secrets como readOnly</strong></p>
<div class="ulist">
<ul>
<li>
<p>Protege credenciales</p>
</li>
<li>
<p>Previene escritura accidental</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa subPath para múltiples montes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Claridad: qué va dónde</p>
</li>
<li>
<p>Flexibilidad: un volumen, múltiples usos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura sizeLimit en emptyDir</strong></p>
<div class="ulist">
<ul>
<li>
<p>Previene agotamiento de disco</p>
</li>
<li>
<p>Evicta Pod automáticamente si lo excede</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta propósito del volumen</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué datos almacena</p>
</li>
<li>
<p>Tiempo de vida esperado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa medium: Memory para caches críticos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alto rendimiento</p>
</li>
<li>
<p>Requiere RAM disponible</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Valida permisos en volúmenes</strong></p>
<div class="ulist">
<ul>
<li>
<p>defaultMode para permisos</p>
</li>
<li>
<p>readOnly para datos inmutables</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_troubleshooting_de_volúmenes">5.1.7. Troubleshooting de Volúmenes</h4>
<div class="paragraph">
<p><strong>Problema: Pod no monta volumen</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver descripción del Pod
kubectl describe pod my-pod

# Buscar errores en MountVolume
# Causas comunes:
# - ConfigMap o Secret no existe
# - mountPath ya existe (en algunas imágenes)
# - Permisos incorrectos

# Ver logs del Pod
kubectl logs my-pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Archivo en ConfigMap no aparece en volumen</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar que ConfigMap existe
kubectl get configmap

# Ver contenido de ConfigMap
kubectl get configmap app-config -o yaml

# Verificar volumeMounts en Pod
kubectl get pod my-pod -o yaml | grep -A 10 volumeMounts

# Las claves del ConfigMap se convierten en archivos
# Clave "db.host" → archivo "db.host"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema: Volumen lleno (sizeLimit excedido)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado del Pod
kubectl describe pod my-pod

# Debería mostrar evento de evicción
# "Pod Evicted: emptyDir exceeds sizeLimit"

# Soluciones:
# 1. Aumentar sizeLimit
# 2. Reducir tamaño de datos
# 3. Usar different storage (PersistentVolume)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_persistent_volumes_pv">5.2. Persistent Volumes (PV)</h3>
<div class="paragraph">
<p><strong>¿Qué es un PersistentVolume?</strong></p>
</div>
<div class="paragraph">
<p>Un PersistentVolume (PV) es una abstracción de almacenamiento a nivel de cluster. Representa un pedazo de almacenamiento en el cluster que ha sido aprovisionado por un administrador o por un provisioner dinámico.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Persistencia</strong>: Los datos persisten después de que el Pod se elimina</p>
</li>
<li>
<p><strong>Independencia</strong>: Existen independientemente de los Pods</p>
</li>
<li>
<p><strong>Recursos de cluster</strong>: Como CPUs y memoria</p>
</li>
<li>
<p><strong>Ciclo de vida</strong>: Administrado por el cluster</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama: Ciclo de vida PV/PVC</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌──────────┐
│ Admin    │ Provisiona almacenamiento
└─────┬────┘
      │
      ▼
┌──────────────────────────────┐
│  PersistentVolume (PV)       │ ← Storage físico (NFS, iSCSI, etc)
├──────────────────────────────┤ Estado: Available
│ 10GB, NFS, ReadWriteOnce     │
└─────┬────────────────────────┘
      │ Pod solicita almacenamiento
      ▼
┌──────────────────────────────┐
│ PersistentVolumeClaim (PVC)  │ Estado: Bound
├──────────────────────────────┤
│ 5GB, ReadWriteOnce           │ ← Bind a PV matching
└──────────────────────────────┘
      │
      ▼
┌──────────────────────────────┐
│ Pod usa volumen              │
├──────────────────────────────┤
│ volumeClaimName: my-pvc      │
└──────────────────────────────┘</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_ciclo_de_vida_de_persistentvolumes">5.2.1. Ciclo de vida de PersistentVolumes</h4>
<div class="paragraph">
<p><strong>Estados de un PV:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Provisioning</strong>: Creación del almacenamiento</p>
<div class="ulist">
<ul>
<li>
<p>Manual: Admin crea PV</p>
</li>
<li>
<p>Dinámico: Provisioner automático (via StorageClass)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Binding</strong>: PVC se vincula a PV</p>
<div class="ulist">
<ul>
<li>
<p>PVC solicita almacenamiento</p>
</li>
<li>
<p>Control loop encuentra PV matching</p>
</li>
<li>
<p>PVC y PV se vinculan mutuamente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Using</strong>: Pod usa el PVC</p>
<div class="ulist">
<ul>
<li>
<p>Pod se monta al PVC</p>
</li>
<li>
<p>Pod accede al almacenamiento</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Releasing</strong>: PVC se elimina</p>
<div class="ulist">
<ul>
<li>
<p>Usuario elimina PVC</p>
</li>
<li>
<p>PV se desvincula (pero no desaparece)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Reclaiming</strong>: Reciclaje del PV</p>
<div class="ulist">
<ul>
<li>
<p>Según ReclaimPolicy</p>
</li>
<li>
<p>Delete, Retain, o Recycle</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>YAML básico de PersistentVolume:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs-10g
spec:
  capacity:
    storage: 10Gi        # Tamaño total
  accessModes:
  - ReadWriteOnce        # Modo de acceso
  persistentVolumeReclaimPolicy: Retain  # Qué hacer al deletear PVC
  storageClassName: standard             # Clase de storage
  nfs:                   # Detalles del backend
    server: 192.168.1.100
    path: /exports/pv</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_modos_de_acceso_access_modes">5.2.2. Modos de Acceso (Access Modes)</h4>
<div class="paragraph">
<p>Los modos de acceso especifican cómo se puede montar el volumen:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Modo</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Soporte</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReadWriteOnce (RWO)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lectura/escritura por un solo nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La mayoría de backends</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReadOnlyMany (ROX)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo lectura por múltiples nodos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NFS, iSCSI, algunos cloud</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReadWriteMany (RWX)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lectura/escritura por múltiples nodos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NFS, algunos cloud</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ReadWriteOncePod (RWOP)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lectura/escritura por un solo Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algunos backends (v1.22+)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Implicaciones prácticas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>RWO</strong>: Base de datos (un servidor), ideal para bloque storage</p>
</li>
<li>
<p><strong>ROX</strong>: Distribución de código (múltiples readers)</p>
</li>
<li>
<p><strong>RWX</strong>: Datos compartidos, NFS típicamente</p>
</li>
<li>
<p><strong>RWOP</strong>: Más restrictivo que RWO, una pod exactamente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># PV puede soportar múltiples modos
accessModes:
- ReadWriteOnce
- ReadOnlyMany

# PVC debe usar modos que PV soporta
# Si PV soporta RWO y ROX, PVC puede pedir RWO</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_políticas_de_reclaim_reclaimpolicy">5.2.3. Políticas de Reclaim (ReclaimPolicy)</h4>
<div class="paragraph">
<p>Define qué ocurre con el almacenamiento cuando se elimina el PVC:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Política</th>
<th class="tableblock halign-left valign-top">Comportamiento</th>
<th class="tableblock halign-left valign-top">Uso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Retain</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mantener datos, PV no reutilizable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Importante: manual cleanup</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Delete</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Eliminar almacenamiento automáticamente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloud volumes, desarrollo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recycle (deprecated)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limpiar y reutilizar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Legado, no usar</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo: Retain</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-important-data
spec:
  capacity:
    storage: 100Gi
  persistentVolumeReclaimPolicy: Retain
  accessModes:
  - ReadWriteOnce
  # Los datos persisten después de eliminar PVC
  # Manual cleanup requerido</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Delete</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-elastic-block
spec:
  capacity:
    storage: 50Gi
  persistentVolumeReclaimPolicy: Delete
  accessModes:
  - ReadWriteOnce
  # Volumen se elimina automáticamente con PVC
  # Útil para cloud (EBS, GCE PD)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_storage_classes">5.2.4. Storage Classes</h4>
<div class="paragraph">
<p>Una StorageClass automatiza el aprovisionamiento de PersistentVolumes.</p>
</div>
<div class="paragraph">
<p><strong>¿Por qué Storage Classes?</strong></p>
</div>
<div class="paragraph">
<p>Sin Storage Classes: Admin debe crear PVs manualmente (tedioso)</p>
</div>
<div class="paragraph">
<p>Con Storage Classes: Sistema crea PVs automáticamente (dinámico)</p>
</div>
<div class="paragraph">
<p><strong>YAML básico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs  # Driver que crea almacenamiento
parameters:
  type: gp3                          # Tipo de volumen
  iops: "3000"
  throughput: "125"
allowVolumeExpansion: true           # Permite crecer volumen
reclaimPolicy: Delete                # ReclaimPolicy por defecto
volumeBindingMode: WaitForFirstConsumer</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Provisioners populares:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Provisioner</th>
<th class="tableblock halign-left valign-top">Cloud provider</th>
<th class="tableblock halign-left valign-top">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/aws-ebs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AWS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EBS volumes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/gce-pd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Google Cloud</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Persistent Disks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/azure-disk</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Azure</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Managed Disks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/cinder</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenStack</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cinder volumes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nfs.io/nfs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(cualquiera)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NFS share</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hostpath.csi.k8s.io</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(local)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Host path (testing)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">longhorn.io/longhorn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(cualquiera)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Distributed storage</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejemplo: NFS StorageClass</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage
provisioner: nfs.io/nfs
parameters:
  server: 192.168.1.100
  path: /exports
allowVolumeExpansion: true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Local Storage</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-fast
provisioner: kubernetes.io/no-provisioner  # Manual PV creation
allowVolumeExpansion: false
volumeBindingMode: WaitForFirstConsumer    # Espera scheduler</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pv_backend_diferentes_tipos_de_almacenamiento">5.2.5. PV Backend: Diferentes tipos de almacenamiento</h4>
<div class="paragraph">
<p><strong>NFS (Network File System):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs
spec:
  capacity:
    storage: 1Gi
  accessModes:
  - ReadWriteMany      # NFS soporta múltiples accesos
  - ReadOnlyMany
  nfs:
    server: nfs-server.example.com
    path: /shared/data</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>iSCSI (SCSI over network):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-iscsi
spec:
  capacity:
    storage: 100Gi
  accessModes:
  - ReadWriteOnce
  iscsi:
    targetPortal: iscsi.example.com:3260
    iqn: iqn.2019-12.com.example:storage
    lun: 0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Local Storage (nodo específico):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-local
spec:
  capacity:
    storage: 50Gi
  accessModes:
  - ReadWriteOnce
  local:
    path: /mnt/fast-ssd
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1  # Vinculado a nodo específico</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_verificación_de_persistentvolumes">5.2.6. Verificación de PersistentVolumes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver todos los PVs
kubectl get pv

# Ver PV específico
kubectl get pv pv-name -o yaml

# Ver información detallada
kubectl describe pv pv-name

# Ver Storage Classes
kubectl get storageclass</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_persistentvolumes">5.2.7. Best Practices para PersistentVolumes</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Plan capacity adecuadamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sobrestima ligeramente</p>
</li>
<li>
<p>Crecimiento futuro</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa appropriate access modes</strong></p>
<div class="ulist">
<ul>
<li>
<p>RWO para bases de datos</p>
</li>
<li>
<p>RWX para compartidos</p>
</li>
<li>
<p>ROX para solo lectura</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Selecciona reclaim policy cuidadosamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Retain para datos críticos</p>
</li>
<li>
<p>Delete para desarrollo</p>
</li>
<li>
<p>Documenta la decisión</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa Storage Classes dinámicas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Automatiza provisioning</p>
</li>
<li>
<p>Consistencia en configuración</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea espacio disponible</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertas cuando se acerca límite</p>
</li>
<li>
<p>Plan para expansión</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Backup y recovery</strong></p>
<div class="ulist">
<ul>
<li>
<p>Snapshots si el backend lo soporta</p>
</li>
<li>
<p>Prueba restauración</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta backend storage</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué tipo de almacenamiento</p>
</li>
<li>
<p>Performance características</p>
</li>
<li>
<p>Política de backup</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Valida access modes requeridos</strong></p>
<div class="ulist">
<ul>
<li>
<p>No todos los backends soportan todos los modos</p>
</li>
<li>
<p>Verifica antes de producción</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>YAML básico de PVC:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: standard  # Referenciar StorageClass
  resources:
    requests:
      storage: 5Gi            # Solicitar 5GB</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Binding automático:</strong></p>
</div>
<div class="paragraph">
<p>Una vez creado PVC, Kubernetes busca un PV que cumpla:
- Suficiente capacidad (PVC pide 5Gi, PV debe tener al menos 5Gi)
- Access modes compatibles
- StorageClassName coincida</p>
</div>
<div class="paragraph">
<p>Si encuentra, vincula automáticamente.</p>
</div>
<div class="paragraph">
<p><strong>Estados de un PVC:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Pending</strong>: Esperando PV disponible</p>
</li>
<li>
<p><strong>Bound</strong>: Vinculado a un PV</p>
</li>
<li>
<p><strong>Lost</strong>: PV fue eliminado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Pod usando PVC</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: my-pvc    # Referenciar PVC</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_expansión_de_volúmenes">5.2.8. Expansión de Volúmenes</h4>
<div class="paragraph">
<p>Si configuraste <code>allowVolumeExpansion: true</code> en StorageClass, puedes expandir un PVC:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Expandir PVC de 5Gi a 10Gi
kubectl patch pvc my-pvc -p '{"spec":{"resources":{"requests":{"storage":"10Gi"}}}}'

# Ver estado
kubectl describe pvc my-pvc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Limitaciones:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Solo expansión (no reducción)</p>
</li>
<li>
<p>Requiere <code>allowVolumeExpansion: true</code> en StorageClass</p>
</li>
<li>
<p>El backend debe soportar expansión</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_snapshots_de_volúmenes">5.2.9. Snapshots de Volúmenes</h4>
<div class="paragraph">
<p>Crear snapshots (capturas) de volúmenes para backup/restore.</p>
</div>
<div class="paragraph">
<p><strong>Requisitos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>StorageClass con snapshot support</p>
</li>
<li>
<p>VolumeSnapshotClass configurada</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Crear snapshot:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: snapshot-pvc1
spec:
  volumeSnapshotClassName: csi-snapshotter
  source:
    persistentVolumeClaimName: my-pvc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Restaurar desde snapshot:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: restored-pvc
spec:
  storageClassName: standard
  accessModes:
  - ReadWriteOnce
  dataSource:
    name: snapshot-pvc1      # Snapshots como source
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  resources:
    requests:
      storage: 5Gi</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_pvc">5.2.10. Best Practices para PVC</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Solicita capacity apropiada</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ni muy poco (evicción)</p>
</li>
<li>
<p>Ni muy mucho (desperdicio)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa StorageClasses explícitamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Claridad</p>
</li>
<li>
<p>Control de comportamiento</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea uso de espacio</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertas cuando se acerca límite</p>
</li>
<li>
<p>Plan para expansión</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta propósito</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué aplicación usa PVC</p>
</li>
<li>
<p>Datos críticos o no</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa backups</strong></p>
<div class="ulist">
<ul>
<li>
<p>Snapshots si backend soporta</p>
</li>
<li>
<p>Exportación de datos</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_dynamic_provisioning">5.3. Dynamic Provisioning</h3>
<div class="paragraph">
<p><strong>¿Qué es Dynamic Provisioning?</strong></p>
</div>
<div class="paragraph">
<p>Dynamic Provisioning crea PersistentVolumes automáticamente cuando se crea un PVC, en lugar de requerir creación manual por admin.</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Admin crea StorageClass con provisioner</p>
</li>
<li>
<p>User crea PVC que referencia StorageClass</p>
</li>
<li>
<p>Control plane detecta PVC sin PV matching</p>
</li>
<li>
<p>Provisioner crea almacenamiento automáticamente</p>
</li>
<li>
<p>Control plane crea PV que representa el almacenamiento</p>
</li>
<li>
<p>PVC se vincula a PV</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Automatización</p>
</li>
<li>
<p>Escalabilidad</p>
</li>
<li>
<p>Consistencia</p>
</li>
<li>
<p>Elástico (crear/eliminar según demanda)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Requisitos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>StorageClass con provisioner válido</p>
</li>
<li>
<p>Provisioner debe estar instalado/configurado</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_configurando_dynamic_provisioning">5.3.1. Configurando Dynamic Provisioning</h4>
<div class="paragraph">
<p><strong>StorageClass con aprovisionamiento dinámico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: aws-ebs-gp3
provisioner: ebs.csi.aws.com  # Driver AWS EBS
allowVolumeExpansion: true
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  encrypted: "true"
  kms_key_id: arn:aws:kms:...
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>volumeBindingMode opciones:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Immediate</strong>: Bind apenas se crea PVC (defecto)</p>
</li>
<li>
<p><strong>WaitForFirstConsumer</strong>: Espera hasta que Pod consume</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>WaitForFirstConsumer es más inteligente para considerar localidad de nodo.</p>
</div>
<div class="paragraph">
<p><strong>Parámetros específicos del provisioner:</strong></p>
</div>
<div class="paragraph">
<p>Cada provisioner tiene sus propios parámetros:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># AWS EBS
parameters:
  type: gp3
  iops: "3000"

# Google Cloud PD
parameters:
  type: pd-ssd
  replication-type: regional-pd

# Azure Disk
parameters:
  storageaccounttype: Premium_LRS
  kind: Managed</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>PVC automáticamente aprovisionada:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-data
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: aws-ebs-gp3   # Referencia StorageClass
  resources:
    requests:
      storage: 100Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>Automáticamente:
1. Provisioner crea volumen EBS de 100GB
2. Control plane crea PV para ese volumen
3. PVC se vincula al PV</p>
</div>
<div class="paragraph">
<p><strong>Verificar provisioning:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver PVC
kubectl get pvc app-data

# Ver PV creado automáticamente
kubectl get pv
# Debería haber nuevo PV vinculado a PVC

# Ver detalles
kubectl describe pvc app-data</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_provisioners_comunes">5.3.2. Provisioners comunes</h4>
<div class="paragraph">
<p><strong>AWS EBS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver -n kube-system</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Google Cloud PD:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">gcloud container clusters update CLUSTER_NAME --enable-disk-csi-driver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Azure Disk:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm repo add azuredisk-csi-driver https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/charts
helm install azuredisk-csi-driver azuredisk-csi-driver/azuredisk-csi-driver -n kube-system</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>NFS (cualquier cloud):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
helm install nfs-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
  --set nfs.server=192.168.1.100 \
  --set nfs.path=/exports</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_dynamic_provisioning">5.3.3. Best Practices para Dynamic Provisioning</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Define StorageClasses claras</strong></p>
<div class="ulist">
<ul>
<li>
<p>fast (SSD)</p>
</li>
<li>
<p>standard (HDD)</p>
</li>
<li>
<p>archive (slow + cheap)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa WaitForFirstConsumer cuando sea posible</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mejor localidad</p>
</li>
<li>
<p>Evita binding prematuro</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta provisioners instalados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué opciones soportan</p>
</li>
<li>
<p>Parámetros disponibles</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configura reclaimPolicy apropiada</strong></p>
<div class="ulist">
<ul>
<li>
<p>Delete para desarrollo</p>
</li>
<li>
<p>Retain para producción</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea provisioner health</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ver logs de provisioner</p>
</li>
<li>
<p>Alertas si no crea volúmenes</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_statefulsets_con_almacenamiento">5.4. StatefulSets con Almacenamiento</h3>
<div class="paragraph">
<p><strong>Volume Claim Templates:</strong></p>
</div>
<div class="paragraph">
<p>StatefulSets usa volumeClaimTemplates para crear un PVC por cada Pod.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-db
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 50Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Resultado:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>mysql-db-0 → PVC: data-mysql-db-0 (50Gi)</p>
</li>
<li>
<p>mysql-db-1 → PVC: data-mysql-db-1 (50Gi)</p>
</li>
<li>
<p>mysql-db-2 → PVC: data-mysql-db-2 (50Gi)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ordenamiento de almacenamiento:</strong></p>
</div>
<div class="paragraph">
<p>StatefulSet espera a que cada Pod esté ready antes de crear el siguiente:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>mysql-db-0 creado</p>
</li>
<li>
<p>PVC data-mysql-db-0 creado y bound</p>
</li>
<li>
<p>mysql-db-0 reaches Ready</p>
</li>
<li>
<p>mysql-db-1 creado</p>
</li>
<li>
<p>PVC data-mysql-db-1 creado y bound</p>
</li>
<li>
<p>mysql-db-1 reaches Ready</p>
</li>
<li>
<p>&#8230;&#8203; (mysql-db-2)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Persistencia en aplicaciones stateful:</strong></p>
</div>
<div class="paragraph">
<p>Los datos persisten incluso si el Pod se elimina:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Pod muere
kubectl delete pod mysql-db-0

# StatefulSet lo recrea
# Nuevo Pod mysql-db-0 se monta a PVC data-mysql-db-0
# Datos intactos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Eliminación de StatefulSet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Eliminar StatefulSet pero mantener Pods
kubectl delete statefulset mysql-db --cascade=orphan

# Eliminar StatefulSet y Pods (pero no PVCs)
kubectl delete statefulset mysql-db

# PVCs persisten (datos no se pierden)
kubectl get pvc
# data-mysql-db-0
# data-mysql-db-1
# data-mysql-db-2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo completo: PostgreSQL con StatefulSet</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl apply -f - &lt;&lt;EOF
---
apiVersion: v1
kind: Service
metadata:
  name: postgresql
spec:
  clusterIP: None
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: postgresql
  replicas: 3
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      containers:
      - name: postgresql
        image: postgres:14
        env:
        - name: POSTGRES_PASSWORD
          value: password
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
          subPath: postgres
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 20Gi
EOF

# Ver StatefulSet
kubectl get statefulset

# Ver Pods con almacenamiento
kubectl get pods -o wide

# Ver PVCs creados
kubectl get pvc

# Conectar a base de datos
kubectl run postgres-client --image=postgres:14 -it --rm -- psql -h postgresql-0.postgresql -U postgres</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_statefulsets_almacenamiento">5.4.1. Best Practices para StatefulSets + Almacenamiento</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Planifica correctamente volumeClaimTemplates</strong></p>
<div class="ulist">
<ul>
<li>
<p>Tamaño</p>
</li>
<li>
<p>StorageClass</p>
</li>
<li>
<p>Access modes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa Headless Services</strong></p>
<div class="ulist">
<ul>
<li>
<p>Necesario para identidad estable</p>
</li>
<li>
<p>Permite acceso directo a Pods</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementa health checks</strong></p>
<div class="ulist">
<ul>
<li>
<p>readiness: base de datos funcional</p>
</li>
<li>
<p>liveness: proceso corriendo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Backup automático</strong></p>
<div class="ulist">
<ul>
<li>
<p>Snapshots periódicos</p>
</li>
<li>
<p>Exportación de datos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación clara</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué datos almacena</p>
</li>
<li>
<p>Política de retención</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_6_configuración_y_secrets">6. Módulo 6: Configuración y Secrets</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_configmaps">6.1. ConfigMaps</h3>
<div class="paragraph">
<p><strong>¿Qué es un ConfigMap?</strong></p>
</div>
<div class="paragraph">
<p>Un ConfigMap es un objeto que almacena datos de configuración no confidencial en pares clave-valor. Permite:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Separación de configuración de aplicación</strong> (12-factor app)</p>
</li>
<li>
<p><strong>Inyectar configuración en Pods</strong> sin modificar imagen</p>
</li>
<li>
<p><strong>Compartir configuración entre Pods</strong></p>
</li>
<li>
<p><strong>Actualizar configuración sin redesplegar</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Casos de uso:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Archivos de configuración (nginx.conf, app.properties)</p>
</li>
<li>
<p>Parámetros de aplicación (conexión DB, URLs)</p>
</li>
<li>
<p>Valores por ambiente (dev, staging, prod)</p>
</li>
<li>
<p>Scripts de inicialización</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>NO usar ConfigMaps para:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Datos sensibles (credenciales, tokens) → usar Secrets</p>
</li>
<li>
<p>Datos grandes (&gt;1MB) → usar persistencia</p>
</li>
<li>
<p>Datos binarios → considerar PersistentVolumes</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_creación_de_configmaps">6.1.1. Creación de ConfigMaps</h4>
<div class="paragraph">
<p><strong>Opción 1: Literales</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl create configmap app-config \
  --from-literal=database.host=localhost \
  --from-literal=database.port=5432 \
  --from-literal=app.name=myapp \
  --from-literal=app.version=1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Desde archivo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear archivo
echo "database.host=localhost" &gt; config.properties
echo "database.port=5432" &gt;&gt; config.properties

# Crear ConfigMap
kubectl create configmap app-config --from-file=config.properties

# Desde directorio (todas los archivos)
kubectl create configmap app-config --from-file=./config/</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: YAML declarativo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: default
data:
  database.host: localhost
  database.port: "5432"
  app.name: myapp
  app.version: "1.0"
  nginx.conf: |
    server {
      listen 80;
      server_name _;
      location / {
        proxy_pass http://backend:8080;
      }
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 4: Mezcla literal + archivo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl create configmap app-config \
  --from-literal=env=production \
  --from-file=config.yml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_consumo_en_pods">6.1.2. Consumo en Pods</h4>
<div class="paragraph">
<p><strong>Opción 1: Variables de entorno (individual)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: DB_HOST
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database.host
    - name: DB_PORT
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database.port
    - name: APP_NAME
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: app.name</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Variables de entorno (bulk)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    envFrom:
    - configMapRef:
        name: app-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>Inyecta TODAS las claves como variables de entorno:
- <code>database.host</code> → <code>DATABASE_HOST</code> (automático conversion)
- <code>database.port</code> → <code>DATABASE_PORT</code></p>
</div>
<div class="paragraph">
<p><strong>Opción 3: Archivos en volumen</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    volumeMounts:
    - name: config
      mountPath: /etc/nginx/conf.d
  volumes:
  - name: config
    configMap:
      name: app-config
      items:
      - key: nginx.conf
        path: default.conf  # Renombrar</code></pre>
</div>
</div>
<div class="paragraph">
<p>Los archivos están disponibles en <code>/etc/nginx/conf.d/default.conf</code>.</p>
</div>
<div class="paragraph">
<p><strong>Opción 4: Command-line arguments</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    args:
    - --database-host=$(DB_HOST)
    - --database-port=$(DB_PORT)
    - --app-name=$(APP_NAME)
    env:
    - name: DB_HOST
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database.host
    - name: DB_PORT
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database.port
    - name: APP_NAME
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: app.name</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_actualización_de_configmaps">6.1.3. Actualización de ConfigMaps</h4>
<div class="paragraph">
<p><strong>Problema: Cambios no se propagan automáticamente</strong></p>
</div>
<div class="paragraph">
<p>Si cambias ConfigMap, Pods existentes NO se actualizan automáticamente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Actualizar ConfigMap
kubectl edit configmap app-config
# O
kubectl patch configmap app-config -p '{"data":{"app.name":"newname"}}'

# Pods existentes NO ven cambios (siguen inyectando datos viejos)
# Solo Pods nuevos ven nuevos valores</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Soluciones:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Reiniciar Pods</strong> (fuerza reinyección):</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl rollout restart deployment/app</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usar volumes</strong> (más dinámico):</p>
<div class="ulist">
<ul>
<li>
<p>ConfigMaps montados como volumen se actualizan automáticamente</p>
</li>
<li>
<p>Cambios se propagan en segundos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Reloader</strong> (herramienta):</p>
<div class="ulist">
<ul>
<li>
<p>Monitorea cambios en ConfigMaps</p>
</li>
<li>
<p>Reinicia Pods automáticamente</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_completo_multi_file_configmap">6.1.4. Ejemplo completo: Multi-file ConfigMap</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear archivos de configuración
mkdir config
cat &gt; config/app.properties &lt;&lt;EOF
server.port=8080
app.name=myapp
database.url=jdbc:mysql://db:3306/mydb
EOF

cat &gt; config/logging.properties &lt;&lt;EOF
log.level=INFO
log.format=json
EOF

# Crear ConfigMap
kubectl create configmap app-config \
  --from-file=config/app.properties \
  --from-file=config/logging.properties

# Ver ConfigMap
kubectl get configmap app-config -o yaml

# Usar en Pod
kubectl apply -f - &lt;&lt;EOF
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: config
      mountPath: /etc/config
  volumes:
  - name: config
    configMap:
      name: app-config
EOF

# Acceder desde Pod
kubectl exec -it app -- cat /etc/config/app.properties</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_configmaps">6.1.5. Best Practices para ConfigMaps</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Separación por ambiente</strong></p>
<div class="ulist">
<ul>
<li>
<p>configmap-dev, configmap-prod</p>
</li>
<li>
<p>Diferentes valores por entorno</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Versionado de ConfigMaps</strong></p>
<div class="ulist">
<ul>
<li>
<p>configmap-v1, configmap-v2</p>
</li>
<li>
<p>Fácil rollback</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación clara</strong></p>
<div class="ulist">
<ul>
<li>
<p>Propósito de cada clave</p>
</li>
<li>
<p>Formato esperado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Limitar tamaño</strong></p>
<div class="ulist">
<ul>
<li>
<p>Máximo 1MB por ConfigMap</p>
</li>
<li>
<p>Múltiples ConfigMaps si necesitas más</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar volúmenes para archivos grandes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Más eficiente que envFrom</p>
</li>
<li>
<p>Actualizaciones dinámicas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No guardes secretos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nunca contraseñas en ConfigMaps</p>
</li>
<li>
<p>Usa Secrets para datos sensibles</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Válida valores</strong></p>
<div class="ulist">
<ul>
<li>
<p>Verifica formato (JSON, YAML)</p>
</li>
<li>
<p>Testing antes de producción</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_secrets">6.1.6. Secrets</h4>
<div class="paragraph">
<p><strong>¿Qué es un Secret?</strong></p>
</div>
<div class="paragraph">
<p>Un Secret es similar a ConfigMap pero diseñado para datos sensibles (credenciales, tokens, llaves). Ofrece:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Encriptación en reposo</strong> (opcional)</p>
</li>
<li>
<p><strong>Control de acceso</strong> (RBAC)</p>
</li>
<li>
<p><strong>Protección en transmisión</strong> (etcd encryption)</p>
</li>
<li>
<p><strong>Montaje seguro</strong> (permisos restringidos por defecto)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Tipos de Secrets:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Propósito</th>
<th class="tableblock halign-left valign-top">Contenido</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Opaque</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Datos genéricos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cualquier base64</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/service-account-token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Token de Service Account</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Token JWT automático</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/dockercfg</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Credenciales Docker (legacy)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo .dockercfg</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/dockerconfigjson</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Credenciales Docker</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">config.json (docker login)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/basic-auth</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Credenciales básicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">username, password</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/ssh-auth</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SSH keys</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ssh-privatekey</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubernetes.io/tls</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificados TLS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls.crt, tls.key</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrap.kubernetes.io/token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bootstrap token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">token, usado en kubeadm</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_creación_de_secrets">6.1.7. Creación de Secrets</h4>
<div class="paragraph">
<p><strong>Opción 1: Literal</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl create secret generic db-credentials \
  --from-literal=username=admin \
  --from-literal=password=secretpassword</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Desde archivo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">echo -n "admin" &gt; username.txt
echo -n "secretpassword" &gt; password.txt

kubectl create secret generic db-credentials \
  --from-file=username=username.txt \
  --from-file=password=password.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: YAML declarativo (base64)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Codificar en base64
echo -n "admin" | base64       # YWRtaW4=
echo -n "secretpass" | base64  # c2VjcmV0cGFzcw==

# Crear Secret YAML
cat &gt; secret.yaml &lt;&lt;EOF
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
data:
  username: YWRtaW4=
  password: c2VjcmV0cGFzcw==
EOF

kubectl apply -f secret.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 4: Secret TLS</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear certificado (o usar existente)
openssl req -x509 -newkey rsa:4096 \
  -keyout tls.key -out tls.crt \
  -days 365 -nodes

# Crear Secret TLS
kubectl create secret tls tls-secret \
  --cert=tls.crt \
  --key=tls.key</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 5: Docker Registry Secret</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl create secret docker-registry regcred \
  --docker-server=docker.io \
  --docker-username=myuser \
  --docker-password=mypassword \
  --docker-email=myuser@example.com</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_codificación_base64">6.1.8. Codificación base64</h4>
<div class="paragraph">
<p><strong>IMPORTANTE:</strong> Base64 NO es encriptación, es solo codificación.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Codificar
echo -n "password" | base64
# cGFzc3dvcmQ=

# Decodificar
echo -n "cGFzc3dvcmQ=" | base64 -d
# password</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>NUNCA</strong> guardes Secrets sin encriptación en control de versiones.</p>
</div>
</div>
<div class="sect3">
<h4 id="_consumo_de_secrets">6.1.9. Consumo de Secrets</h4>
<div class="paragraph">
<p><strong>Opción 1: Variables de entorno</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: username
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: password</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Volumen (recomendado para secretos)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: secrets
      mountPath: /etc/secrets
      readOnly: true  # Recomendado
  volumes:
  - name: secrets
    secret:
      secretName: db-credentials
      defaultMode: 0400  # Solo lectura
      items:
      - key: username
        path: db-user
      - key: password
        path: db-pass</code></pre>
</div>
</div>
<div class="paragraph">
<p>Los archivos están en <code>/etc/secrets/db-user</code> y <code>/etc/secrets/db-pass</code>.</p>
</div>
<div class="paragraph">
<p><strong>Opción 3: Docker Registry (ImagePullSecrets)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  imagePullSecrets:
  - name: regcred  # Secret Docker Registry
  containers:
  - name: app
    image: private-registry.com/myapp:latest</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_buenas_prácticas_de_seguridad">6.1.10. Buenas prácticas de seguridad</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Encriptación en reposo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Habilitar <code>EncryptionConfiguration</code> en API server</p>
</li>
<li>
<p>Secretos encriptados en etcd</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>RBAC sobre Secrets</strong></p>
<div class="ulist">
<ul>
<li>
<p>Limitar acceso a Secrets específicos</p>
</li>
<li>
<p>Solo aplicaciones que los necesitan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Rotación de Secrets</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cambiar contraseñas regularmente</p>
</li>
<li>
<p>Actualizar tokens vencidos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditoría</strong></p>
<div class="ulist">
<ul>
<li>
<p>Loguear acceso a Secrets</p>
</li>
<li>
<p>Monitoreo de cambios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No pushear a git</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar secrets operators</p>
</li>
<li>
<p>Sealed Secrets, Vault, etc</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monta como volumen, no env</strong>*</p>
<div class="ulist">
<ul>
<li>
<p>Volumen es más seguro</p>
</li>
<li>
<p>Evita leaks en logs de ambiente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>readOnly en volumeMounts</strong></p>
<div class="ulist">
<ul>
<li>
<p>Previene modificación accidental</p>
</li>
<li>
<p>Buena defensa en profundidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Limpia Secrets no usados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Reduce superficie de ataque</p>
</li>
<li>
<p>Auditoría simple</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_encriptación_en_reposo">6.1.11. Encriptación en reposo</h4>
<div class="paragraph">
<p><strong>Habilitar EncryptionConfiguration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># /etc/kubernetes/manifests/encryption-config.yaml
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
- resources:
  - secrets
  providers:
  - aescbc:
      keys:
      - name: key1
        secret: &lt;BASE64_32_BYTES&gt;  # 32 bytes base64
  - identity: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Luego editar kube-apiserver:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">--encryption-provider-config=/etc/kubernetes/manifests/encryption-config.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_de_variables_de_entorno">6.2. Gestión de Variables de Entorno</h3>
<div class="paragraph">
<p><strong>¿Cuándo usar qué?</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Método</th>
<th class="tableblock halign-left valign-top">Cuándo usar</th>
<th class="tableblock halign-left valign-top">Ventajas</th>
<th class="tableblock halign-left valign-top">Desventajas</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Env literal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Valores simples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, directo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No flexible</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ConfigMap env</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configuración compartida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reutilizable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Requiere reiniciar Pod para cambios</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ConfigMap volumen</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivos de config</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Actualizaciones dinámicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más complejo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secret env</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Credenciales simples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Seguridad menor que volumen</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secret volumen</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Credenciales importantes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más seguro</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más setup</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Downward API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Información del Pod</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dinámico, no requiere config</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo datos del Pod</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_envfrom_inyección_bulk">6.2.1. EnvFrom: Inyección bulk</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest
    envFrom:
    # Inyectar ConfigMap completo
    - configMapRef:
        name: app-config
    # Inyectar Secret completo
    - secretRef:
        name: db-credentials
    # Prefijo opcional
    - configMapRef:
        name: cache-config
        prefix: CACHE_</code></pre>
</div>
</div>
<div class="paragraph">
<p>Resultados:
- Claves de app-config se convierten en env vars
- Claves de db-credentials se inyectan
- cache-config claves con prefijo <code>CACHE_</code></p>
</div>
<div class="paragraph">
<p><strong>Reglas de conversión:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>database.host</code> → <code>DATABASE_HOST</code></p>
</li>
<li>
<p><code>app-name</code> → <code>APP_NAME</code></p>
</li>
<li>
<p>Puntos y guiones se convierten a underscores</p>
</li>
<li>
<p>Se convierten a mayúsculas</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_downward_api_información_del_pod">6.2.2. Downward API: Información del Pod</h4>
<div class="paragraph">
<p>Inyectar información del Pod sin ConfigMaps/Secrets:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
  labels:
    app: myapp
    version: v1
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    # Información del Pod
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # Labels del Pod
    - name: POD_LABELS
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['version']
    # Requests/Limits
    - name: MEMORY_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.memory
    - name: CPU_REQUEST
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: requests.cpu</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Campos disponibles:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>metadata.name</code>: Nombre del Pod</p>
</li>
<li>
<p><code>metadata.namespace</code>: Namespace</p>
</li>
<li>
<p><code>metadata.uid</code>: UID único</p>
</li>
<li>
<p><code>metadata.labels['key']</code>: Valor de label</p>
</li>
<li>
<p><code>metadata.annotations['key']</code>: Valor de anotación</p>
</li>
<li>
<p><code>status.podIP</code>: IP del Pod</p>
</li>
<li>
<p><code>spec.nodeName</code>: Nombre del nodo</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_downward_api_con_volumen">6.2.3. Downward API con volumen</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
  labels:
    app: myapp
  annotations:
    version: "1.0"
spec:
  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: podinfo
      mountPath: /etc/podinfo
  volumes:
  - name: podinfo
    downwardAPI:
      items:
      - path: "name"
        fieldRef:
          fieldPath: metadata.name
      - path: "namespace"
        fieldRef:
          fieldPath: metadata.namespace
      - path: "labels"
        fieldRef:
          fieldPath: metadata.labels
      - path: "annotations"
        fieldRef:
          fieldPath: metadata.annotations</code></pre>
</div>
</div>
<div class="paragraph">
<p>Archivos en <code>/etc/podinfo/</code>:
- <code>name</code>: Nombre del Pod
- <code>namespace</code>: Namespace del Pod
- <code>labels</code>: Todos los labels
- <code>annotations</code>: Todas las anotaciones</p>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_configuración">6.2.4. Best Practices para Configuración</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usa ConfigMaps para no-secretos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Configuración de aplicación</p>
</li>
<li>
<p>Valores que pueden cambiar por ambiente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa Secrets para datos sensibles</strong></p>
<div class="ulist">
<ul>
<li>
<p>Contraseñas</p>
</li>
<li>
<p>Tokens</p>
</li>
<li>
<p>Claves privadas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monta volúmenes para actualizaciones dinámicas</strong></p>
<div class="ulist">
<ul>
<li>
<p>ConfigMaps en volumen</p>
</li>
<li>
<p>Se actualizan automáticamente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Inyecta variables para info estática</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nombre del Pod</p>
</li>
<li>
<p>Namespace</p>
</li>
<li>
<p>Labels/annotations</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documenta cada variable</strong></p>
<div class="ulist">
<ul>
<li>
<p>Propósito</p>
</li>
<li>
<p>Valores esperados</p>
</li>
<li>
<p>Rango de valores</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Valida en aplicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Valores por defecto</p>
</li>
<li>
<p>Manejo de valores faltantes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Separa por componente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Web app config separada de DB config</p>
</li>
<li>
<p>Facilita reutilización</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usa namespaces para aislamiento</strong></p>
<div class="ulist">
<ul>
<li>
<p>ConfigMaps/Secrets por namespace</p>
</li>
<li>
<p>Mejor control de acceso</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_7_seguridad">7. Módulo 7: Seguridad</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_authentication_y_authorization">7.1. Authentication y Authorization</h3>
<div class="sect3">
<h4 id="_conceptos_fundamentales_2">7.1.1. Conceptos fundamentales</h4>
<div class="paragraph">
<p>La seguridad en Kubernetes se basa en dos conceptos clave:</p>
</div>
<div class="paragraph">
<p><strong>Autenticación (Authentication)</strong>: Verificar <strong>quién</strong> es el usuario/cliente
- ¿Es realmente quien dice ser?
- Basado en credenciales, certificados o tokens</p>
</div>
<div class="paragraph">
<p><strong>Autorización (Authorization)</strong>: Verificar <strong>qué</strong> puede hacer
- ¿Tiene permiso para realizar esta acción?
- Basado en políticas (RBAC, ABAC, Webhook)</p>
</div>
<div class="paragraph">
<p><strong>Acceso a Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Cliente → Autenticación → ¿Es válido? → Autorización → ¿Tiene permisos? → Acción ejecutada
                              ↓ No                            ↓ No
                           Rechazado                      Rechazado</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_métodos_de_autenticación">7.1.2. Métodos de autenticación</h4>
<div class="paragraph">
<p><strong>1. Certificados X.509</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes usa certificados X.509 para autenticar clientes. El servidor API verifica la cadena de confianza.</p>
</div>
<div class="paragraph">
<p>Ejemplo: Cliente kubectl se autentica con certificado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver certificado usado por kubectl
kubectl config view

# Generalmente en ~/.kube/config:
# - client-certificate: /path/to/client.crt
# - client-key: /path/to/client.key
# - certificate-authority: /path/to/ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>El flujo de autenticación con certificados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Cliente envía solicitud HTTPS con certificado
2. Servidor verifica:
   - El certificado está firmado por una CA confiable
   - El certificado no ha expirado
   - El CN (Common Name) se usa como nombre de usuario
3. Si todo es válido → Usuario autenticado</code></pre>
</div>
</div>
<div class="paragraph">
<p>Crear usuario con certificado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Generar clave privada
openssl genrsa -out juan.key 2048

# 2. Crear Certificate Signing Request (CSR)
openssl req -new \
  -key juan.key \
  -out juan.csr \
  -subj "/CN=juan/O=developers"

# 3. Firmar con CA del cluster (normalmente hecho por admin)
openssl x509 -req \
  -in juan.csr \
  -CA /etc/kubernetes/pki/ca.crt \
  -CAkey /etc/kubernetes/pki/ca.key \
  -CAcreateserial \
  -out juan.crt \
  -days 365

# 4. Crear entrada en kubeconfig
kubectl config set-credentials juan \
  --client-certificate=juan.crt \
  --client-key=juan.key</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Bearer Tokens</strong></p>
</div>
<div class="paragraph">
<p>Tokens estáticos: Útiles para service accounts y automación</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Token en header Authorization
curl -H "Authorization: Bearer &lt;token&gt;" https://kubernetes:6443/api/v1/namespaces

# Token en kubeconfig
kubectl config set-credentials myapp --token=&lt;token&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Tokens de Service Account (automáticos):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cada service account tiene un token automático
kubectl get serviceaccount myapp -o jsonpath='{.secrets[0].name}'

# Ver token
kubectl get secret myapp-token-xyz -o jsonpath='{.data.token}' | base64 -d</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. OpenID Connect (OIDC)</strong></p>
</div>
<div class="paragraph">
<p>Integración con proveedores de identidad externos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Configuración en kube-apiserver
--oidc-issuer-url=https://accounts.google.com
--oidc-client-id=kubernetes.apps.googleusercontent.com
--oidc-username-claim=email
--oidc-groups-claim=groups</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ventajas:
- Gestión centralizada de identidades
- SSO (Single Sign-On)
- Integración con providers como Google, Okta, Azure</p>
</div>
</div>
<div class="sect3">
<h4 id="_rbac_role_based_access_control">7.1.3. RBAC (Role-Based Access Control)</h4>
<div class="paragraph">
<p>RBAC es el modelo de autorización recomendado. Define <strong>qué recurso</strong> puede <strong>hacer qué</strong> el usuario/grupo.</p>
</div>
<div class="paragraph">
<p><strong>Componentes RBAC:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Role</strong>: Permisos dentro de un namespace</p>
</li>
<li>
<p><strong>ClusterRole</strong>: Permisos a nivel de cluster</p>
</li>
<li>
<p><strong>RoleBinding</strong>: Vincula Role a usuarios/grupos en un namespace</p>
</li>
<li>
<p><strong>ClusterRoleBinding</strong>: Vincula ClusterRole a usuarios/grupos globalmente</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Creando un Role:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
  namespace: default
rules:
# Regla 1: Permite leer (get, list, watch) Pods
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

# Regla 2: Permite leer logs
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]

# Regla 3: Permite acceder a configmaps específicas
- apiGroups: [""]
  resources: ["configmaps"]
  resourceNames: ["app-config"]
  verbs: ["get"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Conceptos:
- <code>apiGroups</code>: Grupo de API ("" para core, "apps" para Deployments, etc.)
- <code>resources</code>: Qué recursos (pods, services, deployments, etc.)
- <code>verbs</code>: Qué acciones (get, list, create, delete, etc.)
- <code>resourceNames</code>: Opcional - específicas instancias</p>
</div>
<div class="paragraph">
<p><strong>Creando un ClusterRole:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-reader-all-namespaces
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log"]
  verbs: ["get", "list", "watch"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>La diferencia: <code>ClusterRole</code> se aplica a todo el cluster, <code>Role</code> solo a un namespace.</p>
</div>
<div class="paragraph">
<p><strong>RoleBinding: Asignando permisos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
# Usuario individual
- kind: User
  name: juan@example.com
  apiGroup: rbac.authorization.k8s.io

# Grupo de usuarios
- kind: Group
  name: developers
  apiGroup: rbac.authorization.k8s.io

# Service Account
- kind: ServiceAccount
  name: myapp
  namespace: default</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ClusterRoleBinding: Permisos globales</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: read-nodes
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- kind: Group
  name: monitoring
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verbos comunes en RBAC:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Verbo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Descripción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejemplo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">get</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Obtener recurso específico</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl get pod myapp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Listar recursos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl get pods</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Observar cambios</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl get pods --watch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">create</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crear recurso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl create deployment</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">update</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Actualizar recurso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl set image</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Modificar parcialmente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl patch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">delete</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Eliminar recurso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl delete pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">exec</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecutar comando en contenedor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl exec</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">port-forward</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Redireccionar puertos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl port-forward</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ver logs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl logs</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Predicados de recurso (Resource Names):</strong></p>
</div>
<div class="paragraph">
<p>Limitar acceso a recursos específicos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "delete"]
  # Solo el pod "production-app"
  resourceNames: ["production-app"]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verbos especiales (escalables):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Los términos escalables (scale) requieren verbos especiales
- apiGroups: ["apps"]
  resources: ["deployments/scale"]
  verbs: ["get", "create", "update"]

# Acceso a status
- apiGroups: ["apps"]
  resources: ["deployments/status"]
  verbs: ["get"]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Roles predefinidas en Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver roles predefinidas
kubectl get clusterroles | grep -E "system:|cluster"

# Principales:
# - view: Leer la mayoría de recursos (excepto RBAC y secrets)
# - edit: Crear, actualizar, eliminar recursos de aplicación
# - admin: Control total en namespace
# - cluster-admin: Control total del cluster</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_mejores_prácticas_de_autenticación_y_autorización">7.1.4. Mejores prácticas de autenticación y autorización</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usar RBAC en lugar de AllowAll</strong></p>
<div class="ulist">
<ul>
<li>
<p>Denegar por defecto, permitir explícitamente</p>
</li>
<li>
<p>Menos riesgo de acceso no autorizado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Principio de menor privilegio (Least Privilege)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Solo permisos necesarios</p>
</li>
<li>
<p>Revisar regularmente accesos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditar acceso a recursos sensibles</strong></p>
<div class="ulist">
<ul>
<li>
<p>Secrets, RBAC itself, kubelet</p>
</li>
<li>
<p>Logs de auditoría en API server</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar grupos para gestión de usuarios</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cambios en un solo lugar</p>
</li>
<li>
<p>Escalable para muchos usuarios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Separar responsabilidades</strong></p>
<div class="ulist">
<ul>
<li>
<p>Desarrolladores: pods, deployments, logs</p>
</li>
<li>
<p>DevOps: nodes, persistent storage</p>
</li>
<li>
<p>Seguridad: RBAC, secrets, policies</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Rotación periódica de certificados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Certificados no deben ser eternos</p>
</li>
<li>
<p>Automatizar con herramientas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar OpenID Connect para clusters grandes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mejor manejo de identidades</p>
</li>
<li>
<p>Integración con Active Directory, etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorear intentos fallidos de autenticación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Logs de auditoría</p>
</li>
<li>
<p>Alertas sobre patrones sospechosos</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_service_accounts">7.2. Service Accounts</h3>
<div class="sect3">
<h4 id="_qué_es_un_service_account">7.2.1. ¿Qué es un Service Account?</h4>
<div class="paragraph">
<p>Un Service Account es una identidad de Kubernetes para procesos ejecutando en Pods. Permite:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Identificación de Pods</strong> dentro del cluster</p>
</li>
<li>
<p><strong>Autenticación automática</strong> con API server</p>
</li>
<li>
<p><strong>Control de acceso</strong> via RBAC</p>
</li>
<li>
<p><strong>Montaje automático</strong> de tokens</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un Service Account = Usuario para aplicaciones (diferente de Usuarios para humanos)</p>
</div>
<div class="paragraph">
<p>Ejemplo conceptual:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Aplicación en Pod → Service Account → Token JWT → Acceso a API

Cada Pod obtiene automáticamente:
- Token en /var/run/secrets/kubernetes.io/serviceaccount/token
- CA certificate en /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
- Namespace en /var/run/secrets/kubernetes.io/serviceaccount/namespace</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creación_y_gestión_de_service_accounts">7.2.2. Creación y gestión de Service Accounts</h4>
<div class="paragraph">
<p><strong>Crear Service Account:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Método 1: Con kubectl
kubectl create serviceaccount myapp

# Método 2: Declarativo
cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: myapp
  namespace: default
EOF

# Listar service accounts
kubectl get serviceaccounts
kubectl describe sa myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>YAML completo con opciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: myapp
  namespace: default
  annotations:
    # Metadatos opcionales
    description: "Service account para aplicación myapp"
automountServiceAccountToken: true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Asignación a Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  # Especificar qué Service Account usar
  serviceAccountName: myapp  # por defecto: "default"

  containers:
  - name: app
    image: myapp:latest

    # Token montado automáticamente en:
    # /var/run/secrets/kubernetes.io/serviceaccount/</code></pre>
</div>
</div>
<div class="paragraph">
<p>Dentro del contenedor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Token disponible en
cat /var/run/secrets/kubernetes.io/serviceaccount/token

# CA certificate
cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

# Namespace actual
cat /var/run/secrets/kubernetes.io/serviceaccount/namespace</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_token_de_autenticación">7.2.3. Token de autenticación</h4>
<div class="paragraph">
<p><strong>Estructura del Token:</strong></p>
</div>
<div class="paragraph">
<p>El token es un JWT (JSON Web Token) con tres partes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Token = [Header].[Payload].[Signature]

Header: {"alg":"RS256","typ":"JWT"}
Payload: {
  "iss": "kubernetes/serviceaccount",
  "kubernetes.io/serviceaccount/namespace": "default",
  "kubernetes.io/serviceaccount/secret.name": "myapp-token-abc123",
  "kubernetes.io/serviceaccount/service-account.name": "myapp",
  "sub": "system:serviceaccount:default:myapp"
}
Signature: Firmado con clave privada del cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Obtener token actual:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Desde dentro de un Pod
TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)

# Usar token para hacer requests
curl -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  https://kubernetes.default.svc.cluster.local/api/v1/namespaces/default/pods

# Decodificar token (sin verificar firma)
echo $TOKEN | cut -d. -f2 | base64 -d | jq .</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Desde fuera del cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver secreto del token
kubectl get secret &lt;service-account&gt;-token-xyz -o jsonpath='{.data.token}' | base64 -d</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_montaje_automático_automountserviceaccounttoken">7.2.4. Montaje automático (automountServiceAccountToken)</h4>
<div class="paragraph">
<p><strong>Comportamiento por defecto:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Todo Pod obtiene automáticamente el token del Service Account</p>
</li>
<li>
<p>Se monta como volumen en <code>/var/run/secrets/kubernetes.io/serviceaccount/</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Deshabilitar montaje automático:</strong></p>
</div>
<div class="paragraph">
<p>A nivel de Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  # Deshabilitarn automountaje para este Pod
  automountServiceAccountToken: false

  containers:
  - name: app
    image: myapp:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>A nivel de Service Account:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: myapp
# Deshabilitarn automountaje por defecto para esta SA
automountServiceAccountToken: false</code></pre>
</div>
</div>
<div class="paragraph">
<p>Pod puede sobreescribir esta configuración.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo deshabilitar?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pods que no necesitan acceder a API server</p>
</li>
<li>
<p>Por seguridad (minimizar exposición de token)</p>
</li>
<li>
<p>Pods que usan otro mecanismo de autenticación</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_rbac_para_service_accounts">7.2.5. RBAC para Service Accounts</h4>
<div class="paragraph">
<p><strong>Vincular Role a Service Account:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Definir Role con permisos
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
  namespace: default
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log"]
  verbs: ["get", "list"]
---
# 2. Vincular con RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
# Usar Service Account como subject
- kind: ServiceAccount
  name: myapp
  namespace: default
---
# 3. Pod usa Service Account
apiVersion: v1
kind: Pod
metadata:
  name: monitor-app
spec:
  serviceAccountName: myapp
  containers:
  - name: app
    image: python:3.11
    command:
    - python
    - -c
    - |
      import os
      import json
      import requests

      # Leer credenciales montadas
      token = open('/var/run/secrets/kubernetes.io/serviceaccount/token').read()
      ca = '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'

      # Hacer request a API (con permisos definidos en Role)
      headers = {'Authorization': f'Bearer {token}'}
      url = 'https://kubernetes.default/api/v1/namespaces/default/pods'

      resp = requests.get(url, headers=headers, verify=ca)
      print(json.dumps(resp.json(), indent=2))</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Dar permisos a múltiples Service Accounts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-readers
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
# Múltiples service accounts
- kind: ServiceAccount
  name: monitor-app
  namespace: default
- kind: ServiceAccount
  name: logging-app
  namespace: default
# También puedes incluir usuarios y grupos
- kind: User
  name: alice@example.com
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Service Accounts a nivel de Cluster (ClusterRoleBinding):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: view-all-namespaces
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- kind: ServiceAccount
  name: monitoring-app
  namespace: monitoring</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_caso_de_uso_aplicación_que_accede_a_api">7.2.6. Caso de uso: Aplicación que accede a API</h4>
<div class="paragraph">
<p>Ejemplo completo: Aplicación que lista Pods del cluster</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: pod-lister
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: list-pods
  namespace: default
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: list-pods-binding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: list-pods
subjects:
- kind: ServiceAccount
  name: pod-lister
  namespace: default
---
apiVersion: v1
kind: Deployment
metadata:
  name: pod-monitor
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pod-monitor
  template:
    metadata:
      labels:
        app: pod-monitor
    spec:
      serviceAccountName: pod-lister
      containers:
      - name: monitor
        image: python:3.11
        env:
        - name: KUBERNETES_SERVICE_HOST
          value: "kubernetes.default"
        - name: KUBERNETES_SERVICE_PORT
          value: "443"
        command:
        - python
        - -c
        - |
          import os
          import sys
          import json
          from kubernetes import client, config

          # Cargar config desde ServiceAccount
          config.load_incluster_config()

          # Crear cliente
          v1 = client.CoreV1Api()

          # Listar Pods
          print("Pods en el namespace:")
          pods = v1.list_namespaced_pod(namespace='default')
          for pod in pods.items:
              print(f"  - {pod.metadata.name}")</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_service_accounts">7.2.7. Best Practices para Service Accounts</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Crear Service Account por aplicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>No reutilizar entre aplicaciones</p>
</li>
<li>
<p>Facilita control de acceso granular</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar RBAC con least privilege</strong></p>
<div class="ulist">
<ul>
<li>
<p>Solo permisos necesarios</p>
</li>
<li>
<p>Revisar mensualmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Deshabilitar automountaje si no es necesario</strong></p>
<div class="ulist">
<ul>
<li>
<p>Reduce superficie de ataque</p>
</li>
<li>
<p>Pod toma decision consciente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Rotar tokens regularmente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Secrets vencen (configurable)</p>
</li>
<li>
<p>Automatizar rotación</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditar uso de Service Accounts</strong></p>
<div class="ulist">
<ul>
<li>
<p>Logs de auditoría</p>
</li>
<li>
<p>Alertas de uso inusual</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar namespaces para aislamiento</strong></p>
<div class="ulist">
<ul>
<li>
<p>Service Accounts por namespace</p>
</li>
<li>
<p>Mejor control de acceso</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No compartir tokens</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada proceso su propia SA</p>
</li>
<li>
<p>Evita sobreprivilegios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentar permisos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué puede hacer cada SA</p>
</li>
<li>
<p>Por qué necesita esos permisos</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_security_context">7.3. Security Context</h3>
<div class="sect3">
<h4 id="_qué_es_un_security_context">7.3.1. ¿Qué es un Security Context?</h4>
<div class="paragraph">
<p>Un Security Context define restricciones y privilegios de seguridad para:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Nivel de contenedor</strong>: Afecta solo al contenedor especificado</p>
</li>
<li>
<p><strong>Nivel de Pod</strong>: Afecta a todos los contenedores del Pod (puede ser sobrescrito)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Define:
- Usuario y grupo que ejecuta el contenedor (UID/GID)
- Capacidades Linux (capabilities)
- SELinux y AppArmor
- Lectura solo para root filesystem
- Acceso privilegiado</p>
</div>
<div class="paragraph">
<p>Ejemplo conceptual:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─ Pod ────────────────────────────────┐
│  securityContext:                    │
│    runAsUser: 1000                   │
│    fsGroup: 2000                     │
│                                       │
│  ┌─ Contenedor 1 ────────────────┐  │
│  │ securityContext:              │  │
│  │   readOnlyRootFilesystem: ... │  │
│  │ (Hereda de Pod si no override)│  │
│  └───────────────────────────────┘  │
└──────────────────────────────────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_a_nivel_de_pod">7.3.2. Configuración a nivel de Pod</h4>
<div class="paragraph">
<p><strong>Ejecutar como usuario no-root:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: non-root-pod
spec:
  # Security context a nivel de Pod
  securityContext:
    runAsUser: 1000      # UID: 1000
    runAsGroup: 3000     # GID: 3000
    fsGroup: 2000        # GID para volúmenes

  containers:
  - name: app
    image: myapp:latest
    # El contenedor hereda estos valores
    # a menos que sobrescriba en securityContext propio</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Campos principales a nivel de Pod:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Campo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Descripción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Valores</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">runAsUser</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">UID que ejecuta contenedores</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0-65535 (0 = root)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">runAsGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">GID principal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0-65535</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fsGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">GID para volúmenes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">GID</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">runAsNonRoot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rechazar si rootUID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true/false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">seLinuxOptions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Contexto SELinux</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">{level, role, type}</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">seccompProfile</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Perfil seccomp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">type, localhostProfile</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">windowsOptions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Windows-only</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">runAsUsername</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Ejecutar como no-root (seguro):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-app
spec:
  securityContext:
    runAsNonRoot: true          # Rechazar si UID=0
    runAsUser: 1000             # Usuario myapp
    runAsGroup: 1000
    fsGroup: 1000

  containers:
  - name: app
    image: myapp:latest
    # Si imagen intenta ejecutar como root: FALLA</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cambiar propiedad de volúmenes (fsGroup):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-volume
spec:
  securityContext:
    runAsUser: 1000
    fsGroup: 2000  # GID de archivos en volúmenes

  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: data
      mountPath: /data

  volumes:
  - name: data
    emptyDir: {}

  # Resultado: /data es propiedad del grupo 2000
  # Contenedor (UID 1000, GID 2000) puede escribir</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_a_nivel_de_contenedor">7.3.3. Configuración a nivel de Contenedor</h4>
<div class="paragraph">
<p><strong>Sobrescribir securityContext del Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: mixed-users
spec:
  securityContext:
    runAsUser: 1000

  containers:
  # Contenedor 1: Hereda runAsUser: 1000
  - name: app1
    image: myapp:latest

  # Contenedor 2: Sobrescribe
  - name: app2
    image: different-app:latest
    securityContext:
      runAsUser: 2000  # Diferente del Pod
      runAsNonRoot: true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Contenedor con privilegios (peligroso):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  containers:
  - name: privileged-app
    image: privileged:latest
    securityContext:
      privileged: true  # Acceso completo al host

  # USAR SOLO PARA:
  # - Drivers de dispositivo
  # - Networking plugins
  # - Monitoreo de bajo nivel
  # NUNCA para aplicaciones normales</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ReadOnlyRootFilesystem:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: read-only-app
spec:
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      readOnlyRootFilesystem: true  # / es solo lectura

    volumeMounts:
    # Necesario para directorios escribibles
    - name: tmp
      mountPath: /tmp
    - name: var-log
      mountPath: /var/log

  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-log
    emptyDir: {}

  # Resultado: aplicación no puede modificar imagen
  # Solo puede escribir en volúmenes específicos</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_capacidades_linux_linux_capabilities">7.3.4. Capacidades Linux (Linux Capabilities)</h4>
<div class="paragraph">
<p>Las capacidades dividen los permisos de root en unidades específicas.</p>
</div>
<div class="paragraph">
<p><strong>Sin capacidades (no-root):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Usuario normal (UID 1000) sin capacidades especiales
apiVersion: v1
kind: Pod
metadata:
  name: basic-app
spec:
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true

  containers:
  - name: app
    image: myapp:latest
    # No puede:
    # - Escuchar puertos &lt;1024
    # - Cambiar UID/GID
    # - Montar filesystems
    # - Hacer muchas cosas que requieren privilegios</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Agregar capacidades específicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: cap-net-bind-service
spec:
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true

  containers:
  - name: app
    image: myapp:latest
    securityContext:
      capabilities:
        add:
        - NET_BIND_SERVICE  # Escuchar puertos &lt;1024
        - NET_ADMIN         # Administración de red

  # Resultado: usuario 1000 puede escuchar puerto 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Remover capacidades (seguro):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: minimal-caps
spec:
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      # Remover ALL capabilities
      capabilities:
        drop:
        - ALL

  # Resultado: contenedor tiene CERO capacidades
  # Solo puede acceder a recursos explícitamente montados</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Capacidades comunes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Capacidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Permite</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NET_BIND_SERVICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escuchar puertos &lt;1024</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NET_ADMIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configuración de red avanzada</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SYS_ADMIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muchas operaciones del sistema</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NET_RAW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Raw sockets (ping)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CHOWN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cambiar dueño de archivos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DAC_OVERRIDE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ignorar permisos de archivos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SETUID/SETGID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cambiar UID/GID</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SYS_PTRACE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tracing de procesos</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_runasuser_y_runasgroup">7.3.5. RunAsUser y RunAsGroup</h4>
<div class="paragraph">
<p><strong>Concepto:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>runAsUser</code>: UID del usuario que ejecuta</p>
</li>
<li>
<p><code>runAsGroup</code>: GID del grupo principal</p>
</li>
<li>
<p><code>fsGroup</code>: GID para archivos en volúmenes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: user-group-example
spec:
  securityContext:
    runAsUser: 1000      # Proceso con UID 1000
    runAsGroup: 3000     # Grupo principal GID 3000
    fsGroup: 2000        # Archivos en volúmenes propiedad de GID 2000

  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: config
      mountPath: /config

  volumes:
  - name: config
    configMap:
      name: app-config

  # Resultado:
  # ps aux: muestra UID 1000
  # groups: 1000 (primary), 3000 (suplementary)
  # ls /config: propiedad de root:2000</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar dentro del contenedor:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Dentro del contenedor
id        # uid=1000 gid=3000 groups=3000,2000

# Ver permisos de volumen
ls -l /config  # -rw-r--r-- root 2000

# Ver filesystem raíz
stat /  # Uid: ( 0/ root)   Gid: ( 0/ root)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_selinux_y_apparmor">7.3.6. SELinux y AppArmor</h4>
<div class="paragraph">
<p><strong>SELinux (Security Enhanced Linux):</strong></p>
</div>
<div class="paragraph">
<p>Modelo de control de acceso mandatorio (MAC).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: selinux-pod
spec:
  securityContext:
    seLinuxOptions:
      level: "s0:c123,c456"
      type: "container_t"
      role: "system_r"

  containers:
  - name: app
    image: myapp:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>AppArmor (solo Linux Kernel):</strong></p>
</div>
<div class="paragraph">
<p>Modelo MAC más simple que SELinux.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: apparmor-pod
  # Especificar perfil AppArmor
  annotations:
    container.apparmor.security.beta.kubernetes.io/app: localhost/myapp-profile

spec:
  containers:
  - name: app
    image: myapp:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de perfil AppArmor (en worker node):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"># Archivo: /etc/apparmor.d/myapp-profile
#include &lt;tunables/global&gt;

profile myapp-profile flags=(attach_disconnected,mediate_deleted) {
  #include &lt;abstractions/base&gt;

  capability setuid,
  capability setgid,
  capability sys_admin,

  / r,
  /app/** rw,
  /tmp/** rw,

  # Denegar acceso a /root
  deny /root/** rwk,
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_caso_de_uso_aplicación_segura">7.3.7. Caso de uso: Aplicación segura</h4>
<div class="paragraph">
<p>Aplicación con máxima seguridad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seLinuxOptions:
      type: "container_t"
    seccompProfile:
      type: RuntimeDefault

  containers:
  - name: app
    image: myapp:latest

    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE

    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: logs
      mountPath: /var/log
    - name: config
      mountPath: /etc/config
      readOnly: true

  volumes:
  - name: tmp
    emptyDir: {}
  - name: logs
    emptyDir: {}
  - name: config
    configMap:
      name: app-config
      defaultMode: 0444

  # Protecciones:
  # - No puede ser root
  # - No puede elevar privilegios
  # - / es solo lectura
  # - Sin capacidades (excepto NET_BIND_SERVICE)
  # - SELinux context restringido</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_security_context">7.3.8. Best Practices para Security Context</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Ejecutar como no-root siempre</strong></p>
<div class="ulist">
<ul>
<li>
<p>runAsNonRoot: true</p>
</li>
<li>
<p>Especificar UID explícitamente</p>
</li>
<li>
<p>Validar en Dockerfile</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar readOnlyRootFilesystem</strong></p>
<div class="ulist">
<ul>
<li>
<p>Protege contra modificaciones</p>
</li>
<li>
<p>Requiere volúmenes para /tmp, /var/log</p>
</li>
<li>
<p>Aumenta detectabilidad de intrusiones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Remover todas las capacidades</strong></p>
<div class="ulist">
<ul>
<li>
<p>capabilities.drop: ["ALL"]</p>
</li>
<li>
<p>Agregar solo las necesarias</p>
</li>
<li>
<p>Menor superficie de ataque</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Denegar escalada de privilegios</strong></p>
<div class="ulist">
<ul>
<li>
<p>allowPrivilegeEscalation: false</p>
</li>
<li>
<p>Complementa runAsNonRoot</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar fsGroup para volúmenes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Facilita permisos de volumen</p>
</li>
<li>
<p>Automático para pods multi-contenedor</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Evitar contenedores privilegiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>privileged: true solo para drivers/plugins</p>
</li>
<li>
<p>Requiere justificación explícita</p>
</li>
<li>
<p>Auditar uso</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar seccomp profiles</strong></p>
<div class="ulist">
<ul>
<li>
<p>RuntimeDefault: disables syscalls peligrosos</p>
</li>
<li>
<p>Mejora de seguridad por défecto</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Validar en tiempo de admisión</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pod Security Policies (deprecated)</p>
</li>
<li>
<p>Pod Security Standards (actual)</p>
</li>
<li>
<p>Admision controllers</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_pod_security_standards">7.4. Pod Security Standards</h3>
<div class="sect3">
<h4 id="_qué_son_pod_security_standards">7.4.1. ¿Qué son Pod Security Standards?</h4>
<div class="paragraph">
<p>Pod Security Standards (PSS) son políticas de seguridad built-in de Kubernetes que definen diferentes niveles de restricción:</p>
</div>
<div class="paragraph">
<p>Reemplazan a la deprecated Pod Security Policies (PSP).</p>
</div>
<div class="paragraph">
<p><strong>Tres niveles de restricción:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nivel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propósito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Restricciones</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Privileged</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Máxima compatibilidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ninguna restricción</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Baseline</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Seguridad mínima</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Evita vulnerabilidades conocidas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Restricted</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Seguridad máxima</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cumple hardening completo</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Cómo funcionan:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod manifest
    ↓
Pod Security Admission Controller (en API server)
    ↓
¿Qué nivel es el Pod?
    ├─ ¿Cumple Privileged? → Permitido
    ├─ ¿Cumple Baseline? → audit/warn (si está habilitado)
    └─ ¿Cumple Restricted? → enforce (si está habilitado)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_nivel_privileged">7.4.2. Nivel Privileged</h4>
<div class="paragraph">
<p><strong>Propósito:</strong> Máxima compatibilidad, mínimas restricciones. Para pods de sistema/infraestructura.</p>
</div>
<div class="paragraph">
<p><strong>Restricciones:</strong> Ninguna - permite todo</p>
</div>
<div class="paragraph">
<p><strong>Cuándo usar:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Plugins de red</p>
</li>
<li>
<p>Drivers de dispositivo</p>
</li>
<li>
<p>Logging/monitoring del sistema</p>
</li>
<li>
<p>Operadores de infrastructure</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: privileged-system-pod
spec:
  containers:
  - name: privileged-app
    image: infra/network-plugin:latest
    securityContext:
      privileged: true

  # Sin restricciones - no necesita cumplir estándares</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_nivel_baseline">7.4.3. Nivel Baseline</h4>
<div class="paragraph">
<p><strong>Propósito:</strong> Prevenir vulnerabilidades conocidas. Aplicaciones normales.</p>
</div>
<div class="paragraph">
<p><strong>Restricciones (NO se permite):</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Contenedores privilegiados (<code>privileged: true</code>)</p>
</li>
<li>
<p>Acceso a host PID (<code>hostPID: true</code>)</p>
</li>
<li>
<p>Acceso a host IPC (<code>hostIPC: true</code>)</p>
</li>
<li>
<p>Escalar privilegios (<code>allowPrivilegeEscalation: true</code>)</p>
</li>
<li>
<p>Campos de kernel no root (<code>securityContext.seLinuxOptions</code>, <code>securityContext.windowsOptions</code>)</p>
</li>
<li>
<p>Capacidades no permitidas (solo AUDIT_WRITE, CHOWN, DAC_OVERRIDE, FOWNER, FSETID, KILL, NET_BIND_SERVICE, SETFCAP, SETGID, SETPCAP, SETUID, SYS_CHROOT)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Campos requeridos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>securityContext.allowPrivilegeEscalation: false</code> o</p>
</li>
<li>
<p><code>securityContext.capabilities.drop: ["ALL"]</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo válido (Baseline):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: baseline-app
spec:
  securityContext:
    runAsNonRoot: false  # Permitido en Baseline

  containers:
  - name: app
    image: myapp:latest
    securityContext:
      allowPrivilegeEscalation: false  # Required
      capabilities:
        drop:
        - NET_RAW
        # Otras capabilities están permitidas

  # ✓ Cumple Baseline
  # ✗ NO cumple Restricted (falta runAsNonRoot, readOnlyRootFilesystem)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo inválido (viola Baseline):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: baseline-fail
spec:
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      privileged: true  # ✗ NO PERMITIDO en Baseline

  # ✗ Falla Baseline - rechazado con enforce=baseline</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_nivel_restricted">7.4.4. Nivel Restricted</h4>
<div class="paragraph">
<p><strong>Propósito:</strong> Máxima seguridad. Cumplir hardening completo.</p>
</div>
<div class="paragraph">
<p><strong>Restricciones (NO se permite):</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>TODO lo prohibido en Baseline, más:</p>
</li>
<li>
<p>RunAsUser debe ser no-root</p>
</li>
<li>
<p>RunAsNonRoot debe ser true</p>
</li>
<li>
<p>Root filesystem debe ser read-only</p>
</li>
<li>
<p>Capabilities deben ser ALL dropped</p>
</li>
<li>
<p>No se permite escalada de privilegios</p>
</li>
<li>
<p>seccomp debe ser RuntimeDefault o Localhost</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Campos requeridos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">securityContext:
  runAsNonRoot: true
  runAsUser: &lt;non-zero&gt;
  readOnlyRootFilesystem: true
  seccompProfile:
    type: RuntimeDefault
  capabilities:
    drop:
    - ALL
containers[].securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo válido (Restricted):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: restricted-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    readOnlyRootFilesystem: true
    seccompProfile:
      type: RuntimeDefault

  containers:
  - name: app
    image: myapp:latest

    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true

    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-log
      mountPath: /var/log

  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-log
    emptyDir: {}

  # ✓ Cumple Restricted</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo con privilegios específicos (Restricted):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: restricted-with-caps
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    seccompProfile:
      type: RuntimeDefault

  containers:
  - name: app
    image: myapp:latest

    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE  # Solo si es necesario

      readOnlyRootFilesystem: true

  # ✓ Cumple Restricted (capacidad específica es OK)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pod_security_admission">7.4.5. Pod Security Admission</h4>
<div class="paragraph">
<p><strong>Pod Security Admission Controller</strong> aplica PSS automáticamente.</p>
</div>
<div class="paragraph">
<p><strong>Modos de operación:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>enforce</strong>: Rechaza Pods que violen el estándar</p>
</li>
<li>
<p><strong>audit</strong>: Permite el Pod pero lo registra como violación (en audit logs)</p>
</li>
<li>
<p><strong>warn</strong>: Permite el Pod pero muestra warning (en response headers)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Configuración a nivel de Namespace:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Ejemplo: Enforcement de "restricted" en namespace
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Labels disponibles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">pod-security.kubernetes.io/enforce: &lt;level&gt;
pod-security.kubernetes.io/enforce-version: &lt;version&gt;
pod-security.kubernetes.io/audit: &lt;level&gt;
pod-security.kubernetes.io/audit-version: &lt;version&gt;
pod-security.kubernetes.io/warn: &lt;level&gt;
pod-security.kubernetes.io/warn-version: &lt;version&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Valores de <code>&lt;level&gt;</code>: <code>privileged</code>, <code>baseline</code>, <code>restricted</code></p>
</div>
<div class="paragraph">
<p><strong>Ejemplo completo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: app-namespace
  labels:
    # Enforce: Rechazar Pods que no cumplan Restricted
    pod-security.kubernetes.io/enforce: restricted
    # Audit: Registrar Pods que no cumplan Baseline
    pod-security.kubernetes.io/audit: baseline
    # Warn: Advertir sobre Pods que no cumplan Restricted
    pod-security.kubernetes.io/warn: restricted
---
# Este Pod será rechazado en enforce
apiVersion: v1
kind: Pod
metadata:
  name: insecure-app
  namespace: app-namespace
spec:
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      privileged: true  # ✗ Violates Restricted → RECHAZADO

# Este Pod será permitido (pero auditado y advertido)
---
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
  namespace: app-namespace
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
  # ✓ Cumple Restricted → PERMITIDO</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Exemptions (Excepciones):</strong></p>
</div>
<div class="paragraph">
<p>Permitir Pods privilegiados en namespaces específicos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: system-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    # Excepciones para Pods del sistema
    pod-security.kubernetes.io/enforce-version: latest

  # Nota: Las excepciones se configuran en la política
  # (requiere configuración en kube-apiserver)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_en_kube_apiserver">7.4.6. Configuración en kube-apiserver</h4>
<div class="paragraph">
<p>Habilitar Pod Security Admission:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En /etc/kubernetes/manifests/kube-apiserver.yaml
spec:
  containers:
  - name: kube-apiserver
    command:
    - kube-apiserver
    # Habilitar plugin
    - --admission-control=PodSecurity
    # Configuración de default
    - --pod-security-policy-file=/etc/kubernetes/pss/policy.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_mejor_estrategia_de_implementación">7.4.7. Mejor estrategia de implementación</h4>
<div class="paragraph">
<p><strong>Fase 1: Awareness</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    # Solo warn - sin enforcement
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/audit: baseline</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Fase 2: Audit</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Fase 3: Enforcement</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_pod_security_standards">7.4.8. Best Practices para Pod Security Standards</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usar Restricted por defecto</strong></p>
<div class="ulist">
<ul>
<li>
<p>Máxima seguridad</p>
</li>
<li>
<p>Migraciones gradual si es necesario</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Implementar en fases</strong></p>
<div class="ulist">
<ul>
<li>
<p>Warn primero</p>
</li>
<li>
<p>Audit después</p>
</li>
<li>
<p>Enforce finalmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentar excepciones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Por qué un Pod necesita Baseline/Privileged</p>
</li>
<li>
<p>Revisiones periódicas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Validar en desarrollo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Probar localmente con PSS</p>
</li>
<li>
<p>No esperar a production</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditar violaciones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ver audit logs</p>
</li>
<li>
<p>Identificar Pods problemáticos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Gradual para clusters existentes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Empezar con warn</p>
</li>
<li>
<p>Medir impacto</p>
</li>
<li>
<p>Incrementar restricciones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar con otros controles</strong></p>
<div class="ulist">
<ul>
<li>
<p>RBAC</p>
</li>
<li>
<p>Network Policies</p>
</li>
<li>
<p>Security Context</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Mantener actualizado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nuevas versiones de PSS</p>
</li>
<li>
<p>Nuevas restricciones de seguridad</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_network_security">7.5. Network Security</h3>
<div class="sect3">
<h4 id="_network_policies_avanzadas">7.5.1. Network Policies Avanzadas</h4>
<div class="paragraph">
<p>Network Policies ya se cubrieron en el Módulo 4. Aquí vemos configuraciones avanzadas y casos de uso.</p>
</div>
<div class="paragraph">
<p><strong>Recordatorio: Conceptos básicos</strong></p>
</div>
<div class="paragraph">
<p>Network Policies controlan tráfico de red entre Pods:
- Ingress: Tráfico entrante
- Egress: Tráfico saliente</p>
</div>
<div class="paragraph">
<p><strong>Política compleja: Multi-tier con aislamiento</strong></p>
</div>
<div class="paragraph">
<p>Scenario: Web → API → Database</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Namespace para la aplicación
apiVersion: v1
kind: Namespace
metadata:
  name: app
---
# 1. Denegar TODO por defecto (ingress)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
  namespace: app
spec:
  podSelector: {}  # Aplica a todos los Pods
  policyTypes:
  - Ingress
---
# 2. Denegar TODO por defecto (egress)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-egress
  namespace: app
spec:
  podSelector: {}
  policyTypes:
  - Egress
---
# 3. Permitir: Ingress exterior → web
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-from-outside
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector: {}  # Cualquier namespace
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
---
# 4. Permitir: Web → API
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-to-api
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: web
    ports:
    - protocol: TCP
      port: 8080
---
# 5. Permitir: API → Database
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-api-to-db
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: api
    ports:
    - protocol: TCP
      port: 5432
---
# 6. Permitir: Web → Egress (a API)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-allow-outbound-to-api
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: web
  policyTypes:
  - Egress
  egress:
  # A pods API
  - to:
    - podSelector:
        matchLabels:
          tier: api
    ports:
    - protocol: TCP
      port: 8080
  # A DNS (necesario para resolución)
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
# 7. Permitir: API → Egress (a Database + DNS)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: api-allow-outbound-to-db
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: api
  policyTypes:
  - Egress
  egress:
  # A database
  - to:
    - podSelector:
        matchLabels:
          tier: database
    ports:
    - protocol: TCP
      port: 5432
  # A DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
# 8. Permitir: Database → Egress (solo DNS)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: db-allow-outbound-dns
  namespace: app
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Egress
  egress:
  # Solo DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>IPBLOCK: Control por rango de IPs</strong></p>
</div>
<div class="paragraph">
<p>Permitir acceso solo desde subnet específica:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-corporate-network
  namespace: app
spec:
  podSelector:
    matchLabels:
      app: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - ipBlock:
        cidr: 10.0.0.0/8
        except:
        - 10.0.5.0/24  # Excepto esta subnet
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Política con múltiples condiciones (AND):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: complex-policy
spec:
  podSelector:
    matchLabels:
      app: api
  ingress:
  - from:
    # TODAS estas condiciones deben cumplirse (AND lógico)
    - podSelector:
        matchLabels:
          role: frontend
      namespaceSelector:
        matchLabels:
          environment: production
    ports:
    - protocol: TCP
      port: 8080

  # Solo permitir conexiones de Pods etiquetados como frontend
  # en namespaces etiquetados como production</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_seguridad_de_servicios">7.5.2. Seguridad de Servicios</h4>
<div class="paragraph">
<p><strong>Service sin selector (acceso externo controlado):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Exposer servicio solo a ciertos clientes
apiVersion: v1
kind: Service
metadata:
  name: internal-api
spec:
  type: ClusterIP
  # Usar Network Policy para controlar acceso
  selector:
    app: api

---
# Endpoint manual para control específico
apiVersion: v1
kind: Endpoints
metadata:
  name: internal-api
subsets:
- addresses:
  - ip: 10.0.0.5  # IP específica
  ports:
  - port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>LoadBalancer con IP restringida (cloud-specific):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: api
spec:
  type: LoadBalancer
  selector:
    app: api
  ports:
  - port: 443
    targetPort: 8443
  # Restricción de IPs (AWS/GCP/Azure)
  loadBalancerSourceRanges:
  - 203.0.113.0/24  # Solo desde estos ranges

  # ExternalTrafficPolicy
  externalTrafficPolicy: Local
  # Mantiene IP del cliente (vs Cluster = NAT)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tlsmtls_en_comunicación_pod_to_pod">7.5.3. TLS/mTLS en comunicación Pod-to-Pod</h4>
<div class="paragraph">
<p><strong>Necesidad:</strong> Encriptar tráfico entre Pods</p>
</div>
<div class="paragraph">
<p>Opciones:
1. <strong>Manual TLS</strong>: Certificados en cada Pod
2. <strong>Service Mesh</strong>: Automático (Istio, Linkerd)</p>
</div>
<div class="paragraph">
<p><strong>Manual TLS (ejemplo básico):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Crear certificados TLS
apiVersion: v1
kind: Secret
metadata:
  name: api-tls
type: kubernetes.io/tls
data:
  tls.crt: &lt;base64-encoded-cert&gt;
  tls.key: &lt;base64-encoded-key&gt;
---
# 2. Pod que expone TLS
apiVersion: v1
kind: Pod
metadata:
  name: api-server
spec:
  containers:
  - name: api
    image: api:latest
    volumeMounts:
    - name: tls
      mountPath: /etc/tls
      readOnly: true
    env:
    - name: TLS_CERT_FILE
      value: /etc/tls/tls.crt
    - name: TLS_KEY_FILE
      value: /etc/tls/tls.key
  volumes:
  - name: tls
    secret:
      secretName: api-tls
      defaultMode: 0400

  # Aplicación debe escuchar en HTTPS</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_service_mesh_introducción">7.5.4. Service Mesh (Introducción)</h4>
<div class="paragraph">
<p>Un Service Mesh es una capa de infraestructura que maneja comunicación service-to-service.</p>
</div>
<div class="paragraph">
<p><strong>Problemas que resuelve:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Criptografía automática</strong> (mTLS)</p>
</li>
<li>
<p><strong>Load balancing</strong> inteligente</p>
</li>
<li>
<p><strong>Retry y timeout</strong> automáticos</p>
</li>
<li>
<p><strong>Circuit breaking</strong> para fallos</p>
</li>
<li>
<p><strong>Observabilidad</strong> de tráfico</p>
</li>
<li>
<p><strong>Control de tráfico</strong> granular</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Mesh más populares:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mesh</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Característica</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complejidad</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Istio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy completo, control granular</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linkerd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simple, performante</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Baja</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cilium</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integrado con eBPF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kuma</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Agnóstico a infraestructura</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Istio: Ejemplo básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Habilitar sidecar injection en namespace
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    istio-injection: enabled
---
# 2. Definir VirtualService (enrutamiento)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: api
  namespace: production
spec:
  hosts:
  - api
  http:
  - match:
    - uri:
      prefix: "/v1"
    route:
    - destination:
        host: api-v1
        port:
          number: 8080
  - match:
    - uri:
      prefix: "/v2"
    route:
    - destination:
        host: api-v2
        port:
          number: 8080
---
# 3. Definir DestinationRule (política de comunicación)
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: api
  namespace: production
spec:
  host: api
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        http2MaxRequests: 1000
    loadBalancer:
      simple: ROUND_ROBIN
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2

  # Automático mTLS</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Linkerd: Más simple</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Instalar Linkerd
linkerd install | kubectl apply -f -

# 2. Inyectar en namespace
kubectl annotate namespace production \
  linkerd.io/inject=enabled

# 3. Desplegar aplicación
kubectl apply -f app.yaml

# Resultado: Automático mTLS + observabilidad</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_encriptación_de_tráfico">7.5.5. Encriptación de tráfico</h4>
<div class="paragraph">
<p><strong>Opciones de encriptación:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>En Kubernetes:</strong></p>
<div class="ulist">
<ul>
<li>
<p>mTLS entre Pods (Service Mesh)</p>
</li>
<li>
<p>TLS para Services (Ingress, LoadBalancer)</p>
</li>
<li>
<p>Network encryption plugin (Cilium)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>En aplicación:</strong></p>
<div class="ulist">
<ul>
<li>
<p>HTTPS/TLS</p>
</li>
<li>
<p>Aplicación-level encryption</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Cilium: Encriptación automática</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cilium con encriptación IPSec
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: default-encryption
spec:
  # Encriptar todo tráfico
  nodeSelector:
    matchLabels: {}

  # Configurar en helm values
  # --set encryption.enabled=true
  # --set encryption.type=ipsec</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_network_security">7.5.6. Best Practices para Network Security</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Network Policy denegar por defecto</strong></p>
<div class="ulist">
<ul>
<li>
<p><code>default-deny-ingress</code> y <code>default-deny-egress</code></p>
</li>
<li>
<p>Permitir explícitamente lo necesario</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar pod selectors, no IPBLOCK</strong></p>
<div class="ulist">
<ul>
<li>
<p>Más mantenible</p>
</li>
<li>
<p>Dinámico (cambia con labels)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Separar namespaces por seguridad</strong></p>
<div class="ulist">
<ul>
<li>
<p>Policies por namespace</p>
</li>
<li>
<p>Aislar workloads sensibles</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Incluir DNS en egress</strong></p>
<div class="ulist">
<ul>
<li>
<p>Port 53 UDP</p>
</li>
<li>
<p>Necesario para resolución</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar Service Mesh para aplicaciones críticas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Automático mTLS</p>
</li>
<li>
<p>Observabilidad mejorada</p>
</li>
<li>
<p>Canary deployments</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>TLS Ingress para tráfico externo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Https obligatorio</p>
</li>
<li>
<p>Certificados válidos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditar políticas de red</strong></p>
<div class="ulist">
<ul>
<li>
<p>Revisar mensualmente</p>
</li>
<li>
<p>Eliminar políticas obsoletas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar con otras capas</strong></p>
<div class="ulist">
<ul>
<li>
<p>RBAC (quién puede ver Policies)</p>
</li>
<li>
<p>Security Context (uid/gid)</p>
</li>
<li>
<p>Pod Security Standards</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_8_observabilidad">8. Módulo 8: Observabilidad</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_logging">8.1. Logging</h3>
<div class="sect3">
<h4 id="_por_qué_logging_es_crítico">8.1.1. ¿Por qué logging es crítico?</h4>
<div class="paragraph">
<p>El logging captura eventos y errores de aplicaciones para:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Debugging</strong>: Encontrar causa raíz de problemas</p>
</li>
<li>
<p><strong>Auditoría</strong>: Rastrear acciones de usuarios/sistemas</p>
</li>
<li>
<p><strong>Compliance</strong>: Cumplir requisitos regulatorios</p>
</li>
<li>
<p><strong>Performance analysis</strong>: Identificar cuellos de botella</p>
</li>
<li>
<p><strong>Security</strong>: Detectar intrusions y comportamiento anómalo</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Desafíos en Kubernetes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Contenedores efímeros - logs desaparecen cuando muere Pod</p>
</li>
<li>
<p>Múltiples nodos - logs distribuidos en el cluster</p>
</li>
<li>
<p>Múltiples contenedores - coordinación de logs</p>
</li>
<li>
<p>Volumen - aplicaciones generan miles de logs/segundo</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_logs_de_contenedores_2">8.1.2. Logs de Contenedores</h4>
<div class="paragraph">
<p><strong>Ver logs de Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Logs del contenedor más reciente
kubectl logs pod-name

# Logs con formato más detallado
kubectl logs pod-name --all-containers=true

# Logs en tiempo real (follow)
kubectl logs pod-name -f

# Ver logs de contenedor específico (multi-container Pod)
kubectl logs pod-name -c container-name

# Ver logs de Pods anteriores (si se reinició)
kubectl logs pod-name --previous

# Últimas 100 líneas
kubectl logs pod-name --tail=100

# Desde los últimos 1 hora
kubectl logs pod-name --since=1h</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Logs de Deployment/StatefulSet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Logs de todos los Pods del Deployment
kubectl logs deployment/my-app

# Logs más recientes
kubectl logs deployment/my-app --tail=50 -f

# Con labels para filtrar
kubectl logs -l app=myapp -f</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Límite de logs en contenedor:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:latest

    # Redireccionar logs a archivo
    stdout: /var/log/app.log
    stderr: /var/log/app.log

  # El contenedor no debería escribir directamente a disco
  # Kubernetes maneja logs automáticamente</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Los logs están en:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En el worker node
/var/log/pods/&lt;namespace&gt;_&lt;pod-name&gt;_&lt;uid&gt;/&lt;container-name&gt;/
/var/log/pods/default_myapp-abc123_uuid/myapp/</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_estrategias_de_logging">8.1.3. Estrategias de Logging</h4>
<div class="paragraph">
<p><strong>1. Logging estándar (stdout/stderr)</strong></p>
</div>
<div class="paragraph">
<p>La mejor práctica - la aplicación escribe a stdout/stderr:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Python - Logging a stdout
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stdout  # IMPORTANTE: a stdout, no a archivo
)

logger = logging.getLogger(__name__)
logger.info("Aplicación iniciada")</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-logger
spec:
  containers:
  - name: app
    image: myapp:latest
    # Kubernetes automáticamente captura stdout/stderr
    # No requiere configuración adicional</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ventajas:
- Simple y eficiente
- Kubernetes lo maneja automáticamente
- Fácil de agregar (Fluentd, ELK, etc.)</p>
</div>
<div class="paragraph">
<p><strong>2. Sidecar logging (patrón ambassador)</strong></p>
</div>
<div class="paragraph">
<p>Contenedor adicional que recolecta y procesa logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  containers:
  # Contenedor principal
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: log-volume
      mountPath: /var/log/app

  # Sidecar logging
  - name: log-processor
    image: fluentd:latest
    volumeMounts:
    - name: log-volume
      mountPath: /var/log/app

    # El sidecar procesa los logs de app
    # y los envía a sistema central

  volumes:
  - name: log-volume
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Caso de uso:
- Múltiples contenedores en Pod
- Procesamiento específico de logs
- Enriquecimiento de logs con metadata</p>
</div>
<div class="paragraph">
<p><strong>3. Init container para logs históricos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-log-init
spec:
  initContainers:
  - name: setup-logging
    image: alpine:latest
    command:
    - sh
    - -c
    - |
      mkdir -p /var/log/app
      chmod 777 /var/log/app

  containers:
  - name: app
    image: myapp:latest
    volumeMounts:
    - name: log-volume
      mountPath: /var/log/app

  volumes:
  - name: log-volume
    emptyDir: {}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logs_a_nivel_de_cluster">8.1.4. Logs a nivel de Cluster</h4>
<div class="paragraph">
<p><strong>Logs de componentes del sistema:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Logs del kubelet (en worker nodes)
journalctl -u kubelet -f

# Logs del kube-apiserver
kubectl logs -n kube-system pod/kube-apiserver-node1

# Logs del kube-controller-manager
kubectl logs -n kube-system -l component=kube-controller-manager

# Logs del scheduler
kubectl logs -n kube-system -l component=kube-scheduler</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Audit logs (API server)</strong></p>
</div>
<div class="paragraph">
<p>Registra TODOS los requests al API server:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ubicación (en control plane node)
/var/log/kubernetes/audit.log

# Contenido: quién, qué, cuándo, resultado
{
  "level": "RequestResponse",
  "auditID": "abc-123",
  "stage": "ResponseComplete",
  "requestObject": {...},
  "responseObject": {...},
  "user": {
    "username": "admin",
    "uid": "123"
  },
  "verb": "create",
  "objectRef": {
    "resource": "pods",
    "name": "myapp",
    "namespace": "default"
  },
  "sourceIPAddress": "192.168.1.1",
  "requestReceivedTimestamp": "2024-01-15T10:30:00Z"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Eventos de Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver eventos del cluster
kubectl get events

# Ver eventos con más detalle
kubectl describe pod myapp

# Ver eventos de un namespace específico
kubectl get events -n production

# Eventos ordenados por tiempo
kubectl get events --sort-by='.lastTimestamp'

# Eventos de los últimos 30 minutos
kubectl get events --field-selector involvedObject.name=myapp</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_agregación_de_logs">8.1.5. Agregación de Logs</h4>
<div class="paragraph">
<p><strong>Stack ELK (Elasticsearch, Logstash, Kibana) - mejor: EFK (Fluentd)</strong></p>
</div>
<div class="paragraph">
<p>Arquitectura:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─ Worker Node 1 ────────┐
│ Pod logs → Fluentd      │
└──────────┬──────────────┘
           │
           ├─────────────────┐
           │                 │
┌─ Worker Node 2 ────────┐  │
│ Pod logs → Fluentd      │  │
└──────────┬──────────────┘  │
           │                 │
           v                 v
    ┌────────────────┐
    │  Elasticsearch │ (almacenamiento)
    └────────┬───────┘
             │
          ┌──v──┐
          │Kibana│ (visualización)
          └──────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación con Helm:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio de elastic
helm repo add elastic https://helm.elastic.co
helm repo update

# 1. Instalar Elasticsearch
helm install elasticsearch elastic/elasticsearch \
  --namespace logging --create-namespace \
  --set replicas=3 \
  --set resources.requests.memory=1Gi

# 2. Instalar Kibana
helm install kibana elastic/kibana \
  --namespace logging \
  --set elasticsearch.hosts=elasticsearch:9200

# 3. Instalar Fluentd
helm install fluent-bit fluent/fluent-bit \
  --namespace logging \
  -f fluent-bit-values.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración Fluentd:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># DaemonSet Fluentd (corre en cada nodo)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: elasticsearch
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX
          value: logstash
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT
          value: "true"

        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true

      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers

      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>RBAC para Fluentd:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluentd
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: logging</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_búsqueda_de_logs_en_kibana">8.1.6. Búsqueda de logs en Kibana</h4>
<div class="paragraph">
<p><strong>Dashboard Kibana:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Create Index Pattern: "logstash-*"
2. Discover tab: ver logs en tiempo real
3. Visualize: crear gráficos
4. Dashboard: combinar visualizaciones</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Búsquedas útiles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"># Logs de un Pod específico
kubernetes.pod_name: "myapp*"

# Logs de error
level: ERROR

# Logs de un namespace
kubernetes.namespace_name: "production"

# Logs de un contenedor
kubernetes.container_name: "api"

# Logs en rango de tiempo
@timestamp: [2024-01-15T10:00:00Z TO 2024-01-15T11:00:00Z]

# Combinaciones (AND)
kubernetes.pod_name: "api*" AND level: ERROR</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rotación_y_retención_de_logs">8.1.7. Rotación y retención de logs</h4>
<div class="paragraph">
<p><strong>Rotación automática en kubelet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En /etc/kubernetes/kubelet/kubelet-config.yaml
logging:
  # Máximo tamaño de log
  containerLogMaxSize: 10Mi
  # Máximo número de archivos de log
  containerLogMaxFiles: 5</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Con logrotate (en worker nodes):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># /etc/logrotate.d/kubernetes
/var/log/pods/*/*/*.log {
    rotate 10
    daily
    maxage 30
    compress
    copytruncate
    missingok
    notifempty
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>En sistema de agregación:</strong></p>
</div>
<div class="paragraph">
<p>Elasticsearch automáticamente rota por día:
- <code>logstash-2024-01-15</code>
- <code>logstash-2024-01-16</code>
- etc.</p>
</div>
<div class="paragraph">
<p>Política de retención: eliminar logs &gt;30 días</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Eliminar índices antiguos (con CLI)
curl -X DELETE "localhost:9200/logstash-2023-12-01"</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_logging">8.1.8. Best Practices para Logging</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Logs a stdout/stderr</strong></p>
<div class="ulist">
<ul>
<li>
<p>Kubernetes lo captura automáticamente</p>
</li>
<li>
<p>Fácil de agregar</p>
</li>
<li>
<p>No escribir a disco</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar niveles de log apropiados</strong></p>
<div class="ulist">
<ul>
<li>
<p>ERROR: Errores críticos</p>
</li>
<li>
<p>WARN: Situaciones anómalas</p>
</li>
<li>
<p>INFO: Eventos importantes</p>
</li>
<li>
<p>DEBUG: Información detallada</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Estructurar logs (JSON)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Más fácil de parsear</p>
</li>
<li>
<p>Mejor para búsqueda</p>
<div class="literalblock">
<div class="content">
<pre>[source,json]
----
{"timestamp": "2024-01-15T10:30:00Z", "level": "ERROR", "message": "DB connection failed", "service": "api", "pod": "api-xyz"}
----</pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Agregar contexto a logs</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pod name</p>
</li>
<li>
<p>Namespace</p>
</li>
<li>
<p>Container name</p>
</li>
<li>
<p>IP del cliente</p>
</li>
<li>
<p>Request ID</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No loguear datos sensibles</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nunca: passwords, tokens, keys</p>
</li>
<li>
<p>Nunca: PII (personal info)</p>
</li>
<li>
<p>Usar redacción: <code>password=<strong>*</strong></code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorear volumen de logs</strong></p>
<div class="ulist">
<ul>
<li>
<p>Logs voluminosos afectan performance</p>
</li>
<li>
<p>Usar sampling si es necesario</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Retención basada en compliance</strong></p>
<div class="ulist">
<ul>
<li>
<p>Regulatorios (PCI-DSS, HIPAA)</p>
</li>
<li>
<p>Típicamente: 30, 90, o 365 días</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Centralizar logs del cluster</strong></p>
<div class="ulist">
<ul>
<li>
<p>ELK, EFK, Splunk, Datadog, etc.</p>
</li>
<li>
<p>Crítico para debugging distribuido</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_monitoring">8.2. Monitoring</h3>
<div class="sect3">
<h4 id="_métricas_en_kubernetes">8.2.1. Métricas en Kubernetes</h4>
<div class="paragraph">
<p>El monitoreo captura datos sobre:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Utilización de recursos</strong>: CPU, memoria, disco</p>
</li>
<li>
<p><strong>Salud de aplicación</strong>: latencia, errores, throughput</p>
</li>
<li>
<p><strong>Salud de cluster</strong>: nodos disponibles, capacidad</p>
</li>
<li>
<p><strong>Eventos</strong>: crashes, restarts, errores</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Tipos de métricas:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Métrica</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fuente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU usage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubelet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA, capacity planning</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Memory usage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubelet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OOM prevention, resource limits</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Network I/O</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CNI plugin</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bandwidth analysis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Disk I/O</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubelet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage performance</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Application metrics</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">aplicación</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Business metrics, SLA</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">API latency</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">API server</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cluster health</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Sistema de métricas en Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌──────────────────────────────────────────┐
│ Componentes generan métricas             │
│ - kubelet (CPU, memory)                  │
│ - API server (request latency)           │
│ - controller-manager (reconciliation)    │
└───────────────┬──────────────────────────┘
                │
          ┌─────v──────┐
          │Metrics API │ (metrics.k8s.io)
          └─────┬──────┘
                │
       ┌────────┴─────────┐
       │                  │
   ┌───v──┐          ┌─────v──┐
   │ HPA  │          │Dashboards
   └──────┘          └────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_metrics_server">8.2.2. Metrics Server</h4>
<div class="paragraph">
<p>Metrics Server proporciona metrics de CPU y memoria en tiempo real.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver si ya está instalado
kubectl get deployment metrics-server -n kube-system

# Instalar (minikube incluye por defecto)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verificar
kubectl get deployment metrics-server -n kube-system
kubectl top nodes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver métricas de Nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># CPU y memoria de todos los nodos
kubectl top nodes

# Salida:
# NAME           CPU(cores)   CPU%     MEMORY(Mi)   MEMORY%
# worker-node-1  500m         25%      2048Mi       50%
# worker-node-2  250m         12%      1024Mi       25%

# Nodo específico
kubectl top node worker-node-1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver métricas de Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Todos los Pods en namespace
kubectl top pods

# Todos los Pods en todos los namespaces
kubectl top pods -A

# Pods ordenados por CPU
kubectl top pods --sort-by=cpu

# Pods ordenados por memoria
kubectl top pods --sort-by=memory

# Salida:
# NAME                    CPU(m)   MEMORY(Mi)
# api-deployment-abc123   200m     256Mi
# web-deployment-xyz789   100m     128Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Integración con HPA:</strong></p>
</div>
<div class="paragraph">
<p>Metrics Server proporciona datos para Horizontal Pod Autoscaler:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  # Métrica de CPU (de Metrics Server)
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Métrica de memoria (de Metrics Server)
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_prometheus_y_grafana">8.2.3. Prometheus y Grafana</h4>
<div class="paragraph">
<p><strong>Prometheus</strong>: Base de datos de time-series para métricas</p>
</div>
<div class="paragraph">
<p><strong>Grafana</strong>: Visualización de métricas</p>
</div>
<div class="paragraph">
<p><strong>Arquitectura:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────────────────────┐
│ Prometheus Scraper                          │
│ - Kubelet metrics                           │
│ - API server metrics                        │
│ - Application metrics                       │
│ - Node exporter metrics                     │
└────────────┬────────────────────────────────┘
             │
      ┌──────v────────┐
      │ Prometheus DB │ (Time-series)
      └──────┬────────┘
             │
      ┌──────v──────┐
      │  Grafana    │ (Visualization)
      └─────────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación con Helm:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio Prometheus
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Instalar Prometheus Stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace

# Acceder a Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# URL: http://localhost:3000
# Usuario/Password: admin/prom-operator (por defecto)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración Prometheus manual:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
    # Kubernetes API server
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

    # Kubelet metrics
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

    # Pods con anotación prometheus.io/scrape
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Exponer métricas de aplicación:</strong></p>
</div>
<div class="paragraph">
<p>La aplicación necesita exponer métricas en <code>/metrics</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Python con Prometheus client
from prometheus_client import Counter, Histogram, start_http_server
import time

# Definir métricas
request_count = Counter('app_requests_total', 'Total requests')
request_latency = Histogram('app_request_latency_seconds', 'Request latency')

# Iniciar servidor en puerto 8000
start_http_server(8000)

# En tu código
with request_latency.time():
    # Tu código aquí
    request_count.inc()
    time.sleep(0.1)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pod con métricas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: metrics-app
  annotations:
    # Prometheus scrape automático
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
    prometheus.io/path: "/metrics"
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - name: metrics
      containerPort: 8000

    # Liveness probe para /metrics endpoint
    livenessProbe:
      httpGet:
        path: /metrics
        port: metrics
      initialDelaySeconds: 30
      periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Dashboards Grafana útiles:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Cluster Overview</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nodos disponibles</p>
</li>
<li>
<p>Utilización de CPU/Memoria</p>
</li>
<li>
<p>Pods corriendo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Pod Performance</strong></p>
<div class="ulist">
<ul>
<li>
<p>CPU usage por Pod</p>
</li>
<li>
<p>Memory usage por Pod</p>
</li>
<li>
<p>Network I/O</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Application Metrics</strong></p>
<div class="ulist">
<ul>
<li>
<p>Requests/segundo</p>
</li>
<li>
<p>Latencia de requests</p>
</li>
<li>
<p>Error rate</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_alerting">8.2.4. Alerting</h4>
<div class="paragraph">
<p><strong>AlertManager</strong>: Componente que maneja alertas</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Prometheus → Evalúa reglas → Alert disparado
                ↓
          AlertManager
                ↓
    ├─ Email
    ├─ Slack
    ├─ PagerDuty
    └─ Webhook</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración de alertas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
  namespace: monitoring
spec:
  groups:
  - name: app.rules
    interval: 30s
    rules:
    # Alerta: CPU alto
    - alert: PodHighCPU
      expr: |
        sum(rate(container_cpu_usage_seconds_total[5m])) by (pod) &gt; 0.8
      for: 5m
      annotations:
        summary: "Pod {{ $labels.pod }} CPU uso alto"
        description: "CPU &gt; 80% por más de 5 minutos"

    # Alerta: Memoria alta
    - alert: PodHighMemory
      expr: |
        sum(container_memory_usage_bytes) by (pod) &gt; 1073741824
      for: 5m
      annotations:
        summary: "Pod {{ $labels.pod }} memoria &gt; 1Gi"

    # Alerta: Pod restartando
    - alert: PodRestarting
      expr: |
        rate(kube_pod_container_status_restarts_total[15m]) &gt; 0.1
      for: 5m
      annotations:
        summary: "Pod {{ $labels.pod }} restartando frecuentemente"

    # Alerta: Nodo no disponible
    - alert: NodeNotReady
      expr: |
        kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 5m
      annotations:
        summary: "Nodo {{ $labels.node }} no está listo"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración AlertManager:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

    route:
      receiver: 'default'
      group_by: ['alertname', 'cluster']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 4h

      routes:
      # Critical alerts a PagerDuty
      - match:
          severity: critical
        receiver: pagerduty

      # Warnings a Slack
      - match:
          severity: warning
        receiver: slack

    receivers:
    - name: 'default'
      slack_configs:
      - channel: '#alerts'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    - name: 'pagerduty'
      pagerduty_configs:
      - service_key: 'YOUR-SERVICE-KEY'

    - name: 'slack'
      slack_configs:
      - channel: '#warnings'
        title: 'Warning: {{ .GroupLabels.alertname }}'</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_custom_metrics">8.2.5. Custom Metrics</h4>
<div class="paragraph">
<p>Métricas específicas de la aplicación (no CPU/Memory)</p>
</div>
<div class="paragraph">
<p><strong>Tipos:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pod Metrics</strong>: Desde aplicación</p>
</li>
<li>
<p><strong>External Metrics</strong>: Desde sistema externo (cloud, etc.)</p>
</li>
<li>
<p><strong>Object Metrics</strong>: De recursos específicos</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Custom Metrics en HPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 2
  maxReplicas: 20
  metrics:
  # Métrica custom: requests por segundo
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"

  # Métrica externa: queue length
  - type: External
    external:
      metric:
        name: queue_length
        selector:
          matchLabels:
            queue_name: requests
      target:
        type: AverageValue
        averageValue: "100"

  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Adaptador de métricas custom:</strong></p>
</div>
<div class="paragraph">
<p>Prometheus adapter convierte Prometheus metrics en Custom Metrics:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Prometheus adapter
helm install prometheus-adapter prometheus-community/prometheus-adapter \
  --namespace monitoring

# Ver Custom Metrics disponibles
kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq .</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_monitoring">8.2.6. Best Practices para Monitoring</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Metrics vitales del cluster</strong></p>
<div class="ulist">
<ul>
<li>
<p>CPU y memoria por nodo</p>
</li>
<li>
<p>Pods por nodo</p>
</li>
<li>
<p>Capacidad disponible</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Metrics vitales de aplicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Request rate</p>
</li>
<li>
<p>Latency (p50, p95, p99)</p>
</li>
<li>
<p>Error rate</p>
</li>
<li>
<p>Business metrics</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>SLI/SLO</strong></p>
<div class="ulist">
<ul>
<li>
<p>SLI: Service Level Indicator (métrica medible)</p>
</li>
<li>
<p>SLO: Service Level Objective (meta)</p>
</li>
<li>
<p>Ejemplo: "99.9% de requests &lt; 100ms"</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Alertas significativas</strong></p>
<div class="ulist">
<ul>
<li>
<p>No generar "alert fatigue"</p>
</li>
<li>
<p>Solo alertas que requieren acción</p>
</li>
<li>
<p>Documentar qué hacer en cada alerta</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Retención de métricas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Prometheus: 15 días por defecto</p>
</li>
<li>
<p>Long-term storage: InfluxDB, Thanos</p>
</li>
<li>
<p>Ajustar según necesidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Instrumentación de aplicación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar Prometheus client libraries</p>
</li>
<li>
<p>Métricas de negocio (orders, conversions)</p>
</li>
<li>
<p>Exponer en /metrics</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitoreo multi-layer</strong></p>
<div class="ulist">
<ul>
<li>
<p>Infraestructura: CPU, memory, disk</p>
</li>
<li>
<p>Kubernetes: Pod, nodo, cluster</p>
</li>
<li>
<p>Aplicación: requests, latency, errors</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Correlacionar logs y métricas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar timestamps</p>
</li>
<li>
<p>Request IDs entre sistemas</p>
</li>
<li>
<p>Facilita debugging</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_health_checks">8.3. Health Checks</h3>
<div class="sect3">
<h4 id="_qué_son_health_checks">8.3.1. ¿Qué son Health Checks?</h4>
<div class="paragraph">
<p>Health checks permiten a Kubernetes determinar el estado de una aplicación:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>¿Está corriendo?</strong> (Liveness)</p>
</li>
<li>
<p><strong>¿Está lista para recibir tráfico?</strong> (Readiness)</p>
</li>
<li>
<p><strong>¿Terminó de iniciarse?</strong> (Startup)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin health checks, Kubernetes no sabe si un Pod está sano:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─ Pod ──────────────────┐
│ Aplicación iniciada    │ ← ¿Realmente está lista?
│ Pero no responde       │
└────────────────────────┘

Kubernetes asume: Pod running = Pod sano ✗</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con health checks:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─ Pod ──────────────────┐
│ Liveness: ¿Vivo?       │ → Restart si falla
│ Readiness: ¿Listo?     │ → Remover de LB si falla
│ Startup: ¿Iniciado?    │ → Esperar antes de chequear
└────────────────────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_liveness_probes">8.3.2. Liveness Probes</h4>
<div class="paragraph">
<p>Determina si el Pod debe ser reiniciado.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo falla un liveness probe?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicación está en deadlock</p>
</li>
<li>
<p>Out of memory</p>
</li>
<li>
<p>Proceso muerto pero kubelet no lo detectó</p>
</li>
<li>
<p>Bug que causa hang</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Configuración básica (HTTP):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-liveness
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - containerPort: 8080

    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30    # Esperar 30s antes de chequear
      periodSeconds: 10          # Chequear cada 10s
      timeoutSeconds: 5          # Timeout 5s
      failureThreshold: 3        # Reiniciar después de 3 fallos
      successThreshold: 1        # OK con 1 éxito</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Liveness con TCP:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">livenessProbe:
  tcpSocket:
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

  # Util para aplicaciones que escuchan TCP
  # pero no exponen endpoint HTTP</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Liveness con Exec (comando):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">livenessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - |
      # Script customizado
      curl -f http://localhost:8080/health || exit 1

  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

  # Útil para lógica compleja de healthcheck</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ciclo de vida con Liveness:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod inicia
    ↓
Esperan initialDelaySeconds (30s)
    ↓
Cada periodSeconds (10s):
    ├─ Chequear probe
    ├─ Si OK → seguir
    └─ Si FAIL:
        ├─ Contar fallo
        └─ Si failureThreshold (3) alcanzado:
            └─ RESTART Pod</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_readiness_probes">8.3.3. Readiness Probes</h4>
<div class="paragraph">
<p>Determina si el Pod está listo para recibir tráfico.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo falla?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicación iniciando (carga de datos, conexión a DB)</p>
</li>
<li>
<p>Procesando migración de datos</p>
</li>
<li>
<p>No puede conectar a dependencia</p>
</li>
<li>
<p>En maintenance mode</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diferencia key: Liveness reinicia, Readiness solo remueve del LB</strong></p>
</div>
<div class="paragraph">
<p><strong>Configuración (HTTP):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-readiness
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - containerPort: 8080

    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 10    # Esperar menos que liveness
      periodSeconds: 5           # Chequear más frecuente
      timeoutSeconds: 3
      failureThreshold: 2
      successThreshold: 1

      # El /ready endpoint debe retornar:
      # - 200 OK: Listo
      # - 503 Service Unavailable: No listo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Readiness con dependencias:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">readinessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - |
      # Verificar que DB está conectada
      timeout 3 /app/check_db_connection.sh || exit 1

      # Verificar que cache está cargado
      curl -f http://localhost:8080/cache/status || exit 1

  initialDelaySeconds: 5
  periodSeconds: 5
  failureThreshold: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Impacto en Service:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Service con 3 Pods
    ├─ Pod 1: Ready=true   → Incluida en endpoints
    ├─ Pod 2: Ready=false  → REMOVIDA de endpoints
    └─ Pod 3: Ready=true   → Incluida en endpoints

Resultado: Tráfico solo a Pods 1 y 3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_startup_probes">8.3.4. Startup Probes</h4>
<div class="paragraph">
<p>Para aplicaciones que toman mucho tiempo en iniciarse.</p>
</div>
<div class="paragraph">
<p><strong>¿Cuándo usar?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones legacy que tardan minutos en iniciar</p>
</li>
<li>
<p>Servicios que cargan datos al arrancar</p>
</li>
<li>
<p>Compilación en tiempo de inicio</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Sin Startup Probe:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">livenessProbe:
  httpGet:
    path: /health
    port: 8080
  failureThreshold: 3
  periodSeconds: 10
  # Máximo tiempo para iniciar: 3 fallos × 10s = 30s
  # Si app tarda 60s → muere antes de iniciar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Con Startup Probe:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: slow-startup-app
spec:
  containers:
  - name: app
    image: legacy-app:latest
    ports:
    - containerPort: 8080

    # Startup: esperar hasta 120s para iniciar
    startupProbe:
      httpGet:
        path: /health
        port: 8080
      failureThreshold: 12
      periodSeconds: 10
      # Máximo: 12 × 10 = 120 segundos

    # Una vez iniciado, liveness chequea cada 10s
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      periodSeconds: 10
      failureThreshold: 3

    # Readiness chequea antes de recibir tráfico
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
      failureThreshold: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Timeline:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">0s:   Pod inicia, kubelet espera...
0-120s: Startup probe chequea cada 10s
        ├─ Fallos permidos: 12
        └─ Si todos fallan → Restart
120s: Startup éxito
      ├─ Liveness activa (chequea cada 10s)
      └─ Readiness activa (chequea cada 5s)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tipos_de_probes">8.3.5. Tipos de Probes</h4>
<div class="paragraph">
<p><strong>1. httpGet (HTTP GET request)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">livenessProbe:
  httpGet:
    scheme: HTTP          # HTTP o HTTPS
    host: localhost       # Host (default: Pod IP)
    port: 8080            # Puerto
    path: /healthz        # Path
    httpHeaders:
    - name: Authorization
      value: Bearer token123
  initialDelaySeconds: 15
  periodSeconds: 20
  timeoutSeconds: 5

  # Considerado exitoso: HTTP 200-399</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. tcpSocket (TCP connection)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">readinessProbe:
  tcpSocket:
    host: localhost
    port: 5432
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5

  # Considerado exitoso: conexión TCP exitosa
  # NO valida respuesta, solo conecta</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. exec (Ejecutar comando)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">livenessProbe:
  exec:
    command:
    - /bin/bash
    - -c
    - |
      if [ "$(redis-cli ping)" = "PONG" ]; then
        exit 0
      else
        exit 1
      fi
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5

  # Considerado exitoso: exit code 0</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_parámetros_comunes">8.3.6. Parámetros comunes</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Parámetro</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Descripción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Defecto</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">initialDelaySeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Segundos antes de primer chequeo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">periodSeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Intervalo entre chequeos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">timeoutSeconds</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Timeout del probe</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">failureThreshold</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fallos antes de acción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">successThreshold</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Éxitos para pasar de fallido a exitoso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>initialDelaySeconds por tipo:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Liveness</strong>: 30-60s (esperar a que estabilice)</p>
</li>
<li>
<p><strong>Readiness</strong>: 5-15s (debería estar listo rápido)</p>
</li>
<li>
<p><strong>Startup</strong>: 5s-5m (depende de tiempo de inicio)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_health_checks">8.3.7. Best Practices para Health Checks</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Implementar endpoints de health</strong></p>
<div class="ulist">
<ul>
<li>
<p><code>/health</code> o <code>/healthz</code> para liveness</p>
</li>
<li>
<p><code>/ready</code> para readiness</p>
</li>
<li>
<p>Retornar info útil: dependencias, versión</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Liveness conservador</strong></p>
<div class="ulist">
<ul>
<li>
<p>Solo restart si realmente muerto</p>
</li>
<li>
<p>NO chequear dependencias externas</p>
</li>
<li>
<p>Fallos frecuentes = crashes frecuentes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Readiness es más estricto</strong></p>
<div class="ulist">
<ul>
<li>
<p>Chequear todas las dependencias</p>
</li>
<li>
<p>Incluir estado de caché/datos</p>
</li>
<li>
<p>Más fácil fallando que liveness</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Parámetros realistas</strong></p>
<div class="ulist">
<ul>
<li>
<p>initialDelaySeconds &gt; tiempo real de startup</p>
</li>
<li>
<p>timeoutSeconds &lt; 1s para fallos rápidos</p>
</li>
<li>
<p>periodSeconds: 10-30s normalmente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Diferenciar liveness y readiness</strong></p>
<div class="ulist">
<ul>
<li>
<p>NO usar mismo endpoint para ambos</p>
</li>
<li>
<p>Liveness: ¿está vivo?</p>
</li>
<li>
<p>Readiness: ¿puede procesar tráfico?</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Startup probe para aplicaciones lentas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evita restarts durante startup</p>
</li>
<li>
<p>Permite tiempos de inicialización largos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorear probe failures</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertar si muchos restarts</p>
</li>
<li>
<p>Ver logs de probe failures</p>
</li>
<li>
<p>Ajustar parámetros si es necesario</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Ejemplo completo: aplicación real</strong></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: mycompany/api:v1.2.3
        ports:
        - name: http
          containerPort: 8080
        - name: metrics
          containerPort: 8081

        # Startup: esperar máx 60s
        startupProbe:
          httpGet:
            path: /startup
            port: http
          periodSeconds: 5
          failureThreshold: 12

        # Liveness: reiniciar si muerto
        livenessProbe:
          httpGet:
            path: /health
            port: http
            httpHeaders:
            - name: X-Health-Check
              value: "true"
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 3
          timeoutSeconds: 5

        # Readiness: remover de LB si no listo
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 2
          timeoutSeconds: 3

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_resource_monitoring">8.4. Resource Monitoring</h3>
<div class="sect3">
<h4 id="_resource_requests_y_limits">8.4.1. Resource Requests y Limits</h4>
<div class="paragraph">
<p><strong>Requests</strong>: Cantidad mínima garantizada</p>
</div>
<div class="paragraph">
<p><strong>Limits</strong>: Máximo permitido</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: resource-aware
spec:
  containers:
  - name: app
    image: myapp:latest

    resources:
      # Mínimo garantizado (requerido)
      requests:
        cpu: 100m        # 0.1 CPU cores
        memory: 128Mi    # 128 megabytes

      # Máximo permitido (opcional)
      limits:
        cpu: 500m        # 0.5 CPU cores
        memory: 512Mi    # 512 megabytes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Impacto:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Métrica</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Impacto</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">requests</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scheduling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubelet encuentra nodo con espacio disponible</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">limits</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enforcement</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kernel mata proceso si excede (OOMKilled)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">requests</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Usadas para calcular utilización %</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">limits</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Protection</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Evita que 1 Pod monopolice recursos</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_cpu_y_memoria">8.4.2. CPU y Memoria</h4>
<div class="paragraph">
<p><strong>CPU:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Unidad: <code>m</code> (milicore) o decimal</p>
</li>
<li>
<p><code>100m</code> = 0.1 cores</p>
</li>
<li>
<p><code>1000m</code> = 1 core</p>
</li>
<li>
<p><code>1</code> = 1 core</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Equivalentes:
cpu: 100m    # 100 milicores
cpu: 0.1     # 0.1 cores (igual)

# Range típico:
requests:
  cpu: 50m - 500m   # Para aplicaciones típicas
limits:
  cpu: 500m - 2000m</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Memoria:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Unidad: <code>Mi</code> (mebibytes), <code>Gi</code> (gibibytes), <code>M</code> (megabytes)</p>
</li>
<li>
<p><code>128Mi</code> = 128 mebibytes (≈134.2 MB)</p>
</li>
<li>
<p><code>1Gi</code> = 1 gibibyte (≈1.07 GB)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Equivalentes:
memory: 128Mi    # 128 mebibytes
memory: 134M     # ≈134 megabytes

# Range típico:
requests:
  memory: 64Mi - 512Mi   # Para aplicaciones típicas
limits:
  memory: 256Mi - 2Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CPU vs Memoria:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Memoria</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comprimible</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No comprimible</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">No mata proceso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mata proceso si exceed (OOMKilled)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se throttle si excede</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se termina si excede</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Busybait saca recursos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No se puede compartir fácilmente</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>CPU es throttleable - no falla, solo lento</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod A: requests 500m, limit 1000m
Pod B: requests 500m, limit 1000m

En nodo con 1 CPU:
├─ Ambos quieren 1000m (límite)
├─ CPU disponible: 1000m
├─ Ambos se throttlean:
│  ├─ Pod A obtiene ~600m
│  └─ Pod B obtiene ~400m
└─ Sin error, solo más lento</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Memoria NO es comprimible - falla</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod A: requests 256Mi, limit 512Mi
Pod B: requests 256Mi, limit 512Mi

En nodo con 512Mi RAM:
├─ Pod A: usa 480Mi
├─ Pod B: intenta usar 480Mi
└─ NO hay espacio → Pod B muere (OOMKilled)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_qos_classes">8.4.3. QoS Classes</h4>
<div class="paragraph">
<p>Kubernetes asigna QoS (Quality of Service) basado en requests/limits:</p>
</div>
<div class="paragraph">
<p><strong>Guaranteed: Máxima prioridad</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>request == limit para CPU y Memoria</p>
</li>
<li>
<p>Nunca evicted si nodo sin presión</p>
</li>
<li>
<p>Último en ser terminado</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-pod
spec:
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 500m        # Igual a request
        memory: 512Mi    # Igual a request

  # Resultado: QoS = Guaranteed</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Burstable: Prioridad media</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>request &lt; limit (para al menos una métrica)</p>
</li>
<li>
<p>Evicted si nodo con presión y otros Pods necesitan espacio</p>
</li>
<li>
<p>Intermedio</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod
spec:
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
      limits:
        cpu: 1000m       # Mayor que request
        memory: 1Gi      # Mayor que request

  # Resultado: QoS = Burstable</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>BestEffort: Prioridad baja</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Sin requests/limits</p>
</li>
<li>
<p>Evicted primero si nodo con presión</p>
</li>
<li>
<p>"Best effort" - sin garantías</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: besteffort-pod
spec:
  containers:
  - name: app
    image: myapp:latest
    # Sin resources especificada

  # Resultado: QoS = BestEffort</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Eviction order (cuando kubelet necesita liberar recursos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. BestEffort Pods (sin requests/limits)
   ├─ Terminados primero
   └─ Sin advertencia

2. Burstable Pods (usando más que requests)
   ├─ Terminados segundo
   └─ Si excediendo su request

3. Guaranteed Pods (request == limit)
   └─ Nunca evicted (con presión de recurso)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_definir_requests_y_limits">8.4.4. Definir Requests y Limits</h4>
<div class="paragraph">
<p><strong>Paso 1: Medir uso real</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Desplegar sin limits, medir por 1-2 semanas
kubectl deploy app

# Ver uso actual
kubectl top pod -l app=myapp --sort-by=memory

# Monitoreo con Prometheus
# Guardar datos históricos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Paso 2: Set requests basado en P50</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Si P50 (mediana) de CPU es 200m
# Set request a: P50 × 1.2 (20% overhead)
requests.cpu: 250m

# Si P50 de memoria es 300Mi
# Set request a: P50 × 1.5 (50% overhead para safety)
requests.memory: 450Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Paso 3: Set limits basado en P95</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Si P95 de CPU es 600m
# Set limit a: P95 × 1.5
limits.cpu: 900m

# Si P95 de memoria es 600Mi
# Set limit a: P95 × 1.2 (no mucho más para evitar OOM)
limits.memory: 720Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo real:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: mycompany/api:v1

        # Basado en monitoreo de 2 semanas:
        # - P50 CPU: 250m, P95: 600m
        # - P50 Mem: 300Mi, P95: 500Mi

        resources:
          requests:
            cpu: 300m        # P50 × 1.2
            memory: 450Mi    # P50 × 1.5

          limits:
            cpu: 900m        # P95 × 1.5
            memory: 600Mi    # P95 × 1.2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Nodos con límites de capacidad:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver capacidad de nodo
kubectl describe node node-1

# Allocatable (disponible para Pods)
# = Capacity - Reserved
# = (24 CPUs - 4 reserved) × 1000 = 20000m

# Total requests en node &lt; Allocatable
# Si: sum(requests) &gt; Allocatable → Rechazo nuevo Pod</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_vertical_pod_autoscaler_vpa">8.4.5. Vertical Pod Autoscaler (VPA)</h4>
<div class="paragraph">
<p>Automáticamente ajusta requests/limits basado en uso real.</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio
helm repo add fairwinds-stable https://charts.fairwinds.com/stable
helm repo update

# Instalar VPA
helm install vpa fairwinds-stable/vpa \
  --namespace kube-system</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Modos de VPA:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>off</strong>: Solo recomendaciones</p>
</li>
<li>
<p><strong>initial</strong>: Ajusta requests al crear Pod</p>
</li>
<li>
<p><strong>recreate</strong>: Mata Pod si cambios necesarios</p>
</li>
<li>
<p><strong>auto</strong>: Mata Pod si necesario, sino ajusta</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api

  # Modo de operación
  updatePolicy:
    updateMode: "auto"    # off, initial, recreate, auto

  resourcePolicy:
    # Límites de escalado
    containerPolicies:
    - containerName: api
      minAllowed:
        cpu: 100m
        memory: 64Mi
      maxAllowed:
        cpu: 2000m
        memory: 2Gi
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Recomendaciones de VPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver recomendaciones
kubectl describe vpa api-vpa

# Output:
# Recommendation (updated 5m ago):
#   - Target:
#       cpu: 250m
#       memory: 512Mi
#     Lower Bound:
#       cpu: 200m
#       memory: 400Mi
#     Upper Bound:
#       cpu: 500m
#       memory: 1Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>VPA vs Manual adjustment:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aspecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">VPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Setup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Automático</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Accuracy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Basado en datos históricos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Human estimate</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Adjustment</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Automático</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual deployment</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Testing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No separa staging</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Puedo probar</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Learning curve</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Necesita 2-4 semanas de datos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inmediato</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_best_practices_para_resource_monitoring">8.4.6. Best Practices para Resource Monitoring</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Siempre set requests</strong></p>
<div class="ulist">
<ul>
<li>
<p>Crítico para scheduling</p>
</li>
<li>
<p>Sin requests = no garantías de espacio</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Set limits conservadores</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evita que 1 Pod monopolice recursos</p>
</li>
<li>
<p>Especialmente para memoria</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Memoria limits &gt; requests</strong></p>
<div class="ulist">
<ul>
<li>
<p>CPU comprimible, memoria no</p>
</li>
<li>
<p>Margen de ~20% para memory limits</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorear QoS</strong></p>
<div class="ulist">
<ul>
<li>
<p>Garanteed para aplicaciones críticas</p>
</li>
<li>
<p>Burstable para aplicaciones normal</p>
</li>
<li>
<p>BestEffort solo para batch/testing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar VPA para recomendaciones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Dejar correr en "off" mode inicial</p>
</li>
<li>
<p>Ver recomendaciones antes de aplicar</p>
</li>
<li>
<p>Especialmente útil para aplicaciones variables</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Actualizar requests regularmente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Conforme aplicación cambia</p>
</li>
<li>
<p>Trimestral: revisa logs de monitoreo</p>
</li>
<li>
<p>Si Pods siendo evicted: aumentar requests</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Evitar memory limits muy bajos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Causa OOMKilled innecesarios</p>
</li>
<li>
<p>Mejor tener limite más alto que OOM frecuente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Requests para HPA</strong></p>
<div class="ulist">
<ul>
<li>
<p>HPA usa requests para calcular % utilización</p>
</li>
<li>
<p>Sin requests = HPA no funciona bien</p>
</li>
<li>
<p>Asegura que requests sean realistas</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_9_escalado_y_performance">9. Módulo 9: Escalado y Performance</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_horizontal_pod_autoscaler_hpa">9.1. Horizontal Pod Autoscaler (HPA)</h3>
<div class="sect3">
<h4 id="_qué_es_hpa">9.1.1. ¿Qué es HPA?</h4>
<div class="paragraph">
<p>El Horizontal Pod Autoscaler automáticamente escala el número de Pods basado en métricas observadas.</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Metrics Server/Prometheus
         ↓
    Recolecta métricas
         ↓
    HPA Controller evalúa
         ↓
CPU &gt; 70%? → Escala UP (agregar Pods)
CPU &lt; 30%? → Escala DOWN (remover Pods)
         ↓
Actualiza Deployment.replicas</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diferencia HPA vs VPA:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aspecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">VPA</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Qué escala</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número de Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recursos (CPU/Mem) de cada Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuándo activa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Carga alta</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recursos mal configurados</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más instancias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mismas instancias, más recursos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Latencia</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rápida (segundos)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lenta (mata Pod, requiere reinicio)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_métricas_de_escalado">9.1.2. Métricas de Escalado</h4>
<div class="paragraph">
<p><strong>1. Resource Metrics (CPU/Memoria)</strong></p>
</div>
<div class="paragraph">
<p>Las más comunes - basadas en requests:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10

  metrics:
  # Escalar basado en CPU
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # % de request

  # Escalar basado en memoria
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cálculo de utilización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod request: 100m (100 milicores)
Pod actual CPU: 75m

Utilización = (75m / 100m) × 100 = 75%

Si threshold=70%, entonces:
75% &gt; 70% → ESCALAR ARRIBA</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Custom Metrics</strong></p>
</div>
<div class="paragraph">
<p>Métricas específicas de la aplicación (requests/sec, latency, etc.):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 3
  maxReplicas: 30

  metrics:
  # Métrica custom: requests por segundo
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"  # 1000 req/s por Pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. External Metrics</strong></p>
</div>
<div class="paragraph">
<p>Métricas externas (queue length, AWS SQS, etc.):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: queue-consumer-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: queue-consumer
  minReplicas: 2
  maxReplicas: 20

  metrics:
  # Métrica externa: length de cola SQS
  - type: External
    external:
      metric:
        name: sqs_queue_length
        selector:
          matchLabels:
            queue_name: tasks
      target:
        type: AverageValue
        averageValue: "10"  # 10 mensajes por Pod</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_de_hpa">9.1.3. Configuración de HPA</h4>
<div class="paragraph">
<p><strong>HPA v1 (simple, deprecated):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa-v1
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

  # Solo soporta 1 métrica (CPU)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>HPA v2 (recomendado, múltiples métricas):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa-v2
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10

  # Múltiples métricas (AND - todas se evalúan)
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

  # Comportamiento de escalado (v2.4+)
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100        # Doblar Pods
        periodSeconds: 15
      - type: Pods
        value: 4          # O agregar 4 Pods
        periodSeconds: 15
      selectPolicy: Max   # Usar el mayor

    scaleDown:
      stabilizationWindowSeconds: 300  # Esperar 5 min
      policies:
      - type: Percent
        value: 50         # Remover 50%
        periodSeconds: 60
      selectPolicy: Min</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver estado de HPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver HPAs
kubectl get hpa

# Salida:
# NAME       REFERENCE             TARGETS        MINPODS MAXPODS REPLICAS AGE
# app-hpa    Deployment/myapp      75%/70%, ...   2       10      5        2d

# Ver detalles
kubectl describe hpa app-hpa

# Output:
# Metrics:
#   resource cpu on pods (as a percentage of request):
#     Current / Target: 75% / 70%
# Scale Up Events:
#   Time              Reason             Message
#   ----              ------             -------
#   2024-01-15 10:30  SuccessfulRescale  scaled up from 2 to 4 replicas</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_comportamiento_de_escalado">9.1.4. Comportamiento de Escalado</h4>
<div class="paragraph">
<p><strong>Timeline de escalado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Replica 2
    ↓
CPU 75% &gt; 70% threshold → Trigger
    ↓
Evalúa policies, calcula: max(100%, +4 pods) = 4 nuevos
    ↓
0-15s: Scale UP a 6 replicas
    ↓
Espera 15s entre evaluaciones
    ↓
Si todavía &gt; threshold: Scale UP a 12 replicas (máximo 10)
    ↓
Llega a maxReplicas: 10
    ↓
CPU cae a 50%
    ↓
CPU &lt; 30% (downscale threshold)
    ↓
Estabilización: esperar 300s (5 min)
    ↓
Después de 5 min: Scale DOWN 50% = 5 replicas
    ↓
Espera 60s
    ↓
Si todavía &lt; 30%: Scale DOWN a ~2-3 replicas</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parámetros importantes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">behavior:
  scaleUp:
    stabilizationWindowSeconds: 0
    # Tiempo antes de evaluar downscale
    # 0 = inmediato, &gt;0 = esperar

  scaleDown:
    stabilizationWindowSeconds: 300
    # Esperar 300s antes de downscale
    # Evita oscilaciones rápidas

  policies:
  - type: Percent
    value: 100
    # Escalar 100% (doblar)
    # type: Pods también disponible
    # value: 4 (agregar 4 Pods)

  selectPolicy: Max
    # Max: usar mayor escalado
    # Min: usar menor escalado
    # Disable: no escalar en esa dirección</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo práctico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web

  minReplicas: 2      # Mínimo 2
  maxReplicas: 50     # Máximo 50

  metrics:
  # Métrica 1: CPU
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

  # Métrica 2: Memoria
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 85

  # Escalado agresivo arriba, conservador abajo
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0    # Inmediato
      policies:
      - type: Percent
        value: 100                      # Doblar
        periodSeconds: 30
      - type: Pods
        value: 8                        # O +8 Pods
        periodSeconds: 60
      selectPolicy: Max                 # Mayor escalado

    scaleDown:
      stabilizationWindowSeconds: 600   # Esperar 10 min
      policies:
      - type: Percent
        value: 25                       # Remover 25%
        periodSeconds: 60
      selectPolicy: Min                 # Escalado conservador</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_custom_metrics_2">9.1.5. Custom Metrics</h4>
<div class="paragraph">
<p><strong>Prometheus Adapter (convertir métricas Prometheus a Custom Metrics):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Prometheus adapter
helm install prometheus-adapter prometheus-community/prometheus-adapter \
  --namespace monitoring \
  -f values.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración Prometheus Adapter:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: monitoring
data:
  rules.yaml: |
    rules:
    # Convertir métrica Prometheus a Custom Metric
    - seriesQuery: 'http_requests_total{namespace!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)_total"
        as: "${1}_per_second"
      metricsQuery: |
        rate(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;}[2m])

    # Queue length desde métrica externa
    - seriesQuery: 'sqs_queue_length{queue!=""}'
      resources:
        overrides:
          queue: {resource: "queue"}
      name:
        as: "queue_length"
      metricsQuery: |
        &lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>HPA con Custom Metric:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-custom-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api

  minReplicas: 2
  maxReplicas: 20

  metrics:
  # Métrica custom: requests per second
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "500"  # 500 req/s por Pod

  # Métrica custom: latency P95
  - type: Pods
    pods:
      metric:
        name: http_request_latency_p95
        selector:
          matchLabels:
            quantile: "0.95"
      target:
        type: AverageValue
        averageValue: "100m"  # 100ms</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Debug HPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver eventos de HPA
kubectl describe hpa app-hpa

# Ver métricas actuales
kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq .

# Verificar Prometheus adapter
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus-adapter

# Ver métricas raw de Prometheus
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# Acceder a http://localhost:9090</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_hpa">9.1.6. Best Practices para HPA</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Set resource requests correctamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sin requests → HPA no funciona</p>
</li>
<li>
<p>Requests deben ser realistas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar múltiples métricas</strong></p>
<div class="ulist">
<ul>
<li>
<p>No solo CPU</p>
</li>
<li>
<p>CPU + memoria + custom metrics</p>
</li>
<li>
<p>Evalúa todas (AND)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Conservative downscale</strong>*</p>
<div class="ulist">
<ul>
<li>
<p>stabilizationWindowSeconds &gt; 60s</p>
</li>
<li>
<p>Evita oscilaciones</p>
</li>
<li>
<p>Cuesta dinero escalar arriba/abajo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea HPA eventos</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertas si scaling frecuente</p>
</li>
<li>
<p>Significa límites mal configurados</p>
</li>
<li>
<p>O aplicación tiene picos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combina con Pod Disruption Budgets</strong></p>
<div class="ulist">
<ul>
<li>
<p>Protege disponibilidad durante downscale</p>
</li>
<li>
<p>Evita interrupciones de tráfico</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Test con carga realista</strong></p>
<div class="ulist">
<ul>
<li>
<p>Simula picos de tráfico</p>
</li>
<li>
<p>Verifica que scaling es suficiente</p>
</li>
<li>
<p>Ajusta minReplicas/maxReplicas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Metricsserver debe estar instalado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sin Metrics Server → HPA no funciona</p>
</li>
<li>
<p>Verificar: <code>kubectl get deployment metrics-server -n kube-system</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Avoid rapid scaling oscillations</strong></p>
<div class="ulist">
<ul>
<li>
<p>Si escala arriba/abajo constantemente</p>
</li>
<li>
<p>Aumenta stabilizationWindowSeconds</p>
</li>
<li>
<p>Revisa thresholds</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_vertical_pod_autoscaler_vpa_2">9.2. Vertical Pod Autoscaler (VPA)</h3>
<div class="sect3">
<h4 id="_introducción_a_vpa">9.2.1. Introducción a VPA</h4>
<div class="paragraph">
<p>VPA ajusta automáticamente CPU/Memoria <strong>requests</strong> y <strong>limits</strong> basado en uso real.</p>
</div>
<div class="paragraph">
<p><strong>Diferencia clave VPA vs HPA:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aspecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">VPA</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escala</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número de Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recursos por Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Métrica</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Utilización de requests</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso real</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Acción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escala horizontal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escala vertical</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Latencia</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Segundos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minutos (requiere reinicio)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mejora de costo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muchas instancias pequeñas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Menos instancias, mejor sized</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Cuándo usar VPA:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Requests mal configurados</p>
</li>
<li>
<p>Aplicación con uso variable</p>
</li>
<li>
<p>Reducir costos (usa menos Pods con mejor tamaño)</p>
</li>
<li>
<p>Dev clusters (donde availability no es crítica)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Cuándo NO usar VPA:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicaciones de tráfico estable</p>
</li>
<li>
<p>Cuando downtime = problema (requiere reinicio)</p>
</li>
<li>
<p>Producción con SLA estricto</p>
</li>
<li>
<p>Junto con HPA (pueden conflictuar)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_modos_de_operación">9.2.2. Modos de Operación</h4>
<div class="paragraph">
<p><strong>1. off: Solo recomendaciones</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api

  updatePolicy:
    updateMode: "off"   # Solo recomendaciones

  # Ver recomendaciones sin aplicarlas
  # Útil para testing</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver recomendaciones
kubectl describe vpa api-vpa

# Output:
# Recommendation:
#   Container Recommendations:
#   - Container Name: api
#     Lower Bound:
#       cpu: 100m
#       memory: 128Mi
#     Target:
#       cpu: 250m
#       memory: 512Mi
#     Upper Bound:
#       cpu: 500m
#       memory: 1Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. initial: Ajusta solo Pods nuevos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api

  updatePolicy:
    updateMode: "initial"

  # Pods existentes: NO cambian
  # Pods nuevos (después de upgrade): usan recomendaciones
  # Bueno para rollout gradual</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. recreate: Mata Pods si cambios necesarios</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">updatePolicy:
  updateMode: "recreate"

# VPA mata Pod → Deployment lo re-crea con nuevos resources
# Tiempo de downtime: 5-30 segundos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. auto: Mejor esfuerzo (recomendado)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">updatePolicy:
  updateMode: "auto"  # Por defecto "recreate"

# VPA intenta upgradear in-place si es posible
# Sino: mata Pod</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_recomendaciones_de_vpa">9.2.3. Recomendaciones de VPA</h4>
<div class="paragraph">
<p><strong>Componentes que genera VPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Recommender: Recolecta métricas históricas, calcula recomendaciones
2. Updater: Aplica cambios (mata/recrea Pods)
3. Admission Controller: Intercept nuevos Pods, inyecta requests recomendadas</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cálculo de recomendaciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">VPA analiza: P50, P95, P99 de uso histórico

Para CPU:
  - 95-percentil de uso histórico
  - Más margen si oscila mucho

Para Memoria:
  - 95-percentil de uso (memoria no es comprimible)
  - Margen para picos

Genera 3 valores:
  - lowerBound: Mínimo recomendado (P25 aprox)
  - target: Recomendación principal (P95 aprox)
  - upperBound: Máximo sugerido (P99 aprox)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración con limits:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api

  updatePolicy:
    updateMode: "auto"

  # Limitar rango de recomendaciones
  resourcePolicy:
    containerPolicies:
    - containerName: api
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 2Gi
      # VPA no recomendará fuera de estos rangos

      controlledResources: ["cpu", "memory"]
      # Qué recursos ajustar (omit = todos)

      controlledValues: RequestsAndLimits
      # Ajustar requests Y limits
      # "Requests" solo = sin cambiar limits</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_políticas_de_actualización">9.2.4. Políticas de Actualización</h4>
<div class="paragraph">
<p><strong>updatePolicy en VPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">updatePolicy:
  updateMode: auto

  # Parámetros de cómo actualizar
  maxUnavailable: 1    # Máximo Pods unavailable durante update

  minAvailable: 1      # Mínimo Pods disponibles

  minRichVersion: "1.12.0"  # Mínima K8s version requerida

  # Ejemplo: si Deployment tiene 3 replicas
  # maxUnavailable: 1 → máximo 1 Pod muere, mínimo 2 corriendo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Evitar conflictos con HPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># NO RECOMENDADO: Usar VPA + HPA juntos
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  # ...

---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-vpa
spec:
  # Ambos intentan escalar → conflicto

# RECOMENDADO: Solo HPA para tráfico variable
# O: VPA para aplicaciones con recursos mal configured, sin HPA</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_vpa">9.2.5. Best Practices para VPA</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Empezar en modo "off"</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ver recomendaciones por 2-4 semanas</p>
</li>
<li>
<p>Validar antes de aplicar automáticamente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>No usar con HPA</strong></p>
<div class="ulist">
<ul>
<li>
<p>Uno u otro, no ambos</p>
</li>
<li>
<p>Conflictúan en objetivos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar initial mode en producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>Minimiza downtime</p>
</li>
<li>
<p>Nuevos Pods usan recomendaciones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Set minAllowed/maxAllowed realistas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evita recomendaciones extremas</p>
</li>
<li>
<p>Protege contra bugs</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea eventos de VPA</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ver cuándo actualiza Pods</p>
</li>
<li>
<p>Alertar si cambios frecuentes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar con monitoring</strong></p>
<div class="ulist">
<ul>
<li>
<p>Verificar post-actualización</p>
</li>
<li>
<p>Asegurar que recomendaciones son correctas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Para dev/staging only</strong></p>
<div class="ulist">
<ul>
<li>
<p>Producción con downtime: usar manual adjustment</p>
</li>
<li>
<p>O usar initial mode si acceptable</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Check Prometheus metrics</strong></p>
<div class="ulist">
<ul>
<li>
<p><code>vpa_recommendation_updated_pods</code></p>
</li>
<li>
<p><code>vpa_container_recommendation_target</code></p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cluster_autoscaler">9.3. Cluster Autoscaler</h3>
<div class="sect3">
<h4 id="_qué_es_cluster_autoscaler">9.3.1. ¿Qué es Cluster Autoscaler?</h4>
<div class="paragraph">
<p>Cluster Autoscaler automáticamente agrega/remueve <strong>nodos</strong> basado en demanda de Pods.</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Pod no entra en ningún nodo
  ↓
Está en estado Pending
  ↓
Cluster Autoscaler lo detecta
  ↓
Crea nuevo nodo en el cluster
  ↓
Pod se scheduleá en nuevo nodo
  ↓

Y al revés:
Nodo sub-utilizado por X tiempo
  ↓
Cluster Autoscaler lo detecta
  ↓
Drenaja Pods (los mueve a otros nodos)
  ↓
Termina nodo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diferencia con HPA:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aspecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cluster Autoscaler</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escala</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nodos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Trigger</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU/Mem alto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pods Pending</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Acción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Más nodos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reversible</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rápido downscale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lento (drena nodos)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_instalación_y_configuración">9.3.2. Instalación y Configuración</h4>
<div class="paragraph">
<p><strong>Instalar Cluster Autoscaler (EKS, GKE, AKS):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># EKS
helm repo add autoscaler https://kubernetes.github.io/autoscaler
helm install cluster-autoscaler autoscaler/cluster-autoscaler \
  --namespace kube-system \
  --set autoDiscovery.clusterName=my-cluster \
  --set awsRegion=us-east-1 \
  --set cloudProvider=aws

# GKE (automático por defecto)

# AKS
helm install cluster-autoscaler autoscaler/cluster-autoscaler \
  --namespace kube-system \
  --set cloudProvider=azure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  nodes.max: "100"        # Máximo nodos
  nodes.min: "3"          # Mínimo nodos
  scale-down-enabled: "true"
  scale-down-delay-after-add: "10m"
  scale-down-unneeded-time: "10m"  # Nodo sin usar por 10m → remover</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Nodos con Auto-Scaling Groups (ASG):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Cluster Autoscaler monitorea ASG
  ├─ Cuando Pods Pending: aumenta desiredCapacity
  ├─ Cuando nodos sub-utilizados: disminuye desiredCapacity
  └─ Cloud provider (AWS EC2) crea/termina instancias</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_políticas_de_escalado">9.3.3. Políticas de Escalado</h4>
<div class="paragraph">
<p><strong>Scale-down policy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">scale-down-enabled: true
scale-down-delay-after-add: 10m
  - Esperar 10 min después de agregar nodo antes de remover

scale-down-unneeded-time: 10m
  - Nodo debe estar sub-utilizado por 10 min antes de remover

scale-down-utilization-threshold: 0.65
  - Nodo con &lt; 65% utilización es candidato para remover</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Evitar scale-down de nodos importantes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: critical-app
  annotations:
    # Indica que Pod no puede ser evicted
    cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
spec:
  containers:
  - name: app
    image: critical-app:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pod Disruption Budgets:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: critical

  # Durante scale-down: mínimo 1 Pod debe estar disponible
  # Cluster Autoscaler respeta esto</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_monitoreo_de_cluster_autoscaler">9.3.4. Monitoreo de Cluster Autoscaler</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs de Cluster Autoscaler
kubectl logs -n kube-system -l app=cluster-autoscaler -f

# Ver nodos y su utilización
kubectl top nodes

# Ver Pods Pending (causa de scale-up)
kubectl get pods --field-selector=status.phase=Pending -A

# Ver eventos de escalado
kubectl describe nodes | grep -A 5 "ScaleUp"</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_cluster_autoscaler">9.3.5. Best Practices para Cluster Autoscaler</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Configurar requests en Pods</strong></p>
<div class="ulist">
<ul>
<li>
<p>Sin requests → Cluster Autoscaler no puede calcular necesidad</p>
</li>
<li>
<p>Requests = clave para scheduling</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Set min/max nodes realisticemente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Min: mínimo para aplicación crítica</p>
</li>
<li>
<p>Max: límite de costo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Use Pod Disruption Budgets</strong></p>
<div class="ulist">
<ul>
<li>
<p>Protege aplicaciones durante scale-down</p>
</li>
<li>
<p>Asegura disponibilidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar con HPA</strong></p>
<div class="ulist">
<ul>
<li>
<p>HPA escala Pods</p>
</li>
<li>
<p>Cluster Autoscaler escala nodos</p>
</li>
<li>
<p>Complementarios, no conflictivos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorea eventos de scale</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertar si frecuentes Pending Pods</p>
</li>
<li>
<p>Significa minReplicas too low</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Test con diferentes cargas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Scale-up es fácil</p>
</li>
<li>
<p>Scale-down es más delicado (requiere draining)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Configure scale-down conservadoramente</strong></p>
<div class="ulist">
<ul>
<li>
<p>scale-down-unneeded-time &gt; 10min</p>
</li>
<li>
<p>Evita oscilaciones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Considerar reserved capacity</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantener algunos nodos como buffer</p>
</li>
<li>
<p>Para rápido scaling de Pods</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_resource_management">9.4. Resource Management</h3>
<div class="sect3">
<h4 id="_resource_quotas">9.4.1. Resource Quotas</h4>
<div class="paragraph">
<p>Resource Quotas limitan consumo de recursos por namespace.</p>
</div>
<div class="paragraph">
<p><strong>Crear Quota:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ResourceQuota
metadata:
  name: production-quota
  namespace: production
spec:
  # Limites de CPU
  hard:
    requests.cpu: "100"      # 100 CPUs totales
    limits.cpu: "200"        # 200 CPUs en limits

    # Limites de memoria
    requests.memory: "100Gi"  # 100 GB memoria
    limits.memory: "200Gi"

    # Conteos de objetos
    pods: "100"              # Máximo 100 Pods
    replicationcontrollers: "20"
    services: "10"
    persistentvolumeclaims: "4"

  # Scopes (aplicar a Pods específicos)
  scopeSelector:
    matchExpressions:
    - operator: In
      scopeName: PriorityClass
      values: ["high", "medium"]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar uso de Quota:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver Quotas
kubectl get resourcequota -n production

# Ver detalles
kubectl describe resourcequota production-quota -n production

# Output:
# Name:                    production-quota
# Namespace:               production
# Resource                 Used       Hard
# --------                 ----       ----
# limits.cpu               50         200
# limits.memory            50Gi       200Gi
# pods                     30         100
# requests.cpu             25         100
# requests.memory          25Gi       100Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Impacto de Quota:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Intento crear Pod que viola Quota
  ↓
API Server rechaza (403 Forbidden)
  ↓
Error: "exceeded quota: requests.cpu"

Si Quota alcanzado:
  ├─ Nuevos Pods rechazados
  ├─ Deployments quedan Pending
  └─ Requiere eliminar Pods o aumentar Quota</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_limit_ranges">9.4.2. Limit Ranges</h4>
<div class="paragraph">
<p>Limit Ranges especifican min/max de requests/limits por contenedor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: LimitRange
metadata:
  name: container-limits
  namespace: production
spec:
  limits:
  # Limits por contenedor
  - max:
      cpu: "2"          # CPU máxima por contenedor
      memory: "1Gi"
    min:
      cpu: "100m"       # CPU mínima por contenedor
      memory: "128Mi"
    default:
      cpu: "500m"       # Default si no especificado
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
    type: Container

  # Limits por Pod
  - max:
      cpu: "4"          # CPU máxima en Pod
      memory: "4Gi"
    min:
      cpu: "200m"
      memory: "256Mi"
    type: Pod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Validación de LimitRange:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Crear Pod sin requests/limits
  ↓
LimitRange Controller inyecta defaults
  ↓
Pod termina con defaults especificados

Crear Pod con requests &gt; max
  ↓
API Server rechaza
  ↓
Error: "cpu maximum exceeded"</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_priority_classes">9.4.3. Priority Classes</h4>
<div class="paragraph">
<p>Priority Classes especifican importancia de Pods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
globalDefault: false
description: "Para aplicaciones críticas"
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority
value: 100
globalDefault: false
description: "Para batch jobs"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Usar Priority Class en Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: high-priority

  containers:
  - name: app
    image: critical-app:latest

  # Durante escasez de recursos:
  # Pods con prioridad baja son evicted
  # Pods con prioridad alta son protegidos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Preemption:</strong></p>
</div>
<div class="paragraph">
<p>Cuando recurso escaso y Pod con prioridad alta necesita entrar:
1. Pods con prioridad baja son terminados
2. Pod con prioridad alta es scheduled
3. Clusters evita starvation de Pods críticos</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Recursos:
  ├─ Pod A (priority: 1000) ← CRÍTICA
  ├─ Pod B (priority: 100)  ← batch
  └─ Pod C (priority: 100)  ← batch

Pod A necesita espacio
  ↓
Kubelet termina Pods B y C
  ↓
Pod A se scheduleá</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_resource_management">9.4.4. Best Practices para Resource Management</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Implementar Resource Quotas por namespace</strong></p>
<div class="ulist">
<ul>
<li>
<p>Control de costos</p>
</li>
<li>
<p>Previene monopolio de recursos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar Limit Ranges para defaults</strong></p>
<div class="ulist">
<ul>
<li>
<p>Asegura que Pods tienen requests/limits</p>
</li>
<li>
<p>Protege contra mal-configuración</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Definir Priority Classes</strong></p>
<div class="ulist">
<ul>
<li>
<p>Crítica: aplicaciones de producción</p>
</li>
<li>
<p>Normal: aplicaciones estándar</p>
</li>
<li>
<p>Baja: batch, dev, testing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorar consumo de Quota</strong></p>
<div class="ulist">
<ul>
<li>
<p>Alertas cuando &gt; 80% usado</p>
</li>
<li>
<p>Planificación de capacidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Separar namespaces por importancia</strong></p>
<div class="ulist">
<ul>
<li>
<p>Production: recursos garantizados</p>
</li>
<li>
<p>Staging: recursos limitados</p>
</li>
<li>
<p>Dev: best-effort</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar Quota + LimitRange</strong></p>
<div class="ulist">
<ul>
<li>
<p>Quota: límites totales</p>
</li>
<li>
<p>LimitRange: límites por Pod</p>
</li>
<li>
<p>Ambos necesarios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Revisar Quotas regularmente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Conforme aplicaciones crecen</p>
</li>
<li>
<p>Evitar bottlenecks de recursos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentar políticas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Por qué estos valores</p>
</li>
<li>
<p>Cuándo aumentar</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_performance_tuning">9.5. Performance Tuning</h3>
<div class="sect3">
<h4 id="_node_affinity">9.5.1. Node Affinity</h4>
<div class="paragraph">
<p>Controla qué nodos pueden correr Pods.</p>
</div>
<div class="paragraph">
<p><strong>requiredDuringSchedulingIgnoredDuringExecution (requerido):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-required
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-type
            operator: In
            values:
            - gpu
            - high-memory

  containers:
  - name: app
    image: myapp:latest

  # Pod SOLO puede ir a nodos con label:
  # node-type=gpu OR node-type=high-memory
  # Si no hay nodos válidos: Pending</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>preferredDuringSchedulingIgnoredDuringExecution (preferencia):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-preferred
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: cloud.google.com/gke-preemptible
            operator: NotIn
            values:
            - "true"
      - weight: 50
        preference:
          matchExpressions:
          - key: node.kubernetes.io/instance-type
            operator: In
            values:
            - t3.large
            - t3.xlarge

  containers:
  - name: app
    image: myapp:latest

  # Prefiere: nodos no-preemptible (weight 100)
  # Y: nodos t3.large/xlarge (weight 50)
  # Pero acepta otros si necesario</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pod_affinity_y_anti_affinity">9.5.2. Pod Affinity y Anti-Affinity</h4>
<div class="paragraph">
<p>Controla relación entre Pods.</p>
</div>
<div class="paragraph">
<p><strong>Pod Affinity (Pods cercanos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-pod
spec:
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - cache
          topologyKey: kubernetes.io/hostname

  containers:
  - name: web
    image: web:latest

  # Prefiere: mismo nodo que Pods con label app=cache
  # topologyKey=hostname → mismo nodo físico</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pod Anti-Affinity (Pods separados):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: db-pod
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - database
        topologyKey: kubernetes.io/hostname

  containers:
  - name: db
    image: postgres:latest

  # Requerido: NO mismo nodo que otros db Pods
  # Garantiza que DB instances están en nodos diferentes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>topologyKey valores:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kubernetes.io/hostname → Diferente nodo físico
topology.kubernetes.io/zone → Diferente availability zone
topology.kubernetes.io/region → Diferente región
custom-label → Custom label en nodos</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_taints_y_tolerations">9.5.3. Taints y Tolerations</h4>
<div class="paragraph">
<p>Taints: marca que nodo rechaza Pods</p>
</div>
<div class="paragraph">
<p><strong>Agregar Taint a nodo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Taint sin toleración → Pod rechazado
kubectl taint nodes node-1 gpu=yes:NoSchedule

# Efectos:
# NoSchedule: No scheduleá sin toleration
# NoExecute: Termina Pods sin toleration
# PreferNoSchedule: Prefiere otro nodo

# Remover taint
kubectl taint nodes node-1 gpu=yes:NoSchedule-</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Toleration en Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: gpu-app
spec:
  containers:
  - name: app
    image: gpu-app:latest

  tolerations:
  - key: gpu
    operator: Equal
    value: "yes"
    effect: NoSchedule

  # Pod puede entrar en nodos con taint gpu=yes:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso de uso: GPU nodes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Marcar nodo GPU
kubectl taint nodes gpu-node-1 gpu=required:NoSchedule

# 2. Pod que necesita GPU
apiVersion: v1
kind: Pod
metadata:
  name: ml-training
spec:
  # Requerir nodo GPU
  nodeSelector:
    gpu: "true"

  tolerations:
  - key: gpu
    operator: Equal
    value: required
    effect: NoSchedule

  containers:
  - name: training
    image: ml-training:latest
    resources:
      limits:
        nvidia.com/gpu: 1

  # Pod solamente puede entrar en nodos GPU</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso de uso: Nodos dedicados</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Nodos de staging no aceptan Pods de producción
kubectl taint nodes staging-node env=staging:NoExecute

# Production Pods sin toleration → evicted de staging
# Staging Pods con toleration → pueden correr en staging</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_performance_tuning">9.5.4. Best Practices para Performance Tuning</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Node Affinity para características especiales</strong></p>
<div class="ulist">
<ul>
<li>
<p>GPU nodes</p>
</li>
<li>
<p>High-memory nodes</p>
</li>
<li>
<p>Specific instance types</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Pod Anti-Affinity para redundancia</strong></p>
<div class="ulist">
<ul>
<li>
<p>Database replicas en diferentes nodos</p>
</li>
<li>
<p>Web servers distribuidos</p>
</li>
<li>
<p>Garantiza alta disponibilidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Taints para nodos especializados</strong></p>
<div class="ulist">
<ul>
<li>
<p>GPU, SSD, high-memory</p>
</li>
<li>
<p>Aislamiento de workloads</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitorear scheduling decisions</strong></p>
<div class="ulist">
<ul>
<li>
<p>Ver si Pods se schedulean donde se esperan</p>
</li>
<li>
<p>Debugging con kubectl describe pod</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar affinity con resources</strong></p>
<div class="ulist">
<ul>
<li>
<p>Affinity: dónde puede ir</p>
</li>
<li>
<p>Resources: cuántos pueden entrar</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Test affinity rules</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cambios mal configurados = Pods Pending</p>
</li>
<li>
<p>Validar antes de producción</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar preferred, no required</strong></p>
<div class="ulist">
<ul>
<li>
<p>required es inflexible</p>
</li>
<li>
<p>preferred = mejor experiencia</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentar topología de cluster</strong></p>
<div class="ulist">
<ul>
<li>
<p>Qué nodos tienen qué características</p>
</li>
<li>
<p>Labels, taints, zones</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_10_helm">10. Módulo 10: Helm</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introducción_a_helm">10.1. Introducción a Helm</h3>
<div class="sect3">
<h4 id="_qué_es_helm">10.1.1. ¿Qué es Helm?</h4>
<div class="paragraph">
<p>Helm es el <strong>package manager</strong> de Kubernetes. Similiar a apt (Linux), pip (Python), o npm (Node.js).</p>
</div>
<div class="paragraph">
<p><strong>Problemas que resuelve Helm:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Sin Helm:
  ├─ Desplegar aplicación = escribir 20+ YAML manifests
  ├─ Valores hardcodeados en YAML
  ├─ Actualizar versión = editar múltiples archivos
  ├─ Rollback = restaurar YAML anteriores
  └─ Reutilización = copiar/pegar YAML de otros

Con Helm:
  ├─ Desplegar aplicación = helm install chart-name
  ├─ Valores parametrizados (--set, values.yaml)
  ├─ Actualizar versión = helm upgrade release
  ├─ Rollback automático = helm rollback release
  └─ Reutilización = compartir Charts en repositorios</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Componentes clave:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Componente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Descripción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Analogía</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Chart</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Template/Blueprint de aplicación</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">RPM, .deb package</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Release</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Instancia en vivo de un Chart</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Installed package</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Repository</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Colección de Charts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Package registry (apt, npm)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Parámetros de configuración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Config file</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ventajas_del_package_management">10.1.2. Ventajas del Package Management</h4>
<div class="paragraph">
<p><strong>1. Simplificación</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Sin Helm: escribir 30 líneas de YAML
kubectl apply -f service.yaml
kubectl apply -f deployment.yaml
kubectl apply -f configmap.yaml
kubectl apply -f secret.yaml
# ... más archivos

# Con Helm: una línea
helm install myapp ./charts/myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Parametrización</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Sin Helm: editar YAML para cada ambiente
# prod-deployment.yaml, staging-deployment.yaml, dev-deployment.yaml

# Con Helm: único Chart, diferentes valores
helm install myapp-prod ./charts/myapp --values values-prod.yaml
helm install myapp-staging ./charts/myapp --values values-staging.yaml
helm install myapp-dev ./charts/myapp -set replicas=1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Versionamiento</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Helm automáticamente mantiene historial de releases:
├─ myapp-1: version 1.0.0
├─ myapp-2: version 1.1.0 (upgrade)
├─ myapp-3: version 1.2.0 (upgrade)
└─ Rollback a myapp-2 = una línea de comando</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Reutilización</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar Chart de repositorio público
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install postgres bitnami/postgresql

# Chart pregrabado con mejores prácticas
# No necesita configuración manual</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Dependencias</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Chart de aplicación puede depender de otros Charts:
  ├─ postgres (database)
  ├─ redis (cache)
  └─ prometheus (monitoring)

Helm automáticamente instala todas las dependencias</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_arquitectura_de_helm_3">10.1.3. Arquitectura de Helm 3</h4>
<div class="paragraph">
<p><strong>Helm 3 vs Helm 2:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aspecto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Helm 2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Helm 3</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tiller</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Server-side component</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Removido (más seguro)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Etcd o ConfigMaps</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ConfigMaps o Secrets</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Permissions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Requireria cluster-admin</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No requiere permisos especiales</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Templating</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Go templates</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Go templates (igual)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Seguridad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Menor (Tiller tenía acceso)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mayor (cliente-only)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Flujo de Helm 3:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Cliente Helm (helm command)
   ↓ Lee Chart local o repositorio
   ↓
2. Procesa Templates (sustituye valores)
   ↓ Genera YAML puro de Kubernetes
   ↓
3. Kubectl API (helm internamente usa kubectl)
   ↓ Envia manifests a API server
   ↓
4. API Server procesa YAML
   ↓ Crea Deployments, Services, etc.
   ↓
5. Helm almacena metadata
   ↓ ConfigMap con historial de release
   ↓
6. Kubelet ejecuta Pods</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Almacenamiento de Releases:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Helm 3 almacena releases como Secrets (encrypted)
kubectl get secrets -n default | grep sh.helm.release

# Ver contenido de un release
kubectl get secret sh.helm.release.v1.myapp.v1 -o yaml | jq .data.release | base64 -d | gunzip | jq .</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_instalación_de_helm">10.1.4. Instalación de Helm</h4>
<div class="paragraph">
<p><strong>Instalación en Linux/Mac:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar script de instalación
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Verificar instalación
helm version

# Output:
# version.BuildInfo{Version:"v3.12.0", GitCommit:"c9f554..."}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación en Windows:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con Chocolatey
choco install kubernetes-helm

# O descargar manualmente desde
# https://github.com/helm/helm/releases</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Autocompletado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Bash
helm completion bash | sudo tee /etc/bash_completion.d/helm

# Zsh
helm completion zsh | sudo tee /usr/share/zsh/site-functions/_helm

# Fish
helm completion fish | sudo tee /usr/share/fish/vendor_completions.d/helm.fish</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configurar contexto de Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Helm usa el contexto actual de kubectl
kubectl config current-context

# Cambiar contexto si es necesario
kubectl config use-context production-cluster

# Helm ahora deployará a ese cluster
helm install myapp ./charts/myapp</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_primeros_pasos_con_helm">10.1.5. Primeros pasos con Helm</h4>
<div class="paragraph">
<p><strong>Agregar repositorio oficial:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Repositorio oficial de Charts (comunidad)
helm repo add stable https://charts.helm.sh/stable

# Bitnami (Charts de buena calidad)
helm repo add bitnami https://charts.bitnami.com/bitnami

# Actualizar índice local
helm repo update

# Ver repositorios agregados
helm repo list</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Buscar Charts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Buscar nginx
helm search repo nginx

# Output:
# NAME                            CHART VERSION APP VERSION DESCRIPTION
# bitnami/nginx                   13.2.24       1.24.0      NGINX Open Source is a web server...
# stable/nginx-ingress            4.6.0         1.4.0       An ingress controller that uses...

# Ver detalles de un Chart
helm show chart bitnami/nginx
helm show values bitnami/nginx    # Ver valores por defecto
helm show all bitnami/nginx       # Todo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalar un Chart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalación simple
helm install my-nginx bitnami/nginx

# Instalar con valores personalizados
helm install my-nginx bitnami/nginx \
  --set replicaCount=3 \
  --set service.type=LoadBalancer

# Instalar desde archivo values.yaml
helm install my-nginx bitnami/nginx -f values.yaml

# Ver release instalado
helm list

# Salida:
# NAME      NAMESPACE STATUS    CHART         APP VERSION LAST DEPLOYED
# my-nginx  default   deployed  nginx-13.2.24 1.24.0      2024-01-15</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver status:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Status de release específica
helm status my-nginx

# Ver todos los Pods creados por release
kubectl get pods -l app.kubernetes.io/instance=my-nginx

# Ver servicios
kubectl get svc -l app.kubernetes.io/instance=my-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualizar release:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Upgrade a nueva versión
helm upgrade my-nginx bitnami/nginx --set replicaCount=5

# Ver historial de cambios
helm history my-nginx

# Rollback a versión anterior
helm rollback my-nginx 1

# Desinstalar
helm uninstall my-nginx</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_helm">10.1.6. Best Practices para Helm</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usar Charts de repositorios confiables</strong></p>
<div class="ulist">
<ul>
<li>
<p>Bitnami (mantenido, auditoría)</p>
</li>
<li>
<p>Oficiales de aplicaciones (nginx, postgresql)</p>
</li>
<li>
<p>Evitar Charts desconocidos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Versionear values.yaml en Git</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada ambiente: values-prod.yaml, values-staging.yaml</p>
</li>
<li>
<p>Auditoria de cambios</p>
</li>
<li>
<p>Reproducibilidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar valores en lugar de editar templates</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantener Charts limpio</p>
</li>
<li>
<p>Fácil de actualizar Chart</p>
</li>
<li>
<p>Menos conflictos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentar custom values</strong></p>
<div class="ulist">
<ul>
<li>
<p>Por qué cada valor está configurado así</p>
</li>
<li>
<p>Impacto en producción</p>
</li>
<li>
<p>Cuándo cambiar</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Probar Charts antes de producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>helm lint para validación</p>
</li>
<li>
<p>helm template para ver YAML generado</p>
</li>
<li>
<p>helm test para tests (si Chart los soporta)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar namespaces</strong></p>
<div class="ulist">
<ul>
<li>
<p>helm install myapp ./chart -n production</p>
</li>
<li>
<p>Separación entre enviroments</p>
</li>
<li>
<p>Mejor control de RBAC</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Mantener Helm actualizado</strong></p>
<div class="ulist">
<ul>
<li>
<p>Nuevas versiones = mejoras de seguridad</p>
</li>
<li>
<p>helm version para ver versión actual</p>
</li>
<li>
<p>Fácil de actualizar (solo binario)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Combinar con GitOps</strong></p>
<div class="ulist">
<ul>
<li>
<p>Stores values en Git</p>
</li>
<li>
<p>ArgoCD/Flux observa cambios</p>
</li>
<li>
<p>Helm automáticamente actualiza cluster</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_charts">10.2. Charts</h3>
<div class="paragraph">
<p>Un Chart de Helm es un paquete que contiene toda la información necesaria para desplegar una aplicación en Kubernetes. Es similar a un paquete en apt, npm o pip, pero específicamente diseñado para Kubernetes. Un Chart es simplemente un directorio con una estructura definida que contiene plantillas YAML, valores por defecto, metadatos y, opcionalmente, dependencias de otros Charts.</p>
</div>
<div class="paragraph">
<p>Los Charts son la unidad fundamental de reutilización en Helm. Permiten definir una aplicación de forma paramétrica, facilitando el despliegue en múltiples ambientes (desarrollo, staging, producción) con configuraciones diferentes. Un Chart bien diseñado abstrae la complejidad de Kubernetes del usuario final, quien solo necesita proporcionar valores específicos.</p>
</div>
<div class="sect3">
<h4 id="_estructura_de_un_chart">10.2.1. Estructura de un Chart</h4>
<div class="paragraph">
<p>La estructura de un Chart sigue un patrón estándar que Helm espera encontrar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">my-chart/                          # Directorio raíz del Chart
├── Chart.yaml                     # Metadatos del Chart (nombre, versión, etc.)
├── values.yaml                    # Valores por defecto
├── README.md                       # Documentación
├── LICENSE                         # Licencia
├── templates/                      # Plantillas de Kubernetes
│   ├── deployment.yaml            # Plantilla de Deployment
│   ├── service.yaml               # Plantilla de Service
│   ├── ingress.yaml               # Plantilla de Ingress
│   ├── configmap.yaml             # Plantilla de ConfigMap
│   ├── secret.yaml                # Plantilla de Secret
│   ├── hpa.yaml                   # Plantilla de HPA
│   ├── _helpers.tpl               # Plantillas reutilizables (helpers)
│   └── NOTES.txt                  # Notas de post-instalación
├── values/                        # (Opcional) Valores por ambiente
│   ├── values-dev.yaml
│   ├── values-staging.yaml
│   └── values-prod.yaml
├── charts/                        # (Opcional) Dependencias de Charts
│   ├── postgresql-11.0.0/
│   └── redis-15.0.0/
├── .helmignore                    # Archivos ignorados al empaquetar
└── CHANGELOG.md                   # Registro de cambios</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Directorios y archivos clave:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Chart.yaml</strong>: Archivo YAML que define el Chart. Contiene metadatos como nombre, descripción, versión, mantenedores, repositorio y dependencias.</p>
</li>
<li>
<p><strong>values.yaml</strong>: Archivo con valores por defecto. Helm los usa si el usuario no proporciona overrides. Define toda la configuración de la aplicación.</p>
</li>
<li>
<p><strong>templates/</strong>: Directorio que contiene todas las plantillas de Kubernetes. Cada archivo plantilla se procesa con Go templating engine para generar manifiestos YAML finales.</p>
</li>
<li>
<p><strong>charts/</strong>: Directorio que contiene Charts dependientes (subchart). Permite reutilizar Charts dentro de otros Charts.</p>
</li>
<li>
<p><strong>_helpers.tpl</strong>: Archivo especial con plantillas reutilizables (helpers/macros). Evita repetición de código en otras plantillas.</p>
</li>
<li>
<p><strong>NOTES.txt</strong>: Archivo de plantilla que se muestra al usuario después de instalar el Chart. Típicamente contiene instrucciones de post-instalación.</p>
</li>
<li>
<p><strong>.helmignore</strong>: Similar a .gitignore. Define qué archivos ignorar al empaquetar el Chart.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Diagrama de flujo de un Chart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">┌─────────────────────────────────────────────────────────────┐
│                   Chart de Helm                             │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  values.yaml (valores por defecto)                          │
│  ↓ (usuario puede hacer override con --set, -f values.yaml) │
│                                                              │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Helm Template Engine (Go templating)                │    │
│  │                                                     │    │
│  │  deployment.yaml  → Deployment.yaml (YAML final)   │    │
│  │  service.yaml     → Service.yaml   (YAML final)    │    │
│  │  ingress.yaml     → Ingress.yaml   (YAML final)    │    │
│  │  configmap.yaml   → ConfigMap.yaml (YAML final)    │    │
│  │  ...                                                │    │
│  └─────────────────────────────────────────────────────┘    │
│  ↓                                                           │
│  Manifiestos YAML compilados                               │
│  ↓                                                           │
│  Kubernetes API Server (kubectl apply)                      │
│  ↓                                                           │
│  Recursos desplegados en cluster                            │
└─────────────────────────────────────────────────────────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_valores_values_y_values_yaml">10.2.2. Valores (Values) y values.yaml</h4>
<div class="paragraph">
<p>Los valores son la forma principal de parametrizar un Chart. Permiten al usuario personalizar el comportamiento del Chart sin modificar las plantillas.</p>
</div>
<div class="paragraph">
<p><strong>Archivo values.yaml básico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Configuración de réplicas y imagen
replicaCount: 3

image:
  repository: nginx
  pullPolicy: IfNotPresent
  tag: "1.24.0"

# Configuración del servicio
service:
  type: ClusterIP          # ClusterIP, NodePort, LoadBalancer
  port: 80
  targetPort: 8080
  annotations: {}

# Recursos
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# Escalado automático
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Configuración de aplicación
app:
  name: myapp
  environment: production
  debug: false
  logLevel: info

# Base de datos
database:
  enabled: true
  host: postgres.default.svc.cluster.local
  port: 5432
  name: myapp_db
  user: admin
  # Password debería venir de un Secret externo
  passwordSecret:
    name: db-secret
    key: password

# Afinidad de nodos
nodeSelector: {}
  # disktype: ssd

tolerations: []

affinity: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Anidamiento y estructura:</strong></p>
</div>
<div class="paragraph">
<p>Los valores pueden anidarse en múltiples niveles. Se acceden en templates usando la sintaxis de punto (dot notation):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En values.yaml
config:
  database:
    host: localhost
    credentials:
      username: admin
      password: secret123

# En template, se acceden como:
# {{ .Values.config.database.host }}
# {{ .Values.config.database.credentials.username }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Overriding de valores:</strong></p>
</div>
<div class="paragraph">
<p>Los usuarios pueden hacer override de valores de varias formas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Opción 1: Usar --set desde línea de comandos
helm install myapp ./chart \
  --set replicaCount=5 \
  --set image.tag="1.25.0" \
  --set app.environment=staging

# Opción 2: Usar archivo values externo
helm install myapp ./chart -f values-staging.yaml

# Opción 3: Combinar ambos (el segundo override al primero)
helm install myapp ./chart -f values-base.yaml -f values-prod.yaml

# Opción 4: Mergear valores complejos
helm install myapp ./chart \
  -f values-prod.yaml \
  --set-string database.host=prod-db.example.com

# Ver valores resueltos (después de merges)
helm get values myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Valores especiales (Built-in):</strong></p>
</div>
<div class="paragraph">
<p>Helm proporciona algunos valores especiales disponibles automáticamente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En cualquier plantilla, estos están disponibles:

# Información de la versión del Chart
.Chart.Name              # Nombre del Chart
.Chart.Version           # Versión del Chart (ej: 1.0.0)
.Chart.AppVersion        # Versión de la aplicación (ej: 1.24.0)
.Chart.Description       # Descripción
.Chart.Type              # Tipo (application o library)
.Chart.Maintainers       # Lista de mantenedores

# Información de la Release (instalación)
.Release.Name            # Nombre de la Release (ej: myapp)
.Release.Namespace       # Namespace donde se instala
.Release.IsUpgrade       # true si es un upgrade
.Release.IsInstall       # true si es una instalación nueva

# Información del Helm
.Helm.Version            # Versión de Helm (ej: v3.12.0)

# Ejemplo de uso en plantilla:
metadata:
  name: {{ .Release.Name }}
  labels:
    app: {{ .Chart.Name }}
    version: {{ .Chart.Version }}
    managed-by: Helm
    managed-by-version: {{ .Helm.Version }}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_plantillas_templates">10.2.3. Plantillas (Templates)</h4>
<div class="paragraph">
<p>Las plantillas son archivos YAML que usan Go templating engine. Permiten lógica condicional, loops, funciones y manipulación de strings.</p>
</div>
<div class="paragraph">
<p><strong>Sintaxis básica de templates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Variables simples (acceso a valores)
name: {{ .Values.app.name }}

# 2. Condicionales
{{ if .Values.autoscaling.enabled }}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ .Release.Name }}
spec:
  minReplicas: {{ .Values.autoscaling.minReplicas }}
{{ end }}

# 3. Loops
ports:
{{ range .Values.containers }}
  - name: {{ .name }}
    port: {{ .port }}
{{ end }}

# 4. Funciones y pipelines
labels:
  app: {{ .Values.app.name | lower }}  # Convertir a minúsculas
  version: {{ .Chart.Version | quote }} # Agregar comillas

# 5. Funciones de strings
name: {{ .Release.Name }}-{{ randAlphaNum 5 }}  # Generar nombre aleatorio
name: {{ .Release.Name | upper }}                # Mayúsculas
name: {{ .Release.Name | trunc 63 }}             # Truncar a 63 caracteres

# 6. Funciones matemáticas
replicas: {{ .Values.replicaCount | int }}
memory: {{ .Values.resources.memory | int }}Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo de Deployment con templates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-{{ .Chart.Name }}
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Values.app.name }}
    version: {{ .Chart.Version }}
    managed-by: Helm
spec:
  # Replicas puede ser override con --set replicaCount=X
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Values.app.name }}
      instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app: {{ .Values.app.name }}
        instance: {{ .Release.Name }}
      {{- if .Values.podAnnotations }}
      annotations:
        {{- toYaml .Values.podAnnotations | nindent 8 }}
      {{- end }}
    spec:
      serviceAccountName: {{ .Release.Name }}
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        {{- if .Values.app.debug }}
        env:
        - name: DEBUG
          value: "true"
        - name: LOG_LEVEL
          value: {{ .Values.app.logLevel }}
        {{- end }}
        resources:
          {{- toYaml .Values.resources | nindent 10 }}
        {{- if .Values.livenessProbe }}
        livenessProbe:
          {{- toYaml .Values.livenessProbe | nindent 10 }}
        {{- end }}
      {{- if .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml .Values.nodeSelector | nindent 8 }}
      {{- end }}
      {{- if .Values.tolerations }}
      tolerations:
        {{- toYaml .Values.tolerations | nindent 8 }}
      {{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Plantillas auxiliares (_helpers.tpl):</strong></p>
</div>
<div class="paragraph">
<p>El archivo <code>_helpers.tpl</code> contiene macros reutilizables:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">{{/*
Expandir nombre del Chart
*/}}
{{- define "myapp.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 }}
{{- end }}

{{/*
Crear nombre calificado del Chart
*/}}
{{- define "myapp.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Etiquetas comunes
*/}}
{{- define "myapp.labels" -}}
helm.sh/chart: {{ include "myapp.chart" . }}
{{ include "myapp.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "myapp.selectorLabels" -}}
app.kubernetes.io/name: {{ include "myapp.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

# Uso en otros templates:
# metadata:
#   labels:
#     {{- include "myapp.labels" . | nindent 4 }}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_chart_yaml_metadatos_del_chart">10.2.4. Chart.yaml: Metadatos del Chart</h4>
<div class="paragraph">
<p>El archivo <code>Chart.yaml</code> define el Chart y sus propiedades:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v2                    # Versión de API del Chart (v1 es Helm 2, v2 es Helm 3)
name: myapp                       # Nombre único del Chart
version: 1.2.3                    # Versión del Chart (debe seguir semver)
appVersion: "2.0.1"               # Versión de la aplicación que empaqueta

type: application                 # application o library
                                  # library: no genera Pods, solo templates reutilizables

description: "My awesome application"
keywords:
  - myapp
  - web
  - database

# Información sobre el Chart
home: https://github.com/user/myapp
sources:
  - https://github.com/user/myapp

# Licencia del Chart (no de la aplicación)
license: Apache-2.0

# Mantenedores
maintainers:
  - name: John Doe
    email: john@example.com
    url: https://github.com/johndoe

# Icono del Chart (URL a imagen)
icon: https://bitnami.com/assets/stacks/myapp/img/myapp-stack-220x234.png

# Búsqueda en hub.helm.sh
kubeVersion: "&gt;=1.20.0"            # Versión mínima de Kubernetes

# Dependencias del Chart (subchart dependencies)
dependencies:
  - name: postgresql              # Nombre del chart dependiente
    version: "11.0.0"              # Versión exacta
    repository: https://charts.bitnami.com/bitnami
    condition: postgresql.enabled  # Se instala si este valor es true
    tags:
      - database                  # Etiquetas para instalar selectivamente
    alias: mydb                    # Alias para el subchart
    import-values:
      - child                      # Importar valores del subchart

  - name: redis
    version: "17.0.0"
    repository: "oci://registry-1.docker.io/bitnamicharts"
    condition: redis.enabled

# Anotaciones personalizadas
annotations:
  category: Database
  marketplace.bitnami.com/name: "MyApp"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualizar dependencias:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar las dependencias definidas en Chart.yaml
helm dependency update ./myapp

# Listar dependencias
helm dependency list ./myapp

# Salida:
# NAME         VERSION REPOSITORY                              STATUS
# postgresql   11.0.0  https://charts.bitnami.com/bitnami      ok
# redis        17.0.0  oci://registry-1.docker.io/bitnamicharts ok</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dependencias_de_charts_subcharts">10.2.5. Dependencias de Charts (Subcharts)</h4>
<div class="paragraph">
<p>Los Subcharts son Charts reutilizables incluidos dentro de otro Chart. Permiten modularizar aplicaciones complejas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En Chart.yaml del Chart principal (myapp)
dependencies:
  - name: postgresql
    version: "11.x"
    repository: "https://charts.bitnami.com/bitnami"
    condition: postgresql.enabled
    alias: db                      # Permite múltiples instancias
    import-values:
      - child

  - name: redis
    version: "17.x"
    repository: "https://charts.bitnami.com/bitnami"
    condition: redis.enabled

# En values.yaml, configurar los subcharts:
postgresql:
  enabled: true
  auth:
    username: myapp
    password: changeme
    database: myapp_db
  primary:
    persistence:
      enabled: true
      size: 10Gi

redis:
  enabled: true
  auth:
    enabled: true
    password: changeme
  replica:
    replicaCount: 2

# O usar alias
db:                  # Alias del postgresql subchart
  enabled: true
  auth:
    username: myapp
    password: changeme</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Acceder a valores del subchart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Los valores del subchart están disponibles con el nombre de subchart o alias:
env:
  DATABASE_HOST: "{{ .Release.Name }}-postgresql"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "{{ .Values.postgresql.auth.database }}"
  DATABASE_USER: "{{ .Values.postgresql.auth.username }}"

  REDIS_HOST: "{{ .Release.Name }}-redis-master"
  REDIS_PORT: "6379"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estructura de directorios con subcharts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">myapp-chart/
├── Chart.yaml
├── values.yaml
├── templates/
├── charts/                        # Subcharts se descargan aquí
│   ├── postgresql-11.0.0/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   ├── redis-17.0.0/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   └── Chart.lock                 # Lock file (similar a package-lock.json)
└── Chart.lock</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_charts">10.2.6. Best Practices para Charts</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Estructura clara y consistente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantener nombres simples y descriptivos</p>
</li>
<li>
<p>Usar convenciones de nombres consistentes</p>
</li>
<li>
<p>Documentar archivos complejos con comentarios</p>
</li>
<li>
<p>Incluir un README.md completo con ejemplos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Valores bien organizados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Agrupar valores lógicamente (app, database, cache, etc.)</p>
</li>
<li>
<p>Proporcionar valores por defecto seguros</p>
</li>
<li>
<p>Validar rangos razonables (min replicas, max resources)</p>
</li>
<li>
<p>Documentar cada valor en values.yaml</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Templates parametrizados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evitar valores hardcodeados en templates</p>
</li>
<li>
<p>Usar helpers para evitar repetición</p>
</li>
<li>
<p>Mantener templates legibles y simples</p>
</li>
<li>
<p>Comentar lógica compleja (condicionales, loops)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad en Charts</strong></p>
<div class="ulist">
<ul>
<li>
<p>No incluir secretos en values.yaml por defecto</p>
</li>
<li>
<p>Usar referencias a Secrets externos</p>
</li>
<li>
<p>Restringir permisos en RBAC definitions</p>
</li>
<li>
<p>Escanear imágenes OCI en valores por defecto</p>
</li>
<li>
<p>Usar SecurityContext restrictivos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Control de versiones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar Semantic Versioning (MAJOR.MINOR.PATCH)</p>
</li>
<li>
<p>Cambiar Chart.version con cada release</p>
</li>
<li>
<p>Mantener CHANGELOG.md actualizado</p>
</li>
<li>
<p>Usar tags en repositorio de Git</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Testing y validación</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar helm lint regularmente</p>
</li>
<li>
<p>Probar con helm template antes de instalar</p>
</li>
<li>
<p>Crear casos de test con valores diferentes</p>
</li>
<li>
<p>Validar con kubeval o kubeconform</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Dependencias explícitas</strong></p>
<div class="ulist">
<ul>
<li>
<p>Especificar versiones exactas o rangos apropiados</p>
</li>
<li>
<p>Usar conditions para habilitar/deshabilitar opcionalmente</p>
</li>
<li>
<p>Documentar por qué se necesita cada dependencia</p>
</li>
<li>
<p>Mantener dependencies actualizadas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación completa</strong></p>
<div class="ulist">
<ul>
<li>
<p>Incluir NOTES.txt con instrucciones post-instalación</p>
</li>
<li>
<p>Documentar valores complejos en values.yaml</p>
</li>
<li>
<p>Incluir ejemplos de diferentes scenarios</p>
</li>
<li>
<p>Mantener README sincronizado con cambios</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_trabajando_con_helm">10.3. Trabajando con Helm</h3>
<div class="paragraph">
<p>Trabajar con Helm implica interactuar con Charts desde repositorios remotos, instalarlos en clusters de Kubernetes, actualizarlos según cambios de versión o configuración, y revertir cambios cuando sea necesario. Esta sección cubre los flujos de trabajo más comunes y cómo gestionar efficientemente releases en tus clusters.</p>
</div>
<div class="sect3">
<h4 id="_gestión_de_repositorios_de_helm">10.3.1. Gestión de Repositorios de Helm</h4>
<div class="paragraph">
<p>Los repositorios son colecciones remotas de Charts. Helm necesita conocer dónde obtener los Charts antes de instalarlos.</p>
</div>
<div class="paragraph">
<p><strong>Agregar repositorios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio oficial (Charts de la comunidad)
helm repo add stable https://charts.helm.sh/stable

# Agregar Bitnami (Charts de alta calidad, bien mantenidos)
helm repo add bitnami https://charts.bitnami.com/bitnami

# Agregar repositorio personal o corporativo
helm repo add mycompany https://charts.mycompany.com

# Agregar repositorio con autenticación (si es privado)
helm repo add mycompany https://charts.mycompany.com \
  --username myuser \
  --password mypassword

# Agregar repositorio OCI (Docker registry-like)
helm repo add myrepo oci://registry.example.com/helm-charts

# Listar repositorios agregados
helm repo list

# Salida:
# NAME         URL
# stable       https://charts.helm.sh/stable
# bitnami      https://charts.bitnami.com/bitnami
# mycompany    https://charts.mycompany.com</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualizar índices de repositorios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Actualizar el índice local de todos los repositorios
helm repo update

# Salida:
# Hang tight while we grab the latest from your chart repositories...
# ...Successfully got an update from the "stable" chart repository
# ...Successfully got an update from the "bitnami" chart repository
# Update Complete. ⎈ Happy Helming!

# Actualizar repositorio específico
helm repo update stable

# Ver cuándo fue la última actualización
helm repo list</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Remover y gestionar repositorios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Remover un repositorio
helm repo remove stable

# Listar después de remover
helm repo list

# Buscar en todos los repositorios (si el índice está cacheado)
helm search repo nginx

# Salida:
# NAME                            CHART VERSION   APP VERSION   DESCRIPTION
# bitnami/nginx                   15.1.1          1.25.2        NGINX Open Source is a web server...
# stable/nginx-ingress            4.6.0           1.4.0         An ingress controller that uses...</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gestión segura de repositorios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar integridad de Chart descargar archivo de índice
helm repo update --strict

# Listar repositorios con detalles
helm repo list -o json | jq .

# Ejemplo de salida JSON:
# [
#   {
#     "name": "bitnami",
#     "url": "https://charts.bitnami.com/bitnami",
#     "cache": "/root/.cache/helm/repository"
#   }
# ]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_búsqueda_de_charts">10.3.2. Búsqueda de Charts</h4>
<div class="paragraph">
<p>Antes de instalar, necesitas encontrar el Chart adecuado. Helm proporciona varias formas de buscar.</p>
</div>
<div class="paragraph">
<p><strong>Búsqueda en repositorios locales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Buscar Charts por nombre (búsqueda en índice cacheado)
helm search repo nginx

# Salida:
# NAME                            CHART VERSION   APP VERSION   DESCRIPTION
# bitnami/nginx                   15.1.1          1.25.2        NGINX Open Source is a web server...
# bitnami/nginx-ingress-controller 9.8.1          1.8.1         NGINX Ingress Controller Helm Chart

# Buscar con patrón (expresión regular)
helm search repo "^bitnami/.*-ingress"

# Buscar en Hub de Helm (requiere conexión a internet)
helm search hub nginx

# Salida:
# URL                                              CHART VERSION   DESCRIPTION
# https://hub.helm.sh/charts/bitnami/nginx         15.1.1          NGINX Open Source is a web server...
# https://hub.helm.sh/charts/stable/nginx-ingress  4.6.0           An ingress controller that uses...

# Listar todas las versiones de un Chart
helm search repo bitnami/postgresql --versions

# Salida:
# NAME                 CHART VERSION   APP VERSION   DESCRIPTION
# bitnami/postgresql   12.1.0          15.2          PostgreSQL is an object-relational database...
# bitnami/postgresql   12.0.0          15.2          PostgreSQL is an object-relational database...
# bitnami/postgresql   11.9.13         15.2          PostgreSQL is an object-relational database...</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ver detalles de un Chart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver metadatos del Chart (Chart.yaml)
helm show chart bitnami/postgresql

# Ver archivo README del Chart
helm show readme bitnami/postgresql

# Ver valores por defecto
helm show values bitnami/postgresql

# Ver todo junto
helm show all bitnami/postgresql

# Ver específicamente valores con explicaciones
helm show values bitnami/postgresql | head -50
# Salida (primeras líneas):
# auth:
#   existingSecret: ""
#   postgresPassword: ""
#   username: ""
#   password: ""
#   ...

# Inspecionar una versión específica
helm show chart bitnami/postgresql --version 11.9.13</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_instalación_de_charts">10.3.3. Instalación de Charts</h4>
<div class="paragraph">
<p>La instalación crea una "Release" de Helm en el cluster. Una Release es una instancia de un Chart con valores específicos.</p>
</div>
<div class="paragraph">
<p><strong>Instalación básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalación simplest (con valores por defecto)
helm install my-release bitnami/nginx

# Salida:
# NAME: my-release
# LAST DEPLOYED: Mon Jan 15 14:23:45 2024
# NAMESPACE: default
# STATUS: deployed
# REVISION: 1
# NOTES:
# ...

# Verificar que se instaló correctamente
helm list

# Salida:
# NAME         NAMESPACE STATUS    CHART        APP VERSION LAST DEPLOYED
# my-release   default   deployed  nginx-15.1.1 1.25.2      Mon Jan 15 14:23:45 2024

# Ver status detallado
helm status my-release

# Ver recursos creados
kubectl get all -l app.kubernetes.io/instance=my-release</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación con valores personalizados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Opción 1: Usar --set para cambiar valores individuales
helm install my-nginx bitnami/nginx \
  --set replicaCount=3 \
  --set image.tag="1.25.0" \
  --set service.type=LoadBalancer

# Opción 2: Usar --set-string para strings complejos (evita conversiones)
helm install my-app myrepo/myapp \
  --set-string config.datasource="jdbc:postgresql://localhost:5432/mydb"

# Opción 3: Usar --set-json para valores JSON complejos
helm install my-app myrepo/myapp \
  --set-json resources='{"limits":{"cpu":"1","memory":"1Gi"}}'

# Opción 4: Usar archivo values externo
helm install my-nginx bitnami/nginx -f values.yaml

# Opción 5: Usar múltiples archivos (mergean en orden)
helm install my-app myrepo/myapp \
  -f values-base.yaml \
  -f values-prod.yaml \
  --set app.environment=production

# Ver valores resueltos después de instalación
helm get values my-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación en namespaces:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar en namespace específico (lo crea si no existe)
helm install my-app myrepo/myapp -n production --create-namespace

# Instalar con privilegios de cluster-admin (si lo necesita)
helm install my-app myrepo/myapp --service-account admin

# Ver todas las releases en un namespace
helm list -n production

# Ver todas las releases en todos los namespaces
helm list -A

# Salida:
# NAMESPACE    NAME    STATUS    CHART        APP VERSION
# default      nginx   deployed  nginx-15.1.1 1.25.2
# production   myapp   deployed  myapp-1.0.0  1.0.0
# staging      myapp   deployed  myapp-1.0.0  1.0.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación con opciones avanzadas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Dryrun: ver qué se instalaría sin realmente instalar
helm install my-app myrepo/myapp --dry-run --debug

# Salida: manifiestos YAML compilados

# Instalar pero no esperar a que esté listo
helm install my-app myrepo/myapp --no-hooks

# Instalar sin ejecutar tests (si Chart los define)
helm install my-app myrepo/myapp --no-hooks

# Instalar con timeout personalizado
helm install my-app myrepo/myapp --timeout 10m0s

# Instalar sin actualizar dependencias
helm install my-app myrepo/myapp --skip-refresh

# Instalar desde Chart local (desarrollo)
helm install my-app ./mychart --debug

# Ver manifiestos que se instalarían
helm template my-app myrepo/myapp --values values.yaml

# Instalación atómica: rollback automático si algo falla
helm install my-app myrepo/myapp --atomic</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_actualización_y_rollback_de_releases">10.3.4. Actualización y Rollback de Releases</h4>
<div class="paragraph">
<p>Cuando hay nuevas versiones o cambios de configuración, puedes actualizar releases existentes:</p>
</div>
<div class="paragraph">
<p><strong>Actualización (upgrade):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Upgrade a nueva versión del Chart
helm upgrade my-nginx bitnami/nginx

# Upgrade con nuevas versión específica
helm upgrade my-nginx bitnami/nginx --version 15.2.0

# Upgrade y cambiar valores
helm upgrade my-nginx bitnami/nginx \
  --set replicaCount=5 \
  --set image.tag="1.25.1"

# Upgrade desde archivo values
helm upgrade my-nginx bitnami/nginx -f values-prod.yaml

# Upgrade atómico (rollback automático si falla)
helm upgrade my-nginx bitnami/nginx --atomic

# Upgrade con limpieza de hooks viejos
helm upgrade my-nginx bitnami/nginx --cleanup-on-fail

# Ver cambios que haría upgrade (simulación)
helm upgrade my-nginx bitnami/nginx --dry-run --debug

# Upgrade sin recrear Pods
helm upgrade my-nginx bitnami/nginx \
  --set replicaCount=3 \
  --force</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Historial y Rollback:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver historial de releases
helm history my-nginx

# Salida:
# REVISION STATUS      CHART       APP VERSION DESCRIPTION
# 1        superseded  nginx-15.1.1 1.25.2      Install complete
# 2        superseded  nginx-15.1.1 1.25.2      Upgrade complete
# 3        deployed    nginx-15.2.0 1.25.3      Upgrade complete

# Rollback a versión anterior
helm rollback my-nginx 2

# Salida:
# Rollback was a success! Happy Helming!

# Ver estado después de rollback
helm status my-nginx

# Rollback a la versión anterior inmediata
helm rollback my-nginx

# Rollback con limpieza de datos nuevos
helm rollback my-nginx 1 --cleanup-on-fail</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Downgrade (cambiar a versión anterior del Chart):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Downgrade a versión anterior específica del Chart
helm upgrade my-nginx bitnami/nginx --version 15.1.1

# Ver Chart version disponibles
helm search repo bitnami/nginx --versions | head -20

# Downgrade y cambiar valores
helm upgrade my-nginx bitnami/nginx --version 15.1.1 \
  --set replicaCount=2</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gestión_de_releases">10.3.5. Gestión de Releases</h4>
<div class="paragraph">
<p><strong>Ver información de releases:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Listar todas las releases
helm list

# Listar releases en namespace específico
helm list -n production

# Listar todas las releases (todos los namespaces)
helm list -A

# Listar con detalles adicionales
helm list --output json

# Ver valores de una release
helm get values my-nginx

# Ver todos los valores (incluyendo defaults del Chart)
helm get values my-nginx --all

# Ver el Chart.yaml de una release
helm get chart my-nginx

# Ver manifiestos YAML desplegados
helm get manifest my-nginx

# Ver notas (NOTES.txt) de una release
helm get notes my-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Desinstalación de releases:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Desinstalar release
helm uninstall my-nginx

# Salida:
# release "my-nginx" uninstalled

# Desinstalar manteniendo el histórico (permite reinstalar)
helm uninstall my-nginx --keep-history

# Ver histórico después de desinstalar
helm history my-nginx

# Reinstalar desde histórico
helm upgrade --install my-nginx bitnami/nginx

# Desinstalar con timeout personalizado
helm uninstall my-nginx --timeout 5m0s

# Desinstalar todo en un namespace
helm uninstall --all -n production</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_estrategias_de_instalación_avanzadas">10.3.6. Estrategias de Instalación Avanzadas</h4>
<div class="paragraph">
<p><strong>Instalación o actualización (Helm Install or Upgrade):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Comando que instala si no existe, actualiza si existe
# (Muy útil en CI/CD pipelines)
helm upgrade --install my-app myrepo/myapp \
  -f values.yaml \
  -n production \
  --create-namespace

# Con opciones adicionales
helm upgrade --install my-app myrepo/myapp \
  --values values-prod.yaml \
  --set image.tag="v2.0.0" \
  --namespace production \
  --create-namespace \
  --atomic \
  --timeout 10m0s</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalaciones paralelas de mismo Chart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar múltiples releases del mismo Chart
helm install nginx-prod bitnami/nginx \
  --namespace production \
  --set service.type=LoadBalancer \
  --set replicaCount=5

helm install nginx-staging bitnami/nginx \
  --namespace staging \
  --set service.type=ClusterIP \
  --set replicaCount=2

helm install nginx-dev bitnami/nginx \
  --namespace development \
  --set service.type=ClusterIP \
  --set replicaCount=1

# Ver todas
helm list -A

# Todos comparten el mismo Chart pero con configuraciones diferentes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualización en cascada de múltiples releases:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">#!/bin/bash
# Script para actualizar múltiples releases en secuencia

RELEASES=("myapp-dev" "myapp-staging" "myapp-prod")
CHART="myrepo/myapp"
VERSION="2.0.0"

for release in "${RELEASES[@]}"; do
  echo "Actualizando $release..."
  helm upgrade "$release" "$CHART" --version "$VERSION"

  # Esperar a que se estabilice
  kubectl rollout status deployment/"$release" -n "${release%-*}"

  echo "$release actualizado correctamente"
done</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_trabajar_con_helm">10.3.7. Best Practices para Trabajar con Helm</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Siempre usar archivos values en Git</strong></p>
<div class="ulist">
<ul>
<li>
<p>Versionear values-prod.yaml, values-staging.yaml en Git</p>
</li>
<li>
<p>Facilita auditoría y reversión de cambios</p>
</li>
<li>
<p>Reproducibilidad: el mismo archivo = resultados idénticos</p>
</li>
<li>
<p>Comentar valores complejos en YAML</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Validación antes de aplicar cambios</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar helm lint para validar Chart locales</p>
</li>
<li>
<p>Usar helm template para ver manifiestos finales</p>
</li>
<li>
<p>Usar helm diff para ver cambios antes de upgrade</p>
</li>
<li>
<p>Usar --dry-run antes de instalar en producción</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Usar helm upgrade --install en CI/CD</strong></p>
<div class="ulist">
<ul>
<li>
<p>Idempotente: puede ejecutarse múltiples veces</p>
</li>
<li>
<p>Funciona en instalación inicial y upgrades</p>
</li>
<li>
<p>Simplifica pipelines de deployment</p>
</li>
<li>
<p>Usar --atomic para rollback automático en errores</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Gestión de versiones de Charts</strong></p>
<div class="ulist">
<ul>
<li>
<p>Especificar versión exacta en producción</p>
</li>
<li>
<p>helm upgrade --version X.Y.Z myapp myrepo/myapp</p>
</li>
<li>
<p>No usar "latest" en producción</p>
</li>
<li>
<p>Mantener versionamiento semántico</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Monitoreo de releases</strong></p>
<div class="ulist">
<ul>
<li>
<p>Revisar regularmente: helm list -A</p>
</li>
<li>
<p>Documentar qué versión está en qué ambiente</p>
</li>
<li>
<p>Monitorear helm get values para cambios</p>
</li>
<li>
<p>Auditar con: helm history release_name</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Rollback seguro</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantener backup de releases importante: helm get manifest</p>
</li>
<li>
<p>Entender qué hace cada revision antes de rollback</p>
</li>
<li>
<p>Usar --atomic en upgrades para evitar estados inconsistentes</p>
</li>
<li>
<p>Probar en staging antes de producción</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Namespace y RBAC</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar --create-namespace para namespaces nuevos</p>
</li>
<li>
<p>Usar RBAC para restringir quién puede instalar/actualizar</p>
</li>
<li>
<p>Usar service accounts con permisos limitados</p>
</li>
<li>
<p>Implementar policies: solo ciertas personas en producción</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación y mantenimiento</strong></p>
<div class="ulist">
<ul>
<li>
<p>Mantener README con instrucciones de instalación</p>
</li>
<li>
<p>Documentar cambios de configuración por versión</p>
</li>
<li>
<p>Explicar por qué ciertos valores están en producción</p>
</li>
<li>
<p>Mantener rotación de versiones viejas</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_creación_de_charts">10.4. Creación de Charts</h3>
<div class="paragraph">
<p>Crear Charts es la forma más poderosa de usar Helm, permitiendo empaquetar aplicaciones complejas con toda su configuración, valores personalizables y lógica de despliegue. Los Charts bien diseñados hacen posible desplegar la misma aplicación en múltiples ambientes con mínimas variaciones.</p>
</div>
<div class="sect3">
<h4 id="_creación_de_un_chart_desde_cero">10.4.1. Creación de un Chart desde Cero</h4>
<div class="paragraph">
<p>La forma más fácil de comenzar es usando el comando <code>helm create</code>, que genera una estructura de Chart estándar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear Chart básico
helm create myapp

# Esto genera la siguiente estructura:
# myapp/
# ├── Chart.yaml              # Metadatos del Chart
# ├── values.yaml             # Valores por defecto
# ├── charts/                 # Dependencias (subdirectorio vacío)
# ├── templates/              # Plantillas
# │   ├── deployment.yaml
# │   ├── service.yaml
# │   ├── ingress.yaml
# │   ├── NOTES.txt
# │   ├── _helpers.tpl
# │   └── tests/
# │       └── test-connection.yaml
# └── .helmignore

# Examinar la estructura
tree myapp

# Entrar al directorio
cd myapp

# Validar el Chart
helm lint .

# Ver qué se generaría
helm template myapp .</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configurar Chart.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v2
name: myapp                    # Nombre único del Chart
description: "Mi aplicación"   # Descripción
type: application              # application o library

version: 0.1.0                 # Versión del Chart (semver)
appVersion: "1.0"              # Versión de la aplicación

keywords:
  - myapp
  - deployment
  - production

home: https://github.com/user/myapp
sources:
  - https://github.com/user/myapp

maintainers:
  - name: John Doe
    email: john@example.com

kubeVersion: "&gt;=1.20.0"         # Versión mínima de Kubernetes

# Dependencias (si las hay)
dependencies: []</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estructurar values.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Información global
global:
  environment: production
  domain: example.com

# Configuración de réplicas
replicaCount: 3

# Configuración de imagen
image:
  repository: myapp
  pullPolicy: IfNotPresent
  tag: "1.0.0"

# Configuración de servicio
service:
  type: ClusterIP
  port: 80
  targetPort: 8080
  annotations: {}

# Recursos
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# Escalado automático
autoscaling:
  enabled: false
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80

# Sondeos de salud
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5

# Persistencia
persistence:
  enabled: false
  storageClass: ""
  size: 1Gi
  mountPath: /data

# Afinidad y tolerancias
nodeSelector: {}
tolerations: []
affinity: {}

# Anotaciones del pod
podAnnotations: {}

# Labels adicionales
podLabels: {}

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_template_functions_y_pipelines">10.4.2. Template Functions y Pipelines</h4>
<div class="paragraph">
<p>Las funciones transforman y manipulan valores. Los pipelines encadenan funciones.</p>
</div>
<div class="paragraph">
<p><strong>Funciones de string:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Convertir a minúsculas
name: {{ .Values.app.name | lower }}

# Convertir a mayúsculas
env: {{ .Values.environment | upper }}

# Agregar comillas
version: {{ .Values.appVersion | quote }}

# Truncar a N caracteres
short-name: {{ .Values.app.name | trunc 10 }}

# Agregar prefijo/sufijo
instance: {{ .Release.Name | printf "instance-%s" }}

# Reemplazar strings
modified: {{ .Values.text | replace "old" "new" }}

# Dividir y join
path: {{ .Values.paths | join ":" }}

# Cadena de pipes (encadenar funciones)
label: {{ .Values.label | lower | upper | quote }}

# Conversión de tipos
count: {{ .Values.replicas | int }}
ratio: {{ .Values.ratio | float64 }}
boolean: {{ .Values.debug | default false | not }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Funciones de listas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Primer elemento
first: {{ first .Values.items }}

# Último elemento
last: {{ last .Values.items }}

# Iniciales (todos menos el último)
initial: {{ initial .Values.items }}

# Tail (todos menos el primero)
rest: {{ rest .Values.items }}

# Contar elementos
count: {{ .Values.items | len }}

# Invertir orden
reversed: {{ .Values.items | reverse }}

# Uniq (remover duplicados)
unique: {{ .Values.items | uniq }}

# Ordenar
sorted: {{ .Values.items | sortAlpha }}

# Índice específico
second: {{ index .Values.items 1 }}

# Buscar en lista
contains: {{ has "value" .Values.items }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Funciones de diccionarios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Obtener valor con default
value: {{ .Values.config.key | default "default-value" }}

# Empty check
{{- if .Values.config.optional }}
enabled: true
{{- end }}

# Merge dos maps
merged: {{ merge .Values.defaults .Values.custom }}

# Claves del map
keys: {{ keys .Values.config }}

# Valores del map
values: {{ values .Values.config }}

# Has key
{{- if hasKey .Values.config "special" }}
found: true
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Funciones de conversión:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># YAML a string
config: |
  {{ toYaml .Values.configMap | nindent 2 }}

# JSON
json: {{ toPrettyJson .Values.config }}

# A mapa/diccionario
parsed: {{ fromJson .Values.jsonString }}

# Codificación base64
encoded: {{ b64enc "secret-value" }}
decoded: {{ b64dec "c2VjcmV0LXZhbHVl" }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Funciones matemáticas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Suma/Resta/Multiplicación/División
result: {{ add 5 3 }}          # 8
result: {{ sub 10 4 }}         # 6
result: {{ mul 3 4 }}          # 12
result: {{ div 20 4 }}         # 5

# Módulo
remainder: {{ mod 10 3 }}      # 1

# Min/Max
minimum: {{ min 5 2 8 }}       # 2
maximum: {{ max 5 2 8 }}       # 8

# Redondear
rounded: {{ 3.14159 | round 2 }}   # 3.14
ceil: {{ 3.2 | ceil }}             # 4
floor: {{ 3.8 | floor }}           # 3</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Funciones de generación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Generar UUID
uuid: {{ uuidv4 }}

# Generar strings aleatorios
random: {{ randAlphaNum 10 }}
random-alpha: {{ randAlpha 8 }}
random-numeric: {{ randNumeric 5 }}

# Generar con seed (reproducible)
seeded: {{ randAlphaNumSeed (now | unixEpoch) 10 }}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_control_de_flujo">10.4.3. Control de Flujo</h4>
<div class="paragraph">
<p>Las sentencias de control permiten lógica condicional y loops en templates.</p>
</div>
<div class="paragraph">
<p><strong>Condicionales if/else:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># If simple
{{- if .Values.autoscaling.enabled }}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ .Release.Name }}
spec:
  minReplicas: {{ .Values.autoscaling.minReplicas }}
{{- end }}

# If/else
{{- if .Values.database.enabled }}
DATABASE_HOST: "{{ .Values.database.host }}"
{{- else }}
DATABASE_HOST: "localhost"
{{- end }}

# If/else if/else
{{- if eq .Values.environment "production" }}
REPLICAS: 5
{{- else if eq .Values.environment "staging" }}
REPLICAS: 3
{{- else }}
REPLICAS: 1
{{- end }}

# Operadores de comparación
{{- if eq .Values.type "web" }}...{{- end }}      # igual
{{- if ne .Values.type "web" }}...{{- end }}      # no igual
{{- if lt .Values.count 5 }}...{{- end }}         # menor que
{{- if le .Values.count 5 }}...{{- end }}         # menor o igual
{{- if gt .Values.count 5 }}...{{- end }}         # mayor que
{{- if ge .Values.count 5 }}...{{- end }}         # mayor o igual

# Operadores lógicos
{{- if and .Values.tls.enabled .Values.tls.cert }}...{{- end }}      # AND
{{- if or .Values.debug .Values.verbose }}...{{- end }}              # OR
{{- if not .Values.disabled }}...{{- end }}                          # NOT

# With (cambiar scope)
{{- with .Values.database }}
host: {{ .host }}
port: {{ .port }}
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Loops y rangos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Iterar sobre array
ports:
{{- range .Values.ports }}
  - name: {{ .name }}
    port: {{ .port }}
{{- end }}

# Iterar con índice
containers:
{{- range $index, $container := .Values.containers }}
  - name: {{ $container.name }}
    index: {{ $index }}
{{- end }}

# Iterar sobre map/dictionary
env:
{{- range $key, $value := .Values.environment }}
  - name: {{ $key }}
    value: {{ $value | quote }}
{{- end }}

# Iterar con counter
items:
{{- range $i := until 5 }}
  - item: {{ $i }}
{{- end }}

# Iterar sobre range numérico
numbers:
{{- range .Values.numbers }}
  - number: {{ . }}
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Indentación correcta con nindent:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># nindent: Indenta líneas nuevas (importante para YAML)
apiVersion: v1
kind: ConfigMap
data:
  config.yaml: |
    {{- .Values.config | toYaml | nindent 4 }}

# Esto produce:
# apiVersion: v1
# kind: ConfigMap
# data:
#   config.yaml: |
#     key: value
#     nested:
#       key: value

# Sin nindent (INCORRECTO):
# apiVersion: v1
# kind: ConfigMap
# data:
#   config.yaml: |
#   key: value      # &lt;-- Indentación incorrecta</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_named_templates_y_helpers">10.4.4. Named Templates y Helpers</h4>
<div class="paragraph">
<p>Las plantillas nombradas (defined templates) permiten reutilizar código entre templates:</p>
</div>
<div class="paragraph">
<p><strong>Definir y usar templates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En _helpers.tpl (archivo especial para helpers)

{{- define "myapp.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 -}}
{{- end -}}

{{- define "myapp.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 -}}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride -}}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 -}}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 -}}
{{- end -}}
{{- end -}}
{{- end -}}

{{- define "myapp.labels" -}}
helm.sh/chart: {{ include "myapp.chart" . }}
{{ include "myapp.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{- define "myapp.selectorLabels" -}}
app.kubernetes.io/name: {{ include "myapp.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

# Usar los helpers en otros templates:
# metadata:
#   labels:
#     {{- include "myapp.labels" . | nindent 4 }}

# selector:
#   matchLabels:
#     {{- include "myapp.selectorLabels" . | nindent 4 }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Variables en templates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Declarar variables con :=
{{- $name := include "myapp.fullname" . }}
{{- $labels := include "myapp.labels" . }}

# Usar variables
metadata:
  name: {{ $name }}
  labels:
    {{- $labels | nindent 4 }}

# Variables en loops
labels:
{{- range $key, $value := .Values.labels }}
{{- $fullKey := printf "%s-%s" $name $key }}
  {{ $fullKey }}: {{ $value }}
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Scope en templates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># El . (dot) representa el contexto actual
# $root captura el contexto raíz
{{- $root := . }}

{{- range .Values.containers }}
# Aquí, . es el container, no el root
name: {{ .name }}

# Usar $root para acceder valores del root
labels: {{ include "myapp.labels" $root | nindent 2 }}
{{- end }}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_testing_de_charts">10.4.5. Testing de Charts</h4>
<div class="paragraph">
<p>Validar y probar Charts antes de usarlos en producción:</p>
</div>
<div class="paragraph">
<p><strong>Validación con helm lint:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Validación básica
helm lint ./myapp

# Salida:
# ==&gt; Linting ./myapp
# [INFO] Chart.yaml: icon is recommended
# [WARNING] templates/: object name does not conform to DNS naming rules: "my_app"
# 1 chart(s) linted, 0 error(s), 1 warning(s)

# Validación estricta (falla en warnings)
helm lint ./myapp --strict

# Validación con valores personalizados
helm lint ./myapp -f values-prod.yaml

# Validación de todas las versiones
helm lint ./myapp --versions</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificar templates con helm template:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver manifiestos generados
helm template my-release ./myapp

# Salida: manifiestos YAML compilados

# Con valores específicos
helm template my-release ./myapp -f values-prod.yaml

# Con valores desde --set
helm template my-release ./myapp \
  --set replicaCount=5 \
  --set image.tag="1.5.0"

# Guardar manifiestos en archivo
helm template my-release ./myapp &gt; manifests.yaml

# Validar manifiestos con kubeval
helm template my-release ./myapp | kubeval

# Salida:
# PASS - pods-deployment.yaml contains a valid Deployment
# PASS - pods-service.yaml contains a valid Service</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Testing automático en Charts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Charts pueden incluir tests en templates/tests/
# Crear test de conectividad:</code></pre>
</div>
</div>
<div class="paragraph">
<p>En <code>templates/tests/test-connection.yaml</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "myapp.fullname" . }}-test-connection"
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['{{ include "myapp.fullname" . }}:{{ .Values.service.port }}']
  restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejecutar tests:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Chart y ejecutar tests
helm install my-app ./myapp
helm test my-app

# Salida:
# Pod my-app-test-connection pending
# Pod my-app-test-connection succeeded
# NAME: my-app
# LAST DEPLOYED: ...
# NAMESPACE: default
# STATUS: deployed
# ...
# TEST SUITE:     my-app-test-connection
# Last Started:   ...
# Last Completed: ...
# Phase:          Succeeded

# Ver logs del test
kubectl logs my-app-test-connection</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Testing frameworks:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Chart Testing (ct) - Framework de testing para Charts
# Instalar: https://github.com/helm/chart-testing

ct list-changed

# Ejecutar linting en Charts modificados
ct lint --chart-dirs . --validate-maintainers=false

# Instalar y probar Charts en cluster real
ct install --chart-dirs . --chart-repos bitnami=https://charts.bitnami.com/bitnami

# Configuración en .ct/lintconf.yaml:
# general:
#   chart-testing-image: quay.io/helmpack/chart-testing:v3.10.0
# lint:
#   strict: true
#   chart-repos:
#     - bitnami=https://charts.bitnami.com/bitnami</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Testing unitario con Helm:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usar helm unittest (plugin)
helm plugin install https://github.com/helm-unittest/helm-unittest.git

# En tests/deployment_test.yaml:</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">suite: test deployment
templates:
  - deployment.yaml
tests:
  - it: should have correct replicas
    set:
      replicaCount: 3
    asserts:
      - equal:
          path: spec.replicas
          value: 3

  - it: should set resource limits
    set:
      resources:
        limits:
          cpu: "1"
    asserts:
      - equal:
          path: spec.template.spec.containers[0].resources.limits.cpu
          value: "1"

  - it: should not have hpa when disabled
    set:
      autoscaling.enabled: false
    template: hpa.yaml
    asserts:
      - hasDocuments:
          count: 0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejecutar tests unitarios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">helm unittest ./myapp

# Salida:
# === RUN   suite: test deployment
# === RUN   suite: test deployment  it should have correct replicas
# === RUN   suite: test deployment  it should set resource limits
# === RUN   suite: test deployment  it should not have hpa when disabled
# === RUN PASS suite: test deployment
# --- PASS: myapp/templates/deployment.yaml (0.15s)
# --- PASS: myapp/templates/hpa.yaml (0.10s)
# --- PASS: myapp/templates/service.yaml (0.08s)
# PASS - 12 tests in 0.35s</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_crear_charts">10.4.6. Best Practices para Crear Charts</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Estructura consistente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Seguir estructura estándar (Chart.yaml, values.yaml, templates/)</p>
</li>
<li>
<p>Usar helm create para empezar</p>
</li>
<li>
<p>Mantener helpers en _helpers.tpl</p>
</li>
<li>
<p>Documentar helpers complejos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Values bien diseñados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Organizar lógicamente (app, database, cache, etc.)</p>
</li>
<li>
<p>Proporcionar defaults seguros</p>
</li>
<li>
<p>Documentar cada valor</p>
</li>
<li>
<p>Validar ranges (min replicas, max resources)</p>
</li>
<li>
<p>Ejemplos en comentarios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Templates limpios</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar funciones reutilizables</p>
</li>
<li>
<p>Evitar hardcoding de valores</p>
</li>
<li>
<p>Mantener indentación consistente</p>
</li>
<li>
<p>Usar nindent para YAML correcto</p>
</li>
<li>
<p>Comentar lógica compleja</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad</strong></p>
<div class="ulist">
<ul>
<li>
<p>No incluir secrets en values.yaml</p>
</li>
<li>
<p>Usar referencias externas a Secrets</p>
</li>
<li>
<p>Implementar RBAC restrictivo</p>
</li>
<li>
<p>SecurityContext en Pods</p>
</li>
<li>
<p>Validar inputs de usuarios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Testing exhaustivo</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar helm lint regularmente</p>
</li>
<li>
<p>helm template antes de instalar</p>
</li>
<li>
<p>Tests en templates/tests/</p>
</li>
<li>
<p>Chart Testing (ct) framework</p>
</li>
<li>
<p>Unit tests con helm unittest</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Control de versiones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Semantic Versioning (MAJOR.MINOR.PATCH)</p>
</li>
<li>
<p>Cambiar version en cada release</p>
</li>
<li>
<p>CHANGELOG.md actualizado</p>
</li>
<li>
<p>Git tags con versión</p>
</li>
<li>
<p>Historial claro de cambios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Compatibilidad y dependencias</strong></p>
<div class="ulist">
<ul>
<li>
<p>Especificar kubeVersion mínimo</p>
</li>
<li>
<p>Versiones de dependencias explícitas</p>
</li>
<li>
<p>Documentar requisitos previos</p>
</li>
<li>
<p>Probar en múltiples versiones</p>
</li>
<li>
<p>Mantener Chart compatible</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación</strong></p>
<div class="ulist">
<ul>
<li>
<p>README.md completo</p>
</li>
<li>
<p>NOTES.txt con post-instalación</p>
</li>
<li>
<p>Ejemplos en values.yaml</p>
</li>
<li>
<p>Comentarios en templates complejos</p>
</li>
<li>
<p>Documentar breaking changes</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_helm_avanzado">10.5. Helm Avanzado</h3>
<div class="paragraph">
<p>Los features avanzados de Helm permiten implementar patrones sofisticados de despliegue y gestión de aplicaciones. Esto incluye hooks para ejecuciones en momentos específicos del ciclo de vida, gestión de dependencias complejas, y distribución de Charts a través de repositorios.</p>
</div>
<div class="sect3">
<h4 id="_hooks_ganchos_de_ciclo_de_vida">10.5.1. Hooks (Ganchos de Ciclo de Vida)</h4>
<div class="paragraph">
<p>Los hooks permiten ejecutar acciones en momentos específicos durante la instalación, actualización o eliminación de un release.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de hooks disponibles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">pre-install      Ejecuta ANTES de instalar un Chart
post-install     Ejecuta DESPUÉS de instalar un Chart
pre-upgrade      Ejecuta ANTES de actualizar un release
post-upgrade     Ejecuta DESPUÉS de actualizar un release
pre-delete       Ejecuta ANTES de eliminar un release
post-delete      Ejecuta DESPUÉS de eliminar un release
pre-rollback     Ejecuta ANTES de hacer rollback
post-rollback    Ejecuta DESPUÉS de hacer rollback
test             Ejecuta cuando se ejecuta "helm test"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diagrama del ciclo de vida con hooks:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">helm install myapp
         ↓
  pre-install Hook
         ↓
  Crear recursos (Deployment, Service, etc.)
         ↓
  post-install Hook
         ↓
  Release "deployed"

helm upgrade myapp
         ↓
  pre-upgrade Hook
         ↓
  Actualizar recursos
         ↓
  post-upgrade Hook
         ↓
  Release "deployed"

helm uninstall myapp
         ↓
  pre-delete Hook
         ↓
  Eliminar recursos
         ↓
  post-delete Hook
         ↓
  Release "uninstalled"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear un hook post-install (ej: inicializar base de datos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "myapp.fullname" . }}-db-init
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": post-install
    "helm.sh/hook-weight": "1"          # Peso (orden de ejecución)
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  backoffLimit: 3
  template:
    metadata:
      labels:
        {{- include "myapp.labels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "myapp.fullname" . }}
      containers:
      - name: db-init
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        command: ["/bin/sh"]
        args:
          - -c
          - |
            echo "Inicializando base de datos..."
            /app/scripts/init-db.sh
        env:
        - name: DATABASE_HOST
          value: "{{ .Values.database.host }}"
        - name: DATABASE_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
      restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Hook de pre-upgrade (ej: backup de datos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "myapp.fullname" . }}-backup
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"         # Pesos negativos se ejecutan primero
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        {{- include "myapp.labels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "myapp.fullname" . }}
      containers:
      - name: backup
        image: "postgresql:15"
        command: ["/bin/bash"]
        args:
          - -c
          - |
            echo "Backup de base de datos previo al upgrade..."
            pg_dump -h {{ .Values.database.host }} \
              -U {{ .Values.database.user }} \
              -d {{ .Values.database.name }} &gt; /backups/db_backup_$(date +%s).sql
            echo "Backup completado"
        volumeMounts:
        - name: backup-storage
          mountPath: /backups
      volumes:
      - name: backup-storage
        persistentVolumeClaim:
          claimName: backup-pvc
      restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Hook de test (validar instalación):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "myapp.fullname" . }}-smoke-test"
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  containers:
  - name: smoke-test
    image: curlimages/curl:latest
    command:
      - sh
      - -c
      - |
        echo "Ejecutando smoke tests..."

        # Test de health check
        curl -f http://{{ include "myapp.fullname" . }}:{{ .Values.service.port }}/health \
          || exit 1

        # Test de endpoint principal
        curl -f http://{{ include "myapp.fullname" . }}:{{ .Values.service.port }}/api/status \
          || exit 1

        echo "Todos los tests pasaron!"
  restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Hook delete-policy (gestionar limpieza):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Opciones de hook-delete-policy:
"helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"

# before-hook-creation: Eliminar Hook previo si existe
# hook-succeeded:       Eliminar Hook después de ejecución exitosa
# hook-failed:          Eliminar Hook después de fallo
# none:                 No eliminar (por defecto)

# Ejemplo: Hook que persiste para debugging
annotations:
  "helm.sh/hook": post-install
  "helm.sh/hook-delete-policy": ""  # No eliminar, útil para investigar fallos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pesos de hooks para controlar orden:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Los hooks con el mismo tipo se ordenan por peso (ascendente)
# Pesos negativos se ejecutan antes

# Ejecución de múltiples hooks post-install:
annotations:
  "helm.sh/hook": post-install
  "helm.sh/hook-weight": "-10"    # Primero (se ejecuta primero)
---
annotations:
  "helm.sh/hook": post-install
  "helm.sh/hook-weight": "0"      # Segundo
---
annotations:
  "helm.sh/hook": post-install
  "helm.sh/hook-weight": "10"     # Tercero</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gestión_de_dependencias_de_charts">10.5.2. Gestión de Dependencias de Charts</h4>
<div class="paragraph">
<p>Las dependencias permiten incluir otros Charts dentro del tuyo:</p>
</div>
<div class="paragraph">
<p><strong>Declarar dependencias en Chart.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v2
name: myapp-stack
version: 1.0.0

dependencies:
  - name: postgresql
    version: "12.1.0"
    repository: "https://charts.bitnami.com/bitnami"
    condition: postgresql.enabled
    tags:
      - database
    alias: database

  - name: redis
    version: "17.3.0"
    repository: "https://charts.bitnami.com/bitnami"
    condition: redis.enabled
    tags:
      - cache

  - name: prometheus
    version: "15.0.0"
    repository: "https://prometheus-community.github.io/helm-charts"
    condition: prometheus.enabled
    tags:
      - monitoring
    import-values:
      - child

# En values.yaml, configurar las dependencias:
postgresql:
  enabled: true
  auth:
    username: myapp_user
    password: changeme123
    database: myapp_db
  primary:
    persistence:
      enabled: true
      size: 20Gi

redis:
  enabled: true
  auth:
    enabled: true
    password: cacheme123
  replica:
    replicaCount: 2

prometheus:
  enabled: false  # Deshabilitada por defecto</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos para manejar dependencias:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar dependencias definidas en Chart.yaml
helm dependency update ./myapp-stack

# Salida:
# Hang tight while we grab the latest from your chart repositories...
# ...Successfully got an update from the "bitnami" chart repository
# Update Complete. ⎈ Happy Helming!
# Saving 3 charts
# Deleting outdated charts

# Ver estado de dependencias
helm dependency list ./myapp-stack

# Salida:
# NAME         VERSION REPOSITORY                              STATUS
# postgresql   12.1.0  https://charts.bitnami.com/bitnami      ok
# redis        17.3.0  https://charts.bitnami.com/bitnami      ok
# prometheus   15.0.0  https://prometheus-community.github.io   ok

# Ver estructura después de descargar dependencias
tree ./myapp-stack

# Salida:
# myapp-stack/
# ├── Chart.yaml
# ├── values.yaml
# ├── templates/
# ├── charts/
# │   ├── postgresql-12.1.0/
# │   ├── redis-17.3.0/
# │   ├── prometheus-15.0.0/
# │   └── Chart.lock
# └── Chart.lock</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Usar valores de dependencias (subcharts):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En templates, acceder a valores de dependencias:
env:
  DATABASE_HOST: "{{ .Release.Name }}-postgresql"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "{{ .Values.postgresql.auth.database }}"
  DATABASE_USER: "{{ .Values.postgresql.auth.username }}"

  CACHE_HOST: "{{ .Release.Name }}-redis-master"
  CACHE_PORT: "6379"

  PROMETHEUS_ENABLED: "{{ .Values.prometheus.enabled }}"
  {{- if .Values.prometheus.enabled }}
  PROMETHEUS_URL: "http://{{ .Release.Name }}-prometheus:9090"
  {{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Habilitar/Deshabilitar dependencias con tags:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar sin redis (deshabilitarlo)
helm install myapp ./myapp-stack \
  --set redis.enabled=false

# Instalar solo dependencias con tag "database"
helm install myapp ./myapp-stack \
  --set postgresql.enabled=true \
  --set redis.enabled=false \
  --set prometheus.enabled=false

# O usar tags:
helm install myapp ./myapp-stack \
  --set tags.database=true \
  --set tags.cache=false \
  --set tags.monitoring=false</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_subcharts_chart_reutilizables">10.5.3. Subcharts (Chart Reutilizables)</h4>
<div class="paragraph">
<p>Un subchart es un Chart que se incluye dentro de otro. Permite reutilizar configuraciones comunes:</p>
</div>
<div class="paragraph">
<p><strong>Estructura de Subcharts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">myapp-charts/
├── charts/
│   ├── common/                    # Subchart reutilizable
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   ├── templates/
│   │   │   ├── _helpers.tpl
│   │   │   ├── configmap.yaml
│   │   │   └── secret.yaml
│   │   └── README.md
│   ├── database-init/
│   │   ├── Chart.yaml
│   │   ├── templates/
│   │   │   └── job.yaml
│   │   └── values.yaml
│   └── monitoring/
│       ├── Chart.yaml
│       ├── templates/
│       └── values.yaml
├── Chart.yaml
├── values.yaml
└── templates/</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Usar alias para múltiples instancias de subchart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En Chart.yaml: Usar mismo subchart varias veces con alias
dependencies:
  - name: database
    version: "1.0.0"
    repository: file://../charts/database
    alias: db_main        # Alias para base de datos principal
    condition: databases.main.enabled

  - name: database
    version: "1.0.0"
    repository: file://../charts/database
    alias: db_cache       # Alias para base de datos de cache
    condition: databases.cache.enabled

  - name: database
    version: "1.0.0"
    repository: file://../charts/database
    alias: db_backup      # Alias para base de datos de backup
    condition: databases.backup.enabled

# En values.yaml:
databases:
  main:
    enabled: true
    name: myapp
    replica: 3
    size: 100Gi

  cache:
    enabled: true
    name: myapp-cache
    replica: 1
    size: 10Gi

  backup:
    enabled: false
    name: myapp-backup
    replica: 1
    size: 50Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Importar valores de subcharts:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Chart.yaml: Importar ciertos valores del subchart al padre
dependencies:
  - name: database
    version: "1.0.0"
    repository: "https://charts.example.com"
    import-values:
      - child: database.settings    # Subchart path
        parent: settings             # Parent path

# Subchart values.yaml:
database:
  settings:
    maxConnections: 100
    timeout: 30
    ssl: true

# Esto hace disponibles estos valores en parent como:
# .Values.settings.maxConnections
# .Values.settings.timeout
# .Values.settings.ssl</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_repositorios_de_helm_hosting_y_distribución">10.5.4. Repositorios de Helm: Hosting y Distribución</h4>
<div class="paragraph">
<p>Un repositorio de Helm es un servidor HTTP que aloja Chart empaquetados. Permite distribuir Charts a otros usuarios.</p>
</div>
<div class="paragraph">
<p><strong>Estructura de un repositorio:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">https://charts.example.com/
├── index.yaml           # Índice de Charts (generado automáticamente)
├── myapp-1.0.0.tgz      # Charts empaquetados
├── myapp-1.1.0.tgz
├── other-app-2.0.0.tgz
└── other-app-2.1.0.tgz</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Empaquetar un Chart:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear archivo .tgz del Chart
helm package ./myapp

# Salida:
# Successfully packaged chart and saved it to: /home/user/myapp-1.0.0.tgz

# Ver contenido del archivo empaquetado
tar -tzf myapp-1.0.0.tgz | head -20

# Empaquetar múltiples Charts
helm package ./myapp ./other-app

# Versionar automáticamente (incrementar version en Chart.yaml)
helm package ./myapp --version 1.1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear repositorio local:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear directorio para repositorio
mkdir my-helm-repo
cd my-helm-repo

# Empaquetar Charts
helm package ../myapp
helm package ../other-app

# Generar índice (archivo index.yaml)
helm repo index .

# Ver contenido del índice
cat index.yaml

# Salida:
# apiVersion: v1
# entries:
#   myapp:
#   - apiVersion: v2
#     appVersion: "1.0"
#     created: 2024-01-15T10:30:00.123Z
#     description: My awesome application
#     digest: sha256:abc123...
#     name: myapp
#     urls:
#     - myapp-1.0.0.tgz
#     version: 1.0.0
#   other-app:
#   - ...

# Actualizar índice (después de agregar nuevos Charts)
helm repo index . --merge ./index.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Servir repositorio localmente (desarrollo):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Opción 1: Usando Python
cd my-helm-repo
python3 -m http.server 8080

# Opción 2: Usando nginx
docker run -p 8080:80 -v $(pwd):/usr/share/nginx/html:ro nginx

# Opción 3: Usando helm serve (deprecado)
helm serve --repo-path ./

# Usar el repositorio local
helm repo add myrepo http://localhost:8080
helm repo update
helm search repo myrepo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Publicar repositorio en GitHub Pages:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear rama gh-pages
git checkout --orphan gh-pages

# Copiar Charts empaquetados y index.yaml
mkdir -p charts
helm package ../myapp -d charts/
helm package ../other-app -d charts/
helm repo index charts/ --url https://username.github.io/helm-charts

# Commitear y pushear
git add .
git commit -m "Add Helm Charts"
git push origin gh-pages

# Agregar repositorio
helm repo add myrepo https://username.github.io/helm-charts
helm repo update</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Publicar en Helm Hub (hub.helm.sh):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear repositorio público en GitHub
# 2. Asegurar que Chart está bien documentado (Chart.yaml completo)
# 3. Crear Chart.yaml con todos los metadatos necesarios
# 4. Submeter a Helm Hub en: https://github.com/helm/hub/issues

# Requisitos:
# - Chart.yaml bien formado
# - README.md
# - Licencia (LICENSE file)
# - Mantenedores listados
# - Repository público en GitHub
# - Helm 3 compatible (apiVersion: v2)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Repositorio privado con autenticación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Repositorio con autenticación HTTP básica
helm repo add myrepo https://charts.mycompany.com \
  --username myuser \
  --password mypassword

# O guardar credenciales en ~/.netrc (menos seguro)
machine charts.mycompany.com
  login myuser
  password mypassword

# Repositorio con certificados (mTLS)
helm repo add myrepo https://charts.mycompany.com \
  --ca-file ./ca.crt \
  --cert-file ./client.crt \
  --key-file ./client.key

# Ver y actualizar repositorio privado
helm repo update myrepo
helm search repo myrepo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Servidor Helm con Chartmuseum:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Chartmuseum (servidor Helm completo)
helm repo add chartmuseum https://chartmuseum.github.io/charts
helm install chartmuseum chartmuseum/chartmuseum \
  --set persistence.enabled=true \
  --set persistence.size=10Gi

# Usar Chartmuseum
helm repo add mycharts http://chartmuseum-service:8080
helm push ./myapp mycharts

# O usar curl
curl --data-binary "@myapp-1.0.0.tgz" \
  http://localhost:8080/api/charts

# Descargar desde Chartmuseum
helm repo update
helm install myapp mycharts/myapp</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_best_practices_para_helm_avanzado">10.5.5. Best Practices para Helm Avanzado</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Hooks seguros</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar hook-delete-policy apropiadamente</p>
</li>
<li>
<p>Implementar reintentos en Jobs críticos</p>
</li>
<li>
<p>Loguear salida de Hooks para debugging</p>
</li>
<li>
<p>Probar Hooks en staging primero</p>
</li>
<li>
<p>No usar Hooks para lógica crítica (usar operadores)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Dependencias declaradas explícitamente</strong></p>
<div class="ulist">
<ul>
<li>
<p>Especificar versiones exactas de dependencias</p>
</li>
<li>
<p>Documentar por qué se necesita cada dependencia</p>
</li>
<li>
<p>Usar conditions para habilitar opcionalmente</p>
</li>
<li>
<p>Mantener dependencias actualizadas</p>
</li>
<li>
<p>Probar compatibilidad entre versiones</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Subcharts bien modulados</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cada subchart debe ser independiente</p>
</li>
<li>
<p>Proporcionar valores por defecto útiles</p>
</li>
<li>
<p>Documentar interface (qué valores espera)</p>
</li>
<li>
<p>Usar alias para múltiples instancias</p>
</li>
<li>
<p>Mantener versionamiento semántico</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Repositorios seguros</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar HTTPS para todos los repositorios</p>
</li>
<li>
<p>Implementar autenticación en repos privados</p>
</li>
<li>
<p>Verificar integridad de Charts (checksums)</p>
</li>
<li>
<p>Auditar cambios en repositorio</p>
</li>
<li>
<p>Mantener backups de Charts críticos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Gestión de versiones</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar Semantic Versioning estrictamente</p>
</li>
<li>
<p>Documentar cambios en CHANGELOG.md</p>
</li>
<li>
<p>No reutilizar versiones</p>
</li>
<li>
<p>Mantener histórico de versiones antiguas</p>
</li>
<li>
<p>Considerar compatibilidad hacia atrás</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Testing en cada nivel</strong></p>
<div class="ulist">
<ul>
<li>
<p>Tests unitarios para templates</p>
</li>
<li>
<p>Tests de integración en staging</p>
</li>
<li>
<p>Tests de seguridad (kubeval, kubesec)</p>
</li>
<li>
<p>Probar upgrades y rollbacks</p>
</li>
<li>
<p>Validar dependencias funcionan</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Documentación exhaustiva</strong></p>
<div class="ulist">
<ul>
<li>
<p>README.md con instrucciones claras</p>
</li>
<li>
<p>Ejemplos de valores para casos comunes</p>
</li>
<li>
<p>Documentar breaking changes</p>
</li>
<li>
<p>Guías de troubleshooting</p>
</li>
<li>
<p>Comentarios en templates complejos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad en producción</strong></p>
<div class="ulist">
<ul>
<li>
<p>No incluir secrets en values.yaml</p>
</li>
<li>
<p>Usar referencias a Secrets externos</p>
</li>
<li>
<p>Implementar RBAC restrictivo</p>
</li>
<li>
<p>Validar inputs de usuarios</p>
</li>
<li>
<p>Auditar acceso a repositorios privados</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_11_cicd_con_kubernetes">11. Módulo 11: CI/CD con Kubernetes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_estrategias_de_deployment">11.1. Estrategias de Deployment</h3>
<div class="paragraph">
<p><strong>Blue-Green Deployment</strong></p>
</div>
<div class="paragraph">
<p>El patrón Blue-Green proporciona cero downtime al mantener dos ambientes idénticos.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Blue (ambiente actual): versión en producción</p>
</li>
<li>
<p>Green (ambiente nuevo): versión candidata</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El tráfico se conmuta completamente de Blue a Green mediante el servicio.</p>
</div>
<div class="paragraph">
<p>Ventajas:
* Rollback instantáneo cambiando el selector del servicio
* Testing completo del ambiente antes de conmutación
* Bajo riesgo de fallos parciales</p>
</div>
<div class="paragraph">
<p>Desventajas:
* Requiere el doble de recursos en cluster
* Sincronización de datos complicada si hay estado</p>
</div>
<div class="paragraph">
<p>Ejemplo de implementación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Blue - Versión actual en producción
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: app
        image: myapp:v1.0.0
        ports:
        - containerPort: 8080

---
# Green - Versión candidata
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-green
spec:
  replicas: 3
  selector:
    matchLabels:
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: app
        image: myapp:v2.0.0
        ports:
        - containerPort: 8080

---
# Servicio que apunta actualmente a Blue
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
    version: blue  # Cambiar a "green" para conmutar
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Conmutación del tráfico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar que Green está listo
kubectl get pods -l version=green

# Actualizar selector del servicio
kubectl patch service myapp -p '{"spec":{"selector":{"version":"green"}}}'

# Rollback si es necesario
kubectl patch service myapp -p '{"spec":{"selector":{"version":"blue"}}}'

# Eliminar Blue una vez que Green es estable
kubectl delete deployment app-blue</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Canary Deployment</strong></p>
</div>
<div class="paragraph">
<p>Despliega la nueva versión gradualmente a un pequeño porcentaje de usuarios.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reduce riesgo al exponer cambios a pocos usuarios primero</p>
</li>
<li>
<p>Permite validación en producción con tráfico real</p>
</li>
<li>
<p>Facilita detección de problemas antes de rollout completo</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Estrategia:
1. Desplegar nueva versión con 5-10% del tráfico
2. Monitorear métricas de error y latencia
3. Aumentar gradualmente el porcentaje
4. Completar rollout o rollback basado en resultados</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Canary Deployment usando Istio VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: myapp
        subset: v1
      weight: 90
    - destination:
        host: myapp
        subset: v2
      weight: 10
---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo durante canary:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Monitorear tasa de errores en v2 (canary)
kubectl exec -it &lt;prometheus-pod&gt; -- \
  promtool query instant 'rate(requests_errors_total{version="v2"}[5m])'

# Si los errores son bajos, aumentar tráfico
kubectl apply -f - &lt;&lt;EOF
# Actualizar weights en VirtualService: v1: 80, v2: 20
EOF

# Completar rollout
kubectl apply -f - &lt;&lt;EOF
# Actualizar weights a v1: 0, v2: 100
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Rolling Updates Avanzados</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes realiza rolling updates de forma nativa, pero se pueden optimizar con parámetros avanzados.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 3          # Máximo 3 pods adicionales durante update
      maxUnavailable: 1    # Máximo 1 pod unavailable
  minReadySeconds: 30      # Esperar 30s antes de considerarlo ready
  progressDeadlineSeconds: 600
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:v2
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>Control del rolling update:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado del update
kubectl rollout status deployment/app

# Pausar update si hay problemas
kubectl rollout pause deployment/app

# Resumir update
kubectl rollout resume deployment/app

# Ver historial de cambios
kubectl rollout history deployment/app

# Rollback a versión anterior
kubectl rollout undo deployment/app

# Rollback a revisión específica
kubectl rollout undo deployment/app --to-revision=2

# Ver detalles de una revisión
kubectl rollout history deployment/app --revision=2</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>A/B Testing</strong></p>
</div>
<div class="paragraph">
<p>Divide el tráfico basado en características o criterios para validar cambios con usuarios reales.</p>
</div>
<div class="paragraph">
<p>Casos de uso:
* Pruebas de interfaz de usuario (UI/UX)
* Validación de nuevas features
* Comparación de algoritmos</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-ab
spec:
  hosts:
  - myapp
  http:
  # Tráfico de usuario ID par a A
  - match:
    - headers:
        user-id:
          regex: '[0-9]*[02468]$'
    route:
    - destination:
        host: myapp
        subset: version-a
  # Resto del tráfico a B
  - route:
    - destination:
        host: myapp
        subset: version-b
---
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>Análisis de resultados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Comparar métricas entre versiones
kubectl exec -it prometheus-pod -- \
  promtool query instant \
  'avg by (version) (response_time_seconds{app="myapp"})'

# Estadísticas de conversión por versión
kubectl exec -it prometheus-pod -- \
  promtool query instant \
  'rate(conversions_total[1h]) / rate(requests_total[1h]) * 100'</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gitops">11.2. GitOps</h3>
<div class="paragraph">
<p><strong>Principios de GitOps</strong></p>
</div>
<div class="paragraph">
<p>GitOps es una metodología que utiliza Git como fuente única de verdad para el estado deseado de la infraestructura y aplicaciones.</p>
</div>
<div class="paragraph">
<p>Principios fundamentales:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Declarativo</strong>: El estado deseado se describe declarativamente (típicamente en YAML)</p>
</li>
<li>
<p><strong>Versionado en Git</strong>: Todo el código de configuración reside en Git</p>
</li>
<li>
<p><strong>Reconciliación automática</strong>: Un operador asegura que el estado real coincida con Git</p>
</li>
<li>
<p><strong>Observabilidad</strong>: Todas las operaciones están auditadas y visibles</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ventajas:
* Control de cambios mediante Git (PR, reviews, audit trail)
* Rollback fácil: revertir commits en Git revierte cambios en cluster
* Infraestructura como código: mismos procesos que el código fuente
* Automatización: cambios en Git disparan despliegues automáticos
* Seguridad: no requiere acceso directo al cluster para cambios</p>
</div>
<div class="paragraph">
<p>Flujo de trabajo típico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Desarrollador
    ↓
  Git Push
    ↓
  Pull Request
    ↓
  Review &amp; Merge
    ↓
GitOps Operator (ArgoCD/Flux)
    ↓
  Detecta cambio en Git
    ↓
  Obtiene manifiestos actualizados
    ↓
Sincroniza con Kubernetes Cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>ArgoCD</strong></p>
</div>
<div class="paragraph">
<p>ArgoCD es un controlador de despliegue declarativo para Kubernetes que implementa GitOps.</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear namespace para ArgoCD
kubectl create namespace argocd

# Instalar ArgoCD
kubectl apply -n argocd -f \
  https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Exponer UI de ArgoCD
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Obtener contraseña inicial
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d</code></pre>
</div>
</div>
<div class="paragraph">
<p>Componentes de ArgoCD:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>API Server</strong>: Expone UI y API REST</p>
</li>
<li>
<p><strong>Repository Server</strong>: Obtiene manifiestos del repositorio Git</p>
</li>
<li>
<p><strong>Application Controller</strong>: Monitorea aplicaciones y sincroniza estado</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Definición de una Application:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp
  namespace: argocd
spec:
  project: default

  source:
    repoURL: https://github.com/myorg/myapp-config
    targetRevision: main
    path: k8s/                    # Ruta a manifiestos en Git

  destination:
    server: https://kubernetes.default.svc
    namespace: default

  syncPolicy:
    automated:
      prune: true                 # Eliminar recursos no en Git
      selfHeal: true              # Resincronizar si cluster diverge
    syncOptions:
    - CreateNamespace=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo y sincronización:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Listar aplicaciones
argocd app list

# Ver estado detallado de aplicación
argocd app get myapp

# Sincronizar manualmente
argocd app sync myapp

# Esperar a que sync complete
kubectl wait --for=condition=SyncStatusCode=Synced \
  application.argoproj.io/myapp -n argocd

# Ver logs de sincronización
argocd app logs myapp

# Obtener eventos de aplicación
kubectl describe application myapp -n argocd</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Flux</strong></p>
</div>
<div class="paragraph">
<p>Flux es otro operador GitOps que sincroniza cambios de Git con Kubernetes.</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Requisitos
export GITHUB_USER=myuser
export GITHUB_TOKEN=ghp_...

# Instalar Flux CLI
curl -s https://fluxcd.io/install.sh | sudo bash

# Crear buckets para Flux
flux bootstrap github \
  --owner=$GITHUB_USER \
  --repo=fleet \
  --branch=main \
  --path=./clusters/my-cluster \
  --personal</code></pre>
</div>
</div>
<div class="paragraph">
<p>Estructura de Flux:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">fleet/
├── clusters/my-cluster/
│   └── flux-system/
│       ├── gotk-components.yaml
│       ├── gotk-sync.yaml
│       └── kustomization.yaml
└── repos/
    ├── myapp-repo.yaml
    └── myapp-source.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definición de fuente de Git:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: myapp
  namespace: flux-system
spec:
  interval: 1m0s
  url: https://github.com/myorg/myapp-config
  ref:
    branch: main
  secretRef:
    name: git-credentials</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definición de Kustomization (qué sincronizar):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: myapp
  namespace: flux-system
spec:
  interval: 10m0s
  path: ./k8s/

  sourceRef:
    kind: GitRepository
    name: myapp

  prune: true
  wait: true

  postBuild:
    substitute:
      version: "1.0.0"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Comandos útiles de Flux:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver estado de sincronización
flux get source git myapp

# Forzar resincronización
flux reconcile source git myapp

# Ver eventos de Kustomization
flux get kustomization

# Logs de reconciliación
flux logs --all-namespaces --follow</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Reconciliation Loops</strong></p>
</div>
<div class="paragraph">
<p>Los loops de reconciliación son el mecanismo central que mantiene sincronizado el estado.</p>
</div>
<div class="paragraph">
<p>Funcionamiento:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Operador verifica periódicamente el estado deseado (Git)</p>
</li>
<li>
<p>Compara con estado actual (cluster)</p>
</li>
<li>
<p>Si hay diferencias, realiza cambios para alcanzar estado deseado</p>
</li>
<li>
<p>Repite continuamente (típicamente cada 1-5 minutos)</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ventajas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Auto-healing</strong>: Si alguien elimina un recurso manualmente, se restaura</p>
</li>
<li>
<p><strong>Recuperación de desastres</strong>: Si cluster se corrompe, se restaura desde Git</p>
</li>
<li>
<p><strong>Auditoría</strong>: Cada cambio queda registrado en Git</p>
</li>
<li>
<p><strong>Predictibilidad</strong>: El estado es siempre reproducible desde Git</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Configuración de frequency:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Reconciliación cada 30 segundos (más agresivo)
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: myapp
spec:
  interval: 30s

---
# Reconciliación cada 5 minutos (default)
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: myapp
spec:
  interval: 5m0s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo de reconciliación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># ArgoCD: ver estado de sync
argocd app get myapp --refresh

# Flux: ver historial de reconciliación
kubectl describe kustomization myapp -n flux-system

# Ver logs de reconciliación fallida
kubectl logs -n flux-system deploy/kustomize-controller -f \
  | grep myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p>Mejores prácticas de GitOps:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Separar por ambientes</strong>: desarrollo, staging, producción en ramas o directorios</p>
</li>
<li>
<p><strong>Pull request workflow</strong>: cambios deben ser aprobados antes de merge</p>
</li>
<li>
<p><strong>Automatizar tests</strong>: validar YAML antes de desplegar</p>
</li>
<li>
<p><strong>Semantic versioning</strong>: usar tags de Git para versiones</p>
</li>
<li>
<p><strong>Segregación de responsabilidades</strong>: diferentes repos para infra vs apps</p>
</li>
<li>
<p><strong>Secretos seguros</strong>: usar SealedSecrets, External Secrets o similares</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_cicd_pipelines">11.3. CI/CD Pipelines</h3>
<div class="paragraph">
<p><strong>Jenkins con Kubernetes</strong></p>
</div>
<div class="paragraph">
<p>Jenkins ejecuta pipelines en Kubernetes con el plugin Kubernetes.</p>
</div>
<div class="paragraph">
<p>Instalación de Jenkins en K8s:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio Helm de Jenkins
helm repo add jenkins https://charts.jenkins.io
helm repo update

# Instalar Jenkins
helm install jenkins jenkins/jenkins \
  --namespace jenkins \
  --create-namespace \
  --set controller.serviceType=LoadBalancer

# Acceder a Jenkins
kubectl port-forward svc/jenkins -n jenkins 8080:8080

# Obtener contraseña inicial
kubectl exec -n jenkins jenkins-0 -- \
  cat /run/secrets/chart-admin-password</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración de Kubernetes Plugin:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">pipeline {
  agent {
    kubernetes {
      yaml '''
        apiVersion: v1
        kind: Pod
        metadata:
          labels:
            jenkins: agent
        spec:
          serviceAccountName: jenkins
          containers:
          - name: docker
            image: docker:latest
            command:
            - sleep
            args:
            - 99999
            volumeMounts:
            - name: docker-sock
              mountPath: /var/run/docker.sock
          volumes:
          - name: docker-sock
            hostPath:
              path: /var/run/docker.sock
      '''
    }
  }

  stages {
    stage('Build') {
      steps {
        container('docker') {
          sh '''
            docker build -t myapp:${BUILD_NUMBER} .
            docker push registry.example.com/myapp:${BUILD_NUMBER}
          '''
        }
      }
    }

    stage('Deploy') {
      steps {
        sh '''
          kubectl set image deployment/myapp \
            myapp=registry.example.com/myapp:${BUILD_NUMBER}
        '''
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ventajas:
* Escalado automático: crea pods bajo demanda
* Aislamiento: cada job en su propio pod
* Recursos eficientes: pods se eliminan después de ejecutarse</p>
</div>
<div class="paragraph">
<p><strong>GitLab CI/CD</strong></p>
</div>
<div class="paragraph">
<p>GitLab ofrece CI/CD nativo que funciona bien con Kubernetes.</p>
</div>
<div class="paragraph">
<p>Definición en <code>.gitlab-ci.yml</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">stages:
  - build
  - test
  - deploy

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_REGISTRY: registry.gitlab.com
  IMAGE_NAME: $DOCKER_REGISTRY/$CI_PROJECT_PATH

build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $DOCKER_REGISTRY
    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA .
    - docker tag $IMAGE_NAME:$CI_COMMIT_SHA $IMAGE_NAME:latest
    - docker push $IMAGE_NAME:$CI_COMMIT_SHA
    - docker push $IMAGE_NAME:latest

test:
  stage: test
  image: $IMAGE_NAME:$CI_COMMIT_SHA
  script:
    - npm test
    - npm run lint

deploy_staging:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context mygroup/myproject:k8s-agent
    - kubectl set image deployment/myapp myapp=$IMAGE_NAME:$CI_COMMIT_SHA -n staging
  environment:
    name: staging
  only:
    - develop

deploy_production:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context mygroup/myproject:k8s-agent
    - kubectl set image deployment/myapp myapp=$IMAGE_NAME:$CI_COMMIT_SHA -n production
  environment:
    name: production
  when: manual
  only:
    - main</code></pre>
</div>
</div>
<div class="paragraph">
<p>GitLab Runner en Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar runner de GitLab
helm repo add gitlab https://charts.gitlab.io
helm install gitlab-runner gitlab/gitlab-runner \
  --set gitlabUrl=https://gitlab.example.com/ \
  --set gitlabRunnerRegistrationToken=&lt;token&gt; \
  --set runners.image=ubuntu:20.04 \
  --set runners.privileged=true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>GitHub Actions</strong></p>
</div>
<div class="paragraph">
<p>GitHub Actions ejecuta CI/CD directamente en GitHub.</p>
</div>
<div class="paragraph">
<p>Definición en <code>.github/workflows/build.yml</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">name: Build and Deploy

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d &gt; $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/myapp \
            myapp=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \
            -n production
          kubectl rollout status deployment/myapp -n production</code></pre>
</div>
</div>
<div class="paragraph">
<p>Secrets en GitHub Actions:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar secret (vía UI o CLI)
gh secret set KUBE_CONFIG --body "$(cat ~/.kube/config | base64)"
gh secret set DOCKER_USERNAME --body "myusername"
gh secret set DOCKER_PASSWORD --body "mytoken"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Tekton Pipelines</strong></p>
</div>
<div class="paragraph">
<p>Tekton es un framework agnóstico de CI/CD nativo de Kubernetes.</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Tekton
kubectl apply --filename \
  https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml

# Instalar Tekton Triggers
kubectl apply --filename \
  https://storage.googleapis.com/tekton-releases/triggers/latest/release.yaml

# Instalar Tekton Dashboard
kubectl apply --filename \
  https://storage.googleapis.com/tekton-releases/dashboard/latest/release-full.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definición de Task:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: build-docker-image
spec:
  params:
  - name: image-url
    type: string
  - name: image-tag
    type: string
  steps:
  - name: build
    image: docker:latest
    env:
    - name: DOCKER_HOST
      value: tcp://docker:2375
    script: |
      docker build -t $(params.image-url):$(params.image-tag) .
      docker push $(params.image-url):$(params.image-tag)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definición de Pipeline:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: build-and-deploy
spec:
  params:
  - name: git-url
    type: string
  - name: image-url
    type: string

  tasks:
  - name: clone-repo
    taskRef:
      name: git-clone
    params:
    - name: url
      value: $(params.git-url)
    workspaces:
    - name: output
      workspace: source

  - name: build-image
    runAfter:
    - clone-repo
    taskRef:
      name: build-docker-image
    params:
    - name: image-url
      value: $(params.image-url)
    - name: image-tag
      value: latest
    workspaces:
    - name: source
      workspace: source

  - name: deploy
    runAfter:
    - build-image
    taskRef:
      name: deploy-kubernetes
    params:
    - name: image-url
      value: $(params.image-url)

  workspaces:
  - name: source</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ejecución de Pipeline:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear PipelineRun
kubectl apply -f - &lt;&lt;EOF
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: build-and-deploy-run
spec:
  pipelineRef:
    name: build-and-deploy
  params:
  - name: git-url
    value: https://github.com/myorg/myapp
  - name: image-url
    value: registry.example.com/myapp
  workspaces:
  - name: source
    volumeClaimTemplate:
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 1Gi
EOF

# Ver estado de PipelineRun
tkn pipelinerun list
tkn pipelinerun describe build-and-deploy-run

# Logs de ejecución
tkn pipelinerun logs build-and-deploy-run -f</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comparación de Soluciones</strong></p>
</div>
<div class="paragraph">
<p>|Característica|Jenkins|GitLab CI|GitHub Actions|Tekton|
|---|---|---|---|---|
|Instalación|Compleja|Integrada|SaaS|Nativa K8s|
|Escalado|Plugin Kubernetes|Runners|Hosts GitHub|Nativo|
|YAML config|Jenkinsfile|.gitlab-ci.yml|.github/workflows|Pipeline CR|
|Curva aprendizaje|Media|Baja|Baja|Alta|
|Costo|Gratuito|Freemium|Gratuito/Pagado|Gratuito|
|Mejor para|Entornos complejos|Desarrollo rápido|Proyectos GitHub|K8s puro|</p>
</div>
</div>
<div class="sect2">
<h3 id="_image_management">11.4. Image Management</h3>
<div class="paragraph">
<p><strong>Container Registries</strong></p>
</div>
<div class="paragraph">
<p>Los registros de contenedores almacenan y distribuyen imágenes Docker.</p>
</div>
<div class="paragraph">
<p>Registros públicos:
* <strong>Docker Hub</strong>: registry.hub.docker.com - registro público principal
* <strong>GitHub Container Registry (GHCR)</strong>: ghcr.io - integrado con GitHub
* <strong>Google Container Registry (GCR)</strong>: gcr.io - integrado con GCP
* <strong>Amazon ECR</strong>: public.ecr.aws - integrado con AWS</p>
</div>
<div class="paragraph">
<p>Registros privados:
* <strong>Harbor</strong>: registro self-hosted con scanning y replicación
* <strong>Nexus</strong>: gestor de artefactos con soporte Docker
* <strong>Quay</strong>: registro enterpise (RedHat)</p>
</div>
<div class="paragraph">
<p>Configuración de acceso privado en Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear secret para autenticación
kubectl create secret docker-registry regcred \
  --docker-server=registry.example.com \
  --docker-username=myuser \
  --docker-password=mypass \
  --docker-email=myemail@example.com

# Listar secrets
kubectl get secrets

# Ver contenido del secret
kubectl get secret regcred --output="jsonpath={.data.\.dockerconfigjson}" | base64 -d</code></pre>
</div>
</div>
<div class="paragraph">
<p>Uso en Deployment:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      imagePullSecrets:
      - name: regcred              # Referencia al secret de credenciales
      containers:
      - name: app
        image: registry.example.com/myapp:v1.0.0
        ports:
        - containerPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Image Pull Policies</strong></p>
</div>
<div class="paragraph">
<p>Las políticas de pull controlan cómo Kubernetes obtiene imágenes.</p>
</div>
<div class="paragraph">
<p>Políticas disponibles:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: pod-with-pull-policy
spec:
  containers:
  - name: app
    image: myapp:latest
    imagePullPolicy: Always        # Siempre pull (default para :latest)

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-never-pull
spec:
  containers:
  - name: app
    image: myapp:v1.0.0
    imagePullPolicy: Never         # Solo usar imagen local, fallar si no existe

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-if-not-present
spec:
  containers:
  - name: app
    image: myapp:v1.0.0
    imagePullPolicy: IfNotPresent  # Pull solo si no existe localmente</code></pre>
</div>
</div>
<div class="paragraph">
<p>Comportamiento por defecto:
* <code>latest</code>: Always (siempre pull)
* Versión específica (v1.0.0): IfNotPresent (pull solo si falta)
* Sin tag: IfNotPresent</p>
</div>
<div class="paragraph">
<p>Implicaciones de rendimiento:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># BUENA PRÁCTICA: usar tags específicos
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    spec:
      containers:
      - image: myapp:v1.2.3        # Tag específico, IfNotPresent
        imagePullPolicy: IfNotPresent

---
# EVITAR: usar latest sin especificar policy
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-bad
spec:
  template:
    spec:
      containers:
      - image: myapp:latest         # Always pull, más lento</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Image Scanning</strong></p>
</div>
<div class="paragraph">
<p>El scanning detecta vulnerabilidades en imágenes.</p>
</div>
<div class="paragraph">
<p>Herramientas de scanning:
* <strong>Trivy</strong>: scanner rápido y completo (OSS)
* <strong>Clair</strong>: análisis de vulnerabilidades (OSS)
* <strong>Anchore</strong>: scanning empresarial
* <strong>Snyk</strong>: análisis de dependencias y vulnerabilidades</p>
</div>
<div class="paragraph">
<p>Instalación y uso de Trivy:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Trivy
wget https://github.com/aquasecurity/trivy/releases/download/v0.45.0/trivy_0.45.0_Linux-64bit.tar.gz
tar zxvf trivy_0.45.0_Linux-64bit.tar.gz
sudo mv trivy /usr/local/bin/

# Escanear imagen local
trivy image myapp:v1.0.0

# Escanear desde registry remoto
trivy image registry.example.com/myapp:v1.0.0

# Generar reporte en JSON
trivy image --format json --output report.json myapp:v1.0.0

# Escanear filesystem
trivy fs /path/to/app

# Severidad mínima para salir con error
trivy image --severity HIGH,CRITICAL myapp:v1.0.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Integración en CI/CD:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># GitHub Actions
- name: Scan image with Trivy
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: myapp:${{ github.sha }}
    format: 'sarif'
    output: 'trivy-results.sarif'

- name: Upload results to GitHub Security
  uses: github/codeql-action/upload-sarif@v2
  with:
    sarif_file: 'trivy-results.sarif'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># GitLab CI
scan_image:
  stage: scan
  image: aquasec/trivy:latest
  script:
    - trivy image --exit-code 0 --severity MEDIUM,HIGH,CRITICAL
      --format template --template '@/contrib/html.tpl'
      -o report.html $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  artifacts:
    reports:
      container_scanning: container-scanning-report.json
    paths:
      - report.html</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Vulnerability Management</strong></p>
</div>
<div class="paragraph">
<p>Gestión sistémica de vulnerabilidades detectadas.</p>
</div>
<div class="paragraph">
<p>Estrategias de remediación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Actualizar imagen base a versión sin vulnerabilidades
FROM ubuntu:22.04  # En lugar de ubuntu:20.04

# 2. Instalar parches de seguridad
RUN apt-get update &amp;&amp; \
    apt-get install -y --only-upgrade openssl &amp;&amp; \
    apt-get clean &amp;&amp; \
    rm -rf /var/lib/apt/lists/*

# 3. Usar imágenes minimalistas
FROM alpine:3.18  # En lugar de ubuntu

# 4. Eliminar paquetes no necesarios
RUN apk del apk-tools &amp;&amp; \
    rm -rf /var/cache/apk/*</code></pre>
</div>
</div>
<div class="paragraph">
<p>Políticas de admission para bloquear imágenes vulnerables:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Usando Kyverno para bloquear imágenes no escaneadas
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-image-scan
spec:
  validationFailureAction: enforce
  rules:
  - name: check-image-scan
    match:
      resources:
        kinds:
        - Pod
    validate:
      message: "Image must have been scanned"
      pattern:
        spec:
          containers:
          - image: "*//*"
            '(image)': "?*"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo continuo con admission webhooks:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: image-vulnerability-check
webhooks:
- name: image-scan.example.com
  clientConfig:
    service:
      name: image-scan-service
      namespace: security
      path: "/validate"
    caBundle: LS0tLS1CRUdJ...
  rules:
  - operations: ["CREATE", "UPDATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  admissionReviewVersions: ["v1"]
  sideEffects: None</code></pre>
</div>
</div>
<div class="paragraph">
<p>Control de versiones y etiquetado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Etiquetado semántico
docker build -t myapp:v1.2.3 .
docker build -t myapp:latest .
docker build -t myapp:1.2 .
docker build -t myapp:1 .

# Etiquetado con información de build
docker build \
  -t myapp:v1.2.3-build.123 \
  -t myapp:v1.2.3-sha.abc1234 \
  .

# Push a múltiples registros
docker push registry1.example.com/myapp:v1.2.3
docker push registry2.example.com/myapp:v1.2.3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Best practices de gestión de imágenes:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Usar tags específicos</strong>: no depender de <code>latest</code> en producción</p>
</li>
<li>
<p><strong>Escanear regularmente</strong>: no solo en CI, sino también imágenes en uso</p>
</li>
<li>
<p><strong>Segregar imágenes</strong>: development != staging != production</p>
</li>
<li>
<p><strong>Mantener base images actualizadas</strong>: patches de seguridad</p>
</li>
<li>
<p><strong>Documentar dependencias</strong>: lista de paquetes y versiones</p>
</li>
<li>
<p><strong>Auditar acceso al registry</strong>: quién push/pull qué</p>
</li>
<li>
<p><strong>Implementar políticas de retención</strong>: limpiar imágenes viejas</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ejemplo de política de retención en Harbor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Via API
curl -X PUT https://harbor.example.com/api/v2.0/projects/1/retention/rules \
  -H "Content-Type: application/json" \
  -d '{
    "rules": [
      {
        "priority": 1,
        "template_id": "always",
        "tag_selectors": [{"kind": "label", "decoration": "matches", "pattern": "keep"}],
        "repo_selectors": [{"kind": "doublestar", "decoration": "matches", "pattern": "**"}],
        "retain": {
          "num": 10
        }
      }
    ],
    "algorithm": "or"
  }'</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_12_service_mesh">12. Módulo 12: Service Mesh</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introducción_a_service_mesh">12.1. Introducción a Service Mesh</h3>
<div class="paragraph">
<p><strong>Problemas que resuelve</strong></p>
</div>
<div class="paragraph">
<p>En arquitecturas de microservicios complejas, la comunicación entre servicios presenta múltiples desafíos:</p>
</div>
<div class="paragraph">
<p>Problemas tradicionales sin Service Mesh:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Resiliencia</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Sin reintentos automáticos, timeouts o circuit breakers</p>
</li>
<li>
<p>Un servicio lento puede afectar toda la cadena</p>
</li>
<li>
<p>Falta de control sobre comportamiento de fallos</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Observabilidad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Difícil rastrear requests entre múltiples servicios</p>
</li>
<li>
<p>Métricas dispersas en diferentes herramientas</p>
</li>
<li>
<p>Correlación de errores complicada</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Comunicación sin encriptación entre servicios</p>
</li>
<li>
<p>Falta de autenticación/autorización entre servicios</p>
</li>
<li>
<p>Difícil auditoria de quién habla con quién</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Tráfico</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Cambios de versiones requieren cambios de código</p>
</li>
<li>
<p>Difícil implementar canary deploys o A/B testing</p>
</li>
<li>
<p>Load balancing manual y complejo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Gestión</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Cada servicio implementa lógica de resiliencia</p>
</li>
<li>
<p>Duplicación de código entre microservicios</p>
</li>
<li>
<p>Difícil actualizar comportamiento globalmente</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ejemplo del problema:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Cliente → ServiceA → ServiceB → ServiceC
              ↓          ↓          ↓
           Retry?    Timeout?   Circuit?
          Logging?  Metrics?   Security?</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sin Service Mesh, cada servicio debe manejar:
- Reintentos con backoff exponencial
- Timeouts y circuit breakers
- Logging y tracing
- Encriptación TLS
- Autorización</p>
</div>
<div class="paragraph">
<p><strong>Service Mesh como solución</strong></p>
</div>
<div class="paragraph">
<p>Un Service Mesh es una capa de infraestructura dedicada que maneja la comunicación entre servicios (service-to-service communication).</p>
</div>
<div class="paragraph">
<p>Arquitectura típica:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────────────────────────┐
│                  Application Layer              │
│  ServiceA    ServiceB    ServiceC    ServiceD   │
└────┬─────────────┬──────────────┬──────────┬───┘
     │             │              │          │
┌────▼─────────────▼──────────────▼──────────▼───┐
│           Service Mesh (Data Plane)            │
│  Envoy  Envoy  Envoy  Envoy  Envoy  Envoy     │
│ (sidecar proxies)                              │
└────────────────────────────────────────────────┘
     ▲                                        ▲
     └────────────────────────────────────────┘
            Control Plane (Istio/Linkerd)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ventajas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Transparencia</strong>: Los servicios no necesitan cambiar código</p>
</li>
<li>
<p><strong>Centralización</strong>: Políticas definidas en un lugar</p>
</li>
<li>
<p><strong>Consistencia</strong>: Comportamiento uniforme entre todos los servicios</p>
</li>
<li>
<p><strong>Dinamismo</strong>: Cambios sin redeploy de aplicaciones</p>
</li>
<li>
<p><strong>Observabilidad</strong>: Métricas y trazas automáticas</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arquitectura de Service Mesh</strong></p>
</div>
<div class="paragraph">
<p>Componentes principales:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Data Plane</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Proxies sidecar (uno por pod)</p>
</li>
<li>
<p>Interceptan todo el tráfico</p>
</li>
<li>
<p>Típicamente Envoy</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Control Plane</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Configura los proxies</p>
</li>
<li>
<p>Mantiene estado global</p>
</li>
<li>
<p>Gestiona certificados</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>APIs</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Custom Resource Definitions (CRDs)</p>
</li>
<li>
<p>Definen comportamiento de tráfico</p>
</li>
<li>
<p>Políticas de seguridad</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Flujo de una request:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Cliente env́a request → Envoy sidecar del cliente
2. Envoy cliente:
   - Aplica políticas de retry, timeout
   - Selecciona destino (load balancing)
   - Encripta con mTLS
3. Request llega → Envoy sidecar del servidor
4. Envoy servidor:
   - Valida certificado mTLS
   - Verifica authorization policy
   - Registra métricas
5. Request llega → Servidor real</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración básica en Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Inyectar sidecar automáticamente
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    istio-injection: enabled  # Inyectar Envoy sidecar

---
# Política de tráfico
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myservice
spec:
  hosts:
  - myservice
  http:
  - route:
    - destination:
        host: myservice
        port:
          number: 8080

---
# Destino con load balancing
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myservice
spec:
  host: myservice
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
        maxRequestsPerConnection: 2
  outlierDetection:
    consecutive5xxErrors: 5
    interval: 30s
    baseEjectionTime: 30s</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comparación de soluciones Service Mesh</strong></p>
</div>
<div class="paragraph">
<p>| Aspecto | Istio | Linkerd | Consul | AWS App Mesh |
|--------|-------|---------|--------|-------------|
| <strong>Proxy</strong> | Envoy | Linkerd2-proxy | Envoy | Envoy |
| <strong>Lenguaje CP</strong> | Go/C++ | Rust | Go | Proprietary |
| <strong>Curva Aprendizaje</strong> | Alta | Media | Media | Baja |
| <strong>Recursos</strong> | Altos | Bajos | Medios | Managed |
| <strong>Madurez</strong> | Muy madura | Madura | Muy madura | En desarrollo |
| <strong>Características</strong> | Completas | Ligeras | Completas | Limitadas |
| <strong>Multicluster</strong> | Nativo | Nativo | Nativo | No (solo AWS) |
| <strong>Costo</strong> | Gratuito | Gratuito | Gratuito | Por hora |</p>
</div>
<div class="paragraph">
<p><strong>Linkerd - Alternativa ligera</strong></p>
</div>
<div class="paragraph">
<p>Instalación simple:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar repositorio
helm repo add linkerd https://helm.linkerd.io
helm repo update

# Instalar Linkerd
helm install linkerd2 linkerd/linkerd2 \
  --namespace linkerd \
  --create-namespace

# Inyectar automáticamente
kubectl annotate namespace default \
  linkerd.io/inject=enabled</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Consul Service Mesh</strong></p>
</div>
<div class="paragraph">
<p>Integración con HashiCorp Consul:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Consul con Helm
helm install consul hashicorp/consul \
  --set connectInject.enabled=true \
  --set server.replicas=3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definición de tráfico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hcl hljs" data-lang="hcl">Kind = "ServiceDefaults"
Name = "api"
Protocol = "http"

---

Kind = "ServiceRouter"
Name = "api"
Routes = [
  {
    Match = {
      HTTP = {
        PathPrefix = "/v2"
      }
    }
    Destination = {
      Service = "api"
      ServiceSubset = "v2"
    }
  }
]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>AWS App Mesh</strong></p>
</div>
<div class="paragraph">
<p>Integración con AWS:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear mesh
aws appmesh create-mesh --mesh-name production

# Crear virtual node
aws appmesh create-virtual-node \
  --mesh-name production \
  --virtual-node-name api</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_istio">12.2. Istio</h3>
<div class="paragraph">
<p>Istio es el Service Mesh más popular y completo para Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Componentes de Istio</strong></p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar Istio
curl -L https://istio.io/downloadIstio | sh -
cd istio-1.17.0

# Instalar Istio
./bin/istioctl install --set profile=demo -y

# Verificar instalación
kubectl get namespaces --show-labels | grep istio
kubectl get pods -n istio-system</code></pre>
</div>
</div>
<div class="paragraph">
<p>Componentes del Control Plane:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># istiod: Componente central
# - Detecta cambios en servicios
# - Genera configuración para Envoy
# - Maneja certificados mTLS

# Instalado en namespace istio-system
# Pods: istiod-xxxxx

# Ver estado
kubectl get pods -n istio-system
kubectl logs -n istio-system deploy/istiod | tail -20</code></pre>
</div>
</div>
<div class="paragraph">
<p>Componentes del Data Plane:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Envoy sidecars:
# - Inyectados automáticamente en cada pod
# - Interceptan tráfico (inbound/outbound)
# - Aplican políticas de tráfico

# Ver sidecars inyectados
kubectl get pods -o jsonpath='{.items[].spec.containers[*].name}'

# Conectarse al sidecar
kubectl exec -it &lt;pod&gt; -c istio-proxy -- bash</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Virtual Services</strong></p>
</div>
<div class="paragraph">
<p>VirtualService define cómo encaminar el tráfico a destinos reales.</p>
</div>
<div class="paragraph">
<p>Ejemplo básico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:
  - reviews              # Nombre del servicio
  http:
  - route:
    - destination:
        host: reviews
        port:
          number: 9080
        subset: v1       # Versión específica</code></pre>
</div>
</div>
<div class="paragraph">
<p>Routing avanzado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp.example.com

  http:
  # Ruta 1: Traffic de usuarios autenticados a v2
  - match:
    - headers:
        user-type:
          exact: premium
    route:
    - destination:
        host: myapp
        subset: v2
      weight: 100
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s

  # Ruta 2: Traffic de API clients a v3
  - match:
    - headers:
        user-agent:
          prefix: "API-Client"
    route:
    - destination:
        host: myapp
        subset: v3

  # Ruta 3: Path-based routing
  - match:
    - uri:
        prefix: "/api/v1"
    route:
    - destination:
        host: myapp
        subset: v1

  # Ruta 4: Default fallback
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 80
    - destination:
        host: myapp
        subset: v2
      weight: 20</code></pre>
</div>
</div>
<div class="paragraph">
<p>Gestión de conexiones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: bookings
spec:
  hosts:
  - bookings
  http:
  - route:
    - destination:
        host: bookings
        port:
          number: 8080
    # Configuración de conexión
    timeout: 30s           # Timeout total
    retries:
      attempts: 5          # Reintentos
      perTryTimeout: 10s   # Timeout por intento</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Destination Rules</strong></p>
</div>
<div class="paragraph">
<p>DestinationRule define cómo se conecta a un host específico (load balancing, circuitbreaker, etc.).</p>
</div>
<div class="paragraph">
<p>Ejemplo básico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp              # Debe coincidir con VirtualService
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
        http2MaxRequests: 1000
        maxRequestsPerConnection: 2
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      minRequestVolume: 5
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Load Balancing con round-robin:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-lb
spec:
  host: myapp
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN   # Opciones: ROUND_ROBIN, LEAST_REQUEST, RANDOM, PASSTHROUGH

---
# LEAST_REQUEST: Envía tráfico al endpoint con menos solicitudes
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-least
spec:
  host: myapp
  trafficPolicy:
    loadBalancer:
      consistentHash:
        httpHeaderName: "user-id"    # Hash basado en header</code></pre>
</div>
</div>
<div class="paragraph">
<p>Circuit Breaker:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: failover-example
spec:
  host: db
  trafficPolicy:
    outlierDetection:
      consecutive5xxErrors: 5        # Expulsar después de 5 errores
      interval: 30s                  # Revisar cada 30s
      baseEjectionTime: 30s          # Mantener fuera 30s
      maxEjectionPercent: 100        # Sacar todos si es necesario
      minRequestVolume: 5            # Mínimo requests antes de expulsar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gateways</strong></p>
</div>
<div class="paragraph">
<p>Gateway configura un load balancer para tráfico de entrada (Ingress).</p>
</div>
<div class="paragraph">
<p>Ejemplo básico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: main-gateway
spec:
  selector:
    istio: ingressgateway    # Selector del Ingress Controller
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "example.com"
    - "*.example.com"

---
# Vincular Gateway con VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-routes
spec:
  hosts:
  - example.com
  gateways:
  - main-gateway           # Usar este gateway
  http:
  - match:
    - uri:
        prefix: "/api"
    route:
    - destination:
        host: api
        port:
          number: 8080
  - route:
    - destination:
        host: website
        port:
          number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>HTTPS/TLS:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: secure-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: mycert-secret  # Secret con cert y key
    hosts:
    - "example.com"
  # Redirigir HTTP a HTTPS
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "example.com"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Traffic Management</strong></p>
</div>
<div class="paragraph">
<p>Control granular del tráfico entre servicios.</p>
</div>
<div class="paragraph">
<p>Canary Deployment:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Desplegar dos versiones
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: v1
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0.0

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v2
spec:
  replicas: 1              # Solo 1 pod de canary
  selector:
    matchLabels:
      app: myapp
      version: v2
  template:
    metadata:
      labels:
        app: myapp
        version: v2
    spec:
      containers:
      - name: myapp
        image: myapp:v2.0.0

---
# DestinationRule con subsets
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2

---
# VirtualService: 95% a v1, 5% a v2 (canary)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 95
    - destination:
        host: myapp
        subset: v2
      weight: 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>Mirror Traffic (shadow):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-shadow
spec:
  hosts:
  - myapp
  http:
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 100
    mirror:
      host: myapp
      subset: v2            # Copiar tráfico a v2 sin afectar respuesta
    mirrorPercent: 100      # Mirror 100% del tráfico</code></pre>
</div>
</div>
<div class="paragraph">
<p>Rate Limiting con VirtualService:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: api-limiter
spec:
  hosts:
  - api.example.com
  http:
  - route:
    - destination:
        host: api
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo de tráfico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver configuración aplicada
kubectl get virtualservice
kubectl get destinationrule
kubectl get gateway

# Validar configuración
istioctl analyze

# Ver estado detallado
kubectl describe vs myapp
kubectl describe dr myapp

# Logs de Envoy
kubectl logs &lt;pod&gt; -c istio-proxy | tail -50

# Ver estadísticas de Envoy
kubectl exec -it &lt;pod&gt; -c istio-proxy -- \
  curl localhost:15000/stats/prometheus | grep myapp</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_observabilidad_con_service_mesh">12.3. Observabilidad con Service Mesh</h3>
<div class="paragraph">
<p>La observabilidad es una ventaja clave de Service Mesh, proporcionando visibilidad automática.</p>
</div>
<div class="paragraph">
<p><strong>Distributed Tracing</strong></p>
</div>
<div class="paragraph">
<p>El distributed tracing rastrea requests a través de múltiples servicios.</p>
</div>
<div class="paragraph">
<p>Instalación de Jaeger en Istio:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Jaeger con el profile
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.17/samples/addons/jaeger.yaml

# Verificar instalación
kubectl get pods -n istio-system | grep jaeger

# Acceder a Jaeger
kubectl port-forward svc/jaeger -n istio-system 16686:16686
# Navegar a http://localhost:16686</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración de tracing en Istio:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: istio
  namespace: istio-system
data:
  meshConfig: |
    enableTracing: true
    defaultConfig:
      tracing:
        sampling: 100.0         # % de requests a trackear
        zipkin:
          address: zipkin:9411  # Endpoint de Zipkin/Jaeger</code></pre>
</div>
</div>
<div class="paragraph">
<p>Propagación de contexto en aplicaciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Headers de propagación necesarios para tracing:
# jaeger:
#   - uber-trace-id
# zipkin:
#   - x-b3-trace-id
#   - x-b3-span-id
#   - x-b3-parent-span-id
#   - x-b3-sampled

# Ejemplo: curl con headers de tracing
curl -H "x-b3-trace-id: 80f198ee56343ba8" \
     -H "x-b3-span-id: e457b5a2e3d6a0e6" \
     -H "x-b3-sampled: 1" \
     http://myapp:8080/api</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instrumentación de aplicaciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Ejemplo en Python con Jaeger client
from jaeger_client import Config

def init_tracer(service_name):
    config = Config(
        config={
            'sampler': {
                'type': 'const',
                'param': 1,
            },
            'logging': True,
            'local_agent': {
                'reporting_host': 'localhost',
                'reporting_port': 6831,
            }
        },
        service_name=service_name,
        validate=True,
    )
    return config.initialize_tracer()

tracer = init_tracer('myservice')

with tracer.start_span('my-operation') as span:
    span.set_tag('http.method', 'GET')
    span.set_tag('http.url', '/api/users')
    # operación</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ejemplo en Node.js:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-javascript hljs" data-lang="javascript">const initTracer = require('jaeger-client').initTracer;

const config = {
  serviceName: 'myservice',
  sampler: {
    type: 'const',
    param: 1,
  },
  reporter_loggers: true,
};

const tracer = initTracer(config);

const span = tracer.startSpan('my-operation');
span.setTag('http.method', 'GET');
span.setTag('http.url', '/api/users');
// operación
span.finish();</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Kiali</strong></p>
</div>
<div class="paragraph">
<p>Kiali es un panel visual para Service Mesh que muestra la topología de servicios.</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Kiali
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.17/samples/addons/kiali.yaml

# Verificar instalación
kubectl get pods -n istio-system | grep kiali

# Acceder a Kiali
kubectl port-forward svc/kiali -n istio-system 20000:20000
# Navegar a http://localhost:20000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración de Kiali:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: kiali
  namespace: istio-system
data:
  kiali.yaml: |
    auth:
      strategy: anonymous          # Sin autenticación (cambiar en producción)
    external_services:
      prometheus:
        url: http://prometheus:9090
      tracing:
        enabled: true
        url: http://jaeger:16686
    service_type: ClusterIP
    web_root: /kiali</code></pre>
</div>
</div>
<div class="paragraph">
<p>Features de Kiali:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Visualización de topología de servicios</p>
</li>
<li>
<p>Métricas en tiempo real (latencia, tasa de errores)</p>
</li>
<li>
<p>Distributed tracing integrado</p>
</li>
<li>
<p>Validación de configuración</p>
</li>
<li>
<p>Health checks</p>
</li>
<li>
<p>Traffic direction y tasa de error</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Acceso programático a Kiali:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># API de Kiali
kubectl port-forward svc/kiali -n istio-system 20000:20000

# Obtener topología de servicios
curl http://localhost:20000/api/namespaces/default/services

# Obtener métricas de un servicio
curl http://localhost:20000/api/namespaces/default/services/myapp/metrics

# Obtener tráfico entre servicios
curl http://localhost:20000/api/namespaces/default/services/myapp/traffic</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Jaeger</strong></p>
</div>
<div class="paragraph">
<p>Jaeger es una plataforma completa para distributed tracing.</p>
</div>
<div class="paragraph">
<p>Componentes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌────────────┐
│  Cliente   │ → Envía spans
└────────────┘

      ↓

┌────────────────────────┐
│  Jaeger Agent          │ (localhost:6831 UDP)
│  Recibe spans locales  │
└────────────────────────┘

      ↓

┌────────────────────────┐
│  Jaeger Collector      │
│  Recibe spans remotos  │
└────────────────────────┘

      ↓

┌────────────────────────┐
│  Jaeger Query          │
│  UI y API              │
└────────────────────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instalación completa:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usando Jaeger Operator
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo update

# Instalar Jaeger
helm install jaeger jaegertracing/jaeger \
  --namespace observability \
  --create-namespace

# Verificar
kubectl get pods -n observability</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración de muestreo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Muestreo adaptativo: sample 10% de requests
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-configuration
data:
  sampling.json: |
    {
      "default_strategy": {
        "type": "probabilistic",
        "param": 0.1
      }
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p>Consultas en Jaeger:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Encontrar traces por servicio
# En UI: Service dropdown → Select myapp

# Filtrar por tags
# En UI: Add tag filter: error=true

# Buscar trazas lentas
# En UI: Min Duration: 1000ms

# API
curl 'http://localhost:16686/api/traces?service=myapp&amp;limit=10'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Métricas de Servicios</strong></p>
</div>
<div class="paragraph">
<p>Istio proporciona automáticamente métricas de Prometheus.</p>
</div>
<div class="paragraph">
<p>Instalación de Prometheus:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Prometheus
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.17/samples/addons/prometheus.yaml

# Verificar
kubectl get pods -n istio-system | grep prometheus

# Acceder
kubectl port-forward svc/prometheus -n istio-system 9090:9090
# Navegar a http://localhost:9090</code></pre>
</div>
</div>
<div class="paragraph">
<p>Métricas disponibles:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-promql hljs" data-lang="promql"># Tasa de requests por segundo
rate(istio_requests_total[1m])

# Tasa de errores (5xx)
rate(istio_requests_total{response_code=~"5.."}[1m])

# Latencia P95
histogram_quantile(0.95, rate(istio_request_duration_milliseconds_bucket[1m]))

# Tráfico por destino
sum(rate(istio_requests_total[1m])) by (destination_service_name)

# Errores por par de servicios
sum(rate(istio_requests_total{response_code=~"5.."}[1m])) by (source_app, destination_app)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instalación de Grafana:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Grafana
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.17/samples/addons/grafana.yaml

# Acceder
kubectl port-forward svc/grafana -n istio-system 3000:3000
# Navegar a http://localhost:3000 (admin/admin)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Dashboards pre-configurados:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Mesh Dashboard</strong>: Visión general del mesh</p>
</li>
<li>
<p><strong>Service Dashboard</strong>: Métricas por servicio</p>
</li>
<li>
<p><strong>Workload Dashboard</strong>: Métricas por workload</p>
</li>
<li>
<p><strong>Performance Dashboard</strong>: Performance y latencia</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Alertas con Prometheus:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: istio-alerts
spec:
  groups:
  - name: istio
    rules:
    # Alerta: Error rate &gt; 5%
    - alert: HighErrorRate
      expr: |
        rate(istio_requests_total{response_code=~"5.."}[5m]) /
        rate(istio_requests_total[5m]) &gt; 0.05
      for: 5m
      annotations:
        summary: "High error rate for {{ $labels.destination_service }}"

    # Alerta: Latencia P95 &gt; 1s
    - alert: HighLatency
      expr: |
        histogram_quantile(0.95, rate(istio_request_duration_milliseconds_bucket[5m])) &gt; 1000
      for: 5m
      annotations:
        summary: "High latency for {{ $labels.destination_service }}"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Integración con herramientas externas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Exportar métricas a Stackdriver (GCP)
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.17/samples/addons/stackdriver.yaml

# Exportar a Datadog
# Requiere Datadog agent en cluster

# Exportar a New Relic
# Requiere New Relic Kubernetes integration</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_seguridad_en_service_mesh">12.4. Seguridad en Service Mesh</h3>
<div class="paragraph">
<p>Service Mesh proporciona seguridad automática para comunicación entre servicios.</p>
</div>
<div class="paragraph">
<p><strong>mTLS Automático</strong></p>
</div>
<div class="paragraph">
<p>mTLS (Mutual TLS) encripta y autentica la comunicación entre servicios automáticamente.</p>
</div>
<div class="paragraph">
<p>Configuración de mTLS en Istio:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Habilitar mTLS para todo el namespace
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: production
spec:
  mtls:
    mode: STRICT              # STRICT, PERMISSIVE, DISABLE, UNSET</code></pre>
</div>
</div>
<div class="paragraph">
<p>Modos de mTLS:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>STRICT</strong>: Solo tráfico mTLS permitido (recomendado)</p>
</li>
<li>
<p><strong>PERMISSIVE</strong>: Permite mTLS y plaintext (para migración)</p>
</li>
<li>
<p><strong>DISABLE</strong>: Sin mTLS (solo para debugging)</p>
</li>
<li>
<p><strong>UNSET</strong>: Hereda configuración del namespace</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Ejemplo: Migración gradual a mTLS</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Fase 1: PERMISSIVE (permite ambos)
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  mtls:
    mode: PERMISSIVE

---
# Fase 2: STRICT (solo mTLS)
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  mtls:
    mode: STRICT</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración por workload:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: api-mtls
spec:
  selector:
    matchLabels:
      app: api
  mtls:
    mode: STRICT

---
# Pero permitir plaintext para health checks
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: allow-plaintext-health
spec:
  selector:
    matchLabels:
      app: api
  portLevelMtls:
    8080:              # Puerto de health checks
      mode: DISABLE
    8081:              # Puerto de aplicación
      mode: STRICT</code></pre>
</div>
</div>
<div class="paragraph">
<p>Validación de certificados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar certificados mTLS instalados
kubectl exec &lt;pod&gt; -c istio-proxy -- \
  ls -la /etc/certs/workload-cert-chain.pem

# Ver detalles del certificado
kubectl exec &lt;pod&gt; -c istio-proxy -- \
  openssl x509 -in /etc/certs/workload-cert-chain.pem -text -noout

# Probar conexión mTLS
kubectl exec &lt;client-pod&gt; -- \
  curl --cacert /etc/certs/root-cert.pem \
       --cert /etc/certs/cert-chain.pem \
       --key /etc/certs/key.pem \
       https://server:8080/api</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Authorization Policies</strong></p>
</div>
<div class="paragraph">
<p>Control de acceso basado en atributos (ABAC) entre servicios.</p>
</div>
<div class="paragraph">
<p>Política básica (permitir todo):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-all
  namespace: default
spec:
  rules:
  - {}  # Regla vacía = permitir todo</code></pre>
</div>
</div>
<div class="paragraph">
<p>Denegar todo, permitir excepciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: default-deny
spec:
  {} # Nada aquí = denegar por defecto

---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-frontend
spec:
  selector:
    matchLabels:
      app: backend
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/frontend"]
    to:
    - operation:
        methods: ["GET"]
        paths: ["/api/v1/*"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Control granular por métodos y paths:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: api-policy
spec:
  selector:
    matchLabels:
      app: api
  rules:
  # Regla 1: GET /products - público
  - to:
    - operation:
        methods: ["GET"]
        paths: ["/products"]

  # Regla 2: POST /orders - requiere usuario autenticado
  - from:
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        methods: ["POST"]
        paths: ["/orders"]

  # Regla 3: DELETE - solo admin
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/admin"]
    to:
    - operation:
        methods: ["DELETE"]
        paths: ["/admin/*"]

  # Regla 4: Entre servicios
  - from:
    - source:
        principals:
        - "cluster.local/ns/default/sa/frontend"
        - "cluster.local/ns/default/sa/mobile-app"
    to:
    - operation:
        ports: ["8080"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Denegación explícita:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-legacy-app
spec:
  selector:
    matchLabels:
      app: sensitive-data
  rules:
  - {}  # Permitir por defecto

---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-specific
spec:
  selector:
    matchLabels:
      app: sensitive-data
  action: DENY            # DENY en lugar de ALLOW
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/legacy-app"]
    to:
    - operation:
        paths: ["/sensitive/*"]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>JWT Validation</strong></p>
</div>
<div class="paragraph">
<p>Validar tokens JWT para autorización.</p>
</div>
<div class="paragraph">
<p>Configuración básica:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-auth
spec:
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"
    audiences: ["api.example.com"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Validación con cabecera personalizada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-custom-header
spec:
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"
    outputPayloadToHeader: "x-jwt-payload"  # Enviar JWT decodificado aquí</code></pre>
</div>
</div>
<div class="paragraph">
<p>Múltiples issuers:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-multi-issuer
spec:
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"
  - issuer: "https://oauth.github.com"
    jwksUri: "https://github.com/login/oauth/access_token"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Combinación con AuthorizationPolicy:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Autenticar JWT
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-auth
spec:
  selector:
    matchLabels:
      app: api
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"

---
# 2. Autorizar basado en claims JWT
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: jwt-authz
spec:
  selector:
    matchLabels:
      app: api
  rules:
  # Admin: cualquier método
  - from:
    - source:
        requestPrincipals: ["https://auth.example.com/admin"]
    to:
    - operation:
        paths: ["/admin/*"]

  # Usuario normal: solo GET
  - from:
    - source:
        requestPrincipals: ["https://auth.example.com/user"]
    to:
    - operation:
        methods: ["GET"]

  # Custom claim: premium users
  - from:
    - source:
        requestPrincipals: ["*"]
    when:
    - key: request.auth.claims[tier]
      values: ["premium"]
    to:
    - operation:
        paths: ["/api/premium/*"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Debugging de seguridad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver policies aplicadas
kubectl get authorizationpolicies -A

# Validar policy
istioctl analyze -A

# Ver logs de denegación
kubectl logs &lt;pod&gt; -c istio-proxy | grep DENIED

# Monitoreo de tráfico denegado
kubectl exec -it &lt;pod&gt; -c istio-proxy -- \
  curl localhost:15000/stats/prometheus | grep denied</code></pre>
</div>
</div>
<div class="paragraph">
<p>Best practices de seguridad:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Habilitar mTLS STRICT</strong>: Encripción automática de tráfico</p>
</li>
<li>
<p><strong>Default deny, allow exceptions</strong>: Principio de mínimos privilegios</p>
</li>
<li>
<p><strong>Usar service accounts</strong>: Identificar servicios automáticamente</p>
</li>
<li>
<p><strong>Validar JWT</strong>: Tokens deben ser validados</p>
</li>
<li>
<p><strong>Registrar accesos denegados</strong>: Auditoría de intentos fallidos</p>
</li>
<li>
<p><strong>Certificados rotados</strong>: Istio lo hace automáticamente</p>
</li>
<li>
<p><strong>Segregación por namespace</strong>: Aislar por entorno/equipo</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ejemplo completo de seguridad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Habilitar mTLS STRICT
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  mtls:
    mode: STRICT

---
# 2. Denegar todo por defecto
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: default-deny
spec:
  {}

---
# 3. Permitir frontend → backend
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-frontend-to-backend
spec:
  selector:
    matchLabels:
      app: backend
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/frontend"]

---
# 4. Autenticar JWT para API
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: api-jwt
spec:
  selector:
    matchLabels:
      app: api
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"

---
# 5. Autorizar acceso a API
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: api-authz
spec:
  selector:
    matchLabels:
      app: api
  rules:
  - from:
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        methods: ["GET"]</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_13_operaciones_avanzadas">13. Módulo 13: Operaciones Avanzadas</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_cluster_management">13.1. Cluster Management</h3>
<div class="paragraph">
<p><strong>Actualizaciones de Cluster</strong></p>
</div>
<div class="paragraph">
<p>Actualizar Kubernetes sin downtime requiere planificación cuidadosa.</p>
</div>
<div class="paragraph">
<p>Estrategia de actualización:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Planificación
   - Revisar notas de cambio (release notes)
   - Verificar compatibilidad de aplicaciones
   - Backup previo

2. Actualización del Control Plane
   - Actualizar API Server
   - Actualizar Controller Manager
   - Actualizar Scheduler
   - Actualizar etcd

3. Actualización de Nodos
   - Cordon (marcar como no schedulable)
   - Drain (evacuar pods)
   - Actualizar kubelet
   - Uncordon (volver a schedulable)

4. Validación
   - Verificar salud del cluster
   - Revisar logs
   - Pruebas de funcionalidad</code></pre>
</div>
</div>
<div class="paragraph">
<p>Actualización con kubeadm:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar qué versión está disponible
kubeadm upgrade plan

# 2. Actualizar kubeadm en el nodo control plane
apt-get update &amp;&amp; apt-get install -y kubeadm=1.27.0-00

# 3. Planificar actualización
kubeadm upgrade plan v1.27.0

# 4. Aplicar actualización
kubeadm upgrade apply v1.27.0

# 5. Actualizar kubelet en control plane
apt-get install -y kubelet=1.27.0-00 kubectl=1.27.0-00
systemctl daemon-reload
systemctl restart kubelet

# 6. Actualizar nodos worker
for node in worker1 worker2 worker3; do
  kubectl cordon $node
  kubectl drain $node --ignore-daemonsets --delete-emptydir-data
  # SSH al nodo y ejecutar:
  # apt-get install -y kubelet=1.27.0-00
  # systemctl restart kubelet
  kubectl uncordon $node
done</code></pre>
</div>
</div>
<div class="paragraph">
<p>Actualización en cluster managed (EKS/GKE/AKS):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># AWS EKS
aws eks update-cluster-version \
  --name my-cluster \
  --kubernetes-version 1.27

# Google GKE
gcloud container clusters upgrade my-cluster \
  --master-pool-name default-pool \
  --cluster-version 1.27

# Azure AKS
az aks upgrade \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --kubernetes-version 1.27</code></pre>
</div>
</div>
<div class="paragraph">
<p>Verificación post-actualización:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Verificar versión
kubectl version

# Verificar componentes
kubectl get nodes
kubectl get cs
kubectl get componentstatus

# Verificar pods del sistema
kubectl get pods -n kube-system

# Revisar logs
journalctl -u kubelet -n 50</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Backup y Restore</strong></p>
</div>
<div class="paragraph">
<p>Proteger datos críticos del cluster.</p>
</div>
<div class="paragraph">
<p>Herramientas de backup:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Velero</strong>: Solución completa de backup</p>
</li>
<li>
<p><strong>etcd backup</strong>: Backup manual del almacenamiento</p>
</li>
<li>
<p><strong>Application-level</strong>: Backups dentro de la aplicación</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Backup de etcd:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Snapshot de etcd
ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save /backup/etcd-snapshot.db

# Verificar snapshot
ETCDCTL_API=3 etcdctl \
  snapshot status /backup/etcd-snapshot.db

# Restaurar snapshot
ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot restore /backup/etcd-snapshot.db \
  --data-dir=/var/lib/etcd-backup</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instalación de Velero:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar Velero
wget https://github.com/vmware-tanzu/velero/releases/download/v1.11.0/velero-v1.11.0-linux-amd64.tar.gz
tar -xzf velero-v1.11.0-linux-amd64.tar.gz
sudo mv velero-v1.11.0-linux-amd64/velero /usr/local/bin/

# Instalar Velero en cluster (con AWS S3)
velero install \
  --provider aws \
  --bucket velero-backups \
  --secret-file ./credentials-velero \
  --plugins velero/velero-plugin-for-aws:v1.7.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Crear backups con Velero:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Backup completo
velero backup create full-backup

# Backup de namespace específico
velero backup create prod-backup \
  --include-namespaces production

# Backup con schedule
velero schedule create daily-backup \
  --schedule="0 2 * * *" \
  --include-namespaces production

# Ver backups
velero backup get
velero backup describe full-backup
velero backup logs full-backup</code></pre>
</div>
</div>
<div class="paragraph">
<p>Restaurar desde backup:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Restaurar backup completo
velero restore create \
  --from-backup full-backup

# Restaurar namespace específico
velero restore create \
  --from-backup prod-backup \
  --include-namespaces production

# Ver restauraciones
velero restore get
velero restore logs full-backup-20231115123456</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Disaster Recovery</strong></p>
</div>
<div class="paragraph">
<p>Plan de recuperación ante fallos.</p>
</div>
<div class="paragraph">
<p>RTO (Recovery Time Objective) y RPO (Recovery Point Objective):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">RTO: Tiempo máximo para recuperación (e.g., 4 horas)
RPO: Máximo tiempo de pérdida de datos (e.g., 1 hora)

Estrategia:
- RTO bajo → Replicación activa, multi-región
- RPO bajo → Backups frecuentes
- Ambos bajos → Caro, requiere múltiples regiones</code></pre>
</div>
</div>
<div class="paragraph">
<p>DR con múltiples clusters:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cluster primario - namespace
apiVersion: v1
kind: Namespace
metadata:
  name: production

---
# Backup automático en cluster secundario
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: auto-backup
spec:
  schedule: "0 */6 * * *"  # Cada 6 horas
  includedNamespaces:
  - production
  storageLocation: aws-s3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Testing de DR:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear backup de cluster primario
velero backup create pre-disaster-backup

# 2. Simular fallo - restaurar en cluster secundario
# Apuntar kubeconfig al cluster secundario
kubectl config use-context secondary-cluster

# 3. Restaurar aplicación
velero restore create \
  --from-backup pre-disaster-backup

# 4. Validar que funciona
kubectl get all -n production
# Pruebas de funcionalidad

# 5. Replicar tráfico a secundario
# Cambiar DNS/Load balancer</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Multi-cluster Management</strong></p>
</div>
<div class="paragraph">
<p>Gestionar múltiples clusters Kubernetes.</p>
</div>
<div class="paragraph">
<p>Herramientas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Helm</strong>: Desplegar aplicaciones en múltiples clusters</p>
</li>
<li>
<p><strong>Flux/ArgoCD</strong>: GitOps en múltiples clusters</p>
</li>
<li>
<p><strong>Karmada</strong>: Control plane multi-cluster nativo</p>
</li>
<li>
<p><strong>Rancher</strong>: Platform multi-cluster</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Deplyment multi-cluster con Helm:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Agregar contextos
kubectl config use-context cluster1
helm install myapp ./chart --namespace production

kubectl config use-context cluster2
helm install myapp ./chart --namespace production

kubectl config use-context cluster3
helm install myapp ./chart --namespace production</code></pre>
</div>
</div>
<div class="paragraph">
<p>GitOps multi-cluster con ArgoCD:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cluster 1 (primario)
apiVersion: v1
kind: Namespace
metadata:
  name: argocd

---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-cluster1
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/myorg/config
    targetRevision: main
    path: clusters/cluster1
  destination:
    server: https://kubernetes.default.svc
    namespace: production

---
# Cluster 2 (secundario)
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-cluster2
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/myorg/config
    targetRevision: main
    path: clusters/cluster2
  destination:
    server: https://cluster2-api.example.com:6443
    namespace: production</code></pre>
</div>
</div>
<div class="paragraph">
<p>Karmada - Control plane unificado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Karmada
git clone https://github.com/karmada-io/karmada.git
cd karmada
hack/local-up-karmada.sh

# Registrar clusters
karmadactl join cluster1 --cluster-kubeconfig=/path/to/cluster1.conf
karmadactl join cluster2 --cluster-kubeconfig=/path/to/cluster2.conf

# Crear PropagationPolicy (distribuir a múltiples clusters)
cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: policy.karmada.io/v1alpha1
kind: PropagationPolicy
metadata:
  name: multi-cluster-deployment
spec:
  resourceSelectors:
  - apiVersion: apps/v1
    kind: Deployment
    name: myapp
  placement:
    clusterAffinity:
      clusterNames:
      - cluster1
      - cluster2
      - cluster3
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo multi-cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Prometheus federado - scrapar de múltiples clusters
global:
  scrape_interval: 15s

scrape_configs:
- job_name: 'cluster1'
  kubernetes_sd_configs:
  - api_server: https://cluster1-api.example.com:6443
    tls_config:
      ca_file: /etc/prometheus/cluster1-ca.crt

- job_name: 'cluster2'
  kubernetes_sd_configs:
  - api_server: https://cluster2-api.example.com:6443
    tls_config:
      ca_file: /etc/prometheus/cluster2-ca.crt</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_custom_resources_crd">13.2. Custom Resources (CRD)</h3>
<div class="paragraph">
<p>Los Custom Resource Definitions (CRDs) permiten extender la API de Kubernetes con nuevos tipos de recursos.</p>
</div>
<div class="paragraph">
<p><strong>Definición de CRDs</strong></p>
</div>
<div class="paragraph">
<p>Crear un tipo de recurso personalizado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: websites.mycompany.io      # nombre debe ser &lt;plural&gt;.&lt;group&gt;
spec:
  group: mycompany.io              # API group
  scope: Namespaced                # Namespaced o Cluster
  names:
    plural: websites
    singular: website
    kind: Website                  # PascalCase
    shortNames:
    - ws                          # kubectl get ws
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            required:
            - domain
            - owner
            properties:
              domain:
                type: string
                description: "Domain name of website"
                pattern: '^[a-z0-9\-]+\.[a-z]+$'
              owner:
                type: string
              replicas:
                type: integer
                minimum: 1
                maximum: 10
              ssl:
                type: boolean
                default: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Usar el CRD:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear instancia del CRD
cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: mycompany.io/v1
kind: Website
metadata:
  name: my-blog
spec:
  domain: myblog.com
  owner: john@example.com
  replicas: 3
  ssl: true
EOF

# Listar recursos personalizados
kubectl get websites
kubectl get ws

# Ver detalles
kubectl describe website my-blog

# Editar
kubectl edit website my-blog

# Eliminar
kubectl delete website my-blog</code></pre>
</div>
</div>
<div class="paragraph">
<p>Validación de CRDs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: databases.example.io
spec:
  group: example.io
  scope: Namespaced
  names:
    plural: databases
    kind: Database
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            required:
            - engine
            - size
            properties:
              engine:
                type: string
                enum:
                - postgresql
                - mysql
                - mongodb
              size:
                type: string
                pattern: '^[0-9]+Gi$'
              backup:
                type: object
                properties:
                  enabled:
                    type: boolean
                  frequency:
                    type: string
                    enum:
                    - hourly
                    - daily
                    - weekly</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Custom Controllers</strong></p>
</div>
<div class="paragraph">
<p>Un controller observa recursos y realiza acciones.</p>
</div>
<div class="paragraph">
<p>Ejemplo simple de controller en Python:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#!/usr/bin/env python3
from kubernetes import client, config, watch
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cargar configuración del cluster
config.load_incluster_config()

# Crear cliente de Kubernetes
v1 = client.CustomObjectsApi()

# Definir CRD
GROUP = "mycompany.io"
VERSION = "v1"
NAMESPACE = "default"
PLURAL = "websites"

def create_deployment_for_website(website):
    """Crear deployment cuando se crea un Website"""
    name = website['metadata']['name']
    domain = website['spec']['domain']
    replicas = website['spec'].get('replicas', 1)

    deployment = {
        'apiVersion': 'apps/v1',
        'kind': 'Deployment',
        'metadata': {
            'name': f'{name}-deployment',
            'namespace': NAMESPACE,
            'ownerReferences': [{
                'apiVersion': 'mycompany.io/v1',
                'kind': 'Website',
                'name': name,
                'uid': website['metadata']['uid']
            }]
        },
        'spec': {
            'replicas': replicas,
            'selector': {'matchLabels': {'app': name}},
            'template': {
                'metadata': {'labels': {'app': name}},
                'spec': {
                    'containers': [{
                        'name': 'nginx',
                        'image': 'nginx:latest',
                        'env': [{
                            'name': 'DOMAIN',
                            'value': domain
                        }]
                    }]
                }
            }
        }
    }

    return deployment

def watch_websites():
    """Observar cambios en Website resources"""
    w = watch.Watch()

    for event in w.stream(
        v1.list_namespaced_custom_object,
        GROUP, VERSION, NAMESPACE, PLURAL,
        _preload_content=False
    ):
        website = event['object']
        event_type = event['type']
        name = website['metadata']['name']

        logger.info(f"Event: {event_type} on {name}")

        if event_type == 'ADDED':
            # Crear deployment
            deployment = create_deployment_for_website(website)
            logger.info(f"Creating deployment for {name}")
            # Enviar deployment a API

        elif event_type == 'MODIFIED':
            logger.info(f"Updated {name}")

        elif event_type == 'DELETED':
            logger.info(f"Deleted {name}")

if __name__ == '__main__':
    watch_websites()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Operators</strong></p>
</div>
<div class="paragraph">
<p>Un Operator combina CRDs + Controllers para automatizar tareas complejas.</p>
</div>
<div class="paragraph">
<p>Estructura de un Operator:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">my-operator/
├── config/
│   ├── crd/
│   │   └── database_crd.yaml
│   ├── rbac/
│   │   ├── role.yaml
│   │   ├── rolebinding.yaml
│   │   └── serviceaccount.yaml
│   └── manager/
│       └── manager.yaml
├── api/
│   └── v1/
│       ├── database_types.go
│       └── groupversion_info.go
├── controllers/
│   └── database_controller.go
├── main.go
└── Dockerfile</code></pre>
</div>
</div>
<div class="paragraph">
<p>Permisos RBAC para Operator:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-operator

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-operator-role
rules:
# Permisos para el CRD
- apiGroups: ["mycompany.io"]
  resources: ["databases"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permisos para Deployments
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permisos para Services
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permisos para StatefulSets
- apiGroups: ["apps"]
  resources: ["statefulsets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permisos para Secrets
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-operator-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-operator-role
subjects:
- kind: ServiceAccount
  name: my-operator
  namespace: operators</code></pre>
</div>
</div>
<div class="paragraph">
<p>Desplegar Operator:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear namespace
kubectl create namespace operators

# Instalar CRD
kubectl apply -f config/crd/database_crd.yaml

# Crear RBAC
kubectl apply -f config/rbac/ -n operators

# Desplegar Operator
kubectl apply -f config/manager/manager.yaml -n operators

# Verificar
kubectl get pods -n operators
kubectl logs -f deployment/my-operator-controller -n operators</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Operator Framework</strong></p>
</div>
<div class="paragraph">
<p>Kubebuilder simplifica la creación de Operators.</p>
</div>
<div class="paragraph">
<p>Crear proyecto Kubebuilder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Kubebuilder
curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH)
chmod +x kubebuilder
sudo mv kubebuilder /usr/local/bin/

# Crear proyecto
kubebuilder init --domain mycompany.io --repo github.com/mycompany/my-operator

# Crear API (CRD + Controller)
kubebuilder create api \
  --group databases \
  --version v1 \
  --kind Database \
  --resource --controller</code></pre>
</div>
</div>
<div class="paragraph">
<p>Estructura generada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">config/
├── crd/
├── rbac/
├── manager/
└── samples/

api/v1/
├── database_types.go
└── groupversion_info.go

controllers/
└── database_controller.go

main.go
Dockerfile</code></pre>
</div>
</div>
<div class="paragraph">
<p>Definir el tipo de recurso (api/v1/database_types.go):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-go hljs" data-lang="go">package v1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

type DatabaseSpec struct {
	Engine   string `json:"engine"`
	Size     string `json:"size"`
	Backup   bool   `json:"backup,omitempty"`
	Replicas int32  `json:"replicas,omitempty"`
}

type DatabaseStatus struct {
	Phase     string `json:"phase,omitempty"`
	Ready     bool   `json:"ready,omitempty"`
	Endpoint  string `json:"endpoint,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
type Database struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec   DatabaseSpec   `json:"spec,omitempty"`
	Status DatabaseStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true
type DatabaseList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Database `json:"items"`
}

func init() {
	SchemeBuilder.Register(&amp;Database{}, &amp;DatabaseList{})
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Implementar el Controller (controllers/database_controller.go):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-go hljs" data-lang="go">package controllers

import (
	"context"
	"github.com/mycompany/my-operator/api/v1"
	corev1 "k8s.io/api/core/v1"
	appsv1 "k8s.io/api/apps/v1"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

type DatabaseReconciler struct {
	client.Client
}

// +kubebuilder:rbac:groups=databases.mycompany.io,resources=databases,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups="",resources=services,verbs=get;list;watch;create;update;patch;delete

func (r *DatabaseReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	// Obtener Database
	var db v1.Database
	if err := r.Get(ctx, req.NamespacedName, &amp;db); err != nil {
		return ctrl.Result{}, client.IgnoreNotFound(err)
	}

	// Crear/actualizar Deployment
	deployment := &amp;appsv1.Deployment{}
	if err := r.Get(ctx, req.NamespacedName, deployment); err != nil {
		// No existe, crear nuevo
		deployment = r.constructDeployment(&amp;db)
		if err := r.Create(ctx, deployment); err != nil {
			return ctrl.Result{}, err
		}
	}

	// Actualizar status
	db.Status.Phase = "Running"
	db.Status.Ready = true
	db.Status.Endpoint = db.Name + ".default.svc.cluster.local"

	if err := r.Status().Update(ctx, &amp;db); err != nil {
		return ctrl.Result{}, err
	}

	return ctrl.Result{}, nil
}

func (r *DatabaseReconciler) constructDeployment(db *v1.Database) *appsv1.Deployment {
	// Lógica para crear Deployment basado en Database spec
	replicas := int32(1)
	if db.Spec.Replicas &gt; 0 {
		replicas = db.Spec.Replicas
	}

	deployment := &amp;appsv1.Deployment{}
	deployment.Name = db.Name
	deployment.Namespace = db.Namespace
	deployment.Spec.Replicas = &amp;replicas
	// ... más configuración

	return deployment
}

func (r *DatabaseReconciler) SetupWithManager(mgr ctrl.Manager) error {
	return ctrl.NewControllerManagedBy(mgr).
		For(&amp;v1.Database{}).
		Owns(&amp;appsv1.Deployment{}).
		Complete(r)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Compilar y ejecutar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Hacer test
make test

# Generar manifests
make manifests

# Compilar imagen Docker
make docker-build docker-push IMG=myregistry/my-operator:v0.1.0

# Desplegar
make deploy IMG=myregistry/my-operator:v0.1.0

# Crear instancia
kubectl apply -f config/samples/databases_v1_database.yaml

# Ver en acción
kubectl logs -f deployment/my-operator-controller -n my-operator-system</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_admission_controllers">13.3. Admission Controllers</h3>
<div class="paragraph">
<p>Los Admission Controllers interceptan y validan/modifican requests a la API de Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Validating Webhooks</strong></p>
</div>
<div class="paragraph">
<p>Validan requests y rechazan si no cumplen políticas.</p>
</div>
<div class="paragraph">
<p>Crear validating webhook:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-go hljs" data-lang="go">package main

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"

	admissionv1 "k8s.io/api/admission/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

func handleValidate(w http.ResponseWriter, r *http.Request) {
	body, _ := io.ReadAll(r.Body)
	admissionReview := admissionv1.AdmissionReview{}
	json.Unmarshal(body, &amp;admissionReview)

	var pod corev1.Pod
	json.Unmarshal(admissionReview.Request.Object.Raw, &amp;pod)

	allowed := true
	message := ""

	// Validación: Pod debe tener resource limits
	for _, container := range pod.Spec.Containers {
		if container.Resources.Limits == nil {
			allowed = false
			message = "Container must have resource limits"
			break
		}
	}

	// Validación: Pod debe tener probes
	for _, container := range pod.Spec.Containers {
		if container.LivenessProbe == nil {
			allowed = false
			message = "Container must have liveness probe"
			break
		}
	}

	admissionResponse := &amp;admissionv1.AdmissionResponse{
		UID:     admissionReview.Request.UID,
		Allowed: allowed,
		Result: &amp;metav1.Status{
			Message: message,
		},
	}

	responseReview := admissionv1.AdmissionReview{
		TypeMeta: metav1.TypeMeta{
			APIVersion: "admission.k8s.io/v1",
			Kind:       "AdmissionReview",
		},
		Response: admissionResponse,
	}

	respBytes, _ := json.Marshal(responseReview)
	w.Header().Set("Content-Type", "application/json")
	w.Write(respBytes)
}

func main() {
	http.HandleFunc("/validate", handleValidate)
	http.ListenAndServeTLS(":8443", "/etc/webhook/certs/tls.crt", "/etc/webhook/certs/tls.key", nil)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Registrar validating webhook:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: pod-validator
webhooks:
- name: pod-validator.example.com
  clientConfig:
    service:
      name: webhook-service
      namespace: default
      path: "/validate"
    caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN...
  rules:
  - operations: ["CREATE", "UPDATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  admissionReviewVersions: ["v1"]
  sideEffects: None
  failurePolicy: Fail       # Fail = rechazar si webhook no responde</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Mutating Webhooks</strong></p>
</div>
<div class="paragraph">
<p>Modifican requests antes de guardarlos.</p>
</div>
<div class="paragraph">
<p>Ejemplo: Inyectar sidecar automáticamente</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-go hljs" data-lang="go">package main

import (
	"encoding/json"
	"io"
	"net/http"

	admissionv1 "k8s.io/api/admission/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

func handleMutate(w http.ResponseWriter, r *http.Request) {
	body, _ := io.ReadAll(r.Body)
	admissionReview := admissionv1.AdmissionReview{}
	json.Unmarshal(body, &amp;admissionReview)

	var pod corev1.Pod
	json.Unmarshal(admissionReview.Request.Object.Raw, &amp;pod)

	// Agregar sidecar
	sidecar := corev1.Container{
		Name:  "istio-proxy",
		Image: "istio/proxyv2:latest",
	}

	// Crear patch
	patch := []map[string]interface{}{
		{
			"op":    "add",
			"path":  "/spec/containers/-",
			"value": sidecar,
		},
	}

	patchBytes, _ := json.Marshal(patch)

	admissionResponse := &amp;admissionv1.AdmissionResponse{
		UID:     admissionReview.Request.UID,
		Allowed: true,
		Patch:   patchBytes,
		PatchType: func() *admissionv1.PatchType {
			pt := admissionv1.PatchTypeJSONPatch
			return &amp;pt
		}(),
	}

	responseReview := admissionv1.AdmissionReview{
		TypeMeta: metav1.TypeMeta{
			APIVersion: "admission.k8s.io/v1",
			Kind:       "AdmissionReview",
		},
		Response: admissionResponse,
	}

	respBytes, _ := json.Marshal(responseReview)
	w.Header().Set("Content-Type", "application/json")
	w.Write(respBytes)
}

func main() {
	http.HandleFunc("/mutate", handleMutate)
	http.ListenAndServeTLS(":8443", "/etc/webhook/certs/tls.crt", "/etc/webhook/certs/tls.key", nil)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Registrar mutating webhook:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: pod-injector
webhooks:
- name: pod-injector.example.com
  clientConfig:
    service:
      name: webhook-service
      namespace: default
      path: "/mutate"
    caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN...
  rules:
  - operations: ["CREATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  admissionReviewVersions: ["v1"]
  sideEffects: None
  failurePolicy: Ignore    # Ignore = permitir si webhook falla</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>OPA (Open Policy Agent)</strong></p>
</div>
<div class="paragraph">
<p>Motor de políticas agnóstico que funciona con Kubernetes.</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar OPA
curl https://openpolicyagent.org/downloads/latest/opa_linux_amd64 -Lo opa
chmod +x opa

# Iniciar OPA como servidor
opa run -s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Política OPA (Rego):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-rego hljs" data-lang="rego"># policies/pod_policy.rego

package kubernetes.admission

deny[msg] {
    input.request.kind.kind == "Pod"
    container := input.request.object.spec.containers[_]
    not container.resources.limits
    msg := sprintf("Container '%v' must have resource limits", [container.name])
}

deny[msg] {
    input.request.kind.kind == "Pod"
    container := input.request.object.spec.containers[_]
    not container.livenessProbe
    msg := sprintf("Container '%v' must have liveness probe", [container.name])
}

deny[msg] {
    input.request.kind.kind == "Pod"
    image := input.request.object.spec.containers[_].image
    not startswith(image, "gcr.io/")
    msg := sprintf("Image '%v' must be from approved registry (gcr.io)", [image])
}

allow {
    count(deny) == 0
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Integración de OPA con Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Compilar política
opa build -b policies/

# Registrar en cluster
kubectl create configmap opa-policy \
  --from-file=pod_policy.rego \
  -n opa

# Crear ValidatingWebhookConfiguration que use OPA
kubectl apply -f - &lt;&lt;EOF
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: opa-validator
webhooks:
- name: opa.example.com
  clientConfig:
    url: https://opa:8443/v1/data/kubernetes/admission
    caBundle: ...
  rules:
  - operations: ["CREATE", "UPDATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  admissionReviewVersions: ["v1"]
  sideEffects: None
  failurePolicy: Fail
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Kyverno</strong></p>
</div>
<div class="paragraph">
<p>Política de Kubernetes nativa (alternativa más simple a OPA).</p>
</div>
<div class="paragraph">
<p>Instalación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Kyverno
helm repo add kyverno https://kyverno.github.io/kyverno/
helm install kyverno kyverno/kyverno \
  --namespace kyverno \
  --create-namespace</code></pre>
</div>
</div>
<div class="paragraph">
<p>Política: Validar que los pods tengan resource limits</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-requests-limits
spec:
  validationFailureAction: audit  # audit o enforce
  rules:
  - name: check-container-limits
    match:
      resources:
        kinds:
        - Pod
    validate:
      message: "CPU and memory limits required"
      pattern:
        spec:
          containers:
          - resources:
              limits:
                memory: "?*"
                cpu: "?*"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Política: Requerir imágenes de registro específico</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-registry
spec:
  validationFailureAction: enforce
  rules:
  - name: validate-image-registry
    match:
      resources:
        kinds:
        - Pod
    validate:
      message: "Image must be from approved registries"
      pattern:
        spec:
          containers:
          - image: "gcr.io/* | docker.io/* | quay.io/*"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Política: Mutar (agregar labels)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: add-labels
spec:
  rules:
  - name: add-app-label
    match:
      resources:
        kinds:
        - Pod
    mutate:
      patchStrategicMerge:
        metadata:
          labels:
            managed-by: kyverno
            policy-version: "1.0"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Política: Denegar pods privilegiados</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: restrict-privileged-containers
spec:
  validationFailureAction: enforce
  rules:
  - name: privileged
    match:
      resources:
        kinds:
        - Pod
    validate:
      message: "Privileged containers not allowed"
      pattern:
        spec:
          containers:
          - securityContext:
              privileged: false

  - name: capabilities
    match:
      resources:
        kinds:
        - Pod
    validate:
      message: "Dangerous capabilities not allowed"
      pattern:
        spec:
          containers:
          - securityContext:
                capabilities:
                  drop:
                  - ALL</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo de políticas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver políticas
kubectl get clusterpolicies
kubectl get policies -A

# Auditar violaciones (en modo audit)
kubectl get policyreport -A

# Detalle de violación
kubectl describe policyreport -n default

# Logs de Kyverno
kubectl logs -n kyverno deploy/kyverno -f</code></pre>
</div>
</div>
<div class="paragraph">
<p>Comparación: OPA vs Kyverno</p>
</div>
<div class="paragraph">
<p>| Aspecto | OPA | Kyverno |
|---------|-----|---------|
| <strong>Lenguaje</strong> | Rego | YAML |
| <strong>Curva aprendizaje</strong> | Alta | Baja |
| <strong>Complejidad</strong> | Alta | Media |
| <strong>Agnóstico</strong> | Sí | Solo K8s |
| <strong>Rendimiento</strong> | Muy rápido | Rápido |
| <strong>Ecosistema</strong> | Grande | Creciente |
| <strong>Mejor para</strong> | Políticas complejas | Políticas simples |</p>
</div>
</div>
<div class="sect2">
<h3 id="_api_server_2">13.4. API Server</h3>
<div class="paragraph">
<p>El API Server es el centro de Kubernetes. Entender su gestión es crítico para operaciones avanzadas.</p>
</div>
<div class="paragraph">
<p><strong>API Versioning</strong></p>
</div>
<div class="paragraph">
<p>Kubernetes mantiene múltiples versiones de la API para compatibilidad.</p>
</div>
<div class="paragraph">
<p>Tipos de versiones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Alpha:  v1alpha1, v1alpha2     - Experimental, cambios frecuentes
Beta:   v1beta1, v1beta2       - Casi estable, cambios menores
Stable: v1, v2, etc            - Versión de producción</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ejemplo de CRD con múltiples versiones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: databases.example.io
spec:
  group: example.io
  scope: Namespaced
  names:
    plural: databases
    kind: Database
  versions:
  # Versión antigua (beta)
  - name: v1beta1
    served: true
    storage: false
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              engine:
                type: string
              replicas:
                type: integer
  # Versión nueva (stable)
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              engine:
                type: string
              replicas:
                type: integer
              backup:           # Campo nuevo en v1
                type: object
  # Conversión entre versiones
  conversion:
    strategy: Webhook
    webhook:
      clientConfig:
        service:
          name: conversion-webhook
          namespace: default
          path: /convert
      conversionReviewVersions: ["v1"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Estrategia de versiones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Paso 1: Introducir versión nueva, mantener vieja
        - v1beta1 (served: true, storage: true)
        - v2beta1 (served: true, storage: false)

Paso 2: Cambiar storage a nueva versión
        - v1beta1 (served: true, storage: false)
        - v2beta1 (served: true, storage: true)

Paso 3: Eliminar versión vieja
        - v2beta1 (served: true, storage: true)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ver versiones soportadas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver versiones API
kubectl api-versions

# Ver recursos en una versión
kubectl api-resources --api-group apps

# Información detallada
kubectl get apiservice</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>API Deprecation</strong></p>
</div>
<div class="paragraph">
<p>Remover versiones de forma segura.</p>
</div>
<div class="paragraph">
<p>Anunciar deprecation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: databases.example.io
spec:
  group: example.io
  names:
    plural: databases
    kind: Database
  versions:
  # Versión deprecada
  - name: v1alpha1
    served: true
    storage: false
    deprecated: true           # Marcar como deprecada
    deprecationWarning: "v1alpha1 is deprecated, use v1 instead"
    schema:
      openAPIV3Schema:
        type: object
  # Versión recomendada
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object</code></pre>
</div>
</div>
<div class="paragraph">
<p>Kubernetes mantiene un horario de deprecation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Kubernetes 1.18: Funcionalidad marcada como deprecated
Kubernetes 1.19: Última versión que sirve versión deprecated
Kubernetes 1.20: Versión deprecated removida</code></pre>
</div>
</div>
<div class="paragraph">
<p>Checar deprecations:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver políticas de deprecación
kubectl api-resources --deprecated

# Logs de advertencia al usar recurso deprecated
kubectl apply -f old-api.yaml
# Warning: Detected deprecated API object: &lt;kind&gt; ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Herramientas de migración:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># kubepug: analiza manifests en busca de APIs deprecated
wget https://github.com/rikatz/kubepug/releases/download/v1.5.1/kubepug_linux_amd64
chmod +x kubepug_linux_amd64

./kubepug_linux_amd64 --input-file=manifest.yaml --k8s-version v1.22.0

# Resultado: advertencias sobre APIs deprecated</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Custom API Aggregation</strong></p>
</div>
<div class="paragraph">
<p>Extender la API de Kubernetes con servicios customizados.</p>
</div>
<div class="paragraph">
<p>Caso de uso: Crear una API personalizada que vive dentro de Kubernetes.</p>
</div>
<div class="paragraph">
<p>Crear servicio de API customizada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-go hljs" data-lang="go">package main

import (
	"encoding/json"
	"net/http"

	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apiserver/pkg/endpoints/handlers"
	"k8s.io/apiserver/pkg/endpoints/handlers/responsewriters"
)

type Widget struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              WidgetSpec `json:"spec,omitempty"`
}

type WidgetSpec struct {
	Name  string `json:"name"`
	Color string `json:"color"`
}

type WidgetList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Widget `json:"items"`
}

var widgets = []Widget{
	{
		ObjectMeta: metav1.ObjectMeta{Name: "widget1"},
		Spec: WidgetSpec{Name: "Widget 1", Color: "red"},
	},
}

func handleGetWidgets(w http.ResponseWriter, r *http.Request) {
	widgetList := &amp;WidgetList{
		Items: widgets,
	}
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(widgetList)
}

func handleGetWidget(w http.ResponseWriter, r *http.Request) {
	name := r.URL.Query().Get("name")
	for _, widget := range widgets {
		if widget.Name == name {
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(widget)
			return
		}
	}
	http.NotFound(w, r)
}

func main() {
	http.HandleFunc("/apis/example.io/v1/widgets", handleGetWidgets)
	http.HandleFunc("/apis/example.io/v1/widgets/", handleGetWidget)
	http.ListenAndServe(":8443", nil)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Registrar API aggregada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1.example.io
spec:
  # Versión que se sirve
  version: v1
  # Grupo de la API
  group: example.io
  # Dónde encontrar esta API
  service:
    name: my-api-service
    namespace: default
    port: 443
  # Certificado CA del servicio
  caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN...
  # Insecuro en desarrollo
  insecureSkipTLSVerify: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Usar API agregada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Una vez registrada, aparece en api-versions
kubectl api-versions | grep example.io
example.io/v1

# Acceder a través de kubectl
kubectl get widgets

# A través de API REST
curl https://kubernetes:6443/apis/example.io/v1/widgets \
  --cert client.crt \
  --key client.key \
  --cacert ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ejemplo completo con deployment:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: custom-api

---
apiVersion: v1
kind: Service
metadata:
  name: my-api-service
  namespace: custom-api
spec:
  ports:
  - port: 443
    targetPort: 8443
  selector:
    app: my-api

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-api
  namespace: custom-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-api
  template:
    metadata:
      labels:
        app: my-api
    spec:
      containers:
      - name: api
        image: my-api-server:1.0
        ports:
        - containerPort: 8443
        volumeMounts:
        - name: tls
          mountPath: /etc/tls
      volumes:
      - name: tls
        secret:
          secretName: my-api-tls

---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1.example.io
spec:
  version: v1
  group: example.io
  service:
    name: my-api-service
    namespace: custom-api
    port: 443
  caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0t...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Debugging de API Server:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver logs del API Server
kubectl logs -n kube-system kube-apiserver-&lt;node&gt;

# Ver solicitudes a la API
kubectl logs -n kube-system kube-apiserver | grep "audit"

# Metricas del API Server
kubectl get --raw /metrics | grep apiserver_

# Ver hooks de admission registrados
kubectl get validatingwebhookconfigurations
kubectl get mutatingwebhookconfigurations

# Ver API aggregados
kubectl get apiservice</code></pre>
</div>
</div>
<div class="paragraph">
<p>Performance tuning del API Server:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Configuración de API Server (en kube-apiserver)
--max-requests-inflight=400           # Max requests concurrentes sin autenticación
--max-mutating-requests-inflight=200  # Max requests de modificación
--request-timeout=5m                  # Timeout de requests
--etcd-request-timeout=1m             # Timeout al hablar con etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p>Control de rate limiting:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver límites actuales
kubectl get --raw /metrics | grep "apiserver_client_requests_total" | head -5

# Configurar limites por usuario
kubectl apply -f - &lt;&lt;EOF
apiVersion: apiserver.config.k8s.io/v1
kind: FlowSchema
metadata:
  name: default-limits
spec:
  distinguisherMethod:
    type: ByUser
  matchingPrecedence: 1000
  priorityLevelConfiguration:
    name: default-pl
  rules:
  - nonResourceRules:
    - nonResourceURLs:
      - /api
      - /api/*
EOF</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_14_kubernetes_en_producción">14. Módulo 14: Kubernetes en Producción</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_arquitectura_de_producción">14.1. Arquitectura de Producción</h3>
<div class="paragraph">
<p><strong>High Availability</strong></p>
</div>
<div class="paragraph">
<p>Diseñar clusters Kubernetes para máxima disponibilidad.</p>
</div>
<div class="paragraph">
<p>Arquitectura de HA:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────────────────────────────┐
│                  Load Balancer                       │
└──────────┬──────────────────────────┬────────────────┘
           │                          │
    ┌──────▼──────┐          ┌────────▼──────┐
    │  API Server │          │  API Server    │
    │  (Replica1) │          │  (Replica2)    │
    └──────┬──────┘          └────────┬───────┘
           │                          │
    ┌──────▼──────────────────────────▼───────┐
    │         etcd Cluster (3+ nodos)         │
    └────────────────────────────────────────┘
           ▲              ▲              ▲
       Control1      Control2      Control3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración de HA:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. API Server con múltiples réplicas
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  replicas: 3
  selector:
    matchLabels:
      component: kube-apiserver
  template:
    metadata:
      labels:
        component: kube-apiserver
    spec:
      priorityClassName: system-cluster-critical
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: component
                operator: In
                values:
                - kube-apiserver
            topologyKey: kubernetes.io/hostname
      containers:
      - name: kube-apiserver
        image: k8s.gcr.io/kube-apiserver:v1.27.0
        ports:
        - containerPort: 6443
        env:
        - name: ETCD_SERVERS
          value: "https://etcd1:2379,https://etcd2:2379,https://etcd3:2379"

---
# 2. Service para API Server
apiVersion: v1
kind: Service
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  type: LoadBalancer
  selector:
    component: kube-apiserver
  ports:
  - port: 6443
    targetPort: 6443

---
# 3. etcd con múltiples réplicas
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: etcd
  namespace: kube-system
spec:
  serviceName: etcd
  replicas: 3
  selector:
    matchLabels:
      component: etcd
  template:
    metadata:
      labels:
        component: etcd
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: component
                operator: In
                values:
                - etcd
            topologyKey: kubernetes.io/hostname
      containers:
      - name: etcd
        image: quay.io/coreos/etcd:v3.5.0
        ports:
        - containerPort: 2379
          name: client
        - containerPort: 2380
          name: peer
        env:
        - name: ETCD_LISTEN_CLIENT_URLS
          value: "https://0.0.0.0:2379"
        - name: ETCD_INITIAL_CLUSTER
          value: "etcd-0=https://etcd-0.etcd:2380,etcd-1=https://etcd-1.etcd:2380,etcd-2=https://etcd-2.etcd:2380"
        volumeMounts:
        - name: data
          mountPath: /var/lib/etcd
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 100Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>Pod Disruption Budgets para HA:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: apiserver-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      component: kube-apiserver

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: etcd-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      component: etcd

---
# Para aplicaciones críticas
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-app-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: critical-app</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Multi-region Deployments</strong></p>
</div>
<div class="paragraph">
<p>Desplegar aplicaciones en múltiples regiones.</p>
</div>
<div class="paragraph">
<p>Arquitectura multi-región:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌──────────────────┐      ┌──────────────────┐
│   Region US-East │      │   Region EU-West │
├──────────────────┤      ├──────────────────┤
│   Cluster A      │      │   Cluster B      │
│   3 nodos        │      │   3 nodos        │
│   DB Primaria    │      │   DB Replica     │
└──────────────────┘      └──────────────────┘
         ▲                         ▲
         └─────────────────────────┘
          Replicación de datos</code></pre>
</div>
</div>
<div class="paragraph">
<p>Configuración multi-región:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cluster A (US-East) - Primario
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    region: us-east
    tier: primary

---
# Deployment primario
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: production
spec:
  replicas: 3
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: region
            operator: In
            values:
            - us-east
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0.0
        env:
        - name: DB_ENDPOINT
          value: "db-primary.us-east.example.com"

---
# Cluster B (EU-West) - Réplica
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    region: eu-west
    tier: replica

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: production
spec:
  replicas: 3
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: region
            operator: In
            values:
            - eu-west
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0.0
        env:
        - name: DB_ENDPOINT
          value: "db-replica.eu-west.example.com"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Replicación de datos entre regiones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Configurar replicación de BD (ejemplo PostgreSQL)
# Cluster primario US-East
PGUSER=postgres PGPASSWORD=password psql -h db-primary.us-east \
  -c "CREATE PUBLICATION all_tables FOR ALL TABLES;"

# Cluster secundario EU-West
PGUSER=postgres PGPASSWORD=password psql -h db-replica.eu-west \
  -c "CREATE SUBSCRIPTION all_from_primary CONNECTION 'host=db-primary.us-east user=postgres' \
      PUBLICATION all_tables WITH (copy_data = true);"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Load Balancing</strong></p>
</div>
<div class="paragraph">
<p>Distribuir tráfico entre clusters.</p>
</div>
<div class="paragraph">
<p>Global Load Balancer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># DNS con failover automático
apiVersion: v1
kind: Endpoints
metadata:
  name: myapp-global
  namespace: production
subsets:
- addresses:
  - ip: 10.0.0.10  # VIP de cluster US-East
    targetRef:
      kind: Node
      name: us-east-cluster
  - ip: 10.0.1.10  # VIP de cluster EU-West
    targetRef:
      kind: Node
      name: eu-west-cluster
  ports:
  - port: 80
    protocol: TCP

---
# Service que usa esos endpoints
apiVersion: v1
kind: Service
metadata:
  name: myapp-global
  namespace: production
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ingress con múltiples clusters:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Ingress que balancea entre clusters
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-global
  namespace: production
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - myapp.example.com
    secretName: myapp-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-us-east
            port:
              number: 80
      - path: /eu
        pathType: Prefix
        backend:
          service:
            name: myapp-eu-west
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Capacity Planning</strong></p>
</div>
<div class="paragraph">
<p>Planificar recursos para escalar.</p>
</div>
<div class="paragraph">
<p>Análisis de capacidad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Analizar uso actual
kubectl top nodes
kubectl top pods -A

# 2. Proyectar crecimiento (ejemplo: 50% crecimiento anual)
# Node actual: 32GB RAM
# Promedio por pod: 512MB
# Pods actuales: 40
# RAM usada: 20GB

# Crecimiento esperado en 12 meses:
# Pods esperados: 40 * 1.5 = 60
# RAM esperada: 60 * 512MB = 30.72GB
# Con headroom (20%): 30.72GB * 1.2 = 36.86GB
# Nuevas máquinas necesarias: ceil((36.86 - 32) / 32) = 1 nodo

# 3. Monitorear tendencias
kubectl apply -f - &lt;&lt;EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: capacity-planning
data:
  script.sh: |
    #!/bin/bash
    while true; do
      echo "$(date): $(kubectl top nodes | awk 'NR&gt;1 {sum+=\$3} END {print sum}')" &gt;&gt; /tmp/cpu.log
      sleep 3600
    done
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p>Autoscaling de cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cluster Autoscaler (para cloud platforms)
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-priority-expander
  namespace: kube-system
data:
  priorities: |
    10:
      - .*spot.*
    50:
      - .*on-demand.*

---
# Monitoring para capacity planning
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-capacity-planning
data:
  capacity.yml: |
    groups:
    - name: capacity
      rules:
      - record: cluster:node:count
        expr: count(kube_node_status_allocatable)
      - record: cluster:cpu:allocatable
        expr: sum(kube_node_status_allocatable{resource="cpu"})
      - record: cluster:memory:allocatable
        expr: sum(kube_node_status_allocatable{resource="memory"})
      - record: cluster:cpu:usage
        expr: sum(node_cpu_seconds_total) / cluster:cpu:allocatable
      - record: cluster:memory:usage
        expr: sum(node_memory_MemAvailable_bytes) / cluster:memory:allocatable</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alertas de capacidad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: capacity-alerts
spec:
  groups:
  - name: capacity
    rules:
    - alert: ClusterCPUUtilizationHigh
      expr: cluster:cpu:usage &gt; 0.75
      for: 5m
      annotations:
        summary: "Cluster CPU utilization is {{ $value }}"

    - alert: ClusterMemoryUtilizationHigh
      expr: cluster:memory:usage &gt; 0.80
      for: 5m
      annotations:
        summary: "Cluster memory utilization is {{ $value }}"

    - alert: NotEnoughNodesAvailable
      expr: count(kube_node_status_condition{condition="Ready",status="true"}) &lt; 3
      for: 5m
      annotations:
        summary: "Only {{ $value }} nodes available, minimum is 3"</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_hardening">14.2. Hardening</h3>
<div class="paragraph">
<p>Fortalecer la seguridad de Kubernetes siguiendo mejores prácticas.</p>
</div>
<div class="paragraph">
<p><strong>Security Best Practices</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pod Security Standards</strong>:</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Pod Security Policy (deprecated, usar PSS)
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: restricted
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'MustRunAs'
    seLinuxOptions:
      level: "s0:c123,c456"
  fsGroup:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  readOnlyRootFilesystem: true

---
# Pod Security Standards (reemplazo de PSP)
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Seguridad de contenedores</strong>:</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  containers:
  - name: app
    image: myapp:v1
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Network Policies</strong>:</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Denegar todo tráfico por defecto
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
spec:
  podSelector: {}
  policyTypes:
  - Ingress

---
# Permitir solo tráfico específico
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web
spec:
  podSelector:
    matchLabels:
      role: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: production
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>RBAC (Role-Based Access Control)</strong>:</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Role con permisos mínimos
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
  namespace: default
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]

---
# RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
- kind: ServiceAccount
  name: default
  namespace: default</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>CIS Kubernetes Benchmark</strong></p>
</div>
<div class="paragraph">
<p>El CIS Benchmark proporciona recomendaciones de configuración.</p>
</div>
<div class="paragraph">
<p>Checklist de CIS (resumen):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Control Plane Configuration
   ✓ API Server: --basic-auth-file no debe estar configurado
   ✓ API Server: --token-auth-file no debe estar configurado
   ✓ API Server: --enable-admin-admission-controller
   ✓ Kubelet: --protect-kernel-defaults=true

2. ETCD
   ✓ Usar certificados para peer communication
   ✓ client-cert-auth: true
   ✓ Encriptar datos en reposo

3. General Configuration
   ✓ Usar Red Hat Enterprise Linux / CentOS como OS
   ✓ kernel version &gt;= 4.15
   ✓ Configurar SELinux en enforcing</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ejecutar kube-bench para validar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar kube-bench
kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/main/job.yaml

# Ejecutar y obtener resultados
kubectl logs -f job/kube-bench

# Resultados mostrará:
# [PASS] 1.1.1 Ensure that the API server executable permissions are set to 644 or more restrictive
# [FAIL] 1.2.1 Ensure that the --basic-auth-file argument is not set</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Compliance</strong></p>
</div>
<div class="paragraph">
<p>Mantener compliance con regulaciones (GDPR, HIPAA, SOC2, PCI-DSS).</p>
</div>
<div class="paragraph">
<p>Implementar auditoría:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Configurar API Server Audit Log
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# Log de todos los requests a escalada de privilegios
- level: RequestResponse
  verbs: ["create", "update", "patch"]
  resources:
  - group: ""
    resources: ["pods"]
  omitStages:
  - RequestReceived

# Log de todos los requests fallidos
- level: Metadata
  omitStages:
  - RequestReceived
  userGroups:
  - "system:authenticated"

# Log por defecto
- level: None
  omitStages:
  - RequestReceived</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo de compliance:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Validar policies están activas
kubectl get networkpolicies -A

# Verificar RBAC está configurado
kubectl get roles -A
kubectl get rolebindings -A

# Auditar access logs
kubectl logs -n kube-system kube-apiserver | grep audit</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Auditing</strong></p>
</div>
<div class="paragraph">
<p>Registrar y monitorear todas las operaciones.</p>
</div>
<div class="paragraph">
<p>Configuración avanzada de auditoría:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# 1. Log de cambios en secrets
- level: RequestResponse
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: ""
    resources: ["secrets"]
  omitStages:
  - RequestReceived

# 2. Log de cambios en RBAC
- level: RequestResponse
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: "rbac.authorization.k8s.io"
    resources: ["roles", "rolebindings", "clusterroles", "clusterrolebindings"]
  omitStages:
  - RequestReceived

# 3. Log de cambios en control plane
- level: RequestResponse
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: "apps"
    resources: ["deployments", "daemonsets", "statefulsets"]
  omitStages:
  - RequestReceived

# 4. Log de exec en pods
- level: RequestResponse
  verbs: ["create"]
  resources:
  - group: ""
    resources: ["pods/exec", "pods/portforward"]
  omitStages:
  - RequestReceived

# 5. Log todos los demás requests (pero en nivel Metadata)
- level: Metadata
  omitStages:
  - RequestReceived</code></pre>
</div>
</div>
<div class="paragraph">
<p>Analizar audit logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver audit logs
tail -f /var/log/kubernetes/audit.log | jq '.'

# Filtrar por usuario
tail -f /var/log/kubernetes/audit.log | jq 'select(.user.username == "admin")'

# Filtrar por recurso
tail -f /var/log/kubernetes/audit.log | jq 'select(.objectRef.resource == "pods")'

# Filtrar por verbo
tail -f /var/log/kubernetes/audit.log | jq 'select(.verb == "delete")'

# Contar eventos por tipo
jq -r '.verb' /var/log/kubernetes/audit.log | sort | uniq -c

# Detectar actividad sospechosa
jq 'select(.verb == "create" and .objectRef.resource == "clusterrolebindings")' /var/log/kubernetes/audit.log</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alertas en base a audit logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: audit-alerts
data:
  rules.yml: |
    groups:
    - name: kubernetes-audit
      rules:
      - alert: UnauthorizedAPIAccess
        expr: |
          rate(apiserver_audit_event_total{user_agent != "kubelet"}[5m]) &gt; 10
        for: 5m
        annotations:
          summary: "Unauthorized API access detected"

      - alert: PrivilegeEscalation
        expr: |
          apiserver_audit_event_total{verb="create", objectRef_resource="clusterrolebindings"} &gt; 0
        annotations:
          summary: "Potential privilege escalation attempt"

      - alert: SecretAccessViolation
        expr: |
          apiserver_audit_event_total{objectRef_resource="secrets", verb="get"} &gt; 100
        for: 5m
        annotations:
          summary: "Unusual secret access pattern detected"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Enviar audit logs a sistema externo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Configurar webhook para audit logs
# En API Server startup flags:
# --audit-webhook-config-file=/etc/kubernetes/audit-webhook.yaml

# audit-webhook.yaml content:
# apiVersion: v1
# kind: Config
# clusters:
# - name: falco
#   cluster:
#     server: http://falco-service:5555/
# contexts:
# - context:
#     cluster: falco
#     user: ""
#   name: default-context
# current-context: default-context
# preferences: {}
# users: []</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_disaster_recovery">14.3. Disaster Recovery</h3>
<div class="paragraph">
<p><strong>Backup Strategies</strong></p>
</div>
<div class="paragraph">
<p>Estrategias de backup para diferentes datos en Kubernetes.</p>
</div>
<div class="paragraph">
<p>Tipos de backups:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">1. Cluster Backup:
   - Estado del cluster (etcd)
   - Configuración de nodos
   - Definiciones de recursos

2. Application Backup:
   - Datos persistentes (PVs)
   - Configuración de aplicación
   - Secrets y ConfigMaps

3. Database Backup:
   - Snapshots de base de datos
   - Backups transaccionales
   - Replicación

4. Infrastructure Backup:
   - Snapshots de volúmenes
   - Snapshots de máquinas
   - Configuración de red</code></pre>
</div>
</div>
<div class="paragraph">
<p>Plan de backup:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Ejemplo de política de backup diaria
cronSchedule: "0 2 * * *"     # 2 AM diariamente

# Retención
retention:
  ttl: "720h"                  # 30 días

# Locations
locations:
- name: aws-s3
  provider: aws
  bucket: my-backups
  prefix: daily

# Volumenes a respaldar
volumeSnapshotLocation:
  name: aws-ebs
  provider: aws</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Velero</strong></p>
</div>
<div class="paragraph">
<p>Ya cubierto en Módulo 13.1, pero resumen práctico:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear schedules de backup
velero schedule create weekly \
  --schedule="0 2 * * 0" \
  --include-namespaces production \
  --ttl 168h

# Backup incremental
velero backup create prod-backup-$(date +%s) \
  --include-namespaces production \
  --selector app=myapp

# Listar y monitorear
velero backup logs &lt;backup-name&gt;
velero backup describe &lt;backup-name&gt; --details

# Restaurar en nuevo cluster
# En cluster destino:
velero restore create --from-backup prod-backup-123</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>etcd Backup y Restore</strong></p>
</div>
<div class="paragraph">
<p>Backup manual de etcd:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Hacer snapshot
ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 \
  snapshot save backup.db

# 2. Verificar integridad
ETCDCTL_API=3 etcdctl snapshot status backup.db

# 3. Restaurar en nuevo cluster
ETCDCTL_API=3 etcdctl snapshot restore backup.db \
  --data-dir /var/lib/etcd-backup

# 4. Reiniciar etcd con nuevo data-dir
systemctl restart etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p>Automatizar backups de etcd:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: CronJob
metadata:
  name: etcd-backup
  namespace: kube-system
spec:
  schedule: "0 * * * *"  # Cada hora
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: etcd-backup
          containers:
          - name: backup
            image: bitnami/etcd:latest
            command:
            - /bin/sh
            - -c
            - |
              etcdctl --endpoints=http://etcd:2379 \
                snapshot save /backups/etcd-$(date +%s).db
            volumeMounts:
            - name: backup-dir
              mountPath: /backups
          volumes:
          - name: backup-dir
            hostPath:
              path: /mnt/etcd-backups
          restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Testing de Recuperación</strong></p>
</div>
<div class="paragraph">
<p>Validar que los backups funcionan:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear backup
velero backup create test-backup

# 2. Esperar a que complete
velero backup describe test-backup --wait

# 3. Simular desastre - restaurar en namespace de test
velero restore create --from-backup test-backup \
  --namespace-mappings production:test-restore

# 4. Validar
kubectl get all -n test-restore

# 5. Limpiar si todo OK
velero restore delete &lt;restore-name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>DR Testing checklist:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">□ Crear backup
□ Verificar backup está completo
□ Restaurar en ambiente diferente
□ Validar datos están completos
□ Validar aplicaciones funcionan
□ Validar conectividad de BD
□ Pruebas de funcionalidad básicas
□ Documentar tiempo de restauración
□ Limpiar ambiente de test</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cost_optimization">14.4. Cost Optimization</h3>
<div class="paragraph">
<p><strong>Resource Optimization</strong></p>
</div>
<div class="paragraph">
<p>Optimizar uso de recursos del cluster.</p>
</div>
<div class="paragraph">
<p>Análisis de uso:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver uso actual por namespace
kubectl top pods -A | awk '{print $1}' | sort | uniq -c | sort -rn

# Identificar pods sin requests/limits
kubectl get pods -A -o json | jq '.items[] | select(.spec.containers[].resources.requests == null) | .metadata.namespace + "/" + .metadata.name'

# Ver pods que usan más recursos
kubectl top pods -A --sort-by=memory | tail -20</code></pre>
</div>
</div>
<div class="paragraph">
<p>Establecer requests y limits:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: optimized-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        resources:
          requests:
            cpu: 100m          # Mínimo garantizado
            memory: 128Mi
          limits:
            cpu: 500m          # Máximo permitido
            memory: 512Mi       # Evita OOMKill
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]  # Grace period</code></pre>
</div>
</div>
<div class="paragraph">
<p>Usar Vertical Pod Autoscaler (VPA):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: vpa-auto-sizing
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "auto"  # auto, off, initial, recreate
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 1
        memory: 2Gi
      recommendedResources: true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Spot Instances</strong></p>
</div>
<div class="paragraph">
<p>Usar instancias spot (preemptibles) para reducir costos.</p>
</div>
<div class="paragraph">
<p>Affinidad para Spot:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: cost-optimized-app
spec:
  replicas: 3
  template:
    spec:
      affinity:
        nodeAffinity:
          # Preferir spot, permitir on-demand
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                - spot
      tolerations:
      # Tolerar interrupciones de spot
      - key: cloud.google.com/gke-preemptible
        operator: Equal
        value: "true"
        effect: NoSchedule
      containers:
      - name: app
        image: myapp:v1
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 30"]  # Tiempo para graceful shutdown</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cluster Efficiency</strong></p>
</div>
<div class="paragraph">
<p>Maximizar eficiencia del cluster.</p>
</div>
<div class="paragraph">
<p>Bin packing agresivo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
systemReserved:
  cpu: 100m
  memory: 100Mi
kubeReserved:
  cpu: 100m
  memory: 100Mi
evictionHard:
  memory.available: "100Mi"
  nodefs.available: "2%"
  nodefs.inodesFree: "5%"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Priority Classes para importancia:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: critical
value: 1000
globalDefault: false
description: "For critical production workloads"

---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: batch
value: 100
description: "For batch processing jobs"

---
# Usar en Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-app
spec:
  template:
    spec:
      priorityClassName: critical
      containers:
      - name: app
        image: myapp:v1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Cost Monitoring</strong></p>
</div>
<div class="paragraph">
<p>Monitorear y reportar costos.</p>
</div>
<div class="paragraph">
<p>Kubecost - Herramienta de visualización:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Kubecost
helm repo add kubecost https://kubecost.github.io/cost-analyzer/
helm install kubecost kubecost/cost-analyzer \
  --namespace kubecost \
  --create-namespace</code></pre>
</div>
</div>
<div class="paragraph">
<p>Métricas de costo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Acceder a dashboard
kubectl port-forward -n kubecost svc/kubecost 9090:9090

# API para costos por namespace
curl http://localhost:9090/api/v1/allocations

# Costos por pod
curl http://localhost:9090/api/v1/Assets/pods</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alertas de costo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cost-alerts
spec:
  groups:
  - name: kubecost
    rules:
    - alert: HighClusterCost
      expr: kubecost_cluster_hourly_cost &gt; 50
      for: 1h
      annotations:
        summary: "Cluster cost is ${{ $value }}/hour"

    - alert: HighNamespaceCost
      expr: kubecost_namespace_hourly_cost &gt; 10
      for: 1h
      annotations:
        summary: "Namespace {{ $labels.namespace }} cost is ${{ $value }}/hour"</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_troubleshooting_avanzado">14.5. Troubleshooting Avanzado</h3>
<div class="paragraph">
<p><strong>Debugging de Problemas de Red</strong></p>
</div>
<div class="paragraph">
<p>Diagnosticar problemas de conectividad.</p>
</div>
<div class="paragraph">
<p>Verificar CNI:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver plugin CNI
kubectl get daemonset -n kube-system -l k8s-app=flannel

# Verificar IP assignment
kubectl get pods -o wide
kubectl describe pod &lt;pod&gt; | grep IP

# Test conectividad
kubectl run debug --image=busybox --rm -it -- sh
# Desde dentro:
wget http://service-name:port
nslookup service-name
traceroute 10.x.x.x</code></pre>
</div>
</div>
<div class="paragraph">
<p>Debug avanzado con tcpdump:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># En nodo: capturar tráfico
tcpdump -i any -w /tmp/capture.pcap port 8080

# Analizar con Wireshark
# scp capture.pcap local-machine:</code></pre>
</div>
</div>
<div class="paragraph">
<p>Usar Network Policy debugging:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-debug
spec:
  podSelector:
    matchLabels:
      debug: "true"
  ingress:
  - from:
    - podSelector: {}
    ports:
    - port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Performance Issues</strong></p>
</div>
<div class="paragraph">
<p>Identificar y resolver problemas de performance.</p>
</div>
<div class="paragraph">
<p>Analizar latencia:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver requests lentos
kubectl top nodes
kubectl top pods -A --sort-by=cpu

# Analizar API Server latency
kubectl get --raw /metrics | grep apiserver_request_duration_seconds

# Ver logs de latencia
kubectl logs -n kube-system kube-apiserver | grep "duration"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Tuning de Kubelet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># /etc/kubernetes/kubelet-config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
maxPods: 110                    # Max pods por nodo
registryPullQPS: 10            # Rate limit para pulls
registryBurst: 20
serializeImagePulls: false      # Pull paralelo
cpuManager:
  policyName: static            # CPU pinning
topologyManager:
  topologyPolicyName: best-effort  # NUMA awareness</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Resource Contention</strong></p>
</div>
<div class="paragraph">
<p>Gestionar competencia por recursos.</p>
</div>
<div class="paragraph">
<p>CPU throttling:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Detectar pods siendo throttled
kubectl get --raw /metrics | grep 'container_cpu_cfs_throttled_seconds_total'

# Solución: aumentar limits o replicas
kubectl set resources deployment myapp \
  --limits=cpu=500m,memory=512Mi \
  --requests=cpu=250m,memory=256Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>Memory pressure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Detectar pods bajo memory pressure
kubectl describe node &lt;node&gt; | grep -A5 "Conditions"

# Ver eviciones
kubectl get events -A --field-selector reason=Evicted

# Solución: añadir nodos o optimizar requests</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Análisis de Crash Loops</strong></p>
</div>
<div class="paragraph">
<p>Diagnosticar pods que crashean continuamente.</p>
</div>
<div class="paragraph">
<p>Obtener logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver últimos logs antes del crash
kubectl logs &lt;pod&gt; --previous

# Ver todos los eventos
kubectl describe pod &lt;pod&gt;

# Logs con timestamps
kubectl logs &lt;pod&gt; --timestamps

# Ver exit code
kubectl get pod &lt;pod&gt; -o jsonpath='{.status.containerStatuses[0].lastState.terminated.exitCode}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Debugging de crashloops:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Crear pod de debug con mismo image
apiVersion: v1
kind: Pod
metadata:
  name: debug-crash
spec:
  containers:
  - name: debug
    image: myapp:broken
    command: ["/bin/sh"]
    args: ["-c", "sleep 3600"]  # No ejecutar comando que causa crash
    stdin: true
    tty: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Monitoreo de crash loops:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: crash-loop-alerts
spec:
  groups:
  - name: kubernetes
    rules:
    - alert: CrashLooping
      expr: rate(kube_pod_container_status_restarts_total[15m]) &gt; 0.1
      for: 5m
      annotations:
        summary: "Pod {{ $labels.pod }} is crash looping"

    - alert: ContainerNotReady
      expr: min_over_time(kube_pod_status_ready{condition="true"}[1m]) &lt; 1
      for: 5m
      annotations:
        summary: "Pod {{ $labels.pod }} is not ready"</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_15_casos_de_uso_y_patrones">15. Módulo 15: Casos de Uso y Patrones</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_microservicios">15.1. Microservicios</h3>
<div class="paragraph">
<p>Los microservicios representan uno de los casos de uso más comunes y exitosos de Kubernetes. Esta arquitectura divide las aplicaciones en servicios pequeños, independientes y desacoplados que se comunican entre sí.</p>
</div>
<div class="sect3">
<h4 id="_arquitectura_de_microservicios_en_kubernetes">15.1.1. Arquitectura de Microservicios en Kubernetes</h4>
<div class="paragraph">
<p>La arquitectura de microservicios aprovecha las capacidades de Kubernetes de:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Aislamiento</strong>: Cada microservicio corre en su propio contenedor</p>
</li>
<li>
<p><strong>Escalabilidad independiente</strong>: Escalar servicios específicos según la demanda</p>
</li>
<li>
<p><strong>Despliegues independientes</strong>: Actualizar servicios sin afectar otros</p>
</li>
<li>
<p><strong>Resiliencia</strong>: Fallos en un servicio no derriban toda la aplicación</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo de arquitectura típica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────────────────────┐
│                    Cliente / API Gateway                │
└──────────────────┬──────────────────────────────────────┘
                   │
    ┌──────────────┼──────────────┐
    ▼              ▼              ▼
┌────────┐   ┌────────┐   ┌────────────┐
│ Auth   │   │ Order  │   │ Payment    │
│Service │   │Service │   │Service     │
└────────┘   └────────┘   └────────────┘
    │              │              │
    └──────────────┼──────────────┘
                   │
          ┌────────┴────────┐
          ▼                 ▼
    ┌─────────────┐   ┌──────────────┐
    │  Database   │   │ Cache (Redis)│
    └─────────────┘   └──────────────┘</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_service_discovery">15.1.2. Service Discovery</h4>
<div class="paragraph">
<p>En Kubernetes, el service discovery ocurre automáticamente gracias al DNS interno:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Cada servicio obtiene un DNS automático
# Formato: &lt;nombre-servicio&gt;.&lt;namespace&gt;.svc.cluster.local

# Ejemplo: Si tenemos un servicio "api-service" en namespace "production"
# Los pods pueden acceder con: http://api-service.production.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Implementación con Kubernetes Services:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: order-service
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: order-api
  ports:
  - port: 80
    targetPort: 8080
    name: http
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-api
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: order-api
  template:
    metadata:
      labels:
        app: order-api
    spec:
      containers:
      - name: order-api
        image: myregistry/order-api:v1.0
        ports:
        - containerPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>Los pods pueden descubrir servicios automáticamente mediante:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>DNS</strong>: <code>order-service.production.svc.cluster.local</code></p>
</li>
<li>
<p><strong>Variables de entorno</strong>: Kubernetes inyecta variables como <code>ORDER_SERVICE_PORT</code></p>
</li>
<li>
<p><strong>Headless Services</strong>: Para aplicaciones que necesitan IPs específicas de pods</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Headless Service para control fino:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  clusterIP: None  # Headless service
  selector:
    app: postgres
  ports:
  - port: 5432</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_patrones_api_gateway">15.1.3. Patrones API Gateway</h4>
<div class="paragraph">
<p>El API Gateway actúa como punto de entrada único para todos los clientes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-gateway
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.example.com
    secretName: api-tls
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /auth
        pathType: Prefix
        backend:
          service:
            name: auth-service
            port:
              number: 80
      - path: /orders
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80
      - path: /payments
        pathType: Prefix
        backend:
          service:
            name: payment-service
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ventajas del API Gateway:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Punto de entrada único</p>
</li>
<li>
<p>Autenticación y autorización centralizadas</p>
</li>
<li>
<p>Rate limiting y throttling</p>
</li>
<li>
<p>Enrutamiento inteligente</p>
</li>
<li>
<p>Logging y monitoreo centralizado</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_comunicación_entre_servicios">15.1.4. Comunicación Entre Servicios</h4>
<div class="paragraph">
<p>Las estrategias de comunicación incluyen:</p>
</div>
<div class="paragraph">
<p><strong>Sincrónica (REST/gRPC):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Service A llama a Service B
apiVersion: v1
kind: ConfigMap
metadata:
  name: service-urls
data:
  ORDER_SERVICE_URL: "http://order-service.production.svc.cluster.local"
  PAYMENT_SERVICE_URL: "http://payment-service.production.svc.cluster.local"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-consumer
spec:
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        envFrom:
        - configMapRef:
            name: service-urls</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Asincrónica (Mensaje Queue):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Usar RabbitMQ o Kafka para desacoplamiento
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq
spec:
  ports:
  - port: 5672
    targetPort: 5672
  selector:
    app: rabbitmq
---
# Publicar eventos en lugar de llamadas directas
# Event: order.created -&gt; payment-service la escucha</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrones de Resilencia:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Circuit Breaker</strong>: Fallar rápido si un servicio está caído</p>
</li>
<li>
<p><strong>Retry con backoff exponencial</strong>: Reintentar con esperas crecientes</p>
</li>
<li>
<p><strong>Timeout</strong>: Establecer límites de tiempo de espera</p>
</li>
<li>
<p><strong>Bulkhead</strong>: Aislar grupos de recursos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Usar NetworkPolicy para controlar comunicación
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-order-to-payment
spec:
  podSelector:
    matchLabels:
      app: order-api
  policyTypes:
  - Egress
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: payment-api
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_bases_de_datos">15.2. Bases de Datos</h3>
<div class="paragraph">
<p>Kubernetes puede ejecutar bases de datos, aunque requiere consideraciones especiales para persistencia, backup y replicación. Las aplicaciones stateful como las bases de datos tienen requisitos diferentes a las aplicaciones stateless.</p>
</div>
<div class="sect3">
<h4 id="_despliegue_de_bases_de_datos">15.2.1. Despliegue de Bases de Datos</h4>
<div class="paragraph">
<p><strong>Opciones de despliegue:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Managed Services (Recomendado para Producción)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Usar servicios gestionados: AWS RDS, Google Cloud SQL, Azure Database</p>
</li>
<li>
<p>Menor complejidad operacional</p>
</li>
<li>
<p>Backups automáticos</p>
</li>
<li>
<p>Alta disponibilidad</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kubernetes-Native (Para desarrollo y casos específicos)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Aplicable si necesitas control total</p>
</li>
<li>
<p>Requiere expertise en operaciones</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Arquitectura típica para despliegue en Kubernetes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌──────────────────────────────────────────┐
│    Ingress / LoadBalancer                │
│  (Acceso a la base de datos)             │
└──────────────────┬───────────────────────┘
                   │
        ┌──────────┴──────────┐
        ▼                     ▼
   ┌─────────┐           ┌─────────┐
   │ Primary │  Replica  │Replica 2│
   │   DB    │ ------→   │   DB    │
   └────┬────┘           └─────────┘
        │
   ┌────┴─────┐
   ▼          ▼
┌────────┐ ┌────────┐
│PVC: DB │ │PVC: Log│
└────────┘ └────────┘</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_statefulsets_para_bases_de_datos">15.2.2. StatefulSets para Bases de Datos</h4>
<div class="paragraph">
<p>Los StatefulSets son cruciales para aplicaciones stateful que requieren:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Identidades estables</p>
</li>
<li>
<p>Almacenamiento persistente</p>
</li>
<li>
<p>Orden garantizado de despliegue</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: PostgreSQL con StatefulSet</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      terminationGracePeriodSeconds: 30
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 10
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None  # Headless service para StatefulSet
  ports:
  - port: 5432
    targetPort: 5432
  selector:
    app: postgres</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Características importantes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>serviceName</strong>: Necesario para DNS estable</p>
</li>
<li>
<p><strong>volumeClaimTemplates</strong>: Crea un PVC por réplica</p>
</li>
<li>
<p><strong>terminationGracePeriodSeconds</strong>: Tiempo para shutdown limpio</p>
</li>
<li>
<p><strong>Headless Service</strong>: Acceso directo a pods específicos</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_operators_de_bases_de_datos">15.2.3. Operators de Bases de Datos</h4>
<div class="paragraph">
<p>Los Operators automatizan tareas complejas de bases de datos mediante lógica encapsulada en el cluster:</p>
</div>
<div class="paragraph">
<p><strong>Operators populares:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>PostgreSQL Operator</strong>: Automatiza backup, replicación y escalado</p>
</li>
<li>
<p><strong>MySQL Operator</strong>: Gestión automática de MySQL</p>
</li>
<li>
<p><strong>MongoDB Operator</strong>: Manejo de clusters MongoDB</p>
</li>
<li>
<p><strong>Elasticsearch Operator</strong>: Gestión de clusters Elasticsearch</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo usando PostgreSQL Operator:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: my-database
spec:
  instances: 3
  primaryUpdateStrategy: unsupervised
  postgresql:
    parameters:
      max_connections: "200"
      shared_buffers: "256MB"
  bootstrap:
    initdb:
      database: myapp
      owner: app_user
  storage:
    size: 10Gi
    storageClass: fast-ssd
  monitoring:
    enabled: true
  backup:
    barmanObjectStore:
      destinationPath: s3://my-bucket/backups
      s3Credentials:
        accessKeyId:
          name: s3-creds
          key: access_key
        secretAccessKey:
          name: s3-creds
          key: secret_key</code></pre>
</div>
</div>
<div class="paragraph">
<p>El Operator se encarga de:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Crear la estructura del cluster</p>
</li>
<li>
<p>Configurar replicación</p>
</li>
<li>
<p>Gestionar failover automático</p>
</li>
<li>
<p>Realizar backups programados</p>
</li>
<li>
<p>Restauración de datos</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_backup_y_replicación">15.2.4. Backup y Replicación</h4>
<div class="paragraph">
<p><strong>Estrategia de Backup:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Backup programado con CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  schedule: "0 2 * * *"  # Diariamente a las 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:15-alpine
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: password
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h postgres -U postgres mydb &gt; \
              /backups/db-backup-$(date +%Y%m%d-%H%M%S).sql
            volumeMounts:
            - name: backup-storage
              mountPath: /backups
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Replicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Configurar replicación streaming
# En el StatefulSet del Primary:
- name: STREAMING_REPLICATION
  value: "true"
- name: REPLICATION_SLOTS
  value: "replication"

# Replicas se conectan como:
# Host: postgres-0.postgres.default.svc.cluster.local
# Replication user: replicator</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Verificación de estado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver replicas conectadas en PostgreSQL
kubectl exec -it postgres-0 -- \
  psql -U postgres -c "SELECT usename, application_name, state \
  FROM pg_stat_replication;"

# Ver retraso de replicación (lag)
kubectl exec -it postgres-0 -- \
  psql -U postgres -c "SELECT now() - pg_last_xact_replay_timestamp() \
  AS replication_lag;"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Usar StorageClass con replicación en el storage (RAID)</p>
</li>
<li>
<p>Mantener backups en ubicación diferente (S3, GCS, etc.)</p>
</li>
<li>
<p>Implementar automáticas health checks</p>
</li>
<li>
<p>Testear restauración de backups regularmente</p>
</li>
<li>
<p>Usar Operators para automatización</p>
</li>
<li>
<p>Separar base de datos de aplicación en casos de producción</p>
</li>
<li>
<p>Implementar monitoring y alertas</p>
</li>
<li>
<p>Documentar procedimientos de disaster recovery</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_machine_learning">15.3. Machine Learning</h3>
<div class="paragraph">
<p>Kubernetes se ha convertido en la plataforma estándar para entrenar, servir e implementar modelos de machine learning a escala. Permite gestionar los recursos computacionales intensivos y distribuir trabajos de ML complejos.</p>
</div>
<div class="sect3">
<h4 id="_kubeflow">15.3.1. Kubeflow</h4>
<div class="paragraph">
<p>Kubeflow es una plataforma de ML nativa de Kubernetes que proporciona componentes para el ciclo de vida completo del ML.</p>
</div>
<div class="paragraph">
<p><strong>Instalación de Kubeflow:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Kubeflow (requiere kubectl configurado)
cd ~
git clone https://github.com/kubeflow/manifests.git
cd manifests

# Instalar componentes base
kustomize build example | kubectl apply -f -

# Verificar instalación
kubectl get pods -n kubeflow</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Componentes principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Jupyter Notebooks</strong>: Desarrollo interactivo</p>
</li>
<li>
<p><strong>Training Operators</strong>: Para entrenar modelos (TFJob, PyTorchJob)</p>
</li>
<li>
<p><strong>KServe</strong>: Servir modelos en producción</p>
</li>
<li>
<p><strong>Pipelines</strong>: Orquestar flujos de ML complejos</p>
</li>
<li>
<p><strong>AutoML</strong>: Automatizar búsqueda de hyperparámetros</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Entrenar modelo con PyTorchJob</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: pytorch-training
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      template:
        spec:
          containers:
          - name: pytorch
            image: pytorch/pytorch:latest
            command:
            - python
            - /app/train.py
            resources:
              requests:
                memory: "4Gi"
                cpu: "2"
              limits:
                memory: "8Gi"
                cpu: "4"
            volumeMounts:
            - name: training-data
              mountPath: /data
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: ml-data-pvc
    Worker:
      replicas: 3
      template:
        spec:
          containers:
          - name: pytorch
            image: pytorch/pytorch:latest
            command:
            - python
            - /app/train.py
            resources:
              requests:
                memory: "4Gi"
                cpu: "2"
              limits:
                memory: "8Gi"
                cpu: "4"
            volumeMounts:
            - name: training-data
              mountPath: /data
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: ml-data-pvc</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gpu_scheduling">15.3.2. GPU Scheduling</h4>
<div class="paragraph">
<p>Kubernetes puede gestionar GPUs como recursos programables. Esto es crítico para entrenar modelos de deep learning.</p>
</div>
<div class="paragraph">
<p><strong>Configuración de nodos con GPU:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Ver GPUs disponibles en el cluster
kubectl describe nodes | grep -A5 "nvidia.com/gpu"

# Resultado esperado:
# nvidia.com/gpu: 8    (8 GPUs disponibles)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solicitar GPUs en pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: gpu-training
spec:
  containers:
  - name: training
    image: tensorflow/tensorflow:latest-gpu
    resources:
      requests:
        nvidia.com/gpu: 2    # Solicitar 2 GPUs
      limits:
        nvidia.com/gpu: 2
    env:
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estatuas de GPU en el cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver distribución de GPUs
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
GPU:.status.allocatable.nvidia\\.com/gpu,\
GPU_USED:.status.allocated_resources.nvidia\\.com/gpu

# Monitorear uso de GPU
kubectl top nodes --containers

# Logs de GPU en un pod
kubectl logs pod-name | grep CUDA</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Affinity para seleccionar tipo de GPU:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-inference
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values:
                - nvidia-tesla-v100  # Seleccionar GPU V100
      containers:
      - name: inference
        image: tensorflow/tensorflow:latest-gpu
        resources:
          requests:
            nvidia.com/gpu: 1
          limits:
            nvidia.com/gpu: 1</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_model_serving">15.3.3. Model Serving</h4>
<div class="paragraph">
<p>Servir modelos en producción requiere alta disponibilidad, escalabilidad y bajo latencia.</p>
</div>
<div class="paragraph">
<p><strong>KServe para serving de modelos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: iris-classifier
spec:
  predictor:
    sklearn:
      storageUri: s3://my-bucket/models/iris-classifier
      resources:
        requests:
          memory: "1Gi"
          cpu: "500m"
        limits:
          memory: "2Gi"
          cpu: "1"
  transformer:
    containers:
    - name: transformer
      image: my-registry/iris-transformer:v1
      env:
      - name: MODEL_NAME
        value: iris
  explainer:
    containers:
    - name: explainer
      image: my-registry/iris-explainer:v1</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Características:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Automatic scaling</strong>: Escala automática según carga</p>
</li>
<li>
<p><strong>Traffic splitting</strong>: Canary deployments A/B testing</p>
</li>
<li>
<p><strong>Model monitoring</strong>: Detección de data drift</p>
</li>
<li>
<p><strong>Inference logging</strong>: Auditoría y debugging</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo con canary deployment:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: model-v2
spec:
  predictor:
    canaryTrafficPercent: 20  # 20% tráfico al nuevo modelo
    containers:
    - name: kserve-container
      image: model-v2:latest
  predictor:
    canaryTrafficPercent: 80  # 80% tráfico al modelo anterior
    containers:
    - name: kserve-container
      image: model-v1:latest</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_mlops_pipelines">15.3.4. MLOps Pipelines</h4>
<div class="paragraph">
<p>Orquestar flujos complejos de ML con reproducibilidad y auditoría.</p>
</div>
<div class="paragraph">
<p><strong>Kubeflow Pipelines:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import kfp
from kfp import dsl
from kfp.components import create_component_from_func

@create_component_from_func
def prepare_data(input_path: str, output_path: str):
    # Código de preparación de datos
    pass

@create_component_from_func
def train_model(data_path: str, model_path: str):
    # Código de entrenamiento
    pass

@create_component_from_func
def evaluate_model(model_path: str, data_path: str) -&gt; float:
    # Código de evaluación
    return accuracy

@dsl.pipeline(
    name='ML Pipeline',
    description='End-to-end ML pipeline'
)
def ml_pipeline(input_data: str):
    prepare = prepare_data(input_path=input_data,
                          output_path='/data/processed')
    train = train_model(data_path=prepare.outputs['output_path'],
                       model_path='/models/trained')
    evaluate = evaluate_model(model_path=train.outputs['model_path'],
                             data_path=prepare.outputs['output_path'])

# Compilar y ejecutar
kfp.compiler.Compiler().compile(ml_pipeline, 'pipeline.zip')</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ventajas de MLOps Pipelines:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reproducibilidad: Volver a ejecutar con mismos datos y parámetros</p>
</li>
<li>
<p>Auditoría: Registro de qué código/datos creó cada modelo</p>
</li>
<li>
<p>Escalabilidad: Distribuir componentes en múltiples nodos</p>
</li>
<li>
<p>Experimentación: Tracking automático de experimentos</p>
</li>
<li>
<p>Orquestación: Dependencias entre tareas</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo YAML Pipeline:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: ml-pipeline-
spec:
  entrypoint: main
  templates:
  - name: main
    dag:
      tasks:
      - name: prepare-data
        template: prepare
      - name: train
        template: train
        dependencies: prepare-data
      - name: evaluate
        template: evaluate
        dependencies: train

  - name: prepare
    container:
      image: ml-image:v1
      command: [python, prepare.py]

  - name: train
    container:
      image: ml-image:v1
      command: [python, train.py]
      resources:
        requests:
          nvidia.com/gpu: 1

  - name: evaluate
    container:
      image: ml-image:v1
      command: [python, evaluate.py]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para ML en Kubernetes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Usar namespaces separados para desarrollo y producción</p>
</li>
<li>
<p>Implementar resource quotas para limitar consumo</p>
</li>
<li>
<p>Usar network policies para aislamiento</p>
</li>
<li>
<p>Versionear datos y modelos en registries</p>
</li>
<li>
<p>Implementar monitoring de data drift</p>
</li>
<li>
<p>Automated retraining cuando metrics degradan</p>
</li>
<li>
<p>Documentar preprocessing para reproducibilidad</p>
</li>
<li>
<p>Usar GitOps para manage de configuraciones</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_serverless">15.4. Serverless</h3>
<div class="paragraph">
<p>La computación serverless en Kubernetes permite ejecutar funciones y aplicaciones sin gestionar infraestructura. Los usuarios solo escriben código y especifican eventos; la plataforma maneja el escalado automático y la facturación por uso.</p>
</div>
<div class="sect3">
<h4 id="_knative">15.4.1. Knative</h4>
<div class="paragraph">
<p>Knative es la plataforma serverless de Kubernetes más madura y respaldada por Google. Proporciona abstracciones para aplicaciones y funciones.</p>
</div>
<div class="paragraph">
<p><strong>Componentes principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Knative Serving</strong>: Ejecutar aplicaciones sin servidor</p>
</li>
<li>
<p><strong>Knative Eventing</strong>: Enrutamiento de eventos asincrónico</p>
</li>
<li>
<p><strong>Knative Functions</strong>: SDK para crear funciones rápidamente</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Instalación de Knative:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalar Knative Serving
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.8.0/serving-crds.yaml
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.8.0/serving-core.yaml

# Instalar Knative Eventing
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.8.0/eventing-crds.yaml
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.8.0/eventing-core.yaml

# Verificar instalación
kubectl get pods -n knative-serving
kubectl get pods -n knative-eventing</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear un servicio Knative (Serverless):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello-world
spec:
  template:
    spec:
      containers:
      - image: gcr.io/knative-samples/helloworld-go
        env:
        - name: PORT
          value: "8080"
      timeoutSeconds: 300
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "0"        # Scale a 0
        autoscaling.knative.dev/maxScale: "100"      # Máx 100 instancias
        autoscaling.knative.dev/target: "70"         # CPU target
  traffic:
  - percent: 100
    latestRevision: true</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Características de Knative Serving:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Scale-to-zero</strong>: Reducir a 0 cuando no hay tráfico</p>
</li>
<li>
<p><strong>Automatic scaling</strong>: Basado en tráfico (RPS, CPU, custom metrics)</p>
</li>
<li>
<p><strong>Revisiones</strong>: Cada despliegue crea una revisión inmutable</p>
</li>
<li>
<p><strong>Traffic splitting</strong>: Canary deployments y A/B testing</p>
</li>
<li>
<p><strong>Cold start optimization</strong>: Inicialización rápida de funciones</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Knative Function con Python</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: sentiment-analysis
spec:
  template:
    spec:
      containers:
      - image: my-registry/sentiment-analyzer:v1
        ports:
        - containerPort: 8080
        env:
        - name: MODEL_PATH
          value: /models/sentiment
        volumeMounts:
        - name: models
          mountPath: /models
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: ml-models-pvc
      terminationGracePeriodSeconds: 60
    metadata:
      annotations:
        autoscaling.knative.dev/target: "100"  # 100 RPS por instancia
        autoscaling.knative.dev/minScale: "1"

# Traffic splitting: 80% tráfico a v1, 20% a v2
  traffic:
  - revisionName: sentiment-analysis-v1
    percent: 80
  - revisionName: sentiment-analysis-v2
    percent: 20</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_knative_eventing">15.4.2. Knative Eventing</h4>
<div class="paragraph">
<p>Arquitetura event-driven asincrónica para comunicación entre servicios.</p>
</div>
<div class="paragraph">
<p><strong>Conceptos principales:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>EventSource</strong>: Origen de eventos (Kafka, CloudEvents, etc.)</p>
</li>
<li>
<p><strong>Broker</strong>: Enrutador central de eventos</p>
</li>
<li>
<p><strong>Trigger</strong>: Suscripción a eventos con filtros</p>
</li>
<li>
<p><strong>Sink</strong>: Destino de los eventos (servicio, función)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Event-driven pipeline</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># EventSource: Kafka como origen de eventos
apiVersion: sources.knative.dev/v1beta1
kind: KafkaSource
metadata:
  name: order-events
spec:
  bootstrapServers:
  - kafka-broker.kafka:9092
  topics:
  - orders
  consumerGroup: order-processing
  sink:
    ref:
      apiVersion: eventing.knative.dev/v1
      kind: Broker
      name: default
---
# Broker: Enrutador central
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: default
---
# Trigger 1: Procesar órdenes
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: process-order
spec:
  broker: default
  filter:
    attributes:
      type: order.created
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: order-processor
---
# Trigger 2: Enviar notificaciones
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: send-notification
spec:
  broker: default
  filter:
    attributes:
      type: order.completed
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: notification-service</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_openfaas">15.4.3. OpenFaaS</h4>
<div class="paragraph">
<p>Framework serverless más simple y flexible que Knative, con soporte para Docker.</p>
</div>
<div class="paragraph">
<p><strong>Instalación de OpenFaaS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Usar Helm para instalar OpenFaaS
helm repo add openfaas https://openfaas.github.io/faas-netes/
helm install openfaas openfaas/openfaas \
  --namespace openfaas --create-namespace

# Obtener contraseña de admin
kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear una función OpenFaaS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">version: 1.0
provider:
  name: kubernetes
  gateway: http://localhost:8080
functions:
  sentiment-analysis:
    lang: python3
    handler: ./sentiment
    image: username/sentiment-analysis:latest
    environment:
      MODEL: sentiment-v2
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 256Mi
      cpu: 500m
    labels:
      com.openfaas.scale.min: 1
      com.openfaas.scale.max: 50
    annotations:
      prometheus: "true"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estructura de función OpenFaaS (Python):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># handler.py
def handle(req):
    """
    Función serverless OpenFaaS
    req: objeto de request
    """
    import json

    try:
        data = json.loads(req)
        text = data.get('text', '')

        # Análisis de sentimiento
        from textblob import TextBlob
        sentiment = TextBlob(text).sentiment.polarity

        return json.dumps({
            'text': text,
            'sentiment': sentiment,
            'status': 'success'
        })
    except Exception as e:
        return json.dumps({
            'error': str(e),
            'status': 'error'
        })</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kubeless">15.4.4. Kubeless</h4>
<div class="paragraph">
<p>Plataforma serverless diseñada específicamente para Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Instalación de Kubeless:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Descargar e instalar Kubeless
export RELEASE=$(curl -s https://api.github.com/repos/kubeless/kubeless/releases/latest | grep tag_name | cut -d '"' -f 4)
kubectl create ns kubeless
kubectl create -f https://github.com/kubeless/kubeless/releases/download/$RELEASE/kubeless-$RELEASE.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear función Kubeless:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kubeless.io/v1beta1
kind: Function
metadata:
  name: http-trigger
spec:
  handler: index.handler
  runtime: python3.8
  code: |
    def handler(event, context):
        return {
            'statusCode': 200,
            'body': 'Hello from Kubeless!'
        }
  horizontalPodAutoscaler:
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
  limits:
    memory: 256Mi
    cpu: 200m
  requests:
    memory: 128Mi
    cpu: 100m
  service:
    ports:
    - port: 8080
      protocol: TCP
      targetPort: 8080</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_arquitecturas_event_driven">15.4.5. Arquitecturas Event-Driven</h4>
<div class="paragraph">
<p><strong>Patrones comunes:</strong></p>
</div>
<div class="paragraph">
<p><strong>1. Request-Response (Sincrónica):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Client → API Gateway → Function → Response</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Pub-Sub (Asincrónica):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Event Source → Message Broker → Subscribers (múltiples funciones)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. CQRS con Eventos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Command → Write Service → Event → Read Services (actualizar replicas)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo completo: Sistema de órdenes event-driven:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Step 1: Order Service recibe orden
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: order-service
spec:
  template:
    spec:
      containers:
      - image: order-service:v1
---
# Step 2: Broker enruta eventos
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: orders
---
# Step 3: Payment Service procesa pagos
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: payment-processor
spec:
  broker: orders
  filter:
    attributes:
      type: order.created
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: payment-service
---
# Step 4: Shipping Service prepara envío
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: shipping-handler
spec:
  broker: orders
  filter:
    attributes:
      type: order.paid
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: shipping-service
---
# Step 5: Notification Service notifica
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: notification-handler
spec:
  broker: orders
  filter:
    attributes:
      type: order.shipped
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: notification-service</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ventajas de Serverless en Kubernetes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Scale-to-zero</strong>: Ahorra costos cuando no hay carga</p>
</li>
<li>
<p><strong>Escalado automático</strong>: Responde a demanda en segundos</p>
</li>
<li>
<p><strong>Enfoque en código</strong>: Menos preocupación por infraestructura</p>
</li>
<li>
<p><strong>Bajo costo</strong>: Pagar solo por uso real</p>
</li>
<li>
<p><strong>Event-driven</strong>: Natural para microservicios</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Best Practices Serverless:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Mantener funciones pequeñas y enfocadas</p>
</li>
<li>
<p>Implementar health checks</p>
</li>
<li>
<p>Usar tracing distribuido para debugging</p>
</li>
<li>
<p>Monitorear cold starts</p>
</li>
<li>
<p>Implementar retry logic para llamadas fallidas</p>
</li>
<li>
<p>Usar timeouts apropiados</p>
</li>
<li>
<p>Documentar dependencias de eventos</p>
</li>
<li>
<p>Versionear cambios en esquemas de eventos</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_iot_y_edge_computing">15.5. IoT y Edge Computing</h3>
<div class="paragraph">
<p>IoT y Edge Computing requieren orquestación de contenedores en entornos con recursos limitados. Kubernetes proporciona soluciones específicas para estos casos.</p>
</div>
<div class="sect3">
<h4 id="_k3s_kubernetes_ligero_para_edge">15.5.1. K3s: Kubernetes Ligero para Edge</h4>
<div class="paragraph">
<p>K3s es una distribución ligera de Kubernetes, optimizada para entornos con recursos limitados, IoT y edge computing.</p>
</div>
<div class="paragraph">
<p><strong>Características de K3s:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Tamaño reducido</strong>: ~40MB vs 100MB+ de Kubernetes estándar</p>
</li>
<li>
<p><strong>Requisitos bajos</strong>: Funciona con 512MB RAM</p>
</li>
<li>
<p><strong>Binario único</strong>: Fácil instalación y mantenimiento</p>
</li>
<li>
<p><strong>Integración de SQLite</strong>: Base de datos embebida por defecto</p>
</li>
<li>
<p><strong>Soporte completo de Kubernetes</strong>: Compatible con APIs estándar</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Instalación de K3s:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Instalación rápida en Linux
curl -sfL https://get.k3s.io | sh -

# Instalar sin systemd
curl -sfL https://get.k3s.io | sh -s - --no-systemd

# Instalar en Raspberry Pi
curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE="644" sh -

# Verificar instalación
sudo k3s kubectl get nodes

# Unir worker nodes al cluster
K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken ./k3s agent</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Arquitectura mínima K3s:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────────┐
│   K3s Server Node           │
│  (API, kubelet, controller) │
│  ~40MB, 512MB RAM mínimo    │
└──────────┬──────────────────┘
           │
    ┌──────┴──────┬──────────┐
    ▼             ▼          ▼
┌────────┐  ┌────────┐  ┌────────┐
│Worker 1│  │Worker 2│  │Worker 3│
│IoT Dev │  │IoT Dev │  │IoT Dev │
└────────┘  └────────┘  └────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración de K3s para Edge:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Instalación minimal con recursos limitados
apiVersion: v1
kind: Pod
metadata:
  name: edge-app
spec:
  containers:
  - name: app
    image: myapp:edge
    resources:
      requests:
        memory: "32Mi"    # Mínimo
        cpu: "50m"        # 50 milicores
      limits:
        memory: "64Mi"    # Límite bajo
        cpu: "100m"
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    emptyDir: {}
    sizeLimit: 100Mi      # Limitar tamaño de almacenamiento
  nodeSelector:
    node-type: edge       # Ejecutar solo en nodos edge</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Almacenamiento local en K3s:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># StorageClass local para edge
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
# PVC para datos de IoT
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sensor-data
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: local-storage
  resources:
    requests:
      storage: 1Gi</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kubeedge">15.5.2. KubeEdge</h4>
<div class="paragraph">
<p>KubeEdge extiende Kubernetes a dispositivos edge, permitiendo gestionar miles de nodos con latencia baja y desconexión resiliente.</p>
</div>
<div class="paragraph">
<p><strong>Arquitectura de KubeEdge:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────┐
│  Cloud (Cloud Side)     │
│  - Kubernetes Master    │
│  - CloudHub (gRPC)      │
└──────────┬──────────────┘
           │ gRPC Tunnel
    ┌──────┴──────────────────┐
    │  Edge (Edge Side)       │
    │  - EdgeHub (Edge Node)  │
    │  - Device Mapper        │
    │  - MetaManager          │
    └──────┬──────────────────┘
           │
    ┌──────┴──────┬──────────┐
    ▼             ▼          ▼
┌──────────┐ ┌──────────┐ ┌──────────┐
│Raspberry │ │ IoT Dev. │ │ Sensor   │
│   Pi     │ │ Gateway  │ │ Network  │
└──────────┘ └──────────┘ └──────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Instalación de KubeEdge:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Clonar repositorio de KubeEdge
git clone https://github.com/kubeedge/kubeedge.git
cd kubeedge

# Instalar CloudCore en el maestro
./keadm init --advertise-address=&lt;cloud-node-ip&gt;

# Obtener token para unir edge nodes
./keadm gettoken

# Instalar EdgeCore en dispositivo edge
./keadm join --cloudcore-ipport=&lt;cloud-ip&gt;:10000 \
             --token=&lt;token-del-maestro&gt; \
             --edgenode-name=&lt;edge-node-name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración de Device Twin en KubeEdge:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: devices.kubeedge.io/v1alpha2
kind: Device
metadata:
  name: temp-sensor
  namespace: default
spec:
  deviceModelRef:
    name: temperature-model
  nodeSelector:
    nodeName: edge-node-1
  properties:
  - name: temperature
    value: "25.0"
  - name: humidity
    value: "60"
  protocol:
    protocolName: modbus
    protocolConfig:
      ip: "192.168.1.100"
      port: "502"
  twins:
  - propertyName: temperature
    reportedValue: "25.0"
    desiredValue: "25.0"
  - propertyName: humidity
    reportedValue: "60"
    desiredValue: "60"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Aplicación Edge que consume datos de sensores:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: edge-processor
spec:
  replicas: 1
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.kubernetes.io/edge
            operator: In
            values:
            - "true"
  template:
    spec:
      containers:
      - name: processor
        image: sensor-processor:v1
        env:
        - name: DEVICE_NAME
          value: temp-sensor
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
        volumeMounts:
        - name: cache
          mountPath: /var/cache
      volumes:
      - name: cache
        emptyDir:
          sizeLimit: 100Mi</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_edge_deployments_patrones">15.5.3. Edge Deployments: Patrones</h4>
<div class="paragraph">
<p><strong>Patrón 1: Cloud-Native con Síncrónización Edge</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">┌─────────────────────────┐
│  Cloud                  │
│  - Análisis Heavy       │
│  - Machine Learning     │
│  - Almacenamiento       │
└──────────┬──────────────┘
           │ Sincronización
           │ de datos
    ┌──────┴──────┐
    ▼             ▼
┌────────┐  ┌────────┐
│ Edge 1 │  │ Edge 2 │
│ Local  │  │ Local  │
│ Apps   │  │ Apps   │
└────────┘  └────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 2: Filtrado en Edge</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Solo enviar datos importantes a la nube
apiVersion: v1
kind: ConfigMap
metadata:
  name: edge-filter-rules
data:
  rules: |
    # Si temperatura &gt; 30°C, enviar a cloud
    if temperature &gt; 30:
      send_to_cloud()

    # Almacenar datos locales
    store_local()

    # Ejecutar lógica de tiempo real local
    if temperature &gt; 35:
      activate_cooling()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo: IoT Smart Home</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># 1. Define sensor device
apiVersion: devices.kubeedge.io/v1alpha2
kind: Device
metadata:
  name: living-room-sensor
spec:
  deviceModelRef:
    name: climate-sensor
  nodeSelector:
    nodeName: edge-gateway
  protocol:
    protocolName: mqtt
    protocolConfig:
      ip: "192.168.1.50"
      port: "1883"
  twins:
  - propertyName: temperature
    reportedValue: "22"
  - propertyName: humidity
    reportedValue: "45"
---
# 2. Deploy edge app que procesa datos localmente
apiVersion: apps/v1
kind: Deployment
metadata:
  name: climate-controller
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - edge
      containers:
      - name: controller
        image: climate-control:v1
        resources:
          requests:
            memory: "32Mi"
            cpu: "50m"
          limits:
            memory: "64Mi"
            cpu: "100m"
        env:
        - name: SENSOR_NAME
          value: living-room-sensor
---
# 3. Send aggregated data to cloud
apiVersion: batch/v1
kind: CronJob
metadata:
  name: sync-to-cloud
spec:
  schedule: "*/5 * * * *"  # Cada 5 minutos
  jobTemplate:
    spec:
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: node-type
                    operator: In
                    values:
                    - edge
          containers:
          - name: sync
            image: cloud-sync:v1
            env:
            - name: CLOUD_API
              value: "https://cloud.example.com/api"
            resources:
              requests:
                memory: "16Mi"
                cpu: "50m"
          restartPolicy: OnFailure</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_restricciones_de_recursos_en_edge">15.5.4. Restricciones de Recursos en Edge</h4>
<div class="paragraph">
<p><strong>Optimización para dispositivos con recursos limitados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Limitar estrictamente consumo de recursos
apiVersion: v1
kind: Pod
metadata:
  name: lightweight-app
spec:
  containers:
  - name: app
    image: myapp:ultra-light  # Imagen base alpina
    resources:
      requests:
        memory: "16Mi"
        cpu: "25m"
      limits:
        memory: "32Mi"
        cpu: "50m"

    # Desabilitar logs verbosos
    env:
    - name: LOG_LEVEL
      value: "ERROR"

    # Usar buffer pequeño
    - name: BUFFER_SIZE
      value: "16384"

    # No mantener conexiones abiertas
    - name: CONNECTION_TIMEOUT
      value: "30"

    livenessProbe:
      initialDelaySeconds: 60  # Mayor delay en edge
      periodSeconds: 30

    readinessProbe:
      initialDelaySeconds: 30
      periodSeconds: 10

  # Evitar overcommit
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - fast-ssd  # Usar almacenamiento rápido</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitoreo en Edge:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver consumo de recursos en nodos edge
kubectl top nodes -l node-type=edge

# Ver consumo por pod
kubectl top pods -l app=edge-app --namespace=default

# Obtener estado de conectividad de edge nodes
kubectl get nodes -L kubernetes.io/hostname,node-type

# Ver latencia de sincronización
kubectl logs -n kubeedge -l app=edgehub | grep latency</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices para Edge Computing:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Aplicaciones ligeras</strong>: Usar imágenes base mínimas (Alpine, Distroless)</p>
</li>
<li>
<p><strong>Escalado manual</strong>: Edge nodes tienen recursos limitados</p>
</li>
<li>
<p><strong>Cache local</strong>: Minimizar comunicación con cloud</p>
</li>
<li>
<p><strong>Tolerancia a desconexión</strong>: Diseñar apps que funcionen sin cloud</p>
</li>
<li>
<p><strong>Actualizaciones seguras</strong>: Verificar espacio antes de descargar imágenes</p>
</li>
<li>
<p><strong>Monitoreo local</strong>: No enviar todos los logs a cloud</p>
</li>
<li>
<p><strong>Compresión de datos</strong>: Reducir ancho de banda</p>
</li>
<li>
<p><strong>Particionamiento de datos</strong>: Procesar solo datos relevantes</p>
</li>
<li>
<p><strong>Heartbeat</strong>: Detectar desconexión de edge nodes</p>
</li>
<li>
<p><strong>Sincronización inteligente</strong>: Batching de cambios antes de enviar</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_anexos">16. Anexos</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_a_comandos_kubectl_esenciales">16.1. A. Comandos kubectl Esenciales</h3>
<div class="sect3">
<h4 id="_gestión_de_recursos">16.1.1. Gestión de Recursos</h4>
<div class="paragraph">
<p><strong>Crear y aplicar manifiestos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Aplicar un archivo YAML
kubectl apply -f deployment.yaml

# Aplicar todos los archivos en un directorio
kubectl apply -f ./manifests/

# Aplicar cambios de un archivo (editar in-place)
kubectl apply -f deployment.yaml --record

# Ver cambios antes de aplicar
kubectl apply -f deployment.yaml --dry-run=client

# Aplicar con output
kubectl apply -f deployment.yaml -o wide</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Crear recursos imperativamente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear un deployment imperativamente
kubectl create deployment nginx --image=nginx:latest --replicas=3

# Crear un servicio
kubectl expose deployment nginx --port=80 --target-port=80 --type=LoadBalancer

# Crear un namespace
kubectl create namespace production

# Crear un secret
kubectl create secret generic db-secret --from-literal=password=mysecret

# Crear un ConfigMap
kubectl create configmap app-config --from-file=config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Eliminar recursos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Eliminar un recurso
kubectl delete deployment nginx

# Eliminar múltiples tipos
kubectl delete deployment,service nginx

# Eliminar por selector
kubectl delete pods -l app=nginx

# Eliminar todo en un namespace
kubectl delete all --all -n staging

# Eliminar recurso pero esperar a que finalice
kubectl delete pod nginx --grace-period=30</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Actualizar recursos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Actualizar una imagen
kubectl set image deployment/nginx nginx=nginx:1.20 --record

# Escalar manualmente
kubectl scale deployment nginx --replicas=5

# Editar recurso directamente
kubectl edit deployment nginx

# Patch un recurso (cambio mínimo)
kubectl patch deployment nginx -p '{"spec":{"replicas":3}}'

# Rollout a versión anterior
kubectl rollout undo deployment/nginx</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_debugging_y_troubleshooting_2">16.1.2. Debugging y Troubleshooting</h4>
<div class="paragraph">
<p><strong>Inspeccionar recursos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver descripción detallada
kubectl describe pod nginx-xyz

# Ver logs de un pod
kubectl logs nginx-xyz

# Ver logs de contenedor específico en pod multi-contenedor
kubectl logs nginx-xyz -c nginx

# Ver logs en tiempo real
kubectl logs -f nginx-xyz

# Ver logs de pod anterior (si crasheó)
kubectl logs nginx-xyz --previous

# Ver eventos de un pod
kubectl describe pod nginx-xyz | grep Events -A 20</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Acceso a pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ejecutar comando en pod
kubectl exec nginx-xyz -- ls -la

# Ejecutar comando interactivo en pod
kubectl exec -it nginx-xyz -- /bin/bash

# Copiar archivo desde pod
kubectl cp nginx-xyz:/var/log/access.log ./access.log

# Copiar archivo a pod
kubectl cp ./config.yaml nginx-xyz:/etc/config.yaml

# Port-forward a un pod
kubectl port-forward nginx-xyz 8080:80</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitoreo y estado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver consumo de recursos
kubectl top nodes

# Ver consumo por pod
kubectl top pods

# Ver eventos del cluster
kubectl get events --sort-by='.lastTimestamp'

# Ver estado de rollout
kubectl rollout status deployment/nginx

# Ver historial de cambios
kubectl rollout history deployment/nginx

# Ver cambios específicos de revisión
kubectl rollout history deployment/nginx --revision=2</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_consultas_y_filtros">16.1.3. Consultas y Filtros</h4>
<div class="paragraph">
<p><strong>Listar recursos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Listar todos los pods
kubectl get pods

# Listar con información ampliada
kubectl get pods -o wide

# Listar en namespace específico
kubectl get pods -n production

# Listar de todos los namespaces
kubectl get pods --all-namespaces

# Listar deployments
kubectl get deployments

# Listar services
kubectl get svc

# Listar recursos por selector
kubectl get pods -l app=nginx

# Listar recursos sin labels específico
kubectl get pods -L app,version</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Filtros y selecciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Filtrar por label
kubectl get pods -l tier=frontend

# Filtrar por múltiples labels
kubectl get pods -l app=api,version=v1

# Filtrar por namespace
kubectl get pods -n production

# Filtrar por campo
kubectl get pods --field-selector=status.phase=Running

# Filtrar pods en estado fallido
kubectl get pods --field-selector=status.phase=Failed

# Ver solo nombres de pods
kubectl get pods -o name

# Ver en formato JSON
kubectl get pods -o json

# Ver en formato YAML
kubectl get pods -o yaml

# Ver con columnas personalizadas
kubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,RESTARTS:.status.containerStatuses[0].restartCount</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Búsqueda y visualización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Buscar pod por nombre
kubectl get pods | grep nginx

# Ver estructura de un CRD
kubectl explain deployment
kubectl explain deployment.spec

# Ver estructuras anidadas
kubectl explain deployment.spec.template.spec.containers

# Buscar recursos de un tipo específico
kubectl api-resources

# Ver versiones API disponibles
kubectl api-versions</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_shortcuts_y_aliases_útiles">16.1.4. Shortcuts y Aliases Útiles</h4>
<div class="paragraph">
<p><strong>Abreviaturas de kubectl:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear alias en shell
alias k=kubectl
alias kg='kubectl get'
alias kd='kubectl delete'
alias kl='kubectl logs'
alias ke='kubectl exec'
alias kgp='kubectl get pods'
alias kgs='kubectl get svc'
alias kgd='kubectl get deployment'
alias kdesc='kubectl describe'

# Usar bash completion
source &lt;(kubectl completion bash)

# Agregar permanentemente en ~/.bashrc
echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
echo "alias k=kubectl" &gt;&gt; ~/.bashrc
echo "complete -o default -F __start_kubectl k" &gt;&gt; ~/.bashrc</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comandos útiles frecuentes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ver todos los recursos en un namespace
kubectl get all -n production

# Ver pods que se están ejecutando
kubectl get pods --field-selector=status.phase=Running

# Ver pods fallidos
kubectl get pods --field-selector=status.phase=Failed

# Listar nodos con etiquetas
kubectl get nodes --show-labels

# Ver nodos y su capacidad
kubectl get nodes -o wide

# Ver eventos recientes
kubectl get events --sort-by='.lastTimestamp' | tail -20

# Limpiar pods completados
kubectl delete pods --field-selector=status.phase=Succeeded

# Forzar eliminación de pod
kubectl delete pod nginx-xyz --force --grace-period=0

# Ver taints en nodos
kubectl describe nodes | grep Taints

# Aplicar taint a nodo
kubectl taint nodes node-1 gpu=true:NoSchedule

# Quitar taint de nodo
kubectl taint nodes node-1 gpu:NoSchedule-</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Monitoreo rápido:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Watch: actualizar en tiempo real
kubectl get pods -w

# Ver cambios en deployment
kubectl get deployment nginx -w

# Ver status de rollout
kubectl rollout status deployment/nginx -w

# Monitoreo avanzado
watch 'kubectl get pods -o wide'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Exportar y guardar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Exportar configuración de un pod
kubectl get pod nginx-xyz -o yaml &gt; nginx-pod.yaml

# Exportar deployment
kubectl get deployment nginx -o yaml &gt; deployment.yaml

# Exportar todo un namespace
kubectl get all -n production -o yaml &gt; production-backup.yaml

# Exportar sin metadata del sistema
kubectl get pod nginx-xyz -o yaml | kubectl neat</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_b_yaml_reference">16.2. B. YAML Reference</h3>
<div class="sect3">
<h4 id="_sintaxis_básica_de_yaml">16.2.1. Sintaxis Básica de YAML</h4>
<div class="paragraph">
<p>YAML es el formato usado para definir recursos en Kubernetes. Es sensible a la indentación y utiliza espacios (no tabulaciones).</p>
</div>
<div class="paragraph">
<p><strong>Tipos de datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Strings (sin comillas, con comillas, o multiline)
nombre: "Kubernetes"
descripcion: curso de K8s
multiline: |
  Esta es una línea
  Esta es otra línea
  Preserva los saltos de línea

# Números
puerto: 8080
replicas: 3
cpu: 0.5

# Booleanos
habilitado: true
debug: false

# Null
valor_nulo: null
otro_nulo:

# Listas
puertos:
  - 8080
  - 8081
  - 8082

# Objetos (diccionarios)
metadata:
  nombre: mi-app
  version: v1
  labels:
    app: backend
    tier: api

# Alias y referencias
default_labels: &amp;default-labels
  app: myapp
  version: v1

deployment_labels:
  &lt;&lt;: *default-labels  # Hereda las labels
  environment: prod</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comentarios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Este es un comentario de línea

apiVersion: v1  # Versión de la API
kind: Pod       # Tipo de recurso</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_estructura_de_manifiestos_kubernetes">16.2.2. Estructura de Manifiestos Kubernetes</h4>
<div class="paragraph">
<p>Todo recurso de Kubernetes tiene la misma estructura base:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Requerido: Versión de API
apiVersion: v1

# Requerido: Tipo de recurso
kind: Pod

# Requerido: Información del recurso
metadata:
  # Nombre único en el namespace
  name: mi-pod

  # Namespace (default si no especifica)
  namespace: default

  # Labels para seleccionar/agrupar recursos
  labels:
    app: backend
    version: v1
    tier: api

  # Anotaciones para metadatos no identificables
  annotations:
    descripcion: "Pod de ejemplo"
    owner: "team-platform"

# Requerido: Especificación del recurso
spec:
  # Contenido depende del tipo (Pod, Deployment, Service, etc.)
  containers:
  - name: app
    image: nginx:latest</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_versiones_de_api">16.2.3. Versiones de API</h4>
<div class="paragraph">
<p>Las versiones definen qué campos están disponibles:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># Versión estable
apiVersion: v1

# Versiones beta (pueden cambiar)
apiVersion: apps/v1beta1

# Versiones estables con grupo
apiVersion: apps/v1
apiVersion: batch/v1

# Versiones avanzadas
apiVersion: networking.k8s.io/v1
apiVersion: storage.k8s.io/v1
apiVersion: rbac.authorization.k8s.io/v1

# Ver todas las versiones disponibles
# kubectl api-versions</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_campos_comunes_en_recursos">16.2.4. Campos Comunes en Recursos</h4>
<div class="paragraph">
<p><strong>Pod/Deployment/StatefulSet spec.template.spec:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">spec:
  # Tiempo para detener gracefully (shutdown)
  terminationGracePeriodSeconds: 30

  # DNS policy
  dnsPolicy: ClusterFirst

  # Restart policy
  restartPolicy: Always

  # Service account
  serviceAccountName: default

  # Security context (nivel pod)
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true

  # Toleraciones a taints de nodos
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

  # Afinidad a nodos
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd

  # Volúmenes del pod
  volumes:
  - name: config
    configMap:
      name: app-config
  - name: storage
    persistentVolumeClaim:
      claimName: my-pvc

  # Contenedores
  containers:
  - name: app
    image: myapp:v1.0
    imagePullPolicy: IfNotPresent

    # Puertos
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP

    # Variables de entorno
    env:
    - name: LOG_LEVEL
      value: "info"
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password

    # Montar volúmenes
    volumeMounts:
    - name: config
      mountPath: /etc/config
    - name: storage
      mountPath: /data

    # Recursos (solicitudes y límites)
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "500m"

    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3

    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5

    # Security context (nivel contenedor)
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true

    # Ciclo de vida
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "echo 'iniciando'"]
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 15"]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Selector y match:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># En Deployment/Service/etc
selector:
  matchLabels:
    app: nginx
    version: v1

# O alternativa
selector:
  app: nginx
  version: v1</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplos_de_manifiestos_completos">16.2.5. Ejemplos de Manifiestos Completos</h4>
<div class="paragraph">
<p><strong>Ejemplo 1: Pod simple</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Deployment con Service</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: mycompany/api:v2.0
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: api-server
spec:
  selector:
    app: api
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: StatefulSet con PVC</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo 4: ConfigMap y Secret</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  app.properties: |
    server.port=8080
    debug=true
  database.yaml: |
    host: postgres.default.svc.cluster.local
    port: 5432
---
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
data:
  # Base64 encoded (echo -n 'password' | base64)
  password: cGFzc3dvcmQ=
  username: YWRtaW4=</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Validación de sintaxis:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Validar YAML sin aplicar
kubectl apply -f deployment.yaml --dry-run=client

# Validar y ver lo que se aplicaría
kubectl apply -f deployment.yaml --dry-run=client -o yaml

# Usar herramientas externas
# kubeval deployment.yaml
# kube-score score deployment.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_c_glosario">16.3. C. Glosario</h3>
<div class="sect3">
<h4 id="_términos_clave">16.3.1. Términos Clave</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>API Server</strong></dt>
<dd>
<p>Servidor central de Kubernetes que expone la API REST y gestiona la comunicación. Todos los componentes interactúan a través del API Server.</p>
</dd>
<dt class="hdlist1"><strong>Cluster</strong></dt>
<dd>
<p>Conjunto de nodos (máquinas) controlados por Kubernetes para ejecutar cargas de trabajo. Mínimo requiere un nodo master y al menos un nodo worker.</p>
</dd>
<dt class="hdlist1"><strong>ConfigMap</strong></dt>
<dd>
<p>Recurso Kubernetes para almacenar configuración no sensible (variables de entorno, archivos). Los datos están en texto plano.</p>
</dd>
<dt class="hdlist1"><strong>Container Runtime</strong></dt>
<dd>
<p>Software que ejecuta contenedores (Docker, containerd, CRI-O). Kubernetes es agnóstico al runtime.</p>
</dd>
<dt class="hdlist1"><strong>Control Plane (Master)</strong></dt>
<dd>
<p>Conjunto de componentes que toman decisiones sobre el cluster (API Server, Scheduler, Controller Manager, etcd).</p>
</dd>
<dt class="hdlist1"><strong>CRD (Custom Resource Definition)</strong></dt>
<dd>
<p>Extensión que permite definir tipos de recursos personalizados en Kubernetes.</p>
</dd>
<dt class="hdlist1"><strong>Deployment</strong></dt>
<dd>
<p>Controlador que gestiona Pods con replicas, actualizaciones y rollbacks automáticos.</p>
</dd>
<dt class="hdlist1"><strong>DaemonSet</strong></dt>
<dd>
<p>Controlador que asegura que un Pod se ejecute en cada nodo del cluster.</p>
</dd>
<dt class="hdlist1"><strong>Etcd</strong></dt>
<dd>
<p>Base de datos distribuida que almacena toda la información de estado del cluster Kubernetes.</p>
</dd>
<dt class="hdlist1"><strong>Headless Service</strong></dt>
<dd>
<p>Service sin IP de cluster (clusterIP: None) que retorna IPs específicas de Pods para aplicaciones que requieren identidades estables.</p>
</dd>
<dt class="hdlist1"><strong>Health Check</strong></dt>
<dd>
<p>Verificación automatizada del estado de un Pod (liveness probe, readiness probe).</p>
</dd>
<dt class="hdlist1"><strong>Helm</strong></dt>
<dd>
<p>Gestor de paquetes para Kubernetes que simplifica la instalación y configuración de aplicaciones complejas.</p>
</dd>
<dt class="hdlist1"><strong>Image</strong></dt>
<dd>
<p>Plantilla inmutable de un contenedor que contiene código, runtime, librerías y dependencias.</p>
</dd>
<dt class="hdlist1"><strong>Ingress</strong></dt>
<dd>
<p>Recurso que gestiona acceso HTTP/HTTPS externo a servicios dentro del cluster.</p>
</dd>
<dt class="hdlist1"><strong>Job</strong></dt>
<dd>
<p>Controlador para ejecutar Pods una sola vez hasta completarse (para trabajos batch).</p>
</dd>
<dt class="hdlist1"><strong>Kubelet</strong></dt>
<dd>
<p>Agente que corre en cada nodo y asegura que los Pods estén corriendo según la especificación.</p>
</dd>
<dt class="hdlist1"><strong>Kubectl</strong></dt>
<dd>
<p>Herramienta CLI para interactuar con clusters Kubernetes.</p>
</dd>
<dt class="hdlist1"><strong>Label</strong></dt>
<dd>
<p>Par clave-valor que se asigna a recursos para identificación y selección.</p>
</dd>
<dt class="hdlist1"><strong>Namespace</strong></dt>
<dd>
<p>Mecanismo de aislamiento lógico para dividir un cluster en múltiples entornos virtuales.</p>
</dd>
<dt class="hdlist1"><strong>Node</strong></dt>
<dd>
<p>Máquina (física o virtual) que forma parte del cluster Kubernetes.</p>
</dd>
<dt class="hdlist1"><strong>Operator</strong></dt>
<dd>
<p>Controlador personalizado que automatiza procesos operacionales complejos específicos de aplicaciones.</p>
</dd>
<dt class="hdlist1"><strong>Persistent Volume (PV)</strong></dt>
<dd>
<p>Almacenamiento de cluster que persiste independientemente de los Pods.</p>
</dd>
<dt class="hdlist1"><strong>Persistent Volume Claim (PVC)</strong></dt>
<dd>
<p>Solicitud de almacenamiento por parte de un Pod.</p>
</dd>
<dt class="hdlist1"><strong>Pod</strong></dt>
<dd>
<p>Unidad desplegable más pequeña en Kubernetes, generalmente contiene un contenedor (puede tener varios).</p>
</dd>
<dt class="hdlist1"><strong>Probe</strong></dt>
<dd>
<p>Verificación periódica del estado de un contenedor (liveness, readiness, startup).</p>
</dd>
<dt class="hdlist1"><strong>ReplicaSet</strong></dt>
<dd>
<p>Controlador que mantiene un número específico de replicas de un Pod en ejecución.</p>
</dd>
<dt class="hdlist1"><strong>Secret</strong></dt>
<dd>
<p>Recurso para almacenar datos sensibles (contraseñas, tokens, certificados) codificados en base64.</p>
</dd>
<dt class="hdlist1"><strong>Service</strong></dt>
<dd>
<p>Abstracción que expone un conjunto de Pods como servicio de red con un nombre DNS.</p>
</dd>
<dt class="hdlist1"><strong>Service Mesh</strong></dt>
<dd>
<p>Infraestructura de red dedicada que gestiona comunicación entre servicios (Istio, Linkerd).</p>
</dd>
<dt class="hdlist1"><strong>StatefulSet</strong></dt>
<dd>
<p>Controlador para Pods con identidad estable, nombres predecibles y almacenamiento persistente.</p>
</dd>
<dt class="hdlist1"><strong>Storage Class</strong></dt>
<dd>
<p>Define clases de almacenamiento disponibles para provisioning dinámico de PVs.</p>
</dd>
<dt class="hdlist1"><strong>Taint</strong></dt>
<dd>
<p>Marca en un nodo que repele Pods a menos que tengan una toleración correspondiente.</p>
</dd>
<dt class="hdlist1"><strong>Tolerations</strong></dt>
<dd>
<p>Especificación que permite a un Pod ser programado en nodos con taints específicos.</p>
</dd>
<dt class="hdlist1"><strong>Volume</strong></dt>
<dd>
<p>Almacenamiento adjunto a un Pod, puede ser efímero o persistente.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_acrónimos_comunes">16.3.2. Acrónimos Comunes</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Acrónimo</th>
<th class="tableblock halign-left valign-top">Significado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Application Programming Interface</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CNCF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloud Native Computing Foundation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CRD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Custom Resource Definition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ETCD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Distributed Reliable Key-Value Store</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">High Availability (Alta Disponibilidad)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Horizontal Pod Autoscaler</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RBAC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Role-Based Access Control</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RPS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Requests Per Second</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service Level Agreement</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service Level Indicator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLO</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service Level Objective</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VPA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vertical Pod Autoscaler</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">QoS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quality of Service</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DaemonSet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Service ejecutado en todos los nodos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CNI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Network Interface</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CSI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Storage Interface</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YAML</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">YAML Ain&#8217;t Markup Language</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">JSON</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">JavaScript Object Notation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RFC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Request for Comments</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Custom Resource</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CRI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Runtime Interface</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_conceptos_fundamentales_3">16.3.3. Conceptos Fundamentales</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Declarativo vs Imperativo</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Imperativo</strong>: Comando directo (kubectl run, kubectl create)</p>
</li>
<li>
<p><strong>Declarativo</strong>: Describir estado deseado en YAML (kubectl apply)</p>
</li>
<li>
<p>Kubernetes prefiere enfoque declarativo para reproducibilidad</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Eventual Consistency</strong></dt>
<dd>
<p>El estado eventual del cluster coincidirá con el deseado, pero puede tomar tiempo. El Reconciliation Loop verifica y corrige constantemente.</p>
</dd>
<dt class="hdlist1"><strong>Idempotencia</strong></dt>
<dd>
<p>Aplicar la misma configuración múltiples veces produce el mismo resultado final (seguro aplicar varias veces).</p>
</dd>
<dt class="hdlist1"><strong>Reconciliation</strong></dt>
<dd>
<p>Proceso continuo donde Kubernetes compara estado deseado vs actual y toma acciones para alinearlos.</p>
</dd>
<dt class="hdlist1"><strong>Selectors</strong></dt>
<dd>
<p>Mecanismo para seleccionar recursos por labels. Ejemplo: <code>app=nginx,tier=frontend</code></p>
</dd>
<dt class="hdlist1"><strong>Affinity</strong></dt>
<dd>
<p>Reglas para preferir o requerir que Pods se ejecuten en nodos específicos.</p>
</dd>
<dt class="hdlist1"><strong>Pod Disruption Budget (PDB)</strong></dt>
<dd>
<p>Especifica cuántos Pods pueden ser interrumpidos simultáneamente durante maintenance.</p>
</dd>
<dt class="hdlist1"><strong>Quality of Service (QoS)</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Guaranteed</strong>: Requests = Limits (máxima prioridad)</p>
</li>
<li>
<p><strong>Burstable</strong>: Requests &lt; Limits (prioridad media)</p>
</li>
<li>
<p><strong>BestEffort</strong>: Sin requests/limits (baja prioridad)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Graceful Shutdown</strong></dt>
<dd>
<p>Tiempo permitido para que un Pod finalice transacciones antes de ser forzadamente terminado.</p>
</dd>
<dt class="hdlist1"><strong>Blue-Green Deployment</strong></dt>
<dd>
<p>Estrategia donde se mantienen dos ambientes idénticos y se cambia tráfico de uno a otro.</p>
</dd>
<dt class="hdlist1"><strong>Canary Deployment</strong></dt>
<dd>
<p>Desplegar cambios gradualmente a un pequeño porcentaje de usuarios primero.</p>
</dd>
<dt class="hdlist1"><strong>Rolling Update</strong></dt>
<dd>
<p>Actualizar Pods gradualmente, reemplazando instancias antiguas por nuevas.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_d_recursos_adicionales">16.4. D. Recursos Adicionales</h3>
<div class="sect3">
<h4 id="_documentación_oficial">16.4.1. Documentación Oficial</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Kubernetes.io (Fuente Oficial)</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Documentación</strong>: <a href="https://kubernetes.io/docs/" class="bare">https://kubernetes.io/docs/</a></p>
</li>
<li>
<p><strong>Conceptos</strong>: <a href="https://kubernetes.io/docs/concepts/" class="bare">https://kubernetes.io/docs/concepts/</a></p>
</li>
<li>
<p><strong>Tareas</strong>: <a href="https://kubernetes.io/docs/tasks/" class="bare">https://kubernetes.io/docs/tasks/</a></p>
</li>
<li>
<p><strong>Referencias</strong>: <a href="https://kubernetes.io/docs/reference/" class="bare">https://kubernetes.io/docs/reference/</a></p>
</li>
<li>
<p><strong>API oficial</strong>: <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/" class="bare">https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/</a></p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>API Documentation</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Documentación interactiva de API: <code>kubectl api-resources</code></p>
</li>
<li>
<p>Explicación de campos: <code>kubectl explain deployment.spec</code></p>
</li>
<li>
<p>Referencia JSON: <a href="https://kubernetes.io/docs/reference/" class="bare">https://kubernetes.io/docs/reference/</a></p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>CNCF (Cloud Native Computing Foundation)</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Sitio oficial: <a href="https://www.cncf.io/" class="bare">https://www.cncf.io/</a></p>
</li>
<li>
<p>Proyectos incubados: <a href="https://www.cncf.io/projects/" class="bare">https://www.cncf.io/projects/</a></p>
</li>
<li>
<p>Landscape: <a href="https://landscape.cncf.io/" class="bare">https://landscape.cncf.io/</a></p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_libros_recomendados">16.4.2. Libros Recomendados</h4>
<div class="paragraph">
<p><strong>Kubernetes Essentials</strong>
- Autores: Thaha Kamarudin
- Cobertura: Conceptos fundamentales, instalación, despliegue
- Nivel: Principiante a Intermedio</p>
</div>
<div class="paragraph">
<p><strong>Kubernetes in Action (2ª Edición)</strong>
- Autores: Marko Lukša
- Cobertura: Comprehensive guide con ejemplos prácticos
- Nivel: Intermedio a Avanzado</p>
</div>
<div class="paragraph">
<p><strong>The Kubernetes Book</strong>
- Autores: Nigel Poulton
- Cobertura: Desde lo básico hasta temas avanzados
- Nivel: Todos los niveles</p>
</div>
<div class="paragraph">
<p><strong>Cloud Native DevOps with Kubernetes</strong>
- Autores: John Arundel, Justin Domingus
- Cobertura: DevOps practices en Kubernetes
- Nivel: Intermedio a Avanzado</p>
</div>
<div class="paragraph">
<p><strong>Kubernetes Security</strong>
- Autores: Liz Rice, Michael Hausenblas
- Cobertura: Security best practices
- Nivel: Avanzado</p>
</div>
<div class="paragraph">
<p><strong>Kubernetes Patterns</strong>
- Autores: Bilgin Ibryam, Roland Huss
- Cobertura: Patrones de diseño y arquitectura
- Nivel: Intermedio a Avanzado</p>
</div>
</div>
<div class="sect3">
<h4 id="_plataformas_de_aprendizaje_online">16.4.3. Plataformas de Aprendizaje Online</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Linux Academy / A Cloud Guru</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Cursos interactivos en video</p>
</li>
<li>
<p>Labs prácticos</p>
</li>
<li>
<p>Certificación CKA/CKAD</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Udemy</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Cursos variados sobre Kubernetes</p>
</li>
<li>
<p>Precios accesibles</p>
</li>
<li>
<p>Certificados completados</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Pluralsight</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Cursos profesionales estructurados</p>
</li>
<li>
<p>Rutas de aprendizaje por nivel</p>
</li>
<li>
<p>Laboratorios prácticos</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>KodeKloud</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Especialización en Kubernetes</p>
</li>
<li>
<p>Labs prácticos con retroalimentación</p>
</li>
<li>
<p>Preparación para CKA/CKAD/CKS</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Linux Foundation</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Cursos oficiales LF (LFS258, LFS259)</p>
</li>
<li>
<p>Exámenes oficiales CKA/CKAD/CKS</p>
</li>
<li>
<p>Entrenamientos patrocinados</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_comunidades_y_foros">16.4.4. Comunidades y Foros</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Kubernetes Community</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Slack oficial: <a href="https://slack.k8s.io/" class="bare">https://slack.k8s.io/</a></p>
</li>
<li>
<p>Canales por tema: #kubernetes-users, #kubernetes-dev</p>
</li>
<li>
<p>GitHub discussions: <a href="https://github.com/kubernetes/kubernetes" class="bare">https://github.com/kubernetes/kubernetes</a></p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Stack Overflow</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Tag <code>kubernetes</code>: <a href="https://stackoverflow.com/questions/tagged/kubernetes" class="bare">https://stackoverflow.com/questions/tagged/kubernetes</a></p>
</li>
<li>
<p>Miles de preguntas respondidas</p>
</li>
<li>
<p>Búsqueda rápida de soluciones</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Reddit</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>r/kubernetes: Comunidad principal</p>
</li>
<li>
<p>r/devops: Includes Kubernetes discussions</p>
</li>
<li>
<p>Preguntas casuales bienvenidas</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Discord Servers</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Varios servidores comunitarios</p>
</li>
<li>
<p>Canales de #help-general</p>
</li>
<li>
<p>Networking con profesionales</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>CNCF Events</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>KubeCon (conferencia principal)</p>
</li>
<li>
<p>CloudNativeCon (diferentes regiones)</p>
</li>
<li>
<p>Meetups locales</p>
</li>
<li>
<p>Webinars gratuitos</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_blogs_y_sitios_de_referencia">16.4.5. Blogs y Sitios de Referencia</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Kubernetes Blog Oficial</strong></dt>
<dd>
<p><a href="https://kubernetes.io/blog/" class="bare">https://kubernetes.io/blog/</a> - Noticias, tutoriales, releases</p>
</dd>
<dt class="hdlist1"><strong>Blogs de Expertos</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Kelsey Hightower</strong>: <a href="https://kelseyhightower.com/" class="bare">https://kelseyhightower.com/</a></p>
</li>
<li>
<p><strong>Jérôme Petazzoni</strong>: <a href="https://jpetazzo.github.io/" class="bare">https://jpetazzo.github.io/</a></p>
</li>
<li>
<p><strong>Jessie Frazelle</strong>: Blog sobre containers y K8s</p>
</li>
<li>
<p><strong>Cilium Blog</strong>: Networking y security</p>
</li>
<li>
<p><strong>CoreOS Blog</strong>: Container best practices</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Sitios de Referencia</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>DevOps.com</strong>: Articulos sobre DevOps y Kubernetes</p>
</li>
<li>
<p><strong>InfoQ</strong>: Entrevistas y reportes sobre tecnología</p>
</li>
<li>
<p><strong>DZone</strong>: Tutoriales y guías técnicas</p>
</li>
<li>
<p><strong>Linuxize</strong>: Guías paso a paso</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>YouTube Channels</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Kubernetes</strong>: Canal oficial</p>
</li>
<li>
<p><strong>Linux Academy</strong>: Tutoriales completos</p>
</li>
<li>
<p><strong>TechWorld with Nana</strong>: Tutoriales prácticos</p>
</li>
<li>
<p><strong>Mumshad Mannambeth</strong>: KodeKloud tutoriales</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_herramientas_útiles">16.4.6. Herramientas Útiles</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>CLI Tools</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>kubectl</code>: CLI oficial</p>
</li>
<li>
<p><code>kustomize</code>: Customización de manifiestos</p>
</li>
<li>
<p><code>helm</code>: Package manager</p>
</li>
<li>
<p><code>kubectx</code>: Cambiar contextos rápidamente</p>
</li>
<li>
<p><code>kubens</code>: Cambiar namespaces rápidamente</p>
</li>
<li>
<p><code>kubectl-neat</code>: Limpiar metadata innecesaria</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Debugging</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>kubectl-debug</code>: Debugging avanzado</p>
</li>
<li>
<p><code>k9s</code>: Terminal UI para Kubernetes</p>
</li>
<li>
<p><code>stern</code>: Multiline log aggregator</p>
</li>
<li>
<p><code>kubetail</code>: Tail logs de múltiples pods</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Security</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>kubesec</code>: Análisis de seguridad de manifiestos</p>
</li>
<li>
<p><code>polaris</code>: Auditoría de buenas prácticas</p>
</li>
<li>
<p><code>falco</code>: Runtime security monitoring</p>
</li>
<li>
<p><code>kubewarden</code>: Policy engine</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>Monitoring &amp; Observability</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>prometheus</code>: Monitoring (CNCF graduated)</p>
</li>
<li>
<p><code>grafana</code>: Visualization</p>
</li>
<li>
<p><code>loki</code>: Log aggregation</p>
</li>
<li>
<p><code>jaeger</code>: Distributed tracing</p>
</li>
<li>
<p><code>datadog</code>: Observability platform</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><strong>CI/CD Integration</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>GitLab CI</code>: Pipeline nativo</p>
</li>
<li>
<p><code>GitHub Actions</code>: Automatización en GitHub</p>
</li>
<li>
<p><code>ArgoCD</code>: GitOps deployment</p>
</li>
<li>
<p><code>FluxCD</code>: Declarative GitOps</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_guías_rápidas_cheat_sheets">16.4.7. Guías Rápidas (Cheat Sheets)</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>kubectl Cheat Sheet</strong></dt>
<dd>
<p><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/" class="bare">https://kubernetes.io/docs/reference/kubectl/cheatsheet/</a></p>
</dd>
<dt class="hdlist1"><strong>YAML Cheat Sheet</strong></dt>
<dd>
<p>Disponible en múltiples sitios: yamllint.com, yaml-validator.com</p>
</dd>
<dt class="hdlist1"><strong>Kubernetes Architecture Cheat Sheet</strong></dt>
<dd>
<p>Diagramas de arquitectura y componentes</p>
</dd>
<dt class="hdlist1"><strong>Common Commands Quick Reference</strong></dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre># Crear recursos
kubectl create -f manifest.yaml
kubectl apply -f manifest.yaml

# Ver recursos
kubectl get pods
kubectl describe pod &lt;name&gt;

# Debugging
kubectl logs &lt;pod&gt;
kubectl exec -it &lt;pod&gt; -- /bin/bash

# Actualizar
kubectl set image deployment/&lt;name&gt; &lt;container&gt;=&lt;image&gt;
kubectl rollout status deployment/&lt;name&gt;

# Eliminar
kubectl delete pod &lt;name&gt;
kubectl delete -f manifest.yaml</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_certificaciones_kubernetes">16.4.8. Certificaciones Kubernetes</h4>
<div class="paragraph">
<p><strong>Ver sección "E. Certificaciones Kubernetes"</strong></p>
</div>
</div>
<div class="sect3">
<h4 id="_canales_de_noticias">16.4.9. Canales de Noticias</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Docker Official Blog</strong></dt>
<dd>
<p><a href="https://www.docker.com/blog/" class="bare">https://www.docker.com/blog/</a> - Noticias relacionadas con containers</p>
</dd>
<dt class="hdlist1"><strong>Hacker News</strong></dt>
<dd>
<p><a href="https://news.ycombinator.com/" class="bare">https://news.ycombinator.com/</a> - Comunidad tech</p>
</dd>
<dt class="hdlist1"><strong>Product Hunt</strong></dt>
<dd>
<p><a href="https://www.producthunt.com/" class="bare">https://www.producthunt.com/</a> - Nuevas herramientas y proyectos</p>
</dd>
<dt class="hdlist1"><strong>Twitter/X</strong></dt>
<dd>
<p>Seguir hashtags: #kubernetes #k8s #devops #cloudnative</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_e_certificaciones_kubernetes">16.5. E. Certificaciones Kubernetes</h3>
<div class="paragraph">
<p>Las certificaciones Kubernetes de la Linux Foundation son reconocidas internacionalmente y validan expertise en la plataforma.</p>
</div>
<div class="sect3">
<h4 id="_cka_certified_kubernetes_administrator">16.5.1. CKA (Certified Kubernetes Administrator)</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Resumen</strong></dt>
<dd>
<p>Certificación para administradores de Kubernetes que valida la capacidad de diseñar, instalar, configurar y administrar clusters Kubernetes en producción.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p><strong>Tópicos cubiertos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cluster Architecture (30%)</p>
<div class="ulist">
<ul>
<li>
<p>Cluster management</p>
</li>
<li>
<p>High availability</p>
</li>
<li>
<p>Control plane components</p>
</li>
<li>
<p>Etcd</p>
</li>
</ul>
</div>
</li>
<li>
<p>Installation, Configuration &amp; Validation (25%)</p>
<div class="ulist">
<ul>
<li>
<p>Descargar, instalar y configurar componentes</p>
</li>
<li>
<p>Provisionamiento seguro</p>
</li>
</ul>
</div>
</li>
<li>
<p>Workloads &amp; Scheduling (15%)</p>
<div class="ulist">
<ul>
<li>
<p>Deployments, DaemonSets, StatefulSets</p>
</li>
<li>
<p>Resource limits</p>
</li>
<li>
<p>Scheduling</p>
</li>
</ul>
</div>
</li>
<li>
<p>Services &amp; Networking (20%)</p>
<div class="ulist">
<ul>
<li>
<p>Service types</p>
</li>
<li>
<p>Ingress</p>
</li>
<li>
<p>Network policies</p>
</li>
</ul>
</div>
</li>
<li>
<p>Storage (10%)</p>
<div class="ulist">
<ul>
<li>
<p>PV, PVC</p>
</li>
<li>
<p>Storage classes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Requisitos de examen:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Detalle</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 horas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preguntas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15-20 (prácticas)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Examen práctico en CLI</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Passing Score</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">66%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Costo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$395 USD</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Validez</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 años</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Herramientas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo línea de comandos (vim, cat, etc.)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Temas importantes a estudiar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Cluster Upgrade
kubectl drain &lt;node&gt;
kubeadm upgrade plan
kubeadm upgrade apply

# Backup &amp; Restore
kubectl get all --all-namespaces -o yaml &gt; backup.yaml
ETCDCTL_API=3 etcdctl snapshot save snapshot.db
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db

# Troubleshooting
kubectl logs &lt;pod&gt;
kubectl describe node &lt;node&gt;
kubectl get events

# RBAC
kubectl create role &lt;role-name&gt; --verb=create --resource=pods
kubectl create rolebinding &lt;binding&gt; --role=&lt;role&gt; --user=&lt;user&gt;

# Network Policy
kubectl apply -f network-policy.yaml

# Resource Limits
kubectl set resources deployment &lt;name&gt; --limits=cpu=1,memory=512Mi</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Tiempo de preparación recomendado</strong></dt>
<dd>
<p>2-3 meses con 1-2 horas diarias</p>
</dd>
<dt class="hdlist1"><strong>Recursos recomendados</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Udemy: CKA course por Mumshad</p>
</li>
<li>
<p>KodeKloud: Laboratorios CKA</p>
</li>
<li>
<p>Linux Academy: Comprehensive CKA course</p>
</li>
<li>
<p>Documentación oficial de Kubernetes</p>
</li>
<li>
<p>Practice exams: killer.sh (incluido con el examen)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_ckad_certified_kubernetes_application_developer">16.5.2. CKAD (Certified Kubernetes Application Developer)</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Resumen</strong></dt>
<dd>
<p>Certificación para desarrolladores que valida la capacidad de construir, configurar e implementar aplicaciones en Kubernetes.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p><strong>Tópicos cubiertos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Core Concepts (13%)</p>
<div class="ulist">
<ul>
<li>
<p>Pods, ReplicaSets, Deployments</p>
</li>
<li>
<p>Namespaces</p>
</li>
</ul>
</div>
</li>
<li>
<p>Configuration (18%)</p>
<div class="ulist">
<ul>
<li>
<p>ConfigMaps</p>
</li>
<li>
<p>Secrets</p>
</li>
<li>
<p>Security Contexts</p>
</li>
<li>
<p>Service Accounts</p>
</li>
</ul>
</div>
</li>
<li>
<p>Multi-Container Pods (10%)</p>
<div class="ulist">
<ul>
<li>
<p>Pod design patterns</p>
</li>
<li>
<p>Init containers</p>
</li>
<li>
<p>Sidecar containers</p>
</li>
</ul>
</div>
</li>
<li>
<p>Observability (18%)</p>
<div class="ulist">
<ul>
<li>
<p>Logs</p>
</li>
<li>
<p>Monitoring</p>
</li>
<li>
<p>Debugging</p>
</li>
</ul>
</div>
</li>
<li>
<p>Pod Design (20%)</p>
<div class="ulist">
<ul>
<li>
<p>Labels and Selectors</p>
</li>
<li>
<p>Deployments and Rollouts</p>
</li>
<li>
<p>Jobs and CronJobs</p>
</li>
</ul>
</div>
</li>
<li>
<p>Services &amp; Networking (13%)</p>
<div class="ulist">
<ul>
<li>
<p>Services</p>
</li>
<li>
<p>Ingress</p>
</li>
<li>
<p>Network policies</p>
</li>
</ul>
</div>
</li>
<li>
<p>State Persistence (8%)</p>
<div class="ulist">
<ul>
<li>
<p>Volumes</p>
</li>
<li>
<p>PV y PVC</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Requisitos de examen:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Detalle</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2 horas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preguntas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15-20 (prácticas)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Examen práctico en CLI</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Passing Score</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">66%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Costo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$395 USD</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Validez</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 años</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Herramientas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solo kubectl y vim</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Temas importantes a estudiar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Crear manifiestos
kubectl create deployment &lt;name&gt; --image=&lt;image&gt; --dry-run=client -o yaml

# Configuración
kubectl create configmap &lt;name&gt; --from-literal=key=value
kubectl create secret generic &lt;name&gt; --from-literal=key=value

# Health checks
kubectl set probe deployment &lt;name&gt; --liveness --initial-delay=30

# Pod design patterns
# - Init containers
# - Sidecar containers
# - Ambassador pattern

# Jobs and CronJobs
kubectl create job &lt;name&gt; --image=&lt;image&gt;
kubectl create cronjob &lt;name&gt; --schedule="*/5 * * * *" --image=&lt;image&gt;

# Rolling updates
kubectl set image deployment/&lt;name&gt; &lt;container&gt;=&lt;image&gt; --record
kubectl rollout undo deployment/&lt;name&gt; --to-revision=1

# Scaling
kubectl scale deployment &lt;name&gt; --replicas=5</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Tiempo de preparación recomendado</strong></dt>
<dd>
<p>4-6 semanas con 1-2 horas diarias</p>
</dd>
<dt class="hdlist1"><strong>Recursos recomendados</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>KodeKloud: CKAD course</p>
</li>
<li>
<p>Udemy: CKAD course</p>
</li>
<li>
<p>Practice labs: kodekloud.com, katacoda.com</p>
</li>
<li>
<p>Killer.sh practice exams</p>
</li>
<li>
<p>Documentación oficial</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_cks_certified_kubernetes_security_specialist">16.5.3. CKS (Certified Kubernetes Security Specialist)</h4>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Resumen</strong></dt>
<dd>
<p>Certificación avanzada para especialistas en seguridad Kubernetes que valida la capacidad de asegurar clusters y aplicaciones Kubernetes.</p>
</dd>
<dt class="hdlist1"><strong>Requisito Previo</strong></dt>
<dd>
<p>Tener CKA válida (no necesariamente completada, pero requerida para el examen)</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p><strong>Tópicos cubiertos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cluster Setup (10%)</p>
<div class="ulist">
<ul>
<li>
<p>Secure network policies</p>
</li>
<li>
<p>Ingress with TLS</p>
</li>
<li>
<p>RBAC</p>
</li>
<li>
<p>Etcd encryption</p>
</li>
</ul>
</div>
</li>
<li>
<p>Cluster Hardening (15%)</p>
<div class="ulist">
<ul>
<li>
<p>RBAC</p>
</li>
<li>
<p>Service accounts</p>
</li>
<li>
<p>Admission controllers</p>
</li>
<li>
<p>API server access controls</p>
</li>
</ul>
</div>
</li>
<li>
<p>System Hardening (15%)</p>
<div class="ulist">
<ul>
<li>
<p>Minimize host OS footprint</p>
</li>
<li>
<p>Minimize IAM roles</p>
</li>
<li>
<p>Minimize external access</p>
</li>
<li>
<p>Kernel hardening</p>
</li>
</ul>
</div>
</li>
<li>
<p>Minimize Microservice Vulnerabilities (20%)</p>
<div class="ulist">
<ul>
<li>
<p>Security contexts</p>
</li>
<li>
<p>Pod security policies</p>
</li>
<li>
<p>Network policies</p>
</li>
<li>
<p>Image scanning</p>
</li>
<li>
<p>Secrets management</p>
</li>
</ul>
</div>
</li>
<li>
<p>Supply Chain Security (20%)</p>
<div class="ulist">
<ul>
<li>
<p>Image scanning</p>
</li>
<li>
<p>Image signing</p>
</li>
<li>
<p>Secure supply chain</p>
</li>
<li>
<p>Container registries</p>
</li>
</ul>
</div>
</li>
<li>
<p>Monitoring, Logging &amp; Runtime Security (20%)</p>
<div class="ulist">
<ul>
<li>
<p>Audit logging</p>
</li>
<li>
<p>Falco</p>
</li>
<li>
<p>Runtime security</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Requisitos de examen:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Detalle</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2 horas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preguntas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15-20 (prácticas)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Examen práctico en CLI</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Passing Score</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">66%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Costo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">$395 USD</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Validez</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 años</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prerequisito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CKA requerida</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Temas importantes a estudiar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># RBAC
kubectl create role developer --verb=create,list,get --resource=pods
kubectl create rolebinding dev-binding --role=developer --user=user@example.com

# Network Policies
# Deny all, then allow specific

# Pod Security Policies
kubectl apply -f restricted-psp.yaml

# Security Contexts
securityContext:
  runAsUser: 1000
  runAsNonRoot: true
  readOnlyRootFilesystem: true

# Admission controllers
- PodSecurityPolicy
- ResourceQuota
- LimitRanger

# ETCD encryption
--encryption-provider-config=/etc/kubernetes/encryption.yaml

# Audit logging
--audit-log-path=/var/log/audit.log
--audit-policy-file=/etc/kubernetes/audit-policy.yaml

# Falco runtime security
helm install falco falcosecurity/falco

# Image scanning
trivy image myimage:latest
aqua trivy scan</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><strong>Tiempo de preparación recomendado</strong></dt>
<dd>
<p>3-4 meses (después de CKA)</p>
</dd>
<dt class="hdlist1"><strong>Recursos recomendados</strong></dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>KodeKloud: CKS course</p>
</li>
<li>
<p>Udemy: CKS course</p>
</li>
<li>
<p>Killer.sh practice exams</p>
</li>
<li>
<p>Linux Foundation: LFS260 (oficial)</p>
</li>
<li>
<p>Falco documentation</p>
</li>
<li>
<p>OWASP security guidelines</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_estrategia_de_preparación">16.5.4. Estrategia de Preparación</h4>
<div class="paragraph">
<p><strong>Orden recomendado de certificaciones:</strong>
1. Comenzar con CKAD (más accesible)
2. Luego CKA (más administrativo)
3. Finalmente CKS (más avanzado, requiere CKA)</p>
</div>
<div class="paragraph">
<p><strong>Plan de estudio genérico (2-3 meses):</strong></p>
</div>
<div class="paragraph">
<p><strong>Semana 1-2: Conceptos Fundamentales</strong>
- Entender arquitectura de Kubernetes
- Estudiar componentes principales
- Practicar comandos básicos de kubectl</p>
</div>
<div class="paragraph">
<p><strong>Semana 3-4: Recursos Principales</strong>
- Pods, Deployments, StatefulSets
- Services, Ingress
- ConfigMaps, Secrets</p>
</div>
<div class="paragraph">
<p><strong>Semana 5-6: Tópicos Avanzados</strong>
- Storage, Networking
- RBAC, Security
- Monitoring, Logging</p>
</div>
<div class="paragraph">
<p><strong>Semana 7-8: Práctica Intensiva</strong>
- Resolver labs
- Tomar exámenes de práctica
- Enfocarse en áreas débiles</p>
</div>
<div class="paragraph">
<p><strong>Semana 9-10: Preparación Final</strong>
- Exámenes de simulación
- Revisar commands rápidos
- Descansar antes del examen</p>
</div>
<div class="paragraph">
<p><strong>Tips para el examen:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Leer la pregunta cuidadosamente</p>
</li>
<li>
<p>Usar <code>--dry-run=client -o yaml</code> para generar manifiestos</p>
</li>
<li>
<p>Practicar con vim/nano antes del examen</p>
</li>
<li>
<p>Usar bash aliases para comandos comunes</p>
</li>
<li>
<p>No olvidar cambiar de contexto/namespace si es necesario</p>
</li>
<li>
<p>Guardar tiempo para preguntas difíciles</p>
</li>
<li>
<p>Verificar nombres de recursos y labels</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Recursos para práctica:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Recurso</th>
<th class="tableblock halign-left valign-top">URL/Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">killer.sh</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simulador oficial incluido con examen</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">KodeKloud</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kodekloud.com" class="bare">https://kodekloud.com</a> (labs interactivos)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Katacoda</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escenarios de Kubernetes (ahora parte de O&#8217;Reilly)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Play with Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://labs.play-with-k8s.com" class="bare">https://labs.play-with-k8s.com</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linux Academy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Práctica y cursos completos</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Udemy Practice Tests</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Exámenes de simulación</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GitHub Repos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Colecciones de práctica</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_después_de_la_certificación">16.5.5. Después de la Certificación</h4>
<div class="paragraph">
<p><strong>Mantener la certificación actualizada:</strong>
- Las certificaciones son válidas por 3 años
- Renovar tomando el examen nuevamente
- Contribuir a proyectos open source
- Mantener skills con nuevas versiones</p>
</div>
<div class="paragraph">
<p><strong>Siguiente paso:</strong>
- Aplicar conocimientos en proyectos reales
- Contribuir a comunidad Kubernetes
- Especialización en tópicos específicos
- Perseguir certificaciones complementarias (Docker, cloud platforms)</p>
</div>
<div class="paragraph">
<p><strong>Recursos para continuar aprendiendo:</strong>
- Leer código fuente de Kubernetes
- Contribuir a proyectos CNCF
- Asistir a conferencias (KubeCon)
- Escribir blogs sobre experiencias
- Mentorar a otros estudiantes</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-11-24 07:56:09 +0100
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>